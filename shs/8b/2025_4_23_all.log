nohup: ignoring input
2025-04-24 10:43:24.278799: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 10:43:24.531020: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 10:43:24.539007: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 10:43:24.539047: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 10:43:25.132951: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 10:43:25.394519: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 10:43:25.402715: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 10:43:25.402759: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 10:43:31.311175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 10:43:31.311808: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 10:43:31.314358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-24 10:43:32.204709: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 10:43:32.205437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 10:43:32.205458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:17,  5.88s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:07<00:22,  7.64s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:14<00:14,  7.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.67s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:21<00:07,  7.27s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:20<00:07,  7.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:23<00:00,  4.95s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:23<00:00,  5.82s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  4.80s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.48s/it]
model.embed_tokens.weight torch.Size([128256, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([128256, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]model.embed_tokens.weight torch.Size([128256, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([128256, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:01<07:55,  1.87s/it]  0%|          | 1/256 [00:01<07:44,  1.82s/it]  1%|          | 2/256 [00:02<03:59,  1.06it/s]  1%|          | 2/256 [00:02<03:53,  1.09it/s]  1%|          | 3/256 [00:02<03:37,  1.16it/s]  1%|          | 3/256 [00:03<04:02,  1.05it/s]  2%|▏         | 4/256 [00:03<02:42,  1.55it/s]  2%|▏         | 5/256 [00:03<02:03,  2.03it/s]  2%|▏         | 4/256 [00:03<03:10,  1.32it/s]  2%|▏         | 5/256 [00:03<02:32,  1.65it/s]  2%|▏         | 6/256 [00:05<03:47,  1.10it/s]  3%|▎         | 7/256 [00:05<03:01,  1.37it/s]  2%|▏         | 6/256 [00:05<04:08,  1.01it/s]  3%|▎         | 8/256 [00:05<02:11,  1.89it/s]  3%|▎         | 7/256 [00:06<03:15,  1.27it/s]  3%|▎         | 8/256 [00:06<02:20,  1.76it/s]  4%|▎         | 9/256 [00:06<02:40,  1.54it/s]  4%|▎         | 9/256 [00:06<02:29,  1.66it/s]  4%|▍         | 10/256 [00:07<02:24,  1.71it/s]  4%|▍         | 10/256 [00:07<02:49,  1.45it/s]  4%|▍         | 11/256 [00:07<02:12,  1.85it/s]  4%|▍         | 11/256 [00:07<02:30,  1.63it/s]  5%|▍         | 12/256 [00:08<02:27,  1.66it/s]  5%|▍         | 12/256 [00:08<02:39,  1.53it/s]  5%|▌         | 13/256 [00:09<02:43,  1.49it/s]  5%|▌         | 13/256 [00:09<02:50,  1.43it/s]  5%|▌         | 14/256 [00:09<02:31,  1.60it/s]  5%|▌         | 14/256 [00:09<02:34,  1.56it/s]  6%|▌         | 15/256 [00:10<02:17,  1.76it/s]  6%|▌         | 15/256 [00:10<02:18,  1.74it/s]  6%|▋         | 16/256 [00:11<02:41,  1.49it/s]  6%|▋         | 16/256 [00:11<02:40,  1.50it/s]  7%|▋         | 17/256 [00:11<02:13,  1.79it/s]  7%|▋         | 17/256 [00:11<02:13,  1.80it/s]  7%|▋         | 18/256 [00:12<02:46,  1.43it/s]  7%|▋         | 18/256 [00:12<02:46,  1.43it/s]  7%|▋         | 19/256 [00:13<03:18,  1.19it/s]  7%|▋         | 19/256 [00:13<03:19,  1.19it/s]  8%|▊         | 20/256 [00:13<02:30,  1.57it/s]  8%|▊         | 20/256 [00:13<02:31,  1.56it/s]  9%|▊         | 22/256 [00:14<01:44,  2.23it/s]  9%|▊         | 22/256 [00:14<01:46,  2.19it/s]  9%|▉         | 23/256 [00:15<02:40,  1.45it/s]  9%|▉         | 23/256 [00:15<02:43,  1.42it/s]  9%|▉         | 24/256 [00:15<02:04,  1.86it/s]  9%|▉         | 24/256 [00:15<02:06,  1.83it/s] 10%|▉         | 25/256 [00:16<02:04,  1.85it/s] 10%|▉         | 25/256 [00:16<02:07,  1.82it/s] 10%|█         | 26/256 [00:16<01:45,  2.19it/s] 10%|█         | 26/256 [00:16<01:47,  2.14it/s] 11%|█         | 27/256 [00:16<01:23,  2.73it/s] 11%|█         | 27/256 [00:16<01:25,  2.67it/s] 11%|█         | 28/256 [00:17<01:58,  1.93it/s] 11%|█         | 28/256 [00:17<02:00,  1.89it/s] 12%|█▏        | 30/256 [00:19<02:45,  1.36it/s] 12%|█▏        | 30/256 [00:19<02:48,  1.34it/s] 12%|█▏        | 31/256 [00:19<02:22,  1.58it/s] 12%|█▏        | 31/256 [00:20<02:25,  1.55it/s] 12%|█▎        | 32/256 [00:20<02:08,  1.75it/s] 12%|█▎        | 32/256 [00:20<02:09,  1.73it/s] 13%|█▎        | 34/256 [00:21<02:27,  1.50it/s] 13%|█▎        | 34/256 [00:22<02:28,  1.50it/s] 14%|█▎        | 35/256 [00:22<02:29,  1.48it/s] 14%|█▎        | 35/256 [00:22<02:30,  1.47it/s] 14%|█▍        | 36/256 [00:22<02:13,  1.65it/s] 14%|█▍        | 36/256 [00:23<02:15,  1.62it/s] 14%|█▍        | 37/256 [00:23<02:08,  1.70it/s] 14%|█▍        | 37/256 [00:23<02:09,  1.69it/s] 15%|█▍        | 38/256 [00:24<02:49,  1.28it/s] 15%|█▌        | 39/256 [00:24<02:09,  1.68it/s] 15%|█▍        | 38/256 [00:25<02:50,  1.28it/s] 15%|█▌        | 39/256 [00:25<02:09,  1.67it/s] 16%|█▌        | 40/256 [00:25<02:33,  1.40it/s] 16%|█▌        | 40/256 [00:26<02:36,  1.38it/s] 16%|█▌        | 41/256 [00:28<03:59,  1.11s/it] 16%|█▌        | 41/256 [00:28<04:03,  1.13s/it] 16%|█▋        | 42/256 [00:28<03:39,  1.02s/it] 16%|█▋        | 42/256 [00:29<03:42,  1.04s/it] 17%|█▋        | 43/256 [00:29<03:43,  1.05s/it] 17%|█▋        | 43/256 [00:30<03:48,  1.07s/it] 17%|█▋        | 44/256 [00:31<03:52,  1.10s/it] 17%|█▋        | 44/256 [00:31<03:56,  1.11s/it] 18%|█▊        | 45/256 [00:33<05:18,  1.51s/it] 18%|█▊        | 45/256 [00:33<05:16,  1.50s/it] 18%|█▊        | 47/256 [00:36<05:01,  1.44s/it] 18%|█▊        | 47/256 [00:36<04:57,  1.42s/it] 19%|█▉        | 48/256 [00:36<04:08,  1.20s/it] 19%|█▉        | 48/256 [00:37<04:05,  1.18s/it] 19%|█▉        | 49/256 [00:37<03:36,  1.05s/it] 19%|█▉        | 49/256 [00:37<03:33,  1.03s/it] 20%|█▉        | 50/256 [00:39<04:14,  1.23s/it] 20%|█▉        | 51/256 [00:39<03:08,  1.09it/s] 20%|██        | 52/256 [00:39<02:21,  1.44it/s] 20%|█▉        | 50/256 [00:39<04:36,  1.34s/it] 20%|█▉        | 51/256 [00:39<03:24,  1.00it/s] 20%|██        | 52/256 [00:39<02:33,  1.33it/s] 21%|██        | 53/256 [00:41<03:44,  1.10s/it] 21%|██        | 53/256 [00:41<03:40,  1.09s/it] 21%|██        | 54/256 [00:41<02:48,  1.20it/s] 21%|██        | 54/256 [00:41<02:45,  1.22it/s] 21%|██▏       | 55/256 [00:42<02:52,  1.16it/s] 21%|██▏       | 55/256 [00:42<02:57,  1.14it/s] 22%|██▏       | 56/256 [00:44<03:44,  1.12s/it] 22%|██▏       | 56/256 [00:44<03:49,  1.15s/it] 22%|██▏       | 57/256 [00:46<04:19,  1.30s/it] 22%|██▏       | 57/256 [00:46<04:23,  1.32s/it] 23%|██▎       | 58/256 [00:46<03:14,  1.02it/s] 23%|██▎       | 58/256 [00:46<03:17,  1.00it/s] 23%|██▎       | 59/256 [00:49<05:25,  1.65s/it] 23%|██▎       | 59/256 [00:49<05:25,  1.65s/it] 23%|██▎       | 60/256 [00:50<04:11,  1.28s/it] 23%|██▎       | 60/256 [00:50<04:12,  1.29s/it] 24%|██▍       | 61/256 [00:50<03:25,  1.05s/it] 24%|██▍       | 61/256 [00:50<03:25,  1.05s/it] 24%|██▍       | 62/256 [00:51<03:04,  1.05it/s] 24%|██▍       | 62/256 [00:51<03:04,  1.05it/s] 25%|██▍       | 63/256 [00:52<02:47,  1.15it/s] 25%|██▍       | 63/256 [00:52<02:47,  1.15it/s] 25%|██▌       | 64/256 [00:52<02:11,  1.46it/s] 25%|██▌       | 64/256 [00:52<02:12,  1.45it/s] 25%|██▌       | 65/256 [00:52<02:04,  1.54it/s] 25%|██▌       | 65/256 [00:53<02:04,  1.54it/s] 26%|██▌       | 66/256 [00:54<02:53,  1.10it/s] 26%|██▌       | 66/256 [00:54<02:53,  1.10it/s] 26%|██▌       | 67/256 [00:54<02:17,  1.38it/s] 26%|██▌       | 67/256 [00:54<02:16,  1.38it/s] 27%|██▋       | 68/256 [00:55<02:36,  1.20it/s] 27%|██▋       | 68/256 [00:55<02:36,  1.20it/s] 27%|██▋       | 69/256 [00:55<01:57,  1.60it/s] 27%|██▋       | 69/256 [00:56<01:57,  1.59it/s] 27%|██▋       | 70/256 [00:59<04:55,  1.59s/it] 27%|██▋       | 70/256 [01:00<04:58,  1.60s/it] 28%|██▊       | 71/256 [01:00<03:55,  1.27s/it] 28%|██▊       | 71/256 [01:00<03:58,  1.29s/it] 28%|██▊       | 72/256 [01:01<04:13,  1.38s/it] 28%|██▊       | 72/256 [01:02<04:17,  1.40s/it] 29%|██▊       | 73/256 [01:02<03:18,  1.08s/it] 29%|██▊       | 73/256 [01:02<03:21,  1.10s/it] 29%|██▉       | 74/256 [01:02<02:31,  1.20it/s] 29%|██▉       | 74/256 [01:02<02:33,  1.19it/s] 29%|██▉       | 75/256 [01:03<02:23,  1.26it/s] 29%|██▉       | 75/256 [01:03<02:24,  1.25it/s] 30%|██▉       | 76/256 [01:03<02:15,  1.33it/s] 30%|██▉       | 76/256 [01:04<02:16,  1.32it/s] 30%|███       | 77/256 [01:05<02:51,  1.04it/s] 30%|███       | 77/256 [01:05<02:52,  1.04it/s] 31%|███▏      | 80/256 [01:05<01:32,  1.90it/s] 31%|███▏      | 80/256 [01:06<01:33,  1.89it/s] 32%|███▏      | 81/256 [01:06<01:19,  2.19it/s] 32%|███▏      | 81/256 [01:06<01:20,  2.17it/s] 32%|███▏      | 82/256 [01:06<01:25,  2.03it/s] 33%|███▎      | 84/256 [01:06<00:55,  3.12it/s] 32%|███▏      | 82/256 [01:07<01:26,  2.01it/s] 33%|███▎      | 84/256 [01:07<00:55,  3.09it/s] 33%|███▎      | 85/256 [01:07<01:00,  2.81it/s] 33%|███▎      | 85/256 [01:07<01:03,  2.71it/s] 34%|███▎      | 86/256 [01:07<00:55,  3.08it/s] 34%|███▎      | 86/256 [01:07<00:56,  3.03it/s] 34%|███▍      | 88/256 [01:08<00:49,  3.36it/s] 34%|███▍      | 88/256 [01:08<00:50,  3.33it/s] 35%|███▍      | 89/256 [01:09<01:48,  1.54it/s] 35%|███▍      | 89/256 [01:10<01:50,  1.51it/s] 35%|███▌      | 90/256 [01:11<02:09,  1.28it/s] 35%|███▌      | 90/256 [01:11<02:11,  1.26it/s] 36%|███▌      | 92/256 [01:11<01:39,  1.66it/s] 36%|███▌      | 92/256 [01:12<01:40,  1.64it/s] 36%|███▋      | 93/256 [01:12<01:56,  1.40it/s] 36%|███▋      | 93/256 [01:13<01:58,  1.38it/s] 37%|███▋      | 94/256 [01:13<02:00,  1.34it/s] 37%|███▋      | 94/256 [01:14<02:02,  1.32it/s] 37%|███▋      | 95/256 [01:15<02:24,  1.12it/s] 37%|███▋      | 95/256 [01:15<02:26,  1.10it/s] 38%|███▊      | 96/256 [01:15<02:11,  1.22it/s] 38%|███▊      | 96/256 [01:16<02:13,  1.20it/s] 38%|███▊      | 97/256 [01:17<02:35,  1.02it/s] 38%|███▊      | 97/256 [01:17<02:38,  1.00it/s] 38%|███▊      | 98/256 [01:18<02:30,  1.05it/s] 38%|███▊      | 98/256 [01:18<02:32,  1.03it/s] 39%|███▊      | 99/256 [01:18<02:09,  1.21it/s] 39%|███▊      | 99/256 [01:19<02:11,  1.20it/s] 39%|███▉      | 100/256 [01:19<02:19,  1.12it/s] 39%|███▉      | 100/256 [01:20<02:21,  1.10it/s] 39%|███▉      | 101/256 [01:20<02:09,  1.20it/s] 40%|███▉      | 102/256 [01:20<01:42,  1.51it/s] 39%|███▉      | 101/256 [01:20<02:10,  1.18it/s] 40%|███▉      | 102/256 [01:21<01:43,  1.48it/s] 40%|████      | 103/256 [01:21<01:38,  1.55it/s] 41%|████      | 104/256 [01:21<01:25,  1.78it/s] 40%|████      | 103/256 [01:21<01:39,  1.54it/s] 41%|████      | 104/256 [01:22<01:26,  1.75it/s] 41%|████▏     | 106/256 [01:22<01:22,  1.81it/s] 41%|████▏     | 106/256 [01:23<01:24,  1.78it/s] 42%|████▏     | 107/256 [01:25<02:53,  1.16s/it] 42%|████▏     | 108/256 [01:25<02:20,  1.06it/s] 42%|████▏     | 107/256 [01:26<02:56,  1.19s/it] 43%|████▎     | 109/256 [01:26<01:59,  1.23it/s] 42%|████▏     | 108/256 [01:26<02:22,  1.04it/s] 43%|████▎     | 109/256 [01:27<02:01,  1.21it/s] 43%|████▎     | 110/256 [01:27<01:56,  1.26it/s] 43%|████▎     | 110/256 [01:27<01:57,  1.24it/s] 43%|████▎     | 111/256 [01:27<01:50,  1.31it/s] 44%|████▍     | 112/256 [01:28<01:35,  1.50it/s] 43%|████▎     | 111/256 [01:28<01:53,  1.27it/s] 44%|████▍     | 113/256 [01:28<01:13,  1.94it/s] 44%|████▍     | 112/256 [01:28<01:38,  1.46it/s] 44%|████▍     | 113/256 [01:29<01:15,  1.89it/s] 45%|████▍     | 114/256 [01:30<02:35,  1.09s/it] 45%|████▍     | 115/256 [01:31<01:54,  1.23it/s] 45%|████▌     | 116/256 [01:31<01:27,  1.60it/s] 45%|████▍     | 114/256 [01:31<02:42,  1.15s/it] 45%|████▍     | 115/256 [01:31<02:03,  1.14it/s] 45%|████▌     | 116/256 [01:32<01:36,  1.45it/s] 46%|████▌     | 117/256 [01:32<01:41,  1.36it/s] 46%|████▌     | 118/256 [01:32<01:42,  1.34it/s] 46%|████▌     | 117/256 [01:33<01:56,  1.19it/s] 46%|████▌     | 118/256 [01:34<01:52,  1.22it/s] 46%|████▋     | 119/256 [01:34<02:11,  1.04it/s] 46%|████▋     | 119/256 [01:35<02:18,  1.01s/it] 47%|████▋     | 120/256 [01:35<02:33,  1.13s/it] 47%|████▋     | 120/256 [01:37<02:37,  1.16s/it] 47%|████▋     | 121/256 [01:38<03:18,  1.47s/it] 47%|████▋     | 121/256 [01:39<03:21,  1.49s/it] 48%|████▊     | 122/256 [01:39<03:01,  1.36s/it] 48%|████▊     | 123/256 [01:39<02:18,  1.04s/it] 48%|████▊     | 124/256 [01:39<01:41,  1.30it/s] 49%|████▉     | 125/256 [01:39<01:14,  1.75it/s] 49%|████▉     | 126/256 [01:40<00:58,  2.20it/s] 48%|████▊     | 122/256 [01:40<03:04,  1.38s/it] 50%|████▉     | 127/256 [01:40<00:56,  2.30it/s] 50%|█████     | 128/256 [01:40<00:43,  2.94it/s] 48%|████▊     | 123/256 [01:40<02:20,  1.06s/it] 48%|████▊     | 124/256 [01:40<01:42,  1.28it/s] 49%|████▉     | 125/256 [01:41<01:15,  1.73it/s] 49%|████▉     | 126/256 [01:41<01:00,  2.15it/s] 50%|████▉     | 127/256 [01:41<00:55,  2.30it/s] 50%|█████     | 128/256 [01:41<00:43,  2.94it/s] 50%|█████     | 129/256 [01:42<01:42,  1.24it/s] 51%|█████     | 131/256 [01:42<00:59,  2.10it/s] 52%|█████▏    | 132/256 [01:42<00:51,  2.41it/s] 52%|█████▏    | 133/256 [01:43<00:53,  2.28it/s] 50%|█████     | 129/256 [01:43<01:42,  1.24it/s] 51%|█████     | 131/256 [01:43<00:59,  2.09it/s] 52%|█████▏    | 132/256 [01:44<00:51,  2.40it/s] 52%|█████▏    | 133/256 [01:44<00:53,  2.29it/s] 52%|█████▏    | 134/256 [01:46<02:20,  1.15s/it] 53%|█████▎    | 135/256 [01:46<01:44,  1.16it/s] 54%|█████▎    | 137/256 [01:46<01:06,  1.78it/s] 52%|█████▏    | 134/256 [01:47<02:18,  1.14s/it] 53%|█████▎    | 135/256 [01:47<01:42,  1.18it/s] 54%|█████▍    | 138/256 [01:47<01:16,  1.54it/s] 54%|█████▎    | 137/256 [01:48<01:05,  1.80it/s] 54%|█████▍    | 138/256 [01:48<01:15,  1.57it/s] 55%|█████▍    | 140/256 [01:48<01:08,  1.69it/s] 55%|█████▌    | 141/256 [01:49<01:10,  1.64it/s] 55%|█████▍    | 140/256 [01:49<01:07,  1.73it/s] 55%|█████▌    | 142/256 [01:50<01:07,  1.68it/s] 55%|█████▌    | 141/256 [01:50<01:08,  1.67it/s] 55%|█████▌    | 142/256 [01:51<01:05,  1.73it/s] 56%|█████▌    | 143/256 [01:52<02:00,  1.07s/it] 56%|█████▋    | 144/256 [01:52<01:34,  1.19it/s] 56%|█████▌    | 143/256 [01:53<01:57,  1.04s/it] 56%|█████▋    | 144/256 [01:53<01:32,  1.22it/s] 57%|█████▋    | 145/256 [01:53<01:43,  1.07it/s] 57%|█████▋    | 146/256 [01:54<01:30,  1.22it/s] 57%|█████▋    | 145/256 [01:54<01:40,  1.11it/s] 57%|█████▋    | 147/256 [01:54<01:20,  1.36it/s] 57%|█████▋    | 146/256 [01:55<01:28,  1.25it/s] 58%|█████▊    | 148/256 [01:55<01:19,  1.35it/s] 57%|█████▋    | 147/256 [01:55<01:19,  1.38it/s] 58%|█████▊    | 148/256 [01:56<01:18,  1.37it/s] 58%|█████▊    | 149/256 [01:58<02:28,  1.39s/it] 59%|█████▊    | 150/256 [01:58<01:52,  1.06s/it] 58%|█████▊    | 149/256 [01:59<02:26,  1.37s/it] 59%|█████▊    | 150/256 [01:59<01:50,  1.04s/it] 59%|█████▉    | 151/256 [02:00<01:53,  1.08s/it] 59%|█████▉    | 151/256 [02:00<01:51,  1.06s/it] 59%|█████▉    | 152/256 [02:01<01:49,  1.06s/it] 60%|█████▉    | 153/256 [02:01<01:30,  1.13it/s] 59%|█████▉    | 152/256 [02:01<01:49,  1.05s/it] 60%|██████    | 154/256 [02:01<01:11,  1.43it/s] 61%|██████    | 155/256 [02:02<01:01,  1.64it/s] 60%|█████▉    | 153/256 [02:02<01:29,  1.15it/s] 60%|██████    | 154/256 [02:02<01:10,  1.44it/s] 61%|██████    | 155/256 [02:03<01:00,  1.67it/s] 61%|██████    | 156/256 [02:02<01:04,  1.56it/s] 62%|██████▏   | 158/256 [02:03<00:37,  2.59it/s] 62%|██████▏   | 159/256 [02:03<00:36,  2.68it/s] 61%|██████    | 156/256 [02:03<01:02,  1.60it/s] 62%|██████▏   | 158/256 [02:03<00:36,  2.65it/s] 62%|██████▎   | 160/256 [02:03<00:37,  2.55it/s] 62%|██████▏   | 159/256 [02:04<00:35,  2.73it/s] 63%|██████▎   | 161/256 [02:04<00:35,  2.66it/s] 63%|██████▎   | 162/256 [02:04<00:32,  2.86it/s] 62%|██████▎   | 160/256 [02:04<00:37,  2.57it/s] 64%|██████▎   | 163/256 [02:04<00:31,  2.99it/s] 63%|██████▎   | 161/256 [02:04<00:34,  2.77it/s] 63%|██████▎   | 162/256 [02:05<00:32,  2.93it/s] 64%|██████▎   | 163/256 [02:05<00:30,  3.05it/s] 64%|██████▍   | 164/256 [02:06<00:57,  1.61it/s] 64%|██████▍   | 164/256 [02:06<00:55,  1.65it/s] 64%|██████▍   | 165/256 [02:07<01:20,  1.13it/s] 64%|██████▍   | 165/256 [02:08<01:19,  1.14it/s] 65%|██████▍   | 166/256 [02:09<01:35,  1.07s/it] 65%|██████▍   | 166/256 [02:09<01:34,  1.05s/it] 65%|██████▌   | 167/256 [02:09<01:24,  1.06it/s] 66%|██████▌   | 168/256 [02:10<01:04,  1.37it/s] 65%|██████▌   | 167/256 [02:10<01:23,  1.07it/s] 66%|██████▌   | 169/256 [02:10<00:56,  1.54it/s] 66%|██████▌   | 168/256 [02:10<01:03,  1.39it/s] 66%|██████▌   | 169/256 [02:11<00:55,  1.58it/s] 66%|██████▋   | 170/256 [02:11<00:53,  1.60it/s] 67%|██████▋   | 171/256 [02:11<00:41,  2.07it/s] 66%|██████▋   | 170/256 [02:11<00:52,  1.64it/s] 67%|██████▋   | 171/256 [02:11<00:40,  2.12it/s] 68%|██████▊   | 173/256 [02:11<00:34,  2.41it/s] 68%|██████▊   | 173/256 [02:12<00:33,  2.44it/s] 68%|██████▊   | 174/256 [02:13<00:53,  1.53it/s] 68%|██████▊   | 175/256 [02:13<00:45,  1.78it/s] 68%|██████▊   | 174/256 [02:13<00:53,  1.54it/s] 68%|██████▊   | 175/256 [02:14<00:45,  1.79it/s] 69%|██████▉   | 176/256 [02:14<00:57,  1.38it/s] 69%|██████▉   | 176/256 [02:15<00:57,  1.40it/s] 69%|██████▉   | 177/256 [02:15<01:06,  1.19it/s] 69%|██████▉   | 177/256 [02:16<01:06,  1.18it/s] 70%|██████▉   | 178/256 [02:16<00:59,  1.31it/s] 70%|██████▉   | 179/256 [02:16<00:50,  1.53it/s] 70%|██████▉   | 178/256 [02:17<00:58,  1.33it/s] 70%|██████▉   | 179/256 [02:17<00:50,  1.52it/s] 70%|███████   | 180/256 [02:18<01:09,  1.09it/s] 70%|███████   | 180/256 [02:18<01:08,  1.10it/s] 71%|███████   | 181/256 [02:19<01:05,  1.14it/s] 71%|███████   | 181/256 [02:19<01:04,  1.15it/s] 71%|███████   | 182/256 [02:19<01:02,  1.19it/s] 71%|███████   | 182/256 [02:20<01:01,  1.20it/s] 71%|███████▏  | 183/256 [02:22<01:29,  1.23s/it] 71%|███████▏  | 183/256 [02:22<01:28,  1.21s/it] 72%|███████▏  | 184/256 [02:23<01:27,  1.21s/it] 72%|███████▏  | 184/256 [02:23<01:26,  1.20s/it] 72%|███████▏  | 185/256 [02:23<01:11,  1.01s/it] 72%|███████▏  | 185/256 [02:24<01:15,  1.07s/it] 73%|███████▎  | 186/256 [02:24<01:04,  1.08it/s] 73%|███████▎  | 187/256 [02:24<00:48,  1.43it/s] 73%|███████▎  | 186/256 [02:25<01:11,  1.02s/it] 73%|███████▎  | 187/256 [02:25<00:53,  1.30it/s] 73%|███████▎  | 188/256 [02:28<01:52,  1.65s/it] 74%|███████▍  | 189/256 [02:29<01:33,  1.40s/it] 73%|███████▎  | 188/256 [02:29<01:56,  1.71s/it] 74%|███████▍  | 190/256 [02:29<01:06,  1.01s/it] 74%|███████▍  | 189/256 [02:30<01:36,  1.44s/it] 74%|███████▍  | 190/256 [02:30<01:09,  1.05s/it] 75%|███████▍  | 191/256 [02:30<01:07,  1.04s/it] 75%|███████▌  | 192/256 [02:31<00:59,  1.08it/s] 75%|███████▍  | 191/256 [02:31<01:09,  1.07s/it] 75%|███████▌  | 193/256 [02:31<00:46,  1.36it/s] 75%|███████▌  | 192/256 [02:32<01:01,  1.05it/s] 76%|███████▌  | 194/256 [02:32<00:48,  1.29it/s] 75%|███████▌  | 193/256 [02:32<00:47,  1.32it/s] 76%|███████▌  | 195/256 [02:32<00:37,  1.61it/s] 76%|███████▌  | 194/256 [02:33<00:48,  1.28it/s] 76%|███████▌  | 195/256 [02:33<00:38,  1.60it/s] 77%|███████▋  | 196/256 [02:33<00:42,  1.40it/s] 77%|███████▋  | 196/256 [02:34<00:43,  1.38it/s] 77%|███████▋  | 197/256 [02:34<00:49,  1.20it/s] 77%|███████▋  | 198/256 [02:35<00:41,  1.40it/s] 78%|███████▊  | 200/256 [02:35<00:26,  2.09it/s] 77%|███████▋  | 197/256 [02:35<00:49,  1.20it/s] 79%|███████▊  | 201/256 [02:35<00:24,  2.27it/s] 77%|███████▋  | 198/256 [02:36<00:41,  1.40it/s] 78%|███████▊  | 200/256 [02:36<00:26,  2.11it/s] 79%|███████▉  | 202/256 [02:36<00:26,  2.04it/s] 79%|███████▊  | 201/256 [02:36<00:24,  2.29it/s] 79%|███████▉  | 203/256 [02:36<00:23,  2.26it/s] 80%|███████▉  | 204/256 [02:37<00:20,  2.51it/s] 80%|████████  | 205/256 [02:37<00:17,  2.93it/s] 79%|███████▉  | 202/256 [02:37<00:26,  2.03it/s] 79%|███████▉  | 203/256 [02:37<00:23,  2.26it/s] 80%|███████▉  | 204/256 [02:38<00:20,  2.49it/s] 80%|████████  | 205/256 [02:38<00:17,  2.90it/s] 80%|████████  | 206/256 [02:39<00:40,  1.24it/s] 80%|████████  | 206/256 [02:40<00:41,  1.21it/s] 81%|████████  | 207/256 [02:40<00:45,  1.08it/s] 81%|████████▏ | 208/256 [02:40<00:35,  1.36it/s] 81%|████████  | 207/256 [02:41<00:46,  1.06it/s] 82%|████████▏ | 209/256 [02:41<00:37,  1.26it/s] 81%|████████▏ | 208/256 [02:41<00:35,  1.34it/s] 82%|████████▏ | 209/256 [02:42<00:37,  1.25it/s] 82%|████████▏ | 210/256 [02:44<01:00,  1.32s/it] 82%|████████▏ | 211/256 [02:45<00:54,  1.22s/it] 82%|████████▏ | 210/256 [02:45<01:02,  1.35s/it] 83%|████████▎ | 212/256 [02:45<00:47,  1.08s/it] 82%|████████▏ | 211/256 [02:46<00:55,  1.24s/it] 83%|████████▎ | 212/256 [02:47<00:48,  1.09s/it] 84%|████████▎ | 214/256 [02:47<00:35,  1.17it/s] 84%|████████▍ | 215/256 [02:47<00:33,  1.21it/s] 84%|████████▍ | 216/256 [02:48<00:25,  1.55it/s] 84%|████████▎ | 214/256 [02:48<00:35,  1.17it/s] 84%|████████▍ | 215/256 [02:49<00:33,  1.21it/s] 85%|████████▍ | 217/256 [02:49<00:29,  1.34it/s] 84%|████████▍ | 216/256 [02:49<00:25,  1.55it/s] 85%|████████▍ | 217/256 [02:50<00:28,  1.35it/s] 85%|████████▌ | 218/256 [02:50<00:34,  1.09it/s] 85%|████████▌ | 218/256 [02:51<00:34,  1.11it/s] 86%|████████▌ | 219/256 [02:53<00:53,  1.44s/it] 86%|████████▌ | 220/256 [02:53<00:45,  1.27s/it] 86%|████████▌ | 219/256 [02:54<00:52,  1.43s/it] 86%|████████▋ | 221/256 [02:54<00:33,  1.03it/s] 86%|████████▌ | 220/256 [02:55<00:45,  1.26s/it] 86%|████████▋ | 221/256 [02:55<00:33,  1.03it/s] 87%|████████▋ | 222/256 [02:55<00:38,  1.12s/it] 87%|████████▋ | 223/256 [02:56<00:29,  1.12it/s] 88%|████████▊ | 224/256 [02:56<00:21,  1.48it/s] 87%|████████▋ | 222/256 [02:56<00:38,  1.13s/it] 88%|████████▊ | 225/256 [02:57<00:22,  1.36it/s] 87%|████████▋ | 223/256 [02:57<00:29,  1.11it/s] 88%|████████▊ | 224/256 [02:57<00:21,  1.47it/s] 89%|████████▊ | 227/256 [02:57<00:14,  2.01it/s] 89%|████████▉ | 228/256 [02:57<00:12,  2.24it/s] 88%|████████▊ | 225/256 [02:58<00:23,  1.34it/s] 89%|████████▊ | 227/256 [02:58<00:14,  1.98it/s] 89%|████████▉ | 228/256 [02:59<00:12,  2.23it/s] 89%|████████▉ | 229/256 [03:00<00:27,  1.01s/it] 90%|████████▉ | 230/256 [03:01<00:24,  1.08it/s] 89%|████████▉ | 229/256 [03:01<00:27,  1.02s/it] 90%|████████▉ | 230/256 [03:02<00:24,  1.06it/s] 90%|█████████ | 231/256 [03:02<00:28,  1.16s/it] 90%|█████████ | 231/256 [03:04<00:28,  1.14s/it] 91%|█████████ | 232/256 [03:04<00:33,  1.38s/it] 91%|█████████ | 232/256 [03:05<00:32,  1.36s/it] 91%|█████████▏| 234/256 [03:06<00:23,  1.08s/it] 91%|█████████▏| 234/256 [03:07<00:23,  1.07s/it] 92%|█████████▏| 235/256 [03:07<00:24,  1.19s/it] 92%|█████████▏| 236/256 [03:08<00:19,  1.03it/s] 92%|█████████▏| 235/256 [03:08<00:24,  1.18s/it] 92%|█████████▏| 236/256 [03:09<00:19,  1.05it/s] 93%|█████████▎| 237/256 [03:09<00:20,  1.07s/it] 93%|█████████▎| 238/256 [03:09<00:15,  1.13it/s] 93%|█████████▎| 237/256 [03:10<00:20,  1.07s/it] 93%|█████████▎| 238/256 [03:10<00:15,  1.13it/s] 93%|█████████▎| 239/256 [03:11<00:20,  1.19s/it] 94%|█████████▍| 240/256 [03:12<00:14,  1.10it/s] 93%|█████████▎| 239/256 [03:12<00:20,  1.18s/it] 94%|█████████▍| 240/256 [03:13<00:14,  1.11it/s] 94%|█████████▍| 241/256 [03:13<00:14,  1.06it/s] 95%|█████████▍| 242/256 [03:13<00:10,  1.33it/s] 94%|█████████▍| 241/256 [03:14<00:14,  1.06it/s] 95%|█████████▍| 243/256 [03:14<00:10,  1.27it/s] 95%|█████████▍| 242/256 [03:14<00:10,  1.34it/s] 95%|█████████▌| 244/256 [03:14<00:08,  1.47it/s] 96%|█████████▌| 245/256 [03:14<00:06,  1.75it/s] 95%|█████████▍| 243/256 [03:15<00:10,  1.27it/s] 96%|█████████▌| 246/256 [03:15<00:05,  1.82it/s] 95%|█████████▌| 244/256 [03:15<00:08,  1.49it/s] 96%|█████████▋| 247/256 [03:15<00:04,  2.01it/s] 96%|█████████▌| 245/256 [03:16<00:06,  1.77it/s] 97%|█████████▋| 248/256 [03:16<00:03,  2.09it/s] 96%|█████████▌| 246/256 [03:16<00:05,  1.81it/s] 96%|█████████▋| 247/256 [03:16<00:04,  2.00it/s] 97%|█████████▋| 248/256 [03:17<00:03,  2.09it/s] 97%|█████████▋| 249/256 [03:17<00:05,  1.38it/s] 98%|█████████▊| 250/256 [03:17<00:03,  1.80it/s] 98%|█████████▊| 251/256 [03:18<00:02,  1.91it/s] 97%|█████████▋| 249/256 [03:18<00:04,  1.40it/s] 98%|█████████▊| 250/256 [03:18<00:03,  1.83it/s] 98%|█████████▊| 252/256 [03:19<00:02,  1.58it/s] 98%|█████████▊| 251/256 [03:19<00:02,  1.93it/s] 98%|█████████▊| 252/256 [03:20<00:02,  1.60it/s] 99%|█████████▉| 253/256 [03:21<00:03,  1.20s/it] 99%|█████████▉| 253/256 [03:22<00:03,  1.17s/it] 99%|█████████▉| 254/256 [03:23<00:02,  1.27s/it] 99%|█████████▉| 254/256 [03:24<00:02,  1.25s/it]100%|█████████▉| 255/256 [03:24<00:01,  1.21s/it]100%|██████████| 256/256 [03:24<00:00,  1.01it/s]100%|██████████| 256/256 [03:24<00:00,  1.25it/s]
100%|█████████▉| 255/256 [03:25<00:01,  1.20s/it]100%|██████████| 256/256 [03:25<00:00,  1.01it/s]100%|██████████| 256/256 [03:25<00:00,  1.25it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
0 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.8218, device='cuda:0', dtype=torch.float16)
tensor(0.0283, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0312, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0322, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0308, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
0 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.5859, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(0.0410, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.0449, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.0459, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.0415, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
0 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0181, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0197, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0202, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0190, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
0 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0138, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0144, device='cuda:0', dtype=torch.float16) tensor(0.0006, device='cuda:0', dtype=torch.float16)
tensor(0.0152, device='cuda:0', dtype=torch.float16) tensor(0.0006, device='cuda:0', dtype=torch.float16)
tensor(0.0160, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0191, device='cuda:0')
old_score: tensor(0.0006, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0005, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.925878763198853
Validation after dual ascent:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0135, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0126, device='cuda:0', dtype=torch.float16) tensor(0.0006, device='cuda:0', dtype=torch.float16)
tensor(0.0137, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0144, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
0 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.2832, device='cuda:0', dtype=torch.float16) tensor(0.0136, device='cuda:0', dtype=torch.float16)
tensor(0.2559, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.2646, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.2402, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0113, device='cuda:0')
tensor(0.1145, device='cuda:0')
old_score: tensor(0.0147, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0127, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.324817419052124
Validation after dual ascent:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.2612, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.2705, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.2383, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
0 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.2852, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.2842, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.3291, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0104, device='cuda:0')
tensor(0.1047, device='cuda:0')
old_score: tensor(0.0134, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0116, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.327676296234131
Validation after dual ascent:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.3389, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.3359, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.3525, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.3975, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
0 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0202, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0206, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0213, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0218, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0532, device='cuda:0')
old_score: tensor(0.0013, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0012, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.51660919189453
Validation after dual ascent:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0203, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0225, device='cuda:0', dtype=torch.float16) tensor(0.0014, device='cuda:0', dtype=torch.float16)
tensor(0.0210, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0209, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
layer 0 done
1 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.4609, device='cuda:0', dtype=torch.float16) tensor(0.9868, device='cuda:0', dtype=torch.float16)
tensor(0.2227, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.2441, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.2129, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
1 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.0391, device='cuda:0', dtype=torch.float16) tensor(1.4785, device='cuda:0', dtype=torch.float16)
tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.2754, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.3711, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0172, device='cuda:0', dtype=torch.float16)
1 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8340, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.0660, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0771, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0671, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0598, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
Converged at iteration 50
tensor(0.0195, device='cuda:0')
tensor(0.1475, device='cuda:0')
old_score: tensor(0.0071, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0063, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.40205931663513184
Validation after dual ascent:
out_inf: tensor(2.8340, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.0654, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.0720, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0695, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0611, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
1 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7480, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.0325, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0240, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0316, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0273, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0203, device='cuda:0')
old_score: tensor(0.0010, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0009, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.942489624023438
Validation after dual ascent:
out_inf: tensor(1.7480, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.0228, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0166, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0256, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0230, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
1 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.0469, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0190, device='cuda:0')
tensor(0.0360, device='cuda:0')
old_score: tensor(0.0207, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0186, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.237902164459229
Validation after dual ascent:
out_inf: tensor(19.0469, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
1 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.1699, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.3887, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(0.3984, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.3672, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0151, device='cuda:0')
tensor(0.0261, device='cuda:0')
old_score: tensor(0.0189, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0169, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.204793214797974
Validation after dual ascent:
out_inf: tensor(3.1699, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.3262, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.3379, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0163, device='cuda:0', dtype=torch.float16)
1 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(275.5000, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0227, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0317, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0276, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.0268, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0663, device='cuda:0')
old_score: tensor(0.0019, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0018, device='cuda:0', dtype=torch.float16)
Not converged!
Dual ascent finished!
Time: 165.0793104171753
Validation after dual ascent:
out_inf: tensor(275.5000, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0227, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0317, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0276, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.0268, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
layer 1 done
2 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.1953, device='cuda:0', dtype=torch.float16) tensor(0.8467, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.4458, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
2 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.6250, device='cuda:0', dtype=torch.float16) tensor(1.3994, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0694, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(0.6909, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.5752, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
2 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.8262, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(0.1742, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.2231, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.2109, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.1704, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0175, device='cuda:0')
tensor(0.1819, device='cuda:0')
old_score: tensor(0.0211, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0193, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6143333911895752
Validation after dual ascent:
out_inf: tensor(1.8262, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(0.1672, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.2068, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
tensor(0.2124, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
2 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7944, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0201, device='cuda:0', dtype=torch.float16) tensor(0.0014, device='cuda:0', dtype=torch.float16)
tensor(0.0199, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0271, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0242, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0144, device='cuda:0')
old_score: tensor(0.0013, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0011, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.945994853973389
Validation after dual ascent:
out_inf: tensor(0.7944, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0194, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0190, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0232, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0222, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
2 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2637, device='cuda:0', dtype=torch.float16) tensor(0.1295, device='cuda:0', dtype=torch.float16)
tensor(0.2739, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.3506, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.2681, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0081, device='cuda:0')
tensor(0.0373, device='cuda:0')
old_score: tensor(0.0273, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0249, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.774658441543579
Validation after dual ascent:
out_inf: tensor(3.2637, device='cuda:0', dtype=torch.float16) tensor(0.1295, device='cuda:0', dtype=torch.float16)
tensor(0.2659, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.3545, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.3066, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.2710, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
2 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3789, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.2808, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.2900, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.2827, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(0.2646, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0066, device='cuda:0')
tensor(0.0329, device='cuda:0')
old_score: tensor(0.0241, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0220, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.758420467376709
Validation after dual ascent:
out_inf: tensor(2.3789, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.2856, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.2822, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
2 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.3564, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.0348, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0359, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0362, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0330, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0387, device='cuda:0')
old_score: tensor(0.0028, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0026, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.4541952610016
Validation after dual ascent:
out_inf: tensor(0.3564, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.0356, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0355, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0337, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0323, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
layer 2 done
3 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.1875, device='cuda:0', dtype=torch.float16) tensor(0.8096, device='cuda:0', dtype=torch.float16)
tensor(0.5776, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0680, device='cuda:0', dtype=torch.float16)
tensor(0.5483, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
3 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.0625, device='cuda:0', dtype=torch.float16) tensor(1.3125, device='cuda:0', dtype=torch.float16)
tensor(0.8159, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(0.8867, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(0.8813, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
3 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3789, device='cuda:0', dtype=torch.float16) tensor(0.1461, device='cuda:0', dtype=torch.float16)
tensor(0.2349, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.2812, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0164, device='cuda:0')
tensor(0.3543, device='cuda:0')
old_score: tensor(0.0313, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0288, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6222236156463623
Validation after dual ascent:
out_inf: tensor(2.3789, device='cuda:0', dtype=torch.float16) tensor(0.1461, device='cuda:0', dtype=torch.float16)
tensor(0.2362, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
tensor(0.2969, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.2683, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.2415, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
3 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.0289, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0280, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.0312, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0249, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0132, device='cuda:0')
tensor(0.0248, device='cuda:0')
old_score: tensor(0.0021, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0018, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.29637098312378
Validation after dual ascent:
out_inf: tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.0259, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0251, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0305, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0229, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
3 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.8516, device='cuda:0', dtype=torch.float16) tensor(0.1710, device='cuda:0', dtype=torch.float16)
tensor(0.3403, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.3628, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
tensor(0.3301, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.0784, device='cuda:0')
old_score: tensor(0.0354, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0325, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.783457040786743
Validation after dual ascent:
out_inf: tensor(3.8516, device='cuda:0', dtype=torch.float16) tensor(0.1710, device='cuda:0', dtype=torch.float16)
tensor(0.3545, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.3860, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.3745, device='cuda:0', dtype=torch.float16) tensor(0.0348, device='cuda:0', dtype=torch.float16)
tensor(0.3408, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
3 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2812, device='cuda:0', dtype=torch.float16) tensor(0.1065, device='cuda:0', dtype=torch.float16)
tensor(0.2607, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.3135, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.3467, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0116, device='cuda:0')
tensor(0.0634, device='cuda:0')
old_score: tensor(0.0291, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0267, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.755574703216553
Validation after dual ascent:
out_inf: tensor(4.2812, device='cuda:0', dtype=torch.float16) tensor(0.1065, device='cuda:0', dtype=torch.float16)
tensor(0.2610, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.3008, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.2979, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
3 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.4287, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.0429, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.0497, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0469, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0392, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0199, device='cuda:0')
tensor(0.0201, device='cuda:0')
old_score: tensor(0.0042, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0040, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 85.25906753540039
Validation after dual ascent:
out_inf: tensor(0.4287, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.0427, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0490, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.0447, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0394, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
layer 3 done
4 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.0703, device='cuda:0', dtype=torch.float16) tensor(0.8154, device='cuda:0', dtype=torch.float16)
tensor(0.4993, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.6782, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.5903, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
4 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.3125, device='cuda:0', dtype=torch.float16) tensor(1.3848, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.7432, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.7432, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0835, device='cuda:0', dtype=torch.float16)
4 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.8271, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(0.2327, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.2681, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.2362, device='cuda:0', dtype=torch.float16) tensor(0.0284, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0141, device='cuda:0')
tensor(0.2876, device='cuda:0')
old_score: tensor(0.0301, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0278, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6147470474243164
Validation after dual ascent:
out_inf: tensor(1.8271, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(0.2332, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.2446, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.2166, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
4 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.0371, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.0390, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0387, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.0341, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0195, device='cuda:0')
tensor(0.0298, device='cuda:0')
old_score: tensor(0.0029, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0026, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.025463581085205
Validation after dual ascent:
out_inf: tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.0352, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0353, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0335, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0311, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
4 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.0703, device='cuda:0', dtype=torch.float16) tensor(0.2323, device='cuda:0', dtype=torch.float16)
tensor(0.3596, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.5088, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.3633, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.1278, device='cuda:0')
old_score: tensor(0.0415, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0381, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.758650541305542
Validation after dual ascent:
out_inf: tensor(6.0703, device='cuda:0', dtype=torch.float16) tensor(0.2323, device='cuda:0', dtype=torch.float16)
tensor(0.3455, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.5088, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(0.3633, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
4 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.1816, device='cuda:0', dtype=torch.float16) tensor(0.1183, device='cuda:0', dtype=torch.float16)
tensor(0.2603, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
tensor(0.2822, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0097, device='cuda:0')
tensor(0.0949, device='cuda:0')
old_score: tensor(0.0318, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0293, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.76891827583313
Validation after dual ascent:
out_inf: tensor(3.1816, device='cuda:0', dtype=torch.float16) tensor(0.1183, device='cuda:0', dtype=torch.float16)
tensor(0.2576, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.3203, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.2686, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
4 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7847, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.0536, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.0614, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.0560, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0515, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0075, device='cuda:0')
tensor(0.0130, device='cuda:0')
old_score: tensor(0.0055, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 69.22354078292847
Validation after dual ascent:
out_inf: tensor(0.7847, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.0500, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
tensor(0.0559, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0548, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.0520, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
layer 4 done
5 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.9531, device='cuda:0', dtype=torch.float16) tensor(0.8027, device='cuda:0', dtype=torch.float16)
tensor(0.6050, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.6494, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(0.9136, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
tensor(0.6089, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
5 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.0625, device='cuda:0', dtype=torch.float16) tensor(1.4189, device='cuda:0', dtype=torch.float16)
tensor(0.8447, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
tensor(1.1816, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
5 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3457, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(0.2380, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
tensor(0.2277, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
tensor(0.2427, device='cuda:0', dtype=torch.float16) tensor(0.0312, device='cuda:0', dtype=torch.float16)
tensor(0.2068, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0148, device='cuda:0')
tensor(0.3301, device='cuda:0')
old_score: tensor(0.0294, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0273, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6172659397125244
Validation after dual ascent:
out_inf: tensor(2.3457, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(0.2407, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.2286, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.2344, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.2081, device='cuda:0', dtype=torch.float16) tensor(0.0254, device='cuda:0', dtype=torch.float16)
5 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.0343, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.0433, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0489, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.0459, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0182, device='cuda:0')
tensor(0.0226, device='cuda:0')
old_score: tensor(0.0035, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0030, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.612245082855225
Validation after dual ascent:
out_inf: tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.0338, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0436, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0410, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0394, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
5 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7930, device='cuda:0', dtype=torch.float16) tensor(0.2839, device='cuda:0', dtype=torch.float16)
tensor(0.3953, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.5659, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.3926, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0124, device='cuda:0')
tensor(0.0503, device='cuda:0')
old_score: tensor(0.0440, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0404, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.25108003616333
Validation after dual ascent:
out_inf: tensor(3.7930, device='cuda:0', dtype=torch.float16) tensor(0.2839, device='cuda:0', dtype=torch.float16)
tensor(0.3840, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.4214, device='cuda:0', dtype=torch.float16) tensor(0.0444, device='cuda:0', dtype=torch.float16)
tensor(0.5259, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.3726, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
5 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.4980, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
tensor(0.3398, device='cuda:0', dtype=torch.float16) tensor(0.0311, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.3145, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0076, device='cuda:0')
tensor(0.0329, device='cuda:0')
old_score: tensor(0.0337, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0310, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.219467401504517
Validation after dual ascent:
out_inf: tensor(3.4980, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
tensor(0.3027, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.3203, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
tensor(0.3340, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.3447, device='cuda:0', dtype=torch.float16) tensor(0.0284, device='cuda:0', dtype=torch.float16)
5 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.9927, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.0596, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.0639, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.0704, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.0606, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0121, device='cuda:0')
tensor(0.0144, device='cuda:0')
old_score: tensor(0.0062, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0058, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.97611665725708
Validation after dual ascent:
out_inf: tensor(0.9927, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.0576, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.0599, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.0663, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0625, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
layer 5 done
6 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.4375, device='cuda:0', dtype=torch.float16) tensor(0.7603, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.6729, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
tensor(0.6279, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
6 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.8750, device='cuda:0', dtype=torch.float16) tensor(1.4639, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(0.8511, device='cuda:0', dtype=torch.float16) tensor(0.1137, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
6 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(0.2345, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.2725, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.2343, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0163, device='cuda:0')
tensor(0.3595, device='cuda:0')
old_score: tensor(0.0323, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0298, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6144556999206543
Validation after dual ascent:
out_inf: tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(0.2316, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.2468, device='cuda:0', dtype=torch.float16) tensor(0.0319, device='cuda:0', dtype=torch.float16)
tensor(0.2505, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.2317, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
6 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7100, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(0.0560, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.0473, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.0491, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
tensor(0.0516, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0135, device='cuda:0')
tensor(0.0193, device='cuda:0')
old_score: tensor(0.0048, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0042, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.94618558883667
Validation after dual ascent:
out_inf: tensor(1.7100, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(0.0445, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.0465, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
tensor(0.0456, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0465, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
6 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.7656, device='cuda:0', dtype=torch.float16) tensor(0.3118, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.4014, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0132, device='cuda:0')
tensor(0.1570, device='cuda:0')
old_score: tensor(0.0446, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0408, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.8099141120910645
Validation after dual ascent:
out_inf: tensor(5.7656, device='cuda:0', dtype=torch.float16) tensor(0.3118, device='cuda:0', dtype=torch.float16)
tensor(0.3843, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.4424, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.3774, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
6 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5918, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(0.3242, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.3174, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.4414, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.3252, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0086, device='cuda:0')
tensor(0.1158, device='cuda:0')
old_score: tensor(0.0343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0315, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7642529010772705
Validation after dual ascent:
out_inf: tensor(3.5918, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(0.3032, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.2998, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.3428, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
6 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7979, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.0679, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.0689, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0656, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0693, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0148, device='cuda:0')
tensor(0.0268, device='cuda:0')
old_score: tensor(0.0067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0062, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.95690941810608
Validation after dual ascent:
out_inf: tensor(0.7979, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.0716, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.0658, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.0640, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0765, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
layer 6 done
7 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.5156, device='cuda:0', dtype=torch.float16) tensor(0.7461, device='cuda:0', dtype=torch.float16)
tensor(0.6045, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.7778, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
7 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.8281, device='cuda:0', dtype=torch.float16) tensor(1.4727, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(0.8418, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1196, device='cuda:0', dtype=torch.float16)
tensor(0.9473, device='cuda:0', dtype=torch.float16) tensor(0.1081, device='cuda:0', dtype=torch.float16)
7 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.1724, device='cuda:0', dtype=torch.float16)
tensor(0.2412, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
tensor(0.2566, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.2661, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
tensor(0.2301, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0167, device='cuda:0')
tensor(0.3740, device='cuda:0')
old_score: tensor(0.0331, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0304, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6174254417419434
Validation after dual ascent:
out_inf: tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.1724, device='cuda:0', dtype=torch.float16)
tensor(0.2317, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.2588, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
tensor(0.2274, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
7 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3340, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.0530, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.0528, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.0688, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.0556, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0117, device='cuda:0')
tensor(0.0225, device='cuda:0')
old_score: tensor(0.0054, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0047, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.662299871444702
Validation after dual ascent:
out_inf: tensor(2.3340, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.0468, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.0480, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.0517, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
tensor(0.0505, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
7 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3711, device='cuda:0', dtype=torch.float16) tensor(0.3201, device='cuda:0', dtype=torch.float16)
tensor(0.3955, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.3801, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0113, device='cuda:0')
tensor(0.1637, device='cuda:0')
old_score: tensor(0.0446, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0409, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.795391321182251
Validation after dual ascent:
out_inf: tensor(4.3711, device='cuda:0', dtype=torch.float16) tensor(0.3201, device='cuda:0', dtype=torch.float16)
tensor(0.3540, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
7 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6328, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.3350, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.3721, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0075, device='cuda:0')
tensor(0.1243, device='cuda:0')
old_score: tensor(0.0356, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0327, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.765157461166382
Validation after dual ascent:
out_inf: tensor(4.6328, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(0.2983, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.3447, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
tensor(0.3040, device='cuda:0', dtype=torch.float16) tensor(0.0357, device='cuda:0', dtype=torch.float16)
tensor(0.3828, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
7 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.0663, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0639, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.0702, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.0726, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0101, device='cuda:0')
tensor(0.0178, device='cuda:0')
old_score: tensor(0.0072, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0067, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.92915058135986
Validation after dual ascent:
out_inf: tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.0595, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.0616, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.0699, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0657, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
layer 7 done
8 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.1641, device='cuda:0', dtype=torch.float16) tensor(0.7344, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(0.6748, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
8 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.9688, device='cuda:0', dtype=torch.float16) tensor(1.5684, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.1117, device='cuda:0', dtype=torch.float16)
tensor(0.9512, device='cuda:0', dtype=torch.float16) tensor(0.1195, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
8 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.0605, device='cuda:0', dtype=torch.float16) tensor(0.1661, device='cuda:0', dtype=torch.float16)
tensor(0.2759, device='cuda:0', dtype=torch.float16) tensor(0.0347, device='cuda:0', dtype=torch.float16)
tensor(0.2583, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.2939, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.2998, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0184, device='cuda:0')
tensor(0.4356, device='cuda:0')
old_score: tensor(0.0363, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0337, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.615074634552002
Validation after dual ascent:
out_inf: tensor(2.0605, device='cuda:0', dtype=torch.float16) tensor(0.1661, device='cuda:0', dtype=torch.float16)
tensor(0.2588, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.2588, device='cuda:0', dtype=torch.float16) tensor(0.0347, device='cuda:0', dtype=torch.float16)
tensor(0.2646, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
8 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.8223, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
tensor(0.0540, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0538, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0621, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0549, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0183, device='cuda:0')
tensor(0.0120, device='cuda:0')
old_score: tensor(0.0060, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4621455669403076
Validation after dual ascent:
out_inf: tensor(1.8223, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
tensor(0.0444, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0479, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.0562, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0470, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
8 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5547, device='cuda:0', dtype=torch.float16) tensor(0.3135, device='cuda:0', dtype=torch.float16)
tensor(0.3960, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.4683, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0084, device='cuda:0')
tensor(0.0382, device='cuda:0')
old_score: tensor(0.0463, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0427, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.231287479400635
Validation after dual ascent:
out_inf: tensor(3.5547, device='cuda:0', dtype=torch.float16) tensor(0.3135, device='cuda:0', dtype=torch.float16)
tensor(0.4045, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
8 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6016, device='cuda:0', dtype=torch.float16) tensor(0.1488, device='cuda:0', dtype=torch.float16)
tensor(0.3359, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(0.3755, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.3896, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0195, device='cuda:0')
tensor(0.1363, device='cuda:0')
old_score: tensor(0.0368, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0340, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.780334234237671
Validation after dual ascent:
out_inf: tensor(3.6016, device='cuda:0', dtype=torch.float16) tensor(0.1488, device='cuda:0', dtype=torch.float16)
tensor(0.3623, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.3447, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
tensor(0.3477, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.3984, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
8 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2871, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.0641, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0696, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0750, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0665, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0066, device='cuda:0')
tensor(0.0116, device='cuda:0')
old_score: tensor(0.0073, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0069, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 37.00105905532837
Validation after dual ascent:
out_inf: tensor(1.2871, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.0651, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0661, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0815, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0658, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
layer 8 done
9 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.8438, device='cuda:0', dtype=torch.float16) tensor(0.7456, device='cuda:0', dtype=torch.float16)
tensor(0.7593, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.8052, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
9 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.8828, device='cuda:0', dtype=torch.float16) tensor(1.4756, device='cuda:0', dtype=torch.float16)
tensor(0.9478, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(1.0684, device='cuda:0', dtype=torch.float16) tensor(0.1236, device='cuda:0', dtype=torch.float16)
tensor(0.9834, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(0.8872, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
9 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8613, device='cuda:0', dtype=torch.float16) tensor(0.1949, device='cuda:0', dtype=torch.float16)
tensor(0.3447, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.3188, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
tensor(0.3208, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.3179, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0038, device='cuda:0')
tensor(0.1073, device='cuda:0')
old_score: tensor(0.0420, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0387, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7999603748321533
Validation after dual ascent:
out_inf: tensor(2.8613, device='cuda:0', dtype=torch.float16) tensor(0.1949, device='cuda:0', dtype=torch.float16)
tensor(0.3391, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.2998, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.3110, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.2871, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
9 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.1270, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.0649, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.0726, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0677, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.0674, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0176, device='cuda:0')
tensor(0.0267, device='cuda:0')
old_score: tensor(0.0071, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0060, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7375493049621582
Validation after dual ascent:
out_inf: tensor(2.1270, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.0580, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0557, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.0598, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0643, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
9 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6914, device='cuda:0', dtype=torch.float16) tensor(0.3411, device='cuda:0', dtype=torch.float16)
tensor(0.4016, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(0.4402, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.4297, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0119, device='cuda:0')
tensor(0.1863, device='cuda:0')
old_score: tensor(0.0471, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0433, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.793535232543945
Validation after dual ascent:
out_inf: tensor(4.6914, device='cuda:0', dtype=torch.float16) tensor(0.3411, device='cuda:0', dtype=torch.float16)
tensor(0.3643, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.4204, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.4348, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
9 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2891, device='cuda:0', dtype=torch.float16) tensor(0.1571, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.3740, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.3711, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0081, device='cuda:0')
tensor(0.1396, device='cuda:0')
old_score: tensor(0.0375, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0346, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.792353630065918
Validation after dual ascent:
out_inf: tensor(4.2891, device='cuda:0', dtype=torch.float16) tensor(0.1571, device='cuda:0', dtype=torch.float16)
tensor(0.3059, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.3374, device='cuda:0', dtype=torch.float16) tensor(0.0357, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
tensor(0.3604, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
9 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2393, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
tensor(0.0657, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0698, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.0865, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0680, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0176, device='cuda:0')
tensor(0.0216, device='cuda:0')
old_score: tensor(0.0078, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0072, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.917022705078125
Validation after dual ascent:
out_inf: tensor(1.2393, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
tensor(0.0648, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0627, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0827, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.0661, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
layer 9 done
10 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.1250, device='cuda:0', dtype=torch.float16) tensor(0.7710, device='cuda:0', dtype=torch.float16)
tensor(0.9834, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0806, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
10 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.4141, device='cuda:0', dtype=torch.float16) tensor(1.5576, device='cuda:0', dtype=torch.float16)
tensor(0.9023, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
tensor(1.1904, device='cuda:0', dtype=torch.float16) tensor(0.1310, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
10 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.1270, device='cuda:0', dtype=torch.float16) tensor(0.1893, device='cuda:0', dtype=torch.float16)
tensor(0.2761, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.2920, device='cuda:0', dtype=torch.float16) tensor(0.0387, device='cuda:0', dtype=torch.float16)
tensor(0.2759, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0191, device='cuda:0')
tensor(0.4708, device='cuda:0')
old_score: tensor(0.0381, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0353, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.616602897644043
Validation after dual ascent:
out_inf: tensor(2.1270, device='cuda:0', dtype=torch.float16) tensor(0.1893, device='cuda:0', dtype=torch.float16)
tensor(0.2417, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0362, device='cuda:0', dtype=torch.float16)
tensor(0.2808, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(0.2607, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
10 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6934, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.0676, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0682, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.0607, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0673, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0023, device='cuda:0')
tensor(0.0160, device='cuda:0')
old_score: tensor(0.0074, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0065, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7339653968811035
Validation after dual ascent:
out_inf: tensor(2.6934, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.0642, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0612, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0558, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0580, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
10 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.3340, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(0.4023, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4297, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.4346, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0122, device='cuda:0')
tensor(0.1960, device='cuda:0')
old_score: tensor(0.0476, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0439, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.792689323425293
Validation after dual ascent:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.3340, device='cuda:0', dtype=torch.float16)
tensor(0.3804, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.3872, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(0.4072, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.3738, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
10 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.4102, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(0.3311, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.3398, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.3384, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.3127, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0087, device='cuda:0')
tensor(0.1537, device='cuda:0')
old_score: tensor(0.0394, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0363, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.791800498962402
Validation after dual ascent:
out_inf: tensor(3.4102, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(0.3081, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.3325, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.3057, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
10 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.0715, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0757, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.0786, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0781, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0089, device='cuda:0')
tensor(0.0150, device='cuda:0')
old_score: tensor(0.0082, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0076, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.927984952926636
Validation after dual ascent:
out_inf: tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.0652, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0696, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0775, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.0739, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
layer 10 done
11 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7231, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.6694, device='cuda:0', dtype=torch.float16) tensor(0.0803, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.4227, device='cuda:0')
old_score: tensor(0.0791, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.480497121810913
Validation after dual ascent:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7231, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(0.6709, device='cuda:0', dtype=torch.float16) tensor(0.0744, device='cuda:0', dtype=torch.float16)
tensor(0.6494, device='cuda:0', dtype=torch.float16) tensor(0.0766, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
11 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.0781, device='cuda:0', dtype=torch.float16) tensor(1.4941, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
tensor(0.9541, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
11 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9531, device='cuda:0', dtype=torch.float16) tensor(0.2150, device='cuda:0', dtype=torch.float16)
tensor(0.3081, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.2915, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.3042, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.3145, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0038, device='cuda:0')
tensor(0.1086, device='cuda:0')
old_score: tensor(0.0411, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0379, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8047671318054199
Validation after dual ascent:
out_inf: tensor(2.9531, device='cuda:0', dtype=torch.float16) tensor(0.2150, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0362, device='cuda:0', dtype=torch.float16)
tensor(0.2939, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.2788, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.2715, device='cuda:0', dtype=torch.float16) tensor(0.0366, device='cuda:0', dtype=torch.float16)
11 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.0698, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.0667, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.0624, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0760, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0163, device='cuda:0')
tensor(0.0230, device='cuda:0')
old_score: tensor(0.0076, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0064, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7355027198791504
Validation after dual ascent:
out_inf: tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.0705, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.0634, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0574, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.0604, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
11 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.1055, device='cuda:0', dtype=torch.float16) tensor(0.3418, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.3994, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0122, device='cuda:0')
tensor(0.2048, device='cuda:0')
old_score: tensor(0.0479, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0442, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.803290843963623
Validation after dual ascent:
out_inf: tensor(7.1055, device='cuda:0', dtype=torch.float16) tensor(0.3418, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.3887, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.3657, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
11 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.0254, device='cuda:0', dtype=torch.float16) tensor(0.1719, device='cuda:0', dtype=torch.float16)
tensor(0.3584, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.3311, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.3723, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.3174, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0092, device='cuda:0')
tensor(0.1652, device='cuda:0')
old_score: tensor(0.0405, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0374, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.796164512634277
Validation after dual ascent:
out_inf: tensor(3.0254, device='cuda:0', dtype=torch.float16) tensor(0.1719, device='cuda:0', dtype=torch.float16)
tensor(0.3330, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.3159, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.3306, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.3032, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
11 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7607, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.0736, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.0802, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.0779, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.0715, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0059, device='cuda:0')
tensor(0.0113, device='cuda:0')
old_score: tensor(0.0086, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0081, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.857285499572754
Validation after dual ascent:
out_inf: tensor(1.7607, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.0678, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0760, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0676, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
layer 11 done
12 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.8984, device='cuda:0', dtype=torch.float16) tensor(0.7334, device='cuda:0', dtype=torch.float16)
tensor(0.6787, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(0.6646, device='cuda:0', dtype=torch.float16) tensor(0.0791, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.5972, device='cuda:0', dtype=torch.float16) tensor(0.0763, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0155, device='cuda:0')
tensor(0.3536, device='cuda:0')
old_score: tensor(0.0780, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0719, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4806196689605713
Validation after dual ascent:
out_inf: tensor(14.8984, device='cuda:0', dtype=torch.float16) tensor(0.7334, device='cuda:0', dtype=torch.float16)
tensor(0.5972, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.6260, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.5708, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
12 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.3281, device='cuda:0', dtype=torch.float16) tensor(1.3545, device='cuda:0', dtype=torch.float16)
tensor(1.0674, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(0.9053, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.1283, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
12 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.2064, device='cuda:0', dtype=torch.float16)
tensor(0.3232, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(0.3115, device='cuda:0', dtype=torch.float16) tensor(0.0437, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.1046, device='cuda:0')
old_score: tensor(0.0447, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0413, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7996354103088379
Validation after dual ascent:
out_inf: tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.2064, device='cuda:0', dtype=torch.float16)
tensor(0.2856, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(0.3003, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.3032, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.3015, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
12 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.1113, device='cuda:0', dtype=torch.float16) tensor(0.0318, device='cuda:0', dtype=torch.float16)
tensor(0.0753, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.0794, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0781, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0035, device='cuda:0')
tensor(0.0212, device='cuda:0')
old_score: tensor(0.0081, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0068, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7309467792510986
Validation after dual ascent:
out_inf: tensor(3.1113, device='cuda:0', dtype=torch.float16) tensor(0.0318, device='cuda:0', dtype=torch.float16)
tensor(0.0635, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0749, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.0697, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0702, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
12 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3398, device='cuda:0', dtype=torch.float16) tensor(0.3433, device='cuda:0', dtype=torch.float16)
tensor(0.3950, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.4580, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0119, device='cuda:0')
tensor(0.2019, device='cuda:0')
old_score: tensor(0.0468, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0433, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.768493413925171
Validation after dual ascent:
out_inf: tensor(4.3398, device='cuda:0', dtype=torch.float16) tensor(0.3433, device='cuda:0', dtype=torch.float16)
tensor(0.3818, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.4756, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.4653, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.4297, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
12 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.8633, device='cuda:0', dtype=torch.float16) tensor(0.1779, device='cuda:0', dtype=torch.float16)
tensor(0.3457, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.5537, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.3965, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0092, device='cuda:0')
tensor(0.1676, device='cuda:0')
old_score: tensor(0.0411, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0381, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.77080225944519
Validation after dual ascent:
out_inf: tensor(3.8633, device='cuda:0', dtype=torch.float16) tensor(0.1779, device='cuda:0', dtype=torch.float16)
tensor(0.3262, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.3447, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.3142, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
12 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.4414, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.0734, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.0782, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.0867, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0765, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0071, device='cuda:0')
tensor(0.0087, device='cuda:0')
old_score: tensor(0.0090, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0084, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.806348085403442
Validation after dual ascent:
out_inf: tensor(1.4414, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.0681, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0784, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.0854, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.0773, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
layer 12 done
13 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.4219, device='cuda:0', dtype=torch.float16) tensor(0.7480, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.7485, device='cuda:0', dtype=torch.float16) tensor(0.0868, device='cuda:0', dtype=torch.float16)
tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0171, device='cuda:0')
tensor(0.4982, device='cuda:0')
old_score: tensor(0.0860, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0795, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.482996702194214
Validation after dual ascent:
out_inf: tensor(14.4219, device='cuda:0', dtype=torch.float16) tensor(0.7480, device='cuda:0', dtype=torch.float16)
tensor(0.6968, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(0.6870, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
13 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.6875, device='cuda:0', dtype=torch.float16) tensor(1.5703, device='cuda:0', dtype=torch.float16)
tensor(0.9678, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.1449, device='cuda:0', dtype=torch.float16)
tensor(1.1143, device='cuda:0', dtype=torch.float16) tensor(0.1381, device='cuda:0', dtype=torch.float16)
13 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.5605, device='cuda:0', dtype=torch.float16) tensor(0.2041, device='cuda:0', dtype=torch.float16)
tensor(0.3328, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.3210, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.3706, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.3506, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0045, device='cuda:0')
tensor(0.1364, device='cuda:0')
old_score: tensor(0.0478, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0443, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8036854267120361
Validation after dual ascent:
out_inf: tensor(2.5605, device='cuda:0', dtype=torch.float16) tensor(0.2041, device='cuda:0', dtype=torch.float16)
tensor(0.3237, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.3384, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.3936, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.3159, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
13 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3633, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.1019, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.0860, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.0845, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1008, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0039, device='cuda:0')
tensor(0.0253, device='cuda:0')
old_score: tensor(0.0095, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0080, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7317345142364502
Validation after dual ascent:
out_inf: tensor(3.3633, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.0927, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.0788, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0723, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0796, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
13 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.1055, device='cuda:0', dtype=torch.float16) tensor(0.3540, device='cuda:0', dtype=torch.float16)
tensor(0.3804, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.4338, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.5850, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.3843, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0128, device='cuda:0')
tensor(0.2240, device='cuda:0')
old_score: tensor(0.0486, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0450, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.76533317565918
Validation after dual ascent:
out_inf: tensor(5.1055, device='cuda:0', dtype=torch.float16) tensor(0.3540, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.4023, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.3647, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
13 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.7305, device='cuda:0', dtype=torch.float16) tensor(0.1791, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.3877, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.4419, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0100, device='cuda:0')
tensor(0.1889, device='cuda:0')
old_score: tensor(0.0425, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0394, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.770529270172119
Validation after dual ascent:
out_inf: tensor(4.7305, device='cuda:0', dtype=torch.float16) tensor(0.1791, device='cuda:0', dtype=torch.float16)
tensor(0.3618, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.3369, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.4053, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.3604, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
13 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7119, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.0737, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0812, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.0945, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.0773, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0114, device='cuda:0')
tensor(0.0152, device='cuda:0')
old_score: tensor(0.0096, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0090, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.800858736038208
Validation after dual ascent:
out_inf: tensor(1.7119, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.0723, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.0803, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.0848, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.0760, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
layer 13 done
14 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.4922, device='cuda:0', dtype=torch.float16) tensor(0.7446, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
tensor(1.0586, device='cuda:0', dtype=torch.float16) tensor(0.0860, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0166, device='cuda:0')
tensor(0.4797, device='cuda:0')
old_score: tensor(0.0833, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.482212543487549
Validation after dual ascent:
out_inf: tensor(14.4922, device='cuda:0', dtype=torch.float16) tensor(0.7446, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.6802, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(1.0020, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(0.8467, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
14 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.3906, device='cuda:0', dtype=torch.float16) tensor(1.5713, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(0.9927, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1381, device='cuda:0', dtype=torch.float16)
tensor(0.9824, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
14 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8340, device='cuda:0', dtype=torch.float16) tensor(0.2096, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.3491, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.3174, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.3157, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.1253, device='cuda:0')
old_score: tensor(0.0451, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0417, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8017177581787109
Validation after dual ascent:
out_inf: tensor(2.8340, device='cuda:0', dtype=torch.float16) tensor(0.2096, device='cuda:0', dtype=torch.float16)
tensor(0.3013, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.3013, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
14 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8496, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.0800, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.0737, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0868, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0037, device='cuda:0')
tensor(0.0294, device='cuda:0')
old_score: tensor(0.0093, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0078, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7323145866394043
Validation after dual ascent:
out_inf: tensor(2.8496, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.0692, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0706, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0654, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.0828, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
14 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.9609, device='cuda:0', dtype=torch.float16) tensor(0.3792, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0143, device='cuda:0')
tensor(0.2571, device='cuda:0')
old_score: tensor(0.0514, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0476, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7730631828308105
Validation after dual ascent:
out_inf: tensor(4.9609, device='cuda:0', dtype=torch.float16) tensor(0.3792, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.4250, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.5176, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
14 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6836, device='cuda:0', dtype=torch.float16) tensor(0.1786, device='cuda:0', dtype=torch.float16)
tensor(0.4414, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.4736, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.2122, device='cuda:0')
old_score: tensor(0.0438, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0406, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.772284507751465
Validation after dual ascent:
out_inf: tensor(4.6836, device='cuda:0', dtype=torch.float16) tensor(0.1786, device='cuda:0', dtype=torch.float16)
tensor(0.3848, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.3999, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
tensor(0.3342, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
14 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2100, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.0791, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.0972, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1001, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0901, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0058, device='cuda:0')
tensor(0.0147, device='cuda:0')
old_score: tensor(0.0102, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0096, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.789159536361694
Validation after dual ascent:
out_inf: tensor(1.2100, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.0775, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.0861, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.0973, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.0826, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
layer 14 done
15 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.4375, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(1.0215, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
tensor(1.1670, device='cuda:0', dtype=torch.float16) tensor(0.0855, device='cuda:0', dtype=torch.float16)
tensor(0.8159, device='cuda:0', dtype=torch.float16) tensor(0.0879, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0169, device='cuda:0')
tensor(0.5006, device='cuda:0')
old_score: tensor(0.0851, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0787, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4839725494384766
Validation after dual ascent:
out_inf: tensor(18.4375, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(0.9829, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(1.1611, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.8389, device='cuda:0', dtype=torch.float16) tensor(0.0827, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
15 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.8125, device='cuda:0', dtype=torch.float16) tensor(1.5664, device='cuda:0', dtype=torch.float16)
tensor(1.0137, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
tensor(1.0146, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
tensor(1.1514, device='cuda:0', dtype=torch.float16) tensor(0.1428, device='cuda:0', dtype=torch.float16)
tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.1360, device='cuda:0', dtype=torch.float16)
15 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.4570, device='cuda:0', dtype=torch.float16) tensor(0.1949, device='cuda:0', dtype=torch.float16)
tensor(0.3413, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.3430, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.3489, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
tensor(0.3416, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0044, device='cuda:0')
tensor(0.1319, device='cuda:0')
old_score: tensor(0.0472, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0438, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8051271438598633
Validation after dual ascent:
out_inf: tensor(3.4570, device='cuda:0', dtype=torch.float16) tensor(0.1949, device='cuda:0', dtype=torch.float16)
tensor(0.3289, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.3379, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.3372, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.3516, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
15 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.1777, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.0955, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.0868, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0869, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0917, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0038, device='cuda:0')
tensor(0.0284, device='cuda:0')
old_score: tensor(0.0100, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0087, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.744168758392334
Validation after dual ascent:
out_inf: tensor(3.1777, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.0916, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.0806, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.0745, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.0856, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
15 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4033, device='cuda:0', dtype=torch.float16)
tensor(0.5845, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0161, device='cuda:0')
tensor(0.2988, device='cuda:0')
old_score: tensor(0.0545, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.803797721862793
Validation after dual ascent:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4033, device='cuda:0', dtype=torch.float16)
tensor(0.5161, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.4731, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
15 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.9414, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(0.3833, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0454, device='cuda:0', dtype=torch.float16)
tensor(0.4414, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0119, device='cuda:0')
tensor(0.2404, device='cuda:0')
old_score: tensor(0.0449, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0414, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.773159503936768
Validation after dual ascent:
out_inf: tensor(3.9414, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(0.3872, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.3716, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.3557, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
15 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.8164, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.0944, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1033, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1212, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1082, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0027, device='cuda:0')
tensor(0.0163, device='cuda:0')
old_score: tensor(0.0110, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.887434482574463
Validation after dual ascent:
out_inf: tensor(1.8164, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.0968, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0999, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1203, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1001, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
layer 15 done
16 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.0781, device='cuda:0', dtype=torch.float16) tensor(0.7632, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(0.8364, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0834, device='cuda:0', dtype=torch.float16)
tensor(0.8574, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0155, device='cuda:0')
tensor(0.4320, device='cuda:0')
old_score: tensor(0.0803, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0740, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.483168840408325
Validation after dual ascent:
out_inf: tensor(15.0781, device='cuda:0', dtype=torch.float16) tensor(0.7632, device='cuda:0', dtype=torch.float16)
tensor(0.6226, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
tensor(0.8149, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(0.6665, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(0.7363, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
16 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.7656, device='cuda:0', dtype=torch.float16) tensor(1.5420, device='cuda:0', dtype=torch.float16)
tensor(0.9619, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(0.9268, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(0.9673, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.1225, device='cuda:0', dtype=torch.float16)
16 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.5879, device='cuda:0', dtype=torch.float16) tensor(0.1962, device='cuda:0', dtype=torch.float16)
tensor(0.2935, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(0.3540, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.3237, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.3057, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0036, device='cuda:0')
tensor(0.1045, device='cuda:0')
old_score: tensor(0.0415, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0383, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8008213043212891
Validation after dual ascent:
out_inf: tensor(2.5879, device='cuda:0', dtype=torch.float16) tensor(0.1962, device='cuda:0', dtype=torch.float16)
tensor(0.2788, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.3516, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.3057, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.3210, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
16 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4805, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.0901, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.0872, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0849, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.0836, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0051, device='cuda:0')
tensor(0.0259, device='cuda:0')
old_score: tensor(0.0096, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0082, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.736283302307129
Validation after dual ascent:
out_inf: tensor(4.4805, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.0759, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.0749, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.0726, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0743, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
16 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.8281, device='cuda:0', dtype=torch.float16) tensor(0.3892, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
tensor(0.8320, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0174, device='cuda:0')
tensor(0.3444, device='cuda:0')
old_score: tensor(0.0574, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0530, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7768027782440186
Validation after dual ascent:
out_inf: tensor(7.8281, device='cuda:0', dtype=torch.float16) tensor(0.3892, device='cuda:0', dtype=torch.float16)
tensor(0.5176, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.5049, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
16 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6211, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(0.4404, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4639, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0128, device='cuda:0')
tensor(0.2673, device='cuda:0')
old_score: tensor(0.0456, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0421, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.776233911514282
Validation after dual ascent:
out_inf: tensor(3.6211, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(0.4834, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.3682, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
16 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5068, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.0997, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.1185, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1256, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1127, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0022, device='cuda:0')
tensor(0.0168, device='cuda:0')
old_score: tensor(0.0109, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.84697914123535
Validation after dual ascent:
out_inf: tensor(1.5068, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.0904, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1143, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1136, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1133, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
layer 16 done
17 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.5625, device='cuda:0', dtype=torch.float16) tensor(0.7710, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0838, device='cuda:0', dtype=torch.float16)
tensor(0.6958, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.4661, device='cuda:0')
old_score: tensor(0.0819, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0756, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4930975437164307
Validation after dual ascent:
out_inf: tensor(17.5625, device='cuda:0', dtype=torch.float16) tensor(0.7710, device='cuda:0', dtype=torch.float16)
tensor(0.7891, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
17 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.9062, device='cuda:0', dtype=torch.float16) tensor(1.5078, device='cuda:0', dtype=torch.float16)
tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(1.1475, device='cuda:0', dtype=torch.float16) tensor(0.1326, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1350, device='cuda:0', dtype=torch.float16)
tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
17 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.1815, device='cuda:0', dtype=torch.float16)
tensor(0.3691, device='cuda:0', dtype=torch.float16) tensor(0.0454, device='cuda:0', dtype=torch.float16)
tensor(0.3765, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.3657, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.3384, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0043, device='cuda:0')
tensor(0.1341, device='cuda:0')
old_score: tensor(0.0477, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0442, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8044028282165527
Validation after dual ascent:
out_inf: tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.1815, device='cuda:0', dtype=torch.float16)
tensor(0.3462, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.3635, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.3479, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.3784, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
17 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2031, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.0786, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0834, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.0959, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.0864, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0188, device='cuda:0')
tensor(0.0382, device='cuda:0')
old_score: tensor(0.0086, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0073, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7453866004943848
Validation after dual ascent:
out_inf: tensor(4.2031, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.0775, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.0845, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.0822, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0879, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
17 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.8672, device='cuda:0', dtype=torch.float16) tensor(0.3916, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.3592, device='cuda:0')
old_score: tensor(0.0580, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0532, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.80214786529541
Validation after dual ascent:
out_inf: tensor(7.8672, device='cuda:0', dtype=torch.float16) tensor(0.3916, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.5664, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
17 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.4258, device='cuda:0', dtype=torch.float16) tensor(0.1754, device='cuda:0', dtype=torch.float16)
tensor(0.4038, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.4668, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.4214, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0131, device='cuda:0')
tensor(0.2752, device='cuda:0')
old_score: tensor(0.0455, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0417, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.779085397720337
Validation after dual ascent:
out_inf: tensor(3.4258, device='cuda:0', dtype=torch.float16) tensor(0.1754, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.3748, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
17 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0674, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.1151, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1337, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.1282, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1086, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0020, device='cuda:0')
tensor(0.0193, device='cuda:0')
old_score: tensor(0.0116, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.835700035095215
Validation after dual ascent:
out_inf: tensor(1.0674, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.1113, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1279, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1166, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1071, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
layer 17 done
18 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.8984, device='cuda:0', dtype=torch.float16) tensor(0.7246, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(0.8721, device='cuda:0', dtype=torch.float16) tensor(0.0883, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0166, device='cuda:0')
tensor(0.4545, device='cuda:0')
old_score: tensor(0.0839, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0770, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4825439453125
Validation after dual ascent:
out_inf: tensor(15.8984, device='cuda:0', dtype=torch.float16) tensor(0.7246, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.8657, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.8853, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
18 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.8438, device='cuda:0', dtype=torch.float16) tensor(1.5195, device='cuda:0', dtype=torch.float16)
tensor(1.0361, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
tensor(0.9702, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
18 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8105, device='cuda:0', dtype=torch.float16) tensor(0.1840, device='cuda:0', dtype=torch.float16)
tensor(0.3071, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.3193, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.1152, device='cuda:0')
old_score: tensor(0.0421, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0387, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8036298751831055
Validation after dual ascent:
out_inf: tensor(2.8105, device='cuda:0', dtype=torch.float16) tensor(0.1840, device='cuda:0', dtype=torch.float16)
tensor(0.3052, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.3462, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.3396, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
18 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7402, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.0885, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0886, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.0967, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.0800, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0192, device='cuda:0')
tensor(0.0415, device='cuda:0')
old_score: tensor(0.0065, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0057, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.431609630584717
Validation after dual ascent:
out_inf: tensor(2.7402, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.0726, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.0989, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.0863, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0673, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
18 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.6914, device='cuda:0', dtype=torch.float16) tensor(0.3701, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(0.5752, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.3847, device='cuda:0')
old_score: tensor(0.0593, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0543, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.804779529571533
Validation after dual ascent:
out_inf: tensor(7.6914, device='cuda:0', dtype=torch.float16) tensor(0.3701, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
18 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5898, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(0.4294, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.5498, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0137, device='cuda:0')
tensor(0.2923, device='cuda:0')
old_score: tensor(0.0459, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0420, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.78413200378418
Validation after dual ascent:
out_inf: tensor(3.5898, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(0.4353, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0444, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0454, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
18 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3271, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.1129, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1332, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1460, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.1137, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0020, device='cuda:0')
tensor(0.0188, device='cuda:0')
old_score: tensor(0.0111, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.917860507965088
Validation after dual ascent:
out_inf: tensor(1.3271, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.1193, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1238, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1407, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1044, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
layer 18 done
19 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.7891, device='cuda:0', dtype=torch.float16) tensor(0.7505, device='cuda:0', dtype=torch.float16)
tensor(0.9146, device='cuda:0', dtype=torch.float16) tensor(0.0774, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
tensor(0.7349, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(0.8345, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.4571, device='cuda:0')
old_score: tensor(0.0821, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0752, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4828524589538574
Validation after dual ascent:
out_inf: tensor(13.7891, device='cuda:0', dtype=torch.float16) tensor(0.7505, device='cuda:0', dtype=torch.float16)
tensor(0.9048, device='cuda:0', dtype=torch.float16) tensor(0.0697, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(0.7056, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(0.8145, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
19 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.2500, device='cuda:0', dtype=torch.float16) tensor(1.4697, device='cuda:0', dtype=torch.float16)
tensor(1.0771, device='cuda:0', dtype=torch.float16) tensor(0.1180, device='cuda:0', dtype=torch.float16)
tensor(1.0518, device='cuda:0', dtype=torch.float16) tensor(0.1318, device='cuda:0', dtype=torch.float16)
tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(0.9199, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
19 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7363, device='cuda:0', dtype=torch.float16) tensor(0.2056, device='cuda:0', dtype=torch.float16)
tensor(0.3811, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(0.4023, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.4253, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.3569, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0040, device='cuda:0')
tensor(0.1209, device='cuda:0')
old_score: tensor(0.0439, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0403, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8041844367980957
Validation after dual ascent:
out_inf: tensor(2.7363, device='cuda:0', dtype=torch.float16) tensor(0.2056, device='cuda:0', dtype=torch.float16)
tensor(0.3259, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.3748, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.4165, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.3521, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
19 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.5293, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.0889, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.0842, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.0840, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0812, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0159, device='cuda:0')
tensor(0.0351, device='cuda:0')
old_score: tensor(0.0072, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0063, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.005949020385742
Validation after dual ascent:
out_inf: tensor(2.5293, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.0745, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0803, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0758, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0808, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
19 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.5938, device='cuda:0', dtype=torch.float16) tensor(0.3660, device='cuda:0', dtype=torch.float16)
tensor(0.6660, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.5796, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0196, device='cuda:0')
tensor(0.4038, device='cuda:0')
old_score: tensor(0.0604, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0552, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.786055088043213
Validation after dual ascent:
out_inf: tensor(10.5938, device='cuda:0', dtype=torch.float16) tensor(0.3660, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.6514, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
19 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6016, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(0.4097, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.5732, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.3923, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.3038, device='cuda:0')
old_score: tensor(0.0461, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0421, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.786559820175171
Validation after dual ascent:
out_inf: tensor(4.6016, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(0.4158, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.3975, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
19 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.1215, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1406, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.1328, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1234, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
Converged at iteration 50
tensor(0.0200, device='cuda:0')
tensor(0.2407, device='cuda:0')
old_score: tensor(0.0110, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.879591941833496
Validation after dual ascent:
out_inf: tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.1255, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1321, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1246, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1068, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
layer 19 done
20 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.1250, device='cuda:0', dtype=torch.float16) tensor(0.7314, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(0.9189, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.6660, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.4466, device='cuda:0')
old_score: tensor(0.0785, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0718, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.483755350112915
Validation after dual ascent:
out_inf: tensor(17.1250, device='cuda:0', dtype=torch.float16) tensor(0.7314, device='cuda:0', dtype=torch.float16)
tensor(0.7012, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(0.7729, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.8853, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
20 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.9375, device='cuda:0', dtype=torch.float16) tensor(1.5176, device='cuda:0', dtype=torch.float16)
tensor(1.0518, device='cuda:0', dtype=torch.float16) tensor(0.1128, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
20 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8027, device='cuda:0', dtype=torch.float16) tensor(0.2035, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.4087, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4053, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.3325, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.1295, device='cuda:0')
old_score: tensor(0.0457, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0420, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7986564636230469
Validation after dual ascent:
out_inf: tensor(2.8027, device='cuda:0', dtype=torch.float16) tensor(0.2035, device='cuda:0', dtype=torch.float16)
tensor(0.3882, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.4001, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.4192, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.3083, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
20 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4512, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.0857, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0935, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0784, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0872, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0133, device='cuda:0')
tensor(0.0268, device='cuda:0')
old_score: tensor(0.0079, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.334198713302612
Validation after dual ascent:
out_inf: tensor(2.4512, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.0817, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.0763, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0750, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.0730, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
20 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.1719, device='cuda:0', dtype=torch.float16) tensor(0.3706, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(1.6289, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0070, device='cuda:0')
tensor(0.0816, device='cuda:0')
old_score: tensor(0.0621, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0566, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.236936807632446
Validation after dual ascent:
out_inf: tensor(8.1719, device='cuda:0', dtype=torch.float16) tensor(0.3706, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(1.8008, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
20 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.7188, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0149, device='cuda:0')
tensor(0.3266, device='cuda:0')
old_score: tensor(0.0474, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0432, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7873313426971436
Validation after dual ascent:
out_inf: tensor(4.7188, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.6045, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.4434, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
20 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.1136, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1328, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.1553, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.1193, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
Converged at iteration 50
tensor(0.0191, device='cuda:0')
tensor(0.2587, device='cuda:0')
old_score: tensor(0.0115, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0107, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.818130731582642
Validation after dual ascent:
out_inf: tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.1183, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1290, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1487, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.1188, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
layer 20 done
21 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.5625, device='cuda:0', dtype=torch.float16) tensor(0.7207, device='cuda:0', dtype=torch.float16)
tensor(0.8413, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(0.7490, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(0.8315, device='cuda:0', dtype=torch.float16) tensor(0.0806, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0160, device='cuda:0')
tensor(0.3971, device='cuda:0')
old_score: tensor(0.0768, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0701, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4826533794403076
Validation after dual ascent:
out_inf: tensor(20.5625, device='cuda:0', dtype=torch.float16) tensor(0.7207, device='cuda:0', dtype=torch.float16)
tensor(0.8682, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(0.8545, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(0.6104, device='cuda:0', dtype=torch.float16) tensor(0.0653, device='cuda:0', dtype=torch.float16)
21 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.3281, device='cuda:0', dtype=torch.float16) tensor(1.4521, device='cuda:0', dtype=torch.float16)
tensor(1.0771, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
tensor(1.0840, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.0586, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(0.9717, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
21 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.2123, device='cuda:0', dtype=torch.float16)
tensor(0.4194, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.3965, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.3867, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.3525, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0041, device='cuda:0')
tensor(0.1267, device='cuda:0')
old_score: tensor(0.0458, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0419, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8013308048248291
Validation after dual ascent:
out_inf: tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.2123, device='cuda:0', dtype=torch.float16)
tensor(0.4048, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.3921, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.3838, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.3621, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
21 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5596, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.0863, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1069, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.0883, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0928, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0136, device='cuda:0')
tensor(0.0265, device='cuda:0')
old_score: tensor(0.0085, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.399859189987183
Validation after dual ascent:
out_inf: tensor(1.5596, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.0719, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.0970, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0803, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.0876, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
21 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.9570, device='cuda:0', dtype=torch.float16) tensor(0.3918, device='cuda:0', dtype=torch.float16)
tensor(0.6089, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(0.5908, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0078, device='cuda:0')
tensor(0.0833, device='cuda:0')
old_score: tensor(0.0628, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0571, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.233556032180786
Validation after dual ascent:
out_inf: tensor(7.9570, device='cuda:0', dtype=torch.float16) tensor(0.3918, device='cuda:0', dtype=torch.float16)
tensor(0.6411, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.6470, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
21 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6406, device='cuda:0', dtype=torch.float16) tensor(0.1755, device='cuda:0', dtype=torch.float16)
tensor(0.4780, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.4099, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0150, device='cuda:0')
tensor(0.3286, device='cuda:0')
old_score: tensor(0.0476, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0433, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.788523435592651
Validation after dual ascent:
out_inf: tensor(4.6406, device='cuda:0', dtype=torch.float16) tensor(0.1755, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.4155, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
21 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0361, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(0.1487, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1205, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0024, device='cuda:0')
tensor(0.0217, device='cuda:0')
old_score: tensor(0.0116, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.756303071975708
Validation after dual ascent:
out_inf: tensor(1.0361, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(0.1292, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1444, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.1632, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.1219, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
layer 21 done
22 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.1250, device='cuda:0', dtype=torch.float16) tensor(0.6914, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
tensor(0.8521, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
22 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.3125, device='cuda:0', dtype=torch.float16) tensor(1.4814, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(1.0830, device='cuda:0', dtype=torch.float16) tensor(0.1204, device='cuda:0', dtype=torch.float16)
tensor(1.1270, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(0.8730, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
22 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5840, device='cuda:0', dtype=torch.float16) tensor(0.2139, device='cuda:0', dtype=torch.float16)
tensor(0.4634, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0043, device='cuda:0')
tensor(0.1315, device='cuda:0')
old_score: tensor(0.0477, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0436, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7984108924865723
Validation after dual ascent:
out_inf: tensor(3.5840, device='cuda:0', dtype=torch.float16) tensor(0.2139, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.4539, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.3848, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
22 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.1268, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1121, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1209, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1154, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0187, device='cuda:0')
tensor(0.0369, device='cuda:0')
old_score: tensor(0.0091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.404133319854736
Validation after dual ascent:
out_inf: tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.1089, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0999, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.0969, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1001, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
22 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.0703, device='cuda:0', dtype=torch.float16) tensor(0.3762, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.9512, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0075, device='cuda:0')
tensor(0.0874, device='cuda:0')
old_score: tensor(0.0635, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0577, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.243453979492188
Validation after dual ascent:
out_inf: tensor(8.0703, device='cuda:0', dtype=torch.float16) tensor(0.3762, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
22 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7910, device='cuda:0', dtype=torch.float16) tensor(0.1710, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.3405, device='cuda:0')
old_score: tensor(0.0481, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0437, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.783032178878784
Validation after dual ascent:
out_inf: tensor(3.7910, device='cuda:0', dtype=torch.float16) tensor(0.1710, device='cuda:0', dtype=torch.float16)
tensor(0.5498, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.5684, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.4668, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
22 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7646, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.1560, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1560, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.1833, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.1442, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0021, device='cuda:0')
tensor(0.0212, device='cuda:0')
old_score: tensor(0.0114, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.83985733985901
Validation after dual ascent:
out_inf: tensor(0.7646, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.1443, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1617, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1772, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.1392, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
layer 22 done
23 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.3125, device='cuda:0', dtype=torch.float16) tensor(0.7163, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.7549, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(0.7505, device='cuda:0', dtype=torch.float16) tensor(0.0775, device='cuda:0', dtype=torch.float16)
tensor(0.6577, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
23 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.8750, device='cuda:0', dtype=torch.float16) tensor(1.4102, device='cuda:0', dtype=torch.float16)
tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(1.0840, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(1.0869, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
23 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7422, device='cuda:0', dtype=torch.float16) tensor(0.2092, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.4905, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.4495, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0046, device='cuda:0')
tensor(0.1418, device='cuda:0')
old_score: tensor(0.0507, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0462, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.796332836151123
Validation after dual ascent:
out_inf: tensor(2.7422, device='cuda:0', dtype=torch.float16) tensor(0.2092, device='cuda:0', dtype=torch.float16)
tensor(0.4360, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.4595, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.3953, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
23 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.6494, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.1026, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1069, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1060, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.0975, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0185, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.0083, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0073, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9432084560394287
Validation after dual ascent:
out_inf: tensor(0.6494, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.0975, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.0963, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.1041, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.0968, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
23 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10., device='cuda:0', dtype=torch.float16) tensor(0.3748, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.6479, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0074, device='cuda:0')
tensor(0.0892, device='cuda:0')
old_score: tensor(0.0639, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0580, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.252264499664307
Validation after dual ascent:
out_inf: tensor(10., device='cuda:0', dtype=torch.float16) tensor(0.3748, device='cuda:0', dtype=torch.float16)
tensor(0.6714, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
23 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7012, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(0.4448, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0157, device='cuda:0')
tensor(0.3470, device='cuda:0')
old_score: tensor(0.0484, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0439, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.786198139190674
Validation after dual ascent:
out_inf: tensor(3.7012, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(0.5024, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(0.5615, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.4333, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
23 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7808, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.1381, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.1550, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.1621, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.1582, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged at iteration 50
tensor(0.0198, device='cuda:0')
tensor(0.2693, device='cuda:0')
old_score: tensor(0.0113, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.78058123588562
Validation after dual ascent:
out_inf: tensor(0.7808, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.1422, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1719, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.1573, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1616, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
layer 23 done
24 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.5938, device='cuda:0', dtype=torch.float16) tensor(0.7192, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
tensor(0.6143, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
24 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.1406, device='cuda:0', dtype=torch.float16) tensor(1.3848, device='cuda:0', dtype=torch.float16)
tensor(1.1045, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
tensor(1.0830, device='cuda:0', dtype=torch.float16) tensor(0.1091, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1055, device='cuda:0', dtype=torch.float16)
tensor(0.8613, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
24 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.1094, device='cuda:0', dtype=torch.float16) tensor(0.2402, device='cuda:0', dtype=torch.float16)
tensor(0.5386, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.4087, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0048, device='cuda:0')
tensor(0.1426, device='cuda:0')
old_score: tensor(0.0530, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0484, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7973241806030273
Validation after dual ascent:
out_inf: tensor(4.1094, device='cuda:0', dtype=torch.float16) tensor(0.2402, device='cuda:0', dtype=torch.float16)
tensor(0.5405, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.4978, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(0.6553, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.4126, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
24 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.1274, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1158, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1604, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0141, device='cuda:0')
tensor(0.0316, device='cuda:0')
old_score: tensor(0.0101, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.331298112869263
Validation after dual ascent:
out_inf: tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.1059, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1098, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1089, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1261, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
24 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.9844, device='cuda:0', dtype=torch.float16) tensor(0.3760, device='cuda:0', dtype=torch.float16)
tensor(0.6978, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(0.6089, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0076, device='cuda:0')
tensor(0.0903, device='cuda:0')
old_score: tensor(0.0645, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0584, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.231033325195312
Validation after dual ascent:
out_inf: tensor(13.9844, device='cuda:0', dtype=torch.float16) tensor(0.3760, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.7705, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
tensor(0.5903, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
24 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.1758, device='cuda:0', dtype=torch.float16) tensor(0.1705, device='cuda:0', dtype=torch.float16)
tensor(0.5610, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.5376, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.4458, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0159, device='cuda:0')
tensor(0.3517, device='cuda:0')
old_score: tensor(0.0488, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0442, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7868170738220215
Validation after dual ascent:
out_inf: tensor(4.1758, device='cuda:0', dtype=torch.float16) tensor(0.1705, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
24 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.1311, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1775, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.1775, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1459, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged at iteration 50
tensor(0.0194, device='cuda:0')
tensor(0.2681, device='cuda:0')
old_score: tensor(0.0112, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.676403284072876
Validation after dual ascent:
out_inf: tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.1277, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1641, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.1772, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1453, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
layer 24 done
25 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(25.1250, device='cuda:0', dtype=torch.float16) tensor(0.7739, device='cuda:0', dtype=torch.float16)
tensor(0.7886, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(0.7349, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
25 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(22., device='cuda:0', dtype=torch.float16) tensor(1.3662, device='cuda:0', dtype=torch.float16)
tensor(1.0332, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(0.9302, device='cuda:0', dtype=torch.float16) tensor(0.1090, device='cuda:0', dtype=torch.float16)
tensor(1.0928, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
tensor(0.8096, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
25 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.9023, device='cuda:0', dtype=torch.float16) tensor(0.2620, device='cuda:0', dtype=torch.float16)
tensor(0.5181, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.5498, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0050, device='cuda:0')
tensor(0.1496, device='cuda:0')
old_score: tensor(0.0555, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0505, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7939422130584717
Validation after dual ascent:
out_inf: tensor(3.9023, device='cuda:0', dtype=torch.float16) tensor(0.2620, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.5479, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(0.4229, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
25 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3857, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.1306, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1473, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1367, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0140, device='cuda:0')
tensor(0.0256, device='cuda:0')
old_score: tensor(0.0110, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0098, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.253427028656006
Validation after dual ascent:
out_inf: tensor(1.3857, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.1211, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1396, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1147, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1271, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
25 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.0547, device='cuda:0', dtype=torch.float16) tensor(0.4031, device='cuda:0', dtype=torch.float16)
tensor(0.7788, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0713, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
tensor(0.6812, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0083, device='cuda:0')
tensor(0.0947, device='cuda:0')
old_score: tensor(0.0658, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0597, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.230790376663208
Validation after dual ascent:
out_inf: tensor(11.0547, device='cuda:0', dtype=torch.float16) tensor(0.4031, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(0.7705, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
25 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.1777, device='cuda:0', dtype=torch.float16)
tensor(0.5806, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.3664, device='cuda:0')
old_score: tensor(0.0500, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0453, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7857935428619385
Validation after dual ascent:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.1777, device='cuda:0', dtype=torch.float16)
tensor(0.5664, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
tensor(0.5420, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.4761, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
25 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.8223, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.1831, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1683, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.1733, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1683, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0022, device='cuda:0')
tensor(0.0224, device='cuda:0')
old_score: tensor(0.0116, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.59240436553955
Validation after dual ascent:
out_inf: tensor(3.8223, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.1843, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1772, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1667, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1694, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
layer 25 done
26 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.1562, device='cuda:0', dtype=torch.float16) tensor(0.7456, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
26 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.3594, device='cuda:0', dtype=torch.float16) tensor(1.5146, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.0949, device='cuda:0', dtype=torch.float16)
tensor(0.9565, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(0.8457, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
26 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7012, device='cuda:0', dtype=torch.float16) tensor(0.2261, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.5684, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.5576, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.1506, device='cuda:0')
old_score: tensor(0.0560, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7932093143463135
Validation after dual ascent:
out_inf: tensor(3.7012, device='cuda:0', dtype=torch.float16) tensor(0.2261, device='cuda:0', dtype=torch.float16)
tensor(0.5747, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.4387, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
26 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1251, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1259, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1770, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1284, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0172, device='cuda:0')
tensor(0.0273, device='cuda:0')
old_score: tensor(0.0109, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0092, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.397496461868286
Validation after dual ascent:
out_inf: tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1079, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1105, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1794, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1157, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
26 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.4448, device='cuda:0', dtype=torch.float16)
tensor(0.8335, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(0.6606, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0096, device='cuda:0')
tensor(0.1042, device='cuda:0')
old_score: tensor(0.0676, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0612, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.237465620040894
Validation after dual ascent:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.4448, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.6396, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
26 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6758, device='cuda:0', dtype=torch.float16) tensor(0.1924, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.6660, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.4958, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0174, device='cuda:0')
tensor(0.3957, device='cuda:0')
old_score: tensor(0.0518, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0469, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.781953573226929
Validation after dual ascent:
out_inf: tensor(4.6758, device='cuda:0', dtype=torch.float16) tensor(0.1924, device='cuda:0', dtype=torch.float16)
tensor(0.6201, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.5010, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
26 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4688, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.1589, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.2006, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.1841, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.1853, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0026, device='cuda:0')
tensor(0.0270, device='cuda:0')
old_score: tensor(0.0127, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.597325325012207
Validation after dual ascent:
out_inf: tensor(4.4688, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.1630, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.2007, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.1802, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1785, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
layer 26 done
27 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.4062, device='cuda:0', dtype=torch.float16) tensor(0.7368, device='cuda:0', dtype=torch.float16)
tensor(0.7822, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(0.7061, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.6963, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
27 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.2344, device='cuda:0', dtype=torch.float16) tensor(1.4863, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(1.0303, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
27 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.1836, device='cuda:0', dtype=torch.float16) tensor(0.3096, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.6084, device='cuda:0', dtype=torch.float16) tensor(0.0680, device='cuda:0', dtype=torch.float16)
tensor(0.6206, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0058, device='cuda:0')
tensor(0.1754, device='cuda:0')
old_score: tensor(0.0627, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0572, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7974987030029297
Validation after dual ascent:
out_inf: tensor(4.1836, device='cuda:0', dtype=torch.float16) tensor(0.3096, device='cuda:0', dtype=torch.float16)
tensor(0.7197, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.6265, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.6455, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.5200, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
27 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3398, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
tensor(0.1866, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.2209, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.1801, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1649, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0112, device='cuda:0')
tensor(0.0225, device='cuda:0')
old_score: tensor(0.0150, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0133, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.6162402629852295
Validation after dual ascent:
out_inf: tensor(2.3398, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
tensor(0.1633, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1863, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.1704, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1534, device='cuda:0', dtype=torch.float16) tensor(0.0136, device='cuda:0', dtype=torch.float16)
27 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.9219, device='cuda:0', dtype=torch.float16) tensor(0.4941, device='cuda:0', dtype=torch.float16)
tensor(0.8350, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0774, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.7271, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0107, device='cuda:0')
tensor(0.1192, device='cuda:0')
old_score: tensor(0.0708, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0641, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.253146648406982
Validation after dual ascent:
out_inf: tensor(8.9219, device='cuda:0', dtype=torch.float16) tensor(0.4941, device='cuda:0', dtype=torch.float16)
tensor(0.8730, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
27 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6250, device='cuda:0', dtype=torch.float16) tensor(0.2129, device='cuda:0', dtype=torch.float16)
tensor(0.6294, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.6069, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0190, device='cuda:0')
tensor(0.4427, device='cuda:0')
old_score: tensor(0.0549, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0497, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.795334577560425
Validation after dual ascent:
out_inf: tensor(4.6250, device='cuda:0', dtype=torch.float16) tensor(0.2129, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.5884, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(0.5342, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
27 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.0312, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.2019, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.2228, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.2104, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.1975, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0038, device='cuda:0')
tensor(0.0340, device='cuda:0')
old_score: tensor(0.0141, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.47030520439148
Validation after dual ascent:
out_inf: tensor(7.0312, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.1848, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.2275, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
tensor(0.2097, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.2009, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
layer 27 done
28 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.9062, device='cuda:0', dtype=torch.float16) tensor(0.7886, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(0.6499, device='cuda:0', dtype=torch.float16) tensor(0.0695, device='cuda:0', dtype=torch.float16)
28 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.7812, device='cuda:0', dtype=torch.float16) tensor(1.4805, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.1164, device='cuda:0', dtype=torch.float16)
tensor(1.2021, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(0.9902, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
28 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.5117, device='cuda:0', dtype=torch.float16) tensor(0.2810, device='cuda:0', dtype=torch.float16)
tensor(0.6279, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.5908, device='cuda:0', dtype=torch.float16) tensor(0.0719, device='cuda:0', dtype=torch.float16)
tensor(0.5962, device='cuda:0', dtype=torch.float16) tensor(0.0677, device='cuda:0', dtype=torch.float16)
tensor(0.5166, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.1825, device='cuda:0')
old_score: tensor(0.0663, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0605, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.797065019607544
Validation after dual ascent:
out_inf: tensor(5.5117, device='cuda:0', dtype=torch.float16) tensor(0.2810, device='cuda:0', dtype=torch.float16)
tensor(0.6831, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
28 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5146, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.1766, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.1862, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.1829, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.1880, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0110, device='cuda:0')
tensor(0.0671, device='cuda:0')
old_score: tensor(0.0140, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7494831085205078
Validation after dual ascent:
out_inf: tensor(1.5146, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.1549, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1836, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1578, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1968, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
28 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.2734, device='cuda:0', dtype=torch.float16) tensor(0.5459, device='cuda:0', dtype=torch.float16)
tensor(0.9204, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0677, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0124, device='cuda:0')
tensor(0.1312, device='cuda:0')
old_score: tensor(0.0717, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0646, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.272161960601807
Validation after dual ascent:
out_inf: tensor(13.2734, device='cuda:0', dtype=torch.float16) tensor(0.5459, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
28 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.2656, device='cuda:0', dtype=torch.float16) tensor(0.2449, device='cuda:0', dtype=torch.float16)
tensor(0.6694, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.7822, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.5503, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0059, device='cuda:0')
tensor(0.1021, device='cuda:0')
old_score: tensor(0.0574, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0518, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.244301080703735
Validation after dual ascent:
out_inf: tensor(5.2656, device='cuda:0', dtype=torch.float16) tensor(0.2449, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.7568, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.5444, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
28 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.8320, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(0.2178, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.2915, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
tensor(0.2329, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(0.2233, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0052, device='cuda:0')
tensor(0.0464, device='cuda:0')
old_score: tensor(0.0162, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0149, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.544140338897705
Validation after dual ascent:
out_inf: tensor(5.8320, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(0.2251, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.2881, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.2417, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.2086, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
layer 28 done
29 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.8750, device='cuda:0', dtype=torch.float16) tensor(0.7432, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
tensor(0.7642, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6851, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
29 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(34.7812, device='cuda:0', dtype=torch.float16) tensor(1.4082, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1101, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(1.0098, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
29 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.5898, device='cuda:0', dtype=torch.float16) tensor(0.3157, device='cuda:0', dtype=torch.float16)
tensor(0.6870, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
tensor(0.6138, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0070, device='cuda:0')
tensor(0.1981, device='cuda:0')
old_score: tensor(0.0723, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0656, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7997310161590576
Validation after dual ascent:
out_inf: tensor(5.5898, device='cuda:0', dtype=torch.float16) tensor(0.3157, device='cuda:0', dtype=torch.float16)
tensor(0.7583, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(0.6870, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
tensor(0.5576, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
29 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5908, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(0.1993, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.2142, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.2568, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1838, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0185, device='cuda:0')
tensor(0.0154, device='cuda:0')
old_score: tensor(0.0142, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0112, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.20931339263916
Validation after dual ascent:
out_inf: tensor(1.5908, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(0.1827, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1898, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.2231, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1677, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
29 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.6250, device='cuda:0', dtype=torch.float16) tensor(0.5596, device='cuda:0', dtype=torch.float16)
tensor(0.8647, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.0730, device='cuda:0', dtype=torch.float16)
tensor(0.7861, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0132, device='cuda:0')
tensor(0.1336, device='cuda:0')
old_score: tensor(0.0714, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0640, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.294626951217651
Validation after dual ascent:
out_inf: tensor(14.6250, device='cuda:0', dtype=torch.float16) tensor(0.5596, device='cuda:0', dtype=torch.float16)
tensor(0.8955, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.7197, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
29 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.6406, device='cuda:0', dtype=torch.float16) tensor(0.2888, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0650, device='cuda:0', dtype=torch.float16)
tensor(0.7432, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.6123, device='cuda:0', dtype=torch.float16) tensor(0.0563, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0071, device='cuda:0')
tensor(0.1079, device='cuda:0')
old_score: tensor(0.0595, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0533, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.257972955703735
Validation after dual ascent:
out_inf: tensor(10.6406, device='cuda:0', dtype=torch.float16) tensor(0.2888, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.9355, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
29 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.2344, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(0.3110, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.3811, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.3184, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.2808, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0082, device='cuda:0')
tensor(0.0694, device='cuda:0')
old_score: tensor(0.0192, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.526331186294556
Validation after dual ascent:
out_inf: tensor(11.2344, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(0.2764, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.3374, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.2527, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
layer 29 done
30 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.5469, device='cuda:0', dtype=torch.float16) tensor(0.8037, device='cuda:0', dtype=torch.float16)
tensor(0.7100, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.8149, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(0.6216, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
30 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.1875, device='cuda:0', dtype=torch.float16) tensor(1.5479, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
tensor(0.8926, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
tensor(0.9370, device='cuda:0', dtype=torch.float16) tensor(0.0883, device='cuda:0', dtype=torch.float16)
30 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.5781, device='cuda:0', dtype=torch.float16) tensor(0.3391, device='cuda:0', dtype=torch.float16)
tensor(0.7515, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(0.7197, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.6792, device='cuda:0', dtype=torch.float16) tensor(0.0763, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0072, device='cuda:0')
tensor(0.2209, device='cuda:0')
old_score: tensor(0.0801, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0725, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7972445487976074
Validation after dual ascent:
out_inf: tensor(5.5781, device='cuda:0', dtype=torch.float16) tensor(0.3391, device='cuda:0', dtype=torch.float16)
tensor(0.7505, device='cuda:0', dtype=torch.float16) tensor(0.0677, device='cuda:0', dtype=torch.float16)
tensor(0.7075, device='cuda:0', dtype=torch.float16) tensor(0.0803, device='cuda:0', dtype=torch.float16)
tensor(0.7437, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
30 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3457, device='cuda:0', dtype=torch.float16) tensor(0.0910, device='cuda:0', dtype=torch.float16)
tensor(0.3035, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
tensor(0.3013, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.2964, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.2886, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0149, device='cuda:0')
tensor(0.1455, device='cuda:0')
old_score: tensor(0.0211, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0181, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7446908950805664
Validation after dual ascent:
out_inf: tensor(3.3457, device='cuda:0', dtype=torch.float16) tensor(0.0910, device='cuda:0', dtype=torch.float16)
tensor(0.2397, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.2339, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.3198, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
30 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.2812, device='cuda:0', dtype=torch.float16) tensor(0.6279, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.9932, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(0.9951, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.9229, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0180, device='cuda:0')
tensor(0.1385, device='cuda:0')
old_score: tensor(0.0737, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0659, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.287858486175537
Validation after dual ascent:
out_inf: tensor(18.2812, device='cuda:0', dtype=torch.float16) tensor(0.6279, device='cuda:0', dtype=torch.float16)
tensor(0.8774, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.8604, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(0.7627, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
30 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.2344, device='cuda:0', dtype=torch.float16) tensor(0.3794, device='cuda:0', dtype=torch.float16)
tensor(0.7563, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.7705, device='cuda:0', dtype=torch.float16) tensor(0.0672, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0116, device='cuda:0')
tensor(0.1138, device='cuda:0')
old_score: tensor(0.0615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0548, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.255949020385742
Validation after dual ascent:
out_inf: tensor(12.2344, device='cuda:0', dtype=torch.float16) tensor(0.3794, device='cuda:0', dtype=torch.float16)
tensor(0.6943, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
30 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.8438, device='cuda:0', dtype=torch.float16) tensor(0.2015, device='cuda:0', dtype=torch.float16)
tensor(0.4092, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.4182, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.4543, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0183, device='cuda:0')
tensor(0.1293, device='cuda:0')
old_score: tensor(0.0238, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0218, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.51118302345276
Validation after dual ascent:
out_inf: tensor(10.8438, device='cuda:0', dtype=torch.float16) tensor(0.2015, device='cuda:0', dtype=torch.float16)
tensor(0.3794, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
tensor(0.4053, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.4438, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
layer 30 done
31 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.4531, device='cuda:0', dtype=torch.float16) tensor(0.8984, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(0.5942, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
31 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.7969, device='cuda:0', dtype=torch.float16) tensor(1.4180, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0895, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0949, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
31 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.6250, device='cuda:0', dtype=torch.float16) tensor(0.4094, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.5664, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.1209, device='cuda:0')
old_score: tensor(0.0630, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0556, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7992448806762695
Validation after dual ascent:
out_inf: tensor(6.6250, device='cuda:0', dtype=torch.float16) tensor(0.4094, device='cuda:0', dtype=torch.float16)
tensor(0.5718, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.5459, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.5522, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.4502, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
31 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3828, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(0.2668, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
tensor(0.2505, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.3274, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
tensor(0.3230, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.0376, device='cuda:0')
old_score: tensor(0.0205, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0174, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.450338363647461
Validation after dual ascent:
out_inf: tensor(4.3828, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(0.2505, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.2048, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.2927, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.2759, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
31 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.9844, device='cuda:0', dtype=torch.float16) tensor(0.6396, device='cuda:0', dtype=torch.float16)
tensor(0.7876, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(1.6035, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
31 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(24.2812, device='cuda:0', dtype=torch.float16) tensor(0.5508, device='cuda:0', dtype=torch.float16)
tensor(0.6650, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.6714, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.7759, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.5557, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
31 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(315., device='cuda:0', dtype=torch.float16) tensor(0.4722, device='cuda:0', dtype=torch.float16)
tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.5244, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0268, device='cuda:0', dtype=torch.float16)
layer 31 done
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.53it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.34it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.66it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.97it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.70it/s]
dataset loading complete
pruning layer 0 name self_attn.q_proj
Validation after prune:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.8218, device='cuda:0', dtype=torch.float16)
tensor(0.0898, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0977, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.1094, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
tensor(0.0938, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.k_proj
Validation after prune:
out_inf: tensor(10.5859, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(0.1016, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.1016, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1172, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.1016, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.v_proj
Validation after prune:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0228, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0224, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0243, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0210, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0175, device='cuda:0')
tensor(0.0363, device='cuda:0')
old_score: tensor(0.0023, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2238192558288574
Validation after dual ascent:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0234, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0206, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0209, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0241, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0379, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0382, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0427, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0353, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0190, device='cuda:0')
tensor(0.0554, device='cuda:0')
old_score: tensor(0.0004, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0002, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110990047454834
Validation after dual ascent:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0326, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
tensor(0.0333, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
tensor(0.0213, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
tensor(0.0364, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0102, device='cuda:0')
tensor(0.1387, device='cuda:0')
old_score: tensor(0.0204, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0140, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.30064058303833
Validation after dual ascent:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.up_proj
Validation after prune:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.2969, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.2637, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.2402, device='cuda:0', dtype=torch.float16) tensor(0.0185, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0096, device='cuda:0')
tensor(0.1260, device='cuda:0')
old_score: tensor(0.0184, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0127, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.3047850131988525
Validation after dual ascent:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.3145, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.2598, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.2520, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0344, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0409, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0393, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0355, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0559, device='cuda:0')
old_score: tensor(0.0017, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.58445024490356
Validation after dual ascent:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0237, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0273, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0289, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0236, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.5547, device='cuda:0', dtype=torch.float16) tensor(0.9878, device='cuda:0', dtype=torch.float16)
tensor(0.2969, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.3125, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.k_proj
Validation after prune:
out_inf: tensor(10.7344, device='cuda:0', dtype=torch.float16) tensor(1.4805, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.3594, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.3828, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.3711, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.4668, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.1211, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0986, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1602, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0099, device='cuda:0')
tensor(0.0411, device='cuda:0')
old_score: tensor(0.0098, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0068, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9547102451324463
Validation after dual ascent:
out_inf: tensor(2.4668, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.2285, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.1426, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.3281, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.2422, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.3975, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.1646, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.2383, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.1470, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0252, device='cuda:0')
old_score: tensor(0.0011, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.899590492248535
Validation after dual ascent:
out_inf: tensor(1.3975, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.0410, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0371, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0364, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0341, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.gate_proj
Validation after prune:
out_inf: tensor(17.6250, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0181, device='cuda:0')
tensor(0.0309, device='cuda:0')
old_score: tensor(0.0275, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0202, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7560577392578125
Validation after dual ascent:
out_inf: tensor(17.6250, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
tensor(0.3994, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0196, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.6582, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.0257, device='cuda:0')
old_score: tensor(0.0246, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0184, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.768848896026611
Validation after dual ascent:
out_inf: tensor(2.6582, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(1.2031, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.down_proj
Validation after prune:
out_inf: tensor(242.6250, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0303, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0372, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0309, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0652, device='cuda:0')
old_score: tensor(0.0022, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0018, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.02306365966797
Validation after dual ascent:
out_inf: tensor(242.6250, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0311, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.1484, device='cuda:0', dtype=torch.float16) tensor(0.8428, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.7495, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.1094, device='cuda:0', dtype=torch.float16) tensor(1.3975, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.1164, device='cuda:0', dtype=torch.float16)
tensor(1.1611, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(1.1973, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.8105, device='cuda:0', dtype=torch.float16) tensor(0.1139, device='cuda:0', dtype=torch.float16)
tensor(0.2352, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.2441, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.2407, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.2268, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0086, device='cuda:0')
tensor(0.0410, device='cuda:0')
old_score: tensor(0.0282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0211, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9778342247009277
Validation after dual ascent:
out_inf: tensor(1.8105, device='cuda:0', dtype=torch.float16) tensor(0.1139, device='cuda:0', dtype=torch.float16)
tensor(0.1924, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.2289, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
tensor(0.2391, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(0.1979, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.7993, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.0684, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0590, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0615, device='cuda:0', dtype=torch.float16) tensor(0.0014, device='cuda:0', dtype=torch.float16)
tensor(0.0552, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0159, device='cuda:0')
old_score: tensor(0.0017, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0012, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.892926931381226
Validation after dual ascent:
out_inf: tensor(0.7993, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.0552, device='cuda:0', dtype=torch.float16) tensor(0.0014, device='cuda:0', dtype=torch.float16)
tensor(0.0519, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0524, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0356, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.2363, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0110, device='cuda:0')
tensor(0.0443, device='cuda:0')
old_score: tensor(0.0353, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0265, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.756475210189819
Validation after dual ascent:
out_inf: tensor(3.2363, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
tensor(0.4717, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.4529, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.3496, device='cuda:0', dtype=torch.float16) tensor(0.0879, device='cuda:0', dtype=torch.float16)
tensor(0.3018, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
tensor(0.3066, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
tensor(0.3154, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
tensor(0.2817, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0088, device='cuda:0')
tensor(0.0388, device='cuda:0')
old_score: tensor(0.0306, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0233, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.763041019439697
Validation after dual ascent:
out_inf: tensor(2.3496, device='cuda:0', dtype=torch.float16) tensor(0.0879, device='cuda:0', dtype=torch.float16)
tensor(0.2671, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.2817, device='cuda:0', dtype=torch.float16) tensor(0.0254, device='cuda:0', dtype=torch.float16)
tensor(0.2820, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.2549, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.3162, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.0452, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0608, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0664, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.0682, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0373, device='cuda:0')
old_score: tensor(0.0033, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0027, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.55154132843018
Validation after dual ascent:
out_inf: tensor(0.3162, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.0345, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0566, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0552, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0349, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.5938, device='cuda:0', dtype=torch.float16) tensor(0.8057, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.0932, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.0928, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.2732, device='cuda:0')
old_score: tensor(0.0930, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0663, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.479842185974121
Validation after dual ascent:
out_inf: tensor(12.5938, device='cuda:0', dtype=torch.float16) tensor(0.8057, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(1.0537, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.8125, device='cuda:0', dtype=torch.float16) tensor(1.3125, device='cuda:0', dtype=torch.float16)
tensor(1.4180, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0124, device='cuda:0')
tensor(0.2071, device='cuda:0')
old_score: tensor(0.1427, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0999, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8041841983795166
Validation after dual ascent:
out_inf: tensor(19.8125, device='cuda:0', dtype=torch.float16) tensor(1.3125, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0901, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.1091, device='cuda:0', dtype=torch.float16)
tensor(1.4805, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(1.5498, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.4453, device='cuda:0', dtype=torch.float16) tensor(0.1445, device='cuda:0', dtype=torch.float16)
tensor(0.3354, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(0.3394, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(0.3479, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.3267, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0186, device='cuda:0')
tensor(0.4136, device='cuda:0')
old_score: tensor(0.0403, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0304, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6170082092285156
Validation after dual ascent:
out_inf: tensor(2.4453, device='cuda:0', dtype=torch.float16) tensor(0.1445, device='cuda:0', dtype=torch.float16)
tensor(0.3135, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.3113, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.3416, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.3286, device='cuda:0', dtype=torch.float16) tensor(0.0286, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0986, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.0580, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0879, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0896, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0725, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0160, device='cuda:0')
tensor(0.0299, device='cuda:0')
old_score: tensor(0.0025, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0016, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.184049844741821
Validation after dual ascent:
out_inf: tensor(1.0986, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.0643, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0704, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0615, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.0476, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.9062, device='cuda:0', dtype=torch.float16) tensor(0.1700, device='cuda:0', dtype=torch.float16)
tensor(0.8164, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.8926, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0137, device='cuda:0')
tensor(0.0850, device='cuda:0')
old_score: tensor(0.0450, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0337, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.762694835662842
Validation after dual ascent:
out_inf: tensor(3.9062, device='cuda:0', dtype=torch.float16) tensor(0.1700, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.6357, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0362, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.3750, device='cuda:0', dtype=torch.float16) tensor(0.1040, device='cuda:0', dtype=torch.float16)
tensor(0.5996, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.3594, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.3438, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0095, device='cuda:0')
tensor(0.0690, device='cuda:0')
old_score: tensor(0.0361, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0274, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.767149925231934
Validation after dual ascent:
out_inf: tensor(4.3750, device='cuda:0', dtype=torch.float16) tensor(0.1040, device='cuda:0', dtype=torch.float16)
tensor(0.2783, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.3140, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.3145, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.2842, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.4465, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.0466, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0894, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.0798, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.0544, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0195, device='cuda:0')
tensor(0.0290, device='cuda:0')
old_score: tensor(0.0047, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0040, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 85.30155754089355
Validation after dual ascent:
out_inf: tensor(0.4465, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.0549, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0833, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.0560, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0411, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.0703, device='cuda:0', dtype=torch.float16) tensor(0.8042, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0160, device='cuda:0')
tensor(0.1837, device='cuda:0')
old_score: tensor(0.0817, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0581, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4695651531219482
Validation after dual ascent:
out_inf: tensor(12.0703, device='cuda:0', dtype=torch.float16) tensor(0.8042, device='cuda:0', dtype=torch.float16)
tensor(0.7764, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.8604, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.6929, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.9531, device='cuda:0', dtype=torch.float16) tensor(1.3965, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.7637, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(0.3145, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.3291, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.3079, device='cuda:0', dtype=torch.float16) tensor(0.0387, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0166, device='cuda:0')
tensor(0.3348, device='cuda:0')
old_score: tensor(0.0391, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0291, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6226918697357178
Validation after dual ascent:
out_inf: tensor(1.7637, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(0.2869, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
tensor(0.3286, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.3125, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.2620, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0898, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.0752, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.1030, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.1058, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0610, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0218, device='cuda:0')
old_score: tensor(0.0034, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0021, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.88736867904663
Validation after dual ascent:
out_inf: tensor(1.0898, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.0933, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0713, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0974, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0522, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.2773, device='cuda:0', dtype=torch.float16) tensor(0.2358, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0084, device='cuda:0')
tensor(0.0333, device='cuda:0')
old_score: tensor(0.0531, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0397, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.221083402633667
Validation after dual ascent:
out_inf: tensor(6.2773, device='cuda:0', dtype=torch.float16) tensor(0.2358, device='cuda:0', dtype=torch.float16)
tensor(0.6064, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.6860, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.8574, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.6099, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.2246, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.3926, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.3730, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.1077, device='cuda:0')
old_score: tensor(0.0394, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0299, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.785012483596802
Validation after dual ascent:
out_inf: tensor(3.2246, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.2871, device='cuda:0', dtype=torch.float16) tensor(0.0268, device='cuda:0', dtype=torch.float16)
tensor(0.3323, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.3594, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.2742, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.8389, device='cuda:0', dtype=torch.float16) tensor(0.0196, device='cuda:0', dtype=torch.float16)
tensor(0.0845, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.1052, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0981, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0835, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0130, device='cuda:0')
tensor(0.0193, device='cuda:0')
old_score: tensor(0.0064, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 69.26941633224487
Validation after dual ascent:
out_inf: tensor(0.8389, device='cuda:0', dtype=torch.float16) tensor(0.0196, device='cuda:0', dtype=torch.float16)
tensor(0.0624, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
tensor(0.0820, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.0728, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.0670, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.2656, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0937, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0965, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
tensor(1.3828, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.3194, device='cuda:0')
old_score: tensor(0.0942, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0663, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.471298933029175
Validation after dual ascent:
out_inf: tensor(14.2656, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(0.8311, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.9888, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.8286, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.5938, device='cuda:0', dtype=torch.float16) tensor(1.4385, device='cuda:0', dtype=torch.float16)
tensor(1.6797, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1517, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0115, device='cuda:0')
tensor(0.2341, device='cuda:0')
old_score: tensor(0.1475, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1011, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7967052459716797
Validation after dual ascent:
out_inf: tensor(19.5938, device='cuda:0', dtype=torch.float16) tensor(1.4385, device='cuda:0', dtype=torch.float16)
tensor(0.9951, device='cuda:0', dtype=torch.float16) tensor(0.0917, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.1110, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3262, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(0.3096, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.3120, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.2812, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.2783, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0164, device='cuda:0')
tensor(0.3685, device='cuda:0')
old_score: tensor(0.0375, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0282, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6146163940429688
Validation after dual ascent:
out_inf: tensor(2.3262, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(0.2444, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.2673, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.2253, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.3643, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.1357, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.1123, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.1328, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1025, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0123, device='cuda:0')
tensor(0.0278, device='cuda:0')
old_score: tensor(0.0052, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0032, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.289396286010742
Validation after dual ascent:
out_inf: tensor(1.3643, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.0806, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0840, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0850, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.7852, device='cuda:0', dtype=torch.float16) tensor(0.2839, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.9028, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0148, device='cuda:0')
tensor(0.1680, device='cuda:0')
old_score: tensor(0.0570, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0417, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.773046016693115
Validation after dual ascent:
out_inf: tensor(3.7852, device='cuda:0', dtype=torch.float16) tensor(0.2839, device='cuda:0', dtype=torch.float16)
tensor(0.5835, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.7603, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.6851, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.6343, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.7930, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(0.5996, device='cuda:0', dtype=torch.float16) tensor(0.0419, device='cuda:0', dtype=torch.float16)
tensor(0.4961, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0099, device='cuda:0')
tensor(0.1272, device='cuda:0')
old_score: tensor(0.0424, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0316, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7805798053741455
Validation after dual ascent:
out_inf: tensor(3.7930, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.3752, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.3691, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.3623, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.9263, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.0963, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0908, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0967, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1117, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0130, device='cuda:0')
tensor(0.0293, device='cuda:0')
old_score: tensor(0.0074, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0058, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.996137619018555
Validation after dual ascent:
out_inf: tensor(0.9263, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.0831, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.0766, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.0911, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0837, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.5078, device='cuda:0', dtype=torch.float16) tensor(0.7515, device='cuda:0', dtype=torch.float16)
tensor(2.3594, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0170, device='cuda:0')
tensor(0.3070, device='cuda:0')
old_score: tensor(0.1019, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0696, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.471912384033203
Validation after dual ascent:
out_inf: tensor(14.5078, device='cuda:0', dtype=torch.float16) tensor(0.7515, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.9595, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(1.0303, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(1.4609, device='cuda:0', dtype=torch.float16)
tensor(2.4609, device='cuda:0', dtype=torch.float16) tensor(0.1600, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1636, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1587, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0121, device='cuda:0')
tensor(0.2249, device='cuda:0')
old_score: tensor(0.1599, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7967469692230225
Validation after dual ascent:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(1.4609, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(1.0322, device='cuda:0', dtype=torch.float16) tensor(0.0978, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3418, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(0.3604, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.3325, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.3364, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.3081, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0181, device='cuda:0')
tensor(0.4053, device='cuda:0')
old_score: tensor(0.0425, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0311, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6129553318023682
Validation after dual ascent:
out_inf: tensor(2.3418, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(0.2705, device='cuda:0', dtype=torch.float16) tensor(0.0286, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.2883, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.2744, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.6729, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.1296, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.1423, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1240, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.1240, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0165, device='cuda:0')
tensor(0.0243, device='cuda:0')
old_score: tensor(0.0068, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0043, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.914788007736206
Validation after dual ascent:
out_inf: tensor(1.6729, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.0879, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0898, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0830, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0894, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.6719, device='cuda:0', dtype=torch.float16) tensor(0.3132, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0169, device='cuda:0')
tensor(0.0674, device='cuda:0')
old_score: tensor(0.0585, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0430, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.177642583847046
Validation after dual ascent:
out_inf: tensor(5.6719, device='cuda:0', dtype=torch.float16) tensor(0.3132, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.8955, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.8804, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.8184, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0444, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.4004, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0102, device='cuda:0')
tensor(0.0438, device='cuda:0')
old_score: tensor(0.0436, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0326, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.222497940063477
Validation after dual ascent:
out_inf: tensor(3.8184, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(0.3184, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0347, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0347, device='cuda:0', dtype=torch.float16)
tensor(0.3359, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.1377, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.1489, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1431, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1494, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0115, device='cuda:0')
tensor(0.0186, device='cuda:0')
old_score: tensor(0.0082, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0063, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.99394965171814
Validation after dual ascent:
out_inf: tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.0937, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.0933, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0869, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.1035, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.5312, device='cuda:0', dtype=torch.float16) tensor(0.7339, device='cuda:0', dtype=torch.float16)
tensor(1.6328, device='cuda:0', dtype=torch.float16) tensor(0.1055, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1018, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0179, device='cuda:0')
tensor(0.3215, device='cuda:0')
old_score: tensor(0.1041, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0686, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470574378967285
Validation after dual ascent:
out_inf: tensor(16.5312, device='cuda:0', dtype=torch.float16) tensor(0.7339, device='cuda:0', dtype=torch.float16)
tensor(0.9209, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
tensor(1.0020, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.9873, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(0.8604, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.0156, device='cuda:0', dtype=torch.float16) tensor(1.4531, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1758, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1772, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1724, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1737, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0134, device='cuda:0')
tensor(0.2530, device='cuda:0')
old_score: tensor(0.1748, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7965407371520996
Validation after dual ascent:
out_inf: tensor(16.0156, device='cuda:0', dtype=torch.float16) tensor(1.4531, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3711, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(0.3672, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(0.3755, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.3828, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.4351, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0183, device='cuda:0')
tensor(0.4191, device='cuda:0')
old_score: tensor(0.0444, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0318, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6126410961151123
Validation after dual ascent:
out_inf: tensor(2.3711, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(0.2593, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.2764, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.2666, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.2642, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.1758, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.1328, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1240, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1465, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1299, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0130, device='cuda:0')
tensor(0.0212, device='cuda:0')
old_score: tensor(0.0084, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0049, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.643150806427002
Validation after dual ascent:
out_inf: tensor(2.1758, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.0991, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.1001, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.0879, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.0940, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.1406, device='cuda:0', dtype=torch.float16) tensor(0.3281, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.7520, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0139, device='cuda:0')
tensor(0.1872, device='cuda:0')
old_score: tensor(0.0578, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0428, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.748564958572388
Validation after dual ascent:
out_inf: tensor(4.1406, device='cuda:0', dtype=torch.float16) tensor(0.3281, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0454, device='cuda:0', dtype=torch.float16)
tensor(0.5732, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1992, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.4980, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0094, device='cuda:0')
tensor(0.1459, device='cuda:0')
old_score: tensor(0.0446, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0335, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.750257253646851
Validation after dual ascent:
out_inf: tensor(4.1992, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
tensor(0.2981, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.3594, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.2920, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.2046, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2251, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.2007, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0195, device='cuda:0')
tensor(0.0292, device='cuda:0')
old_score: tensor(0.0089, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0067, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.7869598865509
Validation after dual ascent:
out_inf: tensor(1.2920, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.1021, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.1313, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.1373, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.1001, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.8828, device='cuda:0', dtype=torch.float16) tensor(0.7280, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(1.4600, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0186, device='cuda:0')
tensor(0.4100, device='cuda:0')
old_score: tensor(0.1074, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0750, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4716155529022217
Validation after dual ascent:
out_inf: tensor(12.8828, device='cuda:0', dtype=torch.float16) tensor(0.7280, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(1.0518, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.9482, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.2500, device='cuda:0', dtype=torch.float16) tensor(1.5635, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1805, device='cuda:0', dtype=torch.float16)
tensor(1.9346, device='cuda:0', dtype=torch.float16) tensor(0.1765, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1707, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1786, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0145, device='cuda:0')
tensor(0.3152, device='cuda:0')
old_score: tensor(0.1765, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1171, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8004534244537354
Validation after dual ascent:
out_inf: tensor(19.2500, device='cuda:0', dtype=torch.float16) tensor(1.5635, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.3105, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(1.2725, device='cuda:0', dtype=torch.float16) tensor(0.1233, device='cuda:0', dtype=torch.float16)
tensor(1.3428, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.5664, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(0.5249, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4429, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.4380, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.4299, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0998, device='cuda:0')
old_score: tensor(0.0483, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0354, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7978503704071045
Validation after dual ascent:
out_inf: tensor(2.5664, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(0.3677, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.3359, device='cuda:0', dtype=torch.float16) tensor(0.0367, device='cuda:0', dtype=torch.float16)
tensor(0.3521, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.3281, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.8701, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.1538, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1450, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1484, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1858, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0133, device='cuda:0')
tensor(0.0161, device='cuda:0')
old_score: tensor(0.0088, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0052, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9085474014282227
Validation after dual ascent:
out_inf: tensor(1.8701, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.0908, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.0933, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0918, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.0996, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.7051, device='cuda:0', dtype=torch.float16) tensor(0.3147, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(0.8164, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0176, device='cuda:0')
tensor(0.0800, device='cuda:0')
old_score: tensor(0.0590, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0446, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 41.90199828147888
Validation after dual ascent:
out_inf: tensor(3.7051, device='cuda:0', dtype=torch.float16) tensor(0.3147, device='cuda:0', dtype=torch.float16)
tensor(0.6821, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.5498, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.9434, device='cuda:0', dtype=torch.float16) tensor(0.1479, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.4971, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.4341, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0170, device='cuda:0')
tensor(0.0716, device='cuda:0')
old_score: tensor(0.0455, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0347, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.224689722061157
Validation after dual ascent:
out_inf: tensor(3.9434, device='cuda:0', dtype=torch.float16) tensor(0.1479, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.4053, device='cuda:0', dtype=torch.float16) tensor(0.0367, device='cuda:0', dtype=torch.float16)
tensor(0.3389, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.2329, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1885, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.2158, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0117, device='cuda:0')
tensor(0.0213, device='cuda:0')
old_score: tensor(0.0089, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0069, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.91111731529236
Validation after dual ascent:
out_inf: tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.1123, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.1172, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.1333, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.2812, device='cuda:0', dtype=torch.float16) tensor(0.7407, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1128, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(1.6719, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1112, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0194, device='cuda:0')
tensor(0.4487, device='cuda:0')
old_score: tensor(0.1107, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0775, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4697961807250977
Validation after dual ascent:
out_inf: tensor(16.2812, device='cuda:0', dtype=torch.float16) tensor(0.7407, device='cuda:0', dtype=torch.float16)
tensor(1.0605, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(1.1670, device='cuda:0', dtype=torch.float16) tensor(0.0796, device='cuda:0', dtype=torch.float16)
tensor(1.2295, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.0749, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.3438, device='cuda:0', dtype=torch.float16) tensor(1.4648, device='cuda:0', dtype=torch.float16)
tensor(1.7637, device='cuda:0', dtype=torch.float16) tensor(0.1807, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1774, device='cuda:0', dtype=torch.float16)
tensor(1.7930, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(1.7949, device='cuda:0', dtype=torch.float16) tensor(0.1786, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0151, device='cuda:0')
tensor(0.3480, device='cuda:0')
old_score: tensor(0.1774, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1218, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7990403175354004
Validation after dual ascent:
out_inf: tensor(16.3438, device='cuda:0', dtype=torch.float16) tensor(1.4648, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(1.3037, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.2529, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.5527, device='cuda:0', dtype=torch.float16) tensor(0.1927, device='cuda:0', dtype=torch.float16)
tensor(0.5869, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.5923, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.7520, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(0.6260, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.1283, device='cuda:0')
old_score: tensor(0.0566, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0419, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7963521480560303
Validation after dual ascent:
out_inf: tensor(2.5527, device='cuda:0', dtype=torch.float16) tensor(0.1927, device='cuda:0', dtype=torch.float16)
tensor(0.4797, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.4932, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.4712, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.1270, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.1621, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.2222, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1982, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.2246, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0157, device='cuda:0')
tensor(0.0185, device='cuda:0')
old_score: tensor(0.0110, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0065, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7351508140563965
Validation after dual ascent:
out_inf: tensor(2.1270, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.1602, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.1382, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1377, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.1182, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.7910, device='cuda:0', dtype=torch.float16) tensor(0.3401, device='cuda:0', dtype=torch.float16)
tensor(0.9482, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.9307, device='cuda:0', dtype=torch.float16) tensor(0.0625, device='cuda:0', dtype=torch.float16)
tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0617, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0153, device='cuda:0')
tensor(0.2244, device='cuda:0')
old_score: tensor(0.0620, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0458, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.740138292312622
Validation after dual ascent:
out_inf: tensor(3.7910, device='cuda:0', dtype=torch.float16) tensor(0.3401, device='cuda:0', dtype=torch.float16)
tensor(0.6553, device='cuda:0', dtype=torch.float16) tensor(0.0437, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.7900, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.4707, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0106, device='cuda:0')
tensor(0.1722, device='cuda:0')
old_score: tensor(0.0476, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0357, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.737346410751343
Validation after dual ascent:
out_inf: tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
tensor(0.3340, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.3867, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.3877, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
tensor(0.3418, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.2158, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.2156, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.2343, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.2527, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0064, device='cuda:0')
tensor(0.0134, device='cuda:0')
old_score: tensor(0.0098, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0074, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.81549024581909
Validation after dual ascent:
out_inf: tensor(1.2158, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.1329, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.1733, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.1814, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.1255, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.6250, device='cuda:0', dtype=torch.float16) tensor(0.7642, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0200, device='cuda:0')
tensor(0.4949, device='cuda:0')
old_score: tensor(0.1160, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0806, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4682230949401855
Validation after dual ascent:
out_inf: tensor(17.6250, device='cuda:0', dtype=torch.float16) tensor(0.7642, device='cuda:0', dtype=torch.float16)
tensor(0.9946, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0827, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.0834, device='cuda:0', dtype=torch.float16)
tensor(0.9932, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.k_proj
Validation after prune:
out_inf: tensor(14.9609, device='cuda:0', dtype=torch.float16) tensor(1.5439, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1923, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1888, device='cuda:0', dtype=torch.float16)
tensor(2.1875, device='cuda:0', dtype=torch.float16) tensor(0.1796, device='cuda:0', dtype=torch.float16)
tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1895, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0155, device='cuda:0')
tensor(0.3743, device='cuda:0')
old_score: tensor(0.1875, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1263, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7977895736694336
Validation after dual ascent:
out_inf: tensor(14.9609, device='cuda:0', dtype=torch.float16) tensor(1.5439, device='cuda:0', dtype=torch.float16)
tensor(1.2822, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1296, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1879, device='cuda:0', dtype=torch.float16)
tensor(0.5127, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.5127, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0043, device='cuda:0')
tensor(0.1206, device='cuda:0')
old_score: tensor(0.0510, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0375, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7979433536529541
Validation after dual ascent:
out_inf: tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1879, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.3728, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.4111, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.7012, device='cuda:0', dtype=torch.float16) tensor(0.0312, device='cuda:0', dtype=torch.float16)
tensor(0.1934, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.2266, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1685, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0035, device='cuda:0')
tensor(0.0166, device='cuda:0')
old_score: tensor(0.0112, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0069, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7298312187194824
Validation after dual ascent:
out_inf: tensor(2.7012, device='cuda:0', dtype=torch.float16) tensor(0.0312, device='cuda:0', dtype=torch.float16)
tensor(0.1240, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.1143, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.0981, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.3320, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.8223, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.7920, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.2414, device='cuda:0')
old_score: tensor(0.0621, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0463, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.740720272064209
Validation after dual ascent:
out_inf: tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.3320, device='cuda:0', dtype=torch.float16)
tensor(0.6611, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.7100, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.3828, device='cuda:0', dtype=torch.float16) tensor(0.1611, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.4707, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0115, device='cuda:0')
tensor(0.1928, device='cuda:0')
old_score: tensor(0.0495, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0375, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.736047029495239
Validation after dual ascent:
out_inf: tensor(3.3828, device='cuda:0', dtype=torch.float16) tensor(0.1611, device='cuda:0', dtype=torch.float16)
tensor(0.3152, device='cuda:0', dtype=torch.float16) tensor(0.0362, device='cuda:0', dtype=torch.float16)
tensor(0.3965, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.3447, device='cuda:0', dtype=torch.float16) tensor(0.0387, device='cuda:0', dtype=torch.float16)
tensor(0.3394, device='cuda:0', dtype=torch.float16) tensor(0.0366, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0674, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
tensor(0.1875, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1689, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1787, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.0223, device='cuda:0')
old_score: tensor(0.0101, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0078, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.821242809295654
Validation after dual ascent:
out_inf: tensor(1.0674, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
tensor(0.1194, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.1151, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1724, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1309, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.0156, device='cuda:0', dtype=torch.float16) tensor(0.7119, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1148, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0200, device='cuda:0')
tensor(0.4996, device='cuda:0')
old_score: tensor(0.1143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0809, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4739370346069336
Validation after dual ascent:
out_inf: tensor(12.0156, device='cuda:0', dtype=torch.float16) tensor(0.7119, device='cuda:0', dtype=torch.float16)
tensor(1.0020, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.5156, device='cuda:0', dtype=torch.float16) tensor(1.4619, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1995, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1932, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.1848, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1947, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0161, device='cuda:0')
tensor(0.4040, device='cuda:0')
old_score: tensor(0.1930, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1318, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7975602149963379
Validation after dual ascent:
out_inf: tensor(16.5156, device='cuda:0', dtype=torch.float16) tensor(1.4619, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1355, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1285, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.9004, device='cuda:0', dtype=torch.float16) tensor(0.2118, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.3896, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.4185, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0045, device='cuda:0')
tensor(0.1210, device='cuda:0')
old_score: tensor(0.0538, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0396, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7962560653686523
Validation after dual ascent:
out_inf: tensor(2.9004, device='cuda:0', dtype=torch.float16) tensor(0.2118, device='cuda:0', dtype=torch.float16)
tensor(0.3125, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.3350, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.3208, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.3459, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.5098, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.2261, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.2051, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.2008, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.2305, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0180, device='cuda:0')
tensor(0.0294, device='cuda:0')
old_score: tensor(0.0120, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7303860187530518
Validation after dual ascent:
out_inf: tensor(2.5098, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.1318, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1394, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.2812, device='cuda:0', dtype=torch.float16) tensor(0.3416, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.2496, device='cuda:0')
old_score: tensor(0.0625, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0464, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.747983932495117
Validation after dual ascent:
out_inf: tensor(6.2812, device='cuda:0', dtype=torch.float16) tensor(0.3416, device='cuda:0', dtype=torch.float16)
tensor(0.9814, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.9756, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.1602, device='cuda:0', dtype=torch.float16) tensor(0.1702, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0119, device='cuda:0')
tensor(0.2032, device='cuda:0')
old_score: tensor(0.0508, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0384, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.780850172042847
Validation after dual ascent:
out_inf: tensor(3.1602, device='cuda:0', dtype=torch.float16) tensor(0.1702, device='cuda:0', dtype=torch.float16)
tensor(0.3301, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.3486, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.3418, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.3499, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.3467, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.3564, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.2341, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0136, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.0105, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0081, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.815150260925293
Validation after dual ascent:
out_inf: tensor(1.3467, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.1685, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1940, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1643, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.9531, device='cuda:0', dtype=torch.float16) tensor(0.7295, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1109, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1123, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0194, device='cuda:0')
tensor(0.4199, device='cuda:0')
old_score: tensor(0.1115, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4743120670318604
Validation after dual ascent:
out_inf: tensor(14.9531, device='cuda:0', dtype=torch.float16) tensor(0.7295, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.9448, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(0.9209, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.7812, device='cuda:0', dtype=torch.float16) tensor(1.3359, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.1885, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1752, device='cuda:0', dtype=torch.float16)
tensor(2.1797, device='cuda:0', dtype=torch.float16) tensor(0.1833, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0149, device='cuda:0')
tensor(0.3296, device='cuda:0')
old_score: tensor(0.1819, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1217, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7989354133605957
Validation after dual ascent:
out_inf: tensor(19.7812, device='cuda:0', dtype=torch.float16) tensor(1.3359, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.1189, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.2043, device='cuda:0', dtype=torch.float16)
tensor(0.4478, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.4326, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.4644, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(0.4329, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0048, device='cuda:0')
tensor(0.1191, device='cuda:0')
old_score: tensor(0.0574, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0429, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8000819683074951
Validation after dual ascent:
out_inf: tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.2043, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.3755, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.3442, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.3420, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.7598, device='cuda:0', dtype=torch.float16) tensor(0.0318, device='cuda:0', dtype=torch.float16)
tensor(0.1406, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.1710, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1709, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.1826, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0053, device='cuda:0')
tensor(0.0189, device='cuda:0')
old_score: tensor(0.0126, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0070, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7301025390625
Validation after dual ascent:
out_inf: tensor(2.7598, device='cuda:0', dtype=torch.float16) tensor(0.0318, device='cuda:0', dtype=torch.float16)
tensor(0.0977, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0962, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.0884, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.0918, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.1289, device='cuda:0', dtype=torch.float16) tensor(0.3433, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.9873, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(0.9971, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.2429, device='cuda:0')
old_score: tensor(0.0607, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0455, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.750112056732178
Validation after dual ascent:
out_inf: tensor(4.1289, device='cuda:0', dtype=torch.float16) tensor(0.3433, device='cuda:0', dtype=torch.float16)
tensor(0.6870, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.7412, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1211, device='cuda:0', dtype=torch.float16) tensor(0.1771, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(0.4707, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0119, device='cuda:0')
tensor(0.2056, device='cuda:0')
old_score: tensor(0.0509, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0391, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.784392595291138
Validation after dual ascent:
out_inf: tensor(4.1211, device='cuda:0', dtype=torch.float16) tensor(0.1771, device='cuda:0', dtype=torch.float16)
tensor(0.3689, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.3767, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.3564, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.3540, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.2510, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.2725, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.2678, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.2332, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0113, device='cuda:0')
tensor(0.0147, device='cuda:0')
old_score: tensor(0.0112, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.846510648727417
Validation after dual ascent:
out_inf: tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.1545, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1797, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1772, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.5312, device='cuda:0', dtype=torch.float16) tensor(0.7446, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1204, device='cuda:0', dtype=torch.float16)
tensor(1.9766, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0076, device='cuda:0')
tensor(0.2045, device='cuda:0')
old_score: tensor(0.1251, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0886, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.206883430480957
Validation after dual ascent:
out_inf: tensor(14.5312, device='cuda:0', dtype=torch.float16) tensor(0.7446, device='cuda:0', dtype=torch.float16)
tensor(1.0879, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(1.0635, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(1.1582, device='cuda:0', dtype=torch.float16) tensor(0.0907, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18., device='cuda:0', dtype=torch.float16) tensor(1.5449, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.2119, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.2042, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1984, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.2079, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.4604, device='cuda:0')
old_score: tensor(0.2056, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1421, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8026218414306641
Validation after dual ascent:
out_inf: tensor(18., device='cuda:0', dtype=torch.float16) tensor(1.5449, device='cuda:0', dtype=torch.float16)
tensor(1.3789, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(1.5977, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
tensor(1.5996, device='cuda:0', dtype=torch.float16) tensor(0.1399, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.5469, device='cuda:0', dtype=torch.float16) tensor(0.2023, device='cuda:0', dtype=torch.float16)
tensor(0.4614, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.4431, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.4575, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0052, device='cuda:0')
tensor(0.1517, device='cuda:0')
old_score: tensor(0.0611, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0461, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8013010025024414
Validation after dual ascent:
out_inf: tensor(2.5469, device='cuda:0', dtype=torch.float16) tensor(0.2023, device='cuda:0', dtype=torch.float16)
tensor(0.3394, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.3628, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.3293, device='cuda:0', dtype=torch.float16) tensor(0.0454, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.3984, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(0.1777, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.2070, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.1904, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1992, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0053, device='cuda:0')
tensor(0.0246, device='cuda:0')
old_score: tensor(0.0143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0084, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7268333435058594
Validation after dual ascent:
out_inf: tensor(3.3984, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(0.1064, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1230, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.1240, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1162, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.9922, device='cuda:0', dtype=torch.float16) tensor(0.3552, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(1.1064, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2753, device='cuda:0')
old_score: tensor(0.0631, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0475, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.785868167877197
Validation after dual ascent:
out_inf: tensor(4.9922, device='cuda:0', dtype=torch.float16) tensor(0.3552, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.1785, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0130, device='cuda:0')
tensor(0.2329, device='cuda:0')
old_score: tensor(0.0527, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0406, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.787144660949707
Validation after dual ascent:
out_inf: tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.1785, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.2080, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.2137, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.2168, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0194, device='cuda:0')
tensor(0.0182, device='cuda:0')
old_score: tensor(0.0121, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0092, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.778905868530273
Validation after dual ascent:
out_inf: tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.1182, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1727, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1616, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1367, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.0469, device='cuda:0', dtype=torch.float16) tensor(0.7373, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1247, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1224, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0082, device='cuda:0')
tensor(0.1958, device='cuda:0')
old_score: tensor(0.1208, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0839, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.200124979019165
Validation after dual ascent:
out_inf: tensor(14.0469, device='cuda:0', dtype=torch.float16) tensor(0.7373, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(0.9834, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.9795, device='cuda:0', dtype=torch.float16) tensor(0.0857, device='cuda:0', dtype=torch.float16)
tensor(0.9619, device='cuda:0', dtype=torch.float16) tensor(0.0830, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.6406, device='cuda:0', dtype=torch.float16) tensor(1.5488, device='cuda:0', dtype=torch.float16)
tensor(2.7656, device='cuda:0', dtype=torch.float16) tensor(0.2041, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.1958, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1896, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.2010, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0166, device='cuda:0')
tensor(0.4236, device='cuda:0')
old_score: tensor(0.1976, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1343, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7960262298583984
Validation after dual ascent:
out_inf: tensor(20.6406, device='cuda:0', dtype=torch.float16) tensor(1.5488, device='cuda:0', dtype=torch.float16)
tensor(1.4414, device='cuda:0', dtype=torch.float16) tensor(0.1310, device='cuda:0', dtype=torch.float16)
tensor(1.6758, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
tensor(1.5898, device='cuda:0', dtype=torch.float16) tensor(0.1329, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.8203, device='cuda:0', dtype=torch.float16) tensor(0.2081, device='cuda:0', dtype=torch.float16)
tensor(0.4419, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.4385, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.4741, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.1402, device='cuda:0')
old_score: tensor(0.0576, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0434, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7968020439147949
Validation after dual ascent:
out_inf: tensor(2.8203, device='cuda:0', dtype=torch.float16) tensor(0.2081, device='cuda:0', dtype=torch.float16)
tensor(0.3838, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.4182, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.3892, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.3638, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.0879, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.2432, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.1978, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.2178, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.2109, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0071, device='cuda:0')
tensor(0.0280, device='cuda:0')
old_score: tensor(0.0144, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0080, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7281441688537598
Validation after dual ascent:
out_inf: tensor(3.0879, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.1182, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.1641, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1406, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.1445, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.7227, device='cuda:0', dtype=torch.float16) tensor(0.3750, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
tensor(1.5098, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(1.2217, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0181, device='cuda:0')
tensor(0.3068, device='cuda:0')
old_score: tensor(0.0660, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0498, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.744893550872803
Validation after dual ascent:
out_inf: tensor(5.7227, device='cuda:0', dtype=torch.float16) tensor(0.3750, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.9697, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.1055, device='cuda:0', dtype=torch.float16) tensor(0.1766, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.4707, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(0.5342, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0135, device='cuda:0')
tensor(0.2530, device='cuda:0')
old_score: tensor(0.0538, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0416, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.783421277999878
Validation after dual ascent:
out_inf: tensor(5.1055, device='cuda:0', dtype=torch.float16) tensor(0.1766, device='cuda:0', dtype=torch.float16)
tensor(0.3684, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1846, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.2227, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.2191, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.2100, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1890, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0176, device='cuda:0')
tensor(0.0191, device='cuda:0')
old_score: tensor(0.0124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0096, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.7539165019989
Validation after dual ascent:
out_inf: tensor(1.1846, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.1133, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1415, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1494, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1309, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.4375, device='cuda:0', dtype=torch.float16) tensor(0.7837, device='cuda:0', dtype=torch.float16)
tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.1283, device='cuda:0', dtype=torch.float16)
tensor(1.9766, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0084, device='cuda:0')
tensor(0.1890, device='cuda:0')
old_score: tensor(0.1248, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0898, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2030656337738037
Validation after dual ascent:
out_inf: tensor(18.4375, device='cuda:0', dtype=torch.float16) tensor(0.7837, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(1.3447, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
tensor(1.6299, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.9219, device='cuda:0', dtype=torch.float16) tensor(1.5352, device='cuda:0', dtype=torch.float16)
tensor(2.2812, device='cuda:0', dtype=torch.float16) tensor(0.2000, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1891, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1838, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1963, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.4086, device='cuda:0')
old_score: tensor(0.1924, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1348, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.799034833908081
Validation after dual ascent:
out_inf: tensor(21.9219, device='cuda:0', dtype=torch.float16) tensor(1.5352, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
tensor(1.3350, device='cuda:0', dtype=torch.float16) tensor(0.1359, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1376, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1335, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.7598, device='cuda:0', dtype=torch.float16) tensor(0.1940, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.5767, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(0.5068, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0052, device='cuda:0')
tensor(0.1471, device='cuda:0')
old_score: tensor(0.0600, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0460, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7999327182769775
Validation after dual ascent:
out_inf: tensor(2.7598, device='cuda:0', dtype=torch.float16) tensor(0.1940, device='cuda:0', dtype=torch.float16)
tensor(0.4116, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.4524, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.4417, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.4978, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.1309, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
tensor(0.2607, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
tensor(0.2090, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.2427, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.1973, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0032, device='cuda:0')
tensor(0.0325, device='cuda:0')
old_score: tensor(0.0149, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0093, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7341113090515137
Validation after dual ascent:
out_inf: tensor(3.1309, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
tensor(0.1948, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1487, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1807, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1616, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.1719, device='cuda:0', dtype=torch.float16) tensor(0.3999, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.0719, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0089, device='cuda:0')
tensor(0.0604, device='cuda:0')
old_score: tensor(0.0715, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0524, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.195399522781372
Validation after dual ascent:
out_inf: tensor(8.1719, device='cuda:0', dtype=torch.float16) tensor(0.3999, device='cuda:0', dtype=torch.float16)
tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.5273, device='cuda:0', dtype=torch.float16) tensor(0.1764, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0563, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0151, device='cuda:0')
tensor(0.2903, device='cuda:0')
old_score: tensor(0.0560, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0423, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.782364130020142
Validation after dual ascent:
out_inf: tensor(4.5273, device='cuda:0', dtype=torch.float16) tensor(0.1764, device='cuda:0', dtype=torch.float16)
tensor(0.3704, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.9863, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.1899, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.2168, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.2051, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0067, device='cuda:0')
tensor(0.0178, device='cuda:0')
old_score: tensor(0.0135, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.820066213607788
Validation after dual ascent:
out_inf: tensor(1.9863, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.1462, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1506, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.8594, device='cuda:0', dtype=torch.float16) tensor(0.7515, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.1150, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1161, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0088, device='cuda:0')
tensor(0.1781, device='cuda:0')
old_score: tensor(0.1149, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0809, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.200137138366699
Validation after dual ascent:
out_inf: tensor(14.8594, device='cuda:0', dtype=torch.float16) tensor(0.7515, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(1.0322, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.1719, device='cuda:0', dtype=torch.float16) tensor(1.5117, device='cuda:0', dtype=torch.float16)
tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.1848, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.1761, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1710, device='cuda:0', dtype=torch.float16)
tensor(2.1797, device='cuda:0', dtype=torch.float16) tensor(0.1819, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0150, device='cuda:0')
tensor(0.3459, device='cuda:0')
old_score: tensor(0.1785, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1223, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7954792976379395
Validation after dual ascent:
out_inf: tensor(21.1719, device='cuda:0', dtype=torch.float16) tensor(1.5117, device='cuda:0', dtype=torch.float16)
tensor(1.5254, device='cuda:0', dtype=torch.float16) tensor(0.1196, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
tensor(1.5830, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.2695, device='cuda:0', dtype=torch.float16) tensor(0.1937, device='cuda:0', dtype=torch.float16)
tensor(0.4319, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.4412, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.4924, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0043, device='cuda:0')
tensor(0.1156, device='cuda:0')
old_score: tensor(0.0527, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0395, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7968916893005371
Validation after dual ascent:
out_inf: tensor(2.2695, device='cuda:0', dtype=torch.float16) tensor(0.1937, device='cuda:0', dtype=torch.float16)
tensor(0.3359, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.3538, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.3665, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.3757, device='cuda:0', dtype=torch.float16) tensor(0.0387, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.8164, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.2319, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.2178, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.2783, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0139, device='cuda:0')
tensor(0.0249, device='cuda:0')
old_score: tensor(0.0135, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7342023849487305
Validation after dual ascent:
out_inf: tensor(3.8164, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.1182, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1587, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1204, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.4844, device='cuda:0', dtype=torch.float16) tensor(0.3877, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(1.8242, device='cuda:0', dtype=torch.float16) tensor(0.0735, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0086, device='cuda:0')
tensor(0.0704, device='cuda:0')
old_score: tensor(0.0743, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0551, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.202380180358887
Validation after dual ascent:
out_inf: tensor(7.4844, device='cuda:0', dtype=torch.float16) tensor(0.3877, device='cuda:0', dtype=torch.float16)
tensor(1.0137, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.4355, device='cuda:0', dtype=torch.float16) tensor(0.1714, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.3163, device='cuda:0')
old_score: tensor(0.0561, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0428, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.789356708526611
Validation after dual ascent:
out_inf: tensor(3.4355, device='cuda:0', dtype=torch.float16) tensor(0.1714, device='cuda:0', dtype=torch.float16)
tensor(0.4346, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.1914, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.2057, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.2278, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.2036, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0067, device='cuda:0')
tensor(0.0180, device='cuda:0')
old_score: tensor(0.0131, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0100, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.804790496826172
Validation after dual ascent:
out_inf: tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.1128, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1290, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1797, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1472, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.1406, device='cuda:0', dtype=torch.float16) tensor(0.7559, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.1198, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1188, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1186, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0091, device='cuda:0')
tensor(0.1879, device='cuda:0')
old_score: tensor(0.1176, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0836, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2053024768829346
Validation after dual ascent:
out_inf: tensor(18.1406, device='cuda:0', dtype=torch.float16) tensor(0.7559, device='cuda:0', dtype=torch.float16)
tensor(1.0576, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.5156, device='cuda:0', dtype=torch.float16) tensor(1.4668, device='cuda:0', dtype=torch.float16)
tensor(1.8984, device='cuda:0', dtype=torch.float16) tensor(0.1851, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.1820, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1738, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1826, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.3715, device='cuda:0')
old_score: tensor(0.1809, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1261, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8025591373443604
Validation after dual ascent:
out_inf: tensor(19.5156, device='cuda:0', dtype=torch.float16) tensor(1.4668, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1219, device='cuda:0', dtype=torch.float16)
tensor(1.4365, device='cuda:0', dtype=torch.float16) tensor(0.1310, device='cuda:0', dtype=torch.float16)
tensor(1.3350, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(1.4131, device='cuda:0', dtype=torch.float16) tensor(0.1231, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3652, device='cuda:0', dtype=torch.float16) tensor(0.1799, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.4915, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.4763, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0051, device='cuda:0')
tensor(0.1441, device='cuda:0')
old_score: tensor(0.0598, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0455, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8031346797943115
Validation after dual ascent:
out_inf: tensor(2.3652, device='cuda:0', dtype=torch.float16) tensor(0.1799, device='cuda:0', dtype=torch.float16)
tensor(0.3940, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.4004, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.3911, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.3760, device='cuda:0', dtype=torch.float16) tensor(0.0444, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.0362, device='cuda:0', dtype=torch.float16)
tensor(0.3008, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.3359, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.2920, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.3711, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0153, device='cuda:0')
tensor(0.0236, device='cuda:0')
old_score: tensor(0.0122, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.915759325027466
Validation after dual ascent:
out_inf: tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.0362, device='cuda:0', dtype=torch.float16)
tensor(0.1240, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.1357, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.1582, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.1328, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.6133, device='cuda:0', dtype=torch.float16) tensor(0.3938, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.0766, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.0791, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0755, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0095, device='cuda:0')
tensor(0.0738, device='cuda:0')
old_score: tensor(0.0767, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0551, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.20605182647705
Validation after dual ascent:
out_inf: tensor(7.6133, device='cuda:0', dtype=torch.float16) tensor(0.3938, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(1.7070, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(1.4961, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.8540, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.2324, device='cuda:0', dtype=torch.float16) tensor(0.1731, device='cuda:0', dtype=torch.float16)
tensor(0.5674, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.7012, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(0.5581, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0162, device='cuda:0')
tensor(0.3213, device='cuda:0')
old_score: tensor(0.0571, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0422, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.79116153717041
Validation after dual ascent:
out_inf: tensor(3.2324, device='cuda:0', dtype=torch.float16) tensor(0.1731, device='cuda:0', dtype=torch.float16)
tensor(0.4150, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.4590, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
tensor(0.3745, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1885, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.2266, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.2205, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.2666, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0040, device='cuda:0')
tensor(0.0192, device='cuda:0')
old_score: tensor(0.0139, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.793384552001953
Validation after dual ascent:
out_inf: tensor(1.1885, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.1792, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1735, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1714, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1587, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.6719, device='cuda:0', dtype=torch.float16) tensor(0.7085, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(2.4766, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0091, device='cuda:0')
tensor(0.1881, device='cuda:0')
old_score: tensor(0.1158, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0819, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2070932388305664
Validation after dual ascent:
out_inf: tensor(15.6719, device='cuda:0', dtype=torch.float16) tensor(0.7085, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.0788, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4844, device='cuda:0', dtype=torch.float16) tensor(1.4805, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1836, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1851, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1769, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1830, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0157, device='cuda:0')
tensor(0.3722, device='cuda:0')
old_score: tensor(0.1821, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1265, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8026840686798096
Validation after dual ascent:
out_inf: tensor(19.4844, device='cuda:0', dtype=torch.float16) tensor(1.4805, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.1332, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
tensor(1.2334, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.8027, device='cuda:0', dtype=torch.float16) tensor(0.1826, device='cuda:0', dtype=torch.float16)
tensor(0.5132, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(0.4958, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.4800, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.4438, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0045, device='cuda:0')
tensor(0.1227, device='cuda:0')
old_score: tensor(0.0528, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0394, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.80672287940979
Validation after dual ascent:
out_inf: tensor(2.8027, device='cuda:0', dtype=torch.float16) tensor(0.1826, device='cuda:0', dtype=torch.float16)
tensor(0.3599, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.3862, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.4150, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(0.3667, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.7500, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.2966, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.2354, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.2012, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.3252, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0193, device='cuda:0')
old_score: tensor(0.0078, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0046, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.833917379379272
Validation after dual ascent:
out_inf: tensor(2.7500, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.2603, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
tensor(0.2280, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.1555, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.2119, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.9844, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0088, device='cuda:0')
tensor(0.0789, device='cuda:0')
old_score: tensor(0.0775, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0557, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.24473524093628
Validation after dual ascent:
out_inf: tensor(6.9844, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(1.0283, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.5723, device='cuda:0', dtype=torch.float16) tensor(0.1660, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.3368, device='cuda:0')
old_score: tensor(0.0572, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0422, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.792999029159546
Validation after dual ascent:
out_inf: tensor(3.5723, device='cuda:0', dtype=torch.float16) tensor(0.1660, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.4434, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.1973, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1866, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.2057, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.1855, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0039, device='cuda:0')
tensor(0.0183, device='cuda:0')
old_score: tensor(0.0131, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0100, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.844547986984253
Validation after dual ascent:
out_inf: tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.1459, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1661, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1770, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1479, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.3984, device='cuda:0', dtype=torch.float16) tensor(0.7393, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1148, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(1.6523, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0095, device='cuda:0')
tensor(0.1883, device='cuda:0')
old_score: tensor(0.1152, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0803, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2072482109069824
Validation after dual ascent:
out_inf: tensor(13.3984, device='cuda:0', dtype=torch.float16) tensor(0.7393, device='cuda:0', dtype=torch.float16)
tensor(1.0986, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(1.2227, device='cuda:0', dtype=torch.float16) tensor(0.0855, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.7344, device='cuda:0', dtype=torch.float16) tensor(1.4424, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1742, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1777, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1710, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1738, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0151, device='cuda:0')
tensor(0.3581, device='cuda:0')
old_score: tensor(0.1742, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1196, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8002259731292725
Validation after dual ascent:
out_inf: tensor(17.7344, device='cuda:0', dtype=torch.float16) tensor(1.4424, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1133, device='cuda:0', dtype=torch.float16)
tensor(1.3174, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(1.3457, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.8359, device='cuda:0', dtype=torch.float16) tensor(0.2029, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.4778, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0048, device='cuda:0')
tensor(0.1309, device='cuda:0')
old_score: tensor(0.0565, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0413, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8008053302764893
Validation after dual ascent:
out_inf: tensor(2.8359, device='cuda:0', dtype=torch.float16) tensor(0.2029, device='cuda:0', dtype=torch.float16)
tensor(0.4072, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.4165, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.3962, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.3794, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.2393, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.2177, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.3901, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.0219, device='cuda:0')
old_score: tensor(0.0084, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.84307074546814
Validation after dual ascent:
out_inf: tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.1667, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.1831, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.2781, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.3281, device='cuda:0', dtype=torch.float16) tensor(0.3662, device='cuda:0', dtype=torch.float16)
tensor(2.0625, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(1.7148, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0091, device='cuda:0')
tensor(0.0826, device='cuda:0')
old_score: tensor(0.0790, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0565, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.248316049575806
Validation after dual ascent:
out_inf: tensor(11.3281, device='cuda:0', dtype=torch.float16) tensor(0.3662, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(2.5273, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
tensor(1.0107, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4766, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0170, device='cuda:0')
tensor(0.3463, device='cuda:0')
old_score: tensor(0.0577, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0423, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.795894384384155
Validation after dual ascent:
out_inf: tensor(4.4766, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
tensor(0.4292, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.2035, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.1816, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.1794, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0037, device='cuda:0')
tensor(0.0185, device='cuda:0')
old_score: tensor(0.0130, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0098, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.837390661239624
Validation after dual ascent:
out_inf: tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.1544, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1631, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1353, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1528, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.8906, device='cuda:0', dtype=torch.float16) tensor(0.7134, device='cuda:0', dtype=torch.float16)
tensor(1.6328, device='cuda:0', dtype=torch.float16) tensor(0.1095, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0097, device='cuda:0')
tensor(0.1914, device='cuda:0')
old_score: tensor(0.1099, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0767, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2029855251312256
Validation after dual ascent:
out_inf: tensor(16.8906, device='cuda:0', dtype=torch.float16) tensor(0.7134, device='cuda:0', dtype=torch.float16)
tensor(1.1689, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.0781, device='cuda:0', dtype=torch.float16) tensor(1.4824, device='cuda:0', dtype=torch.float16)
tensor(1.5791, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.1691, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1625, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1630, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0145, device='cuda:0')
tensor(0.3327, device='cuda:0')
old_score: tensor(0.1649, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7954754829406738
Validation after dual ascent:
out_inf: tensor(19.0781, device='cuda:0', dtype=torch.float16) tensor(1.4824, device='cuda:0', dtype=torch.float16)
tensor(1.3076, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(1.4014, device='cuda:0', dtype=torch.float16) tensor(0.1219, device='cuda:0', dtype=torch.float16)
tensor(1.2227, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.2006, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.5210, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.4924, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.1351, device='cuda:0')
old_score: tensor(0.0580, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0424, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.796929121017456
Validation after dual ascent:
out_inf: tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.2006, device='cuda:0', dtype=torch.float16)
tensor(0.4700, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.4907, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.4475, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.2617, device='cuda:0', dtype=torch.float16) tensor(0.0347, device='cuda:0', dtype=torch.float16)
tensor(0.1924, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1719, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1804, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2139, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0173, device='cuda:0')
tensor(0.0339, device='cuda:0')
old_score: tensor(0.0091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0057, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.193904161453247
Validation after dual ascent:
out_inf: tensor(2.2617, device='cuda:0', dtype=torch.float16) tensor(0.0347, device='cuda:0', dtype=torch.float16)
tensor(0.1802, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.1475, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.1658, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.1533, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.7930, device='cuda:0', dtype=torch.float16) tensor(0.3694, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.0808, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(1.5898, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(1.4316, device='cuda:0', dtype=torch.float16) tensor(0.0804, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0089, device='cuda:0')
tensor(0.0920, device='cuda:0')
old_score: tensor(0.0818, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0577, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.217777490615845
Validation after dual ascent:
out_inf: tensor(7.7930, device='cuda:0', dtype=torch.float16) tensor(0.3694, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.9775, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0156, device='cuda:0', dtype=torch.float16) tensor(0.1692, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0179, device='cuda:0')
tensor(0.3716, device='cuda:0')
old_score: tensor(0.0598, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0433, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.773888826370239
Validation after dual ascent:
out_inf: tensor(4.0156, device='cuda:0', dtype=torch.float16) tensor(0.1692, device='cuda:0', dtype=torch.float16)
tensor(0.4600, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1416, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1978, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.1984, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1575, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0027, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.0136, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.73418402671814
Validation after dual ascent:
out_inf: tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1299, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1465, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1318, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.q_proj
Validation after prune:
out_inf: tensor(20.1719, device='cuda:0', dtype=torch.float16) tensor(0.7051, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(1.9375, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0111, device='cuda:0')
tensor(0.1624, device='cuda:0')
old_score: tensor(0.1052, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0729, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2033848762512207
Validation after dual ascent:
out_inf: tensor(20.1719, device='cuda:0', dtype=torch.float16) tensor(0.7051, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(1.2031, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.5156, device='cuda:0', dtype=torch.float16) tensor(1.4219, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1605, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1661, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1594, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1600, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0143, device='cuda:0')
tensor(0.3060, device='cuda:0')
old_score: tensor(0.1615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1104, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7951869964599609
Validation after dual ascent:
out_inf: tensor(21.5156, device='cuda:0', dtype=torch.float16) tensor(1.4219, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.3770, device='cuda:0', dtype=torch.float16) tensor(0.2078, device='cuda:0', dtype=torch.float16)
tensor(0.4490, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
tensor(0.5317, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.4331, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0048, device='cuda:0')
tensor(0.1281, device='cuda:0')
old_score: tensor(0.0582, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0419, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7972800731658936
Validation after dual ascent:
out_inf: tensor(3.3770, device='cuda:0', dtype=torch.float16) tensor(0.2078, device='cuda:0', dtype=torch.float16)
tensor(0.4934, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.4312, device='cuda:0', dtype=torch.float16) tensor(0.0454, device='cuda:0', dtype=torch.float16)
tensor(0.4111, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
tensor(0.4263, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.3096, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.2852, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.3867, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.2383, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0183, device='cuda:0')
tensor(0.0423, device='cuda:0')
old_score: tensor(0.0119, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.279928922653198
Validation after dual ascent:
out_inf: tensor(1.3096, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.1890, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.1399, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.1182, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.7500, device='cuda:0', dtype=torch.float16) tensor(0.3901, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(1.7051, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0098, device='cuda:0')
tensor(0.0924, device='cuda:0')
old_score: tensor(0.0831, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0580, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.213398456573486
Validation after dual ascent:
out_inf: tensor(8.7500, device='cuda:0', dtype=torch.float16) tensor(0.3901, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(1.1787, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(1.4727, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.3008, device='cuda:0', dtype=torch.float16) tensor(0.1716, device='cuda:0', dtype=torch.float16)
tensor(0.4939, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0180, device='cuda:0')
tensor(0.3697, device='cuda:0')
old_score: tensor(0.0604, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0432, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.770934581756592
Validation after dual ascent:
out_inf: tensor(4.3008, device='cuda:0', dtype=torch.float16) tensor(0.1716, device='cuda:0', dtype=torch.float16)
tensor(0.5664, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.4675, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.4365, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1455, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.1592, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.2314, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.2107, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.1709, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0031, device='cuda:0')
tensor(0.0199, device='cuda:0')
old_score: tensor(0.0142, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.731420278549194
Validation after dual ascent:
out_inf: tensor(1.1455, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.1287, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1484, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1702, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1292, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.7656, device='cuda:0', dtype=torch.float16) tensor(0.6836, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.0992, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.0992, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0119, device='cuda:0')
tensor(0.1630, device='cuda:0')
old_score: tensor(0.1011, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0695, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2026333808898926
Validation after dual ascent:
out_inf: tensor(18.7656, device='cuda:0', dtype=torch.float16) tensor(0.6836, device='cuda:0', dtype=torch.float16)
tensor(0.9380, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.4375, device='cuda:0', dtype=torch.float16) tensor(1.4600, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.2878, device='cuda:0')
old_score: tensor(0.1539, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1044, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.794513463973999
Validation after dual ascent:
out_inf: tensor(18.4375, device='cuda:0', dtype=torch.float16) tensor(1.4600, device='cuda:0', dtype=torch.float16)
tensor(1.1318, device='cuda:0', dtype=torch.float16) tensor(0.0984, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(1.1504, device='cuda:0', dtype=torch.float16) tensor(0.1066, device='cuda:0', dtype=torch.float16)
tensor(1.0732, device='cuda:0', dtype=torch.float16) tensor(0.0995, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.5527, device='cuda:0', dtype=torch.float16) tensor(0.2104, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(0.4951, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.4800, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0050, device='cuda:0')
tensor(0.1302, device='cuda:0')
old_score: tensor(0.0605, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0432, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7954709529876709
Validation after dual ascent:
out_inf: tensor(3.5527, device='cuda:0', dtype=torch.float16) tensor(0.2104, device='cuda:0', dtype=torch.float16)
tensor(0.4885, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.4070, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.3887, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.3018, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.2135, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.3628, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1812, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.2046, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0141, device='cuda:0')
tensor(0.0323, device='cuda:0')
old_score: tensor(0.0090, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0058, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.123286008834839
Validation after dual ascent:
out_inf: tensor(1.3018, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.2852, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.3708, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.1829, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.1392, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.5430, device='cuda:0', dtype=torch.float16) tensor(0.3750, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(1.3789, device='cuda:0', dtype=torch.float16) tensor(0.0830, device='cuda:0', dtype=torch.float16)
tensor(1.1367, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0095, device='cuda:0')
tensor(0.0956, device='cuda:0')
old_score: tensor(0.0829, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0582, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.212890148162842
Validation after dual ascent:
out_inf: tensor(7.5430, device='cuda:0', dtype=torch.float16) tensor(0.3750, device='cuda:0', dtype=torch.float16)
tensor(0.9893, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.8223, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
tensor(0.5996, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0184, device='cuda:0')
tensor(0.3794, device='cuda:0')
old_score: tensor(0.0605, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0435, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.782957315444946
Validation after dual ascent:
out_inf: tensor(3.8223, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(0.4985, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.4229, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.7388, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.1599, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1719, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.1865, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
tensor(0.1656, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0030, device='cuda:0')
tensor(0.0189, device='cuda:0')
old_score: tensor(0.0137, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0100, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.770331144332886
Validation after dual ascent:
out_inf: tensor(0.7388, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.1350, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1372, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1389, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1204, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.q_proj
Validation after prune:
out_inf: tensor(20.7656, device='cuda:0', dtype=torch.float16) tensor(0.7100, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0984, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0978, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0124, device='cuda:0')
tensor(0.1505, device='cuda:0')
old_score: tensor(0.0995, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0692, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2013094425201416
Validation after dual ascent:
out_inf: tensor(20.7656, device='cuda:0', dtype=torch.float16) tensor(0.7100, device='cuda:0', dtype=torch.float16)
tensor(1.1182, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(1.0537, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.8833, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.4219, device='cuda:0', dtype=torch.float16) tensor(1.3887, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1489, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1500, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.2822, device='cuda:0')
old_score: tensor(0.1505, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1037, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7903575897216797
Validation after dual ascent:
out_inf: tensor(20.4219, device='cuda:0', dtype=torch.float16) tensor(1.3887, device='cuda:0', dtype=torch.float16)
tensor(1.1885, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
tensor(1.2451, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.1299, device='cuda:0', dtype=torch.float16) tensor(0.0993, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.7109, device='cuda:0', dtype=torch.float16) tensor(0.2039, device='cuda:0', dtype=torch.float16)
tensor(0.5044, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.5479, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0053, device='cuda:0')
tensor(0.1367, device='cuda:0')
old_score: tensor(0.0632, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0454, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7920620441436768
Validation after dual ascent:
out_inf: tensor(2.7109, device='cuda:0', dtype=torch.float16) tensor(0.2039, device='cuda:0', dtype=torch.float16)
tensor(0.4829, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
tensor(0.4580, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.4734, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.6650, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.2402, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.2080, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1970, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1895, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0162, device='cuda:0')
tensor(0.0312, device='cuda:0')
old_score: tensor(0.0092, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0058, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.295740365982056
Validation after dual ascent:
out_inf: tensor(0.6650, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.1316, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.2096, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.2097, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.0938, device='cuda:0', dtype=torch.float16) tensor(0.3696, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(1.7773, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(1.1807, device='cuda:0', dtype=torch.float16) tensor(0.0808, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0949, device='cuda:0')
old_score: tensor(0.0826, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0581, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.210797309875488
Validation after dual ascent:
out_inf: tensor(10.0938, device='cuda:0', dtype=torch.float16) tensor(0.3696, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(2.2070, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.7969, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(0.5996, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0185, device='cuda:0')
tensor(0.3788, device='cuda:0')
old_score: tensor(0.0607, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0434, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.772547245025635
Validation after dual ascent:
out_inf: tensor(3.7969, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(0.5713, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.4536, device='cuda:0', dtype=torch.float16) tensor(0.0419, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.8916, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1553, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1715, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.1896, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0030, device='cuda:0')
tensor(0.0178, device='cuda:0')
old_score: tensor(0.0133, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.660204887390137
Validation after dual ascent:
out_inf: tensor(0.8916, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.1411, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1592, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1619, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1882, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.q_proj
Validation after prune:
out_inf: tensor(21.9219, device='cuda:0', dtype=torch.float16) tensor(0.7139, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(1.6719, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0142, device='cuda:0')
tensor(0.1389, device='cuda:0')
old_score: tensor(0.0961, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0661, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2096099853515625
Validation after dual ascent:
out_inf: tensor(21.9219, device='cuda:0', dtype=torch.float16) tensor(0.7139, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.0781, device='cuda:0', dtype=torch.float16) tensor(1.3672, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
tensor(1.3828, device='cuda:0', dtype=torch.float16) tensor(0.1428, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1378, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.1680, device='cuda:0', dtype=torch.float16) tensor(0.2349, device='cuda:0', dtype=torch.float16)
tensor(0.6924, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.5889, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.5542, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0055, device='cuda:0')
tensor(0.1392, device='cuda:0')
old_score: tensor(0.0676, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0481, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7919735908508301
Validation after dual ascent:
out_inf: tensor(4.1680, device='cuda:0', dtype=torch.float16) tensor(0.2349, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.6260, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.8232, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.3240, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.2430, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.2620, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.2957, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.0224, device='cuda:0')
old_score: tensor(0.0092, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0055, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.905431985855103
Validation after dual ascent:
out_inf: tensor(0.8232, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.2444, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.2288, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.2288, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.1760, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.gate_proj
Validation after prune:
out_inf: tensor(12.0156, device='cuda:0', dtype=torch.float16) tensor(0.3723, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0095, device='cuda:0')
tensor(0.0965, device='cuda:0')
old_score: tensor(0.0834, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0585, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.24527907371521
Validation after dual ascent:
out_inf: tensor(12.0156, device='cuda:0', dtype=torch.float16) tensor(0.3723, device='cuda:0', dtype=torch.float16)
tensor(1.0791, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(1.6797, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(1.1367, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.9365, device='cuda:0', dtype=torch.float16) tensor(0.0563, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1445, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.3841, device='cuda:0')
old_score: tensor(0.0615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0437, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.796967267990112
Validation after dual ascent:
out_inf: tensor(4.1445, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.7012, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.4829, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.1443, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1897, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.1639, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.1713, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0031, device='cuda:0')
tensor(0.0175, device='cuda:0')
old_score: tensor(0.0132, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.639280319213867
Validation after dual ascent:
out_inf: tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.1382, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1481, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1350, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1566, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.q_proj
Validation after prune:
out_inf: tensor(23.9688, device='cuda:0', dtype=torch.float16) tensor(0.7622, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.0978, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1001, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0162, device='cuda:0')
tensor(0.1322, device='cuda:0')
old_score: tensor(0.0979, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0663, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.206768751144409
Validation after dual ascent:
out_inf: tensor(23.9688, device='cuda:0', dtype=torch.float16) tensor(0.7622, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0719, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.9219, device='cuda:0', dtype=torch.float16) tensor(1.3369, device='cuda:0', dtype=torch.float16)
tensor(1.9375, device='cuda:0', dtype=torch.float16) tensor(0.1428, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1406, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.2607, device='cuda:0')
old_score: tensor(0.1423, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0957, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7934186458587646
Validation after dual ascent:
out_inf: tensor(21.9219, device='cuda:0', dtype=torch.float16) tensor(1.3369, device='cuda:0', dtype=torch.float16)
tensor(1.4990, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(1.2930, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.8711, device='cuda:0', dtype=torch.float16) tensor(0.2556, device='cuda:0', dtype=torch.float16)
tensor(0.6377, device='cuda:0', dtype=torch.float16) tensor(0.0700, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0705, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0057, device='cuda:0')
tensor(0.1422, device='cuda:0')
old_score: tensor(0.0709, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0498, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7939894199371338
Validation after dual ascent:
out_inf: tensor(3.8711, device='cuda:0', dtype=torch.float16) tensor(0.2556, device='cuda:0', dtype=torch.float16)
tensor(0.6167, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
tensor(0.5171, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.4854, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.5918, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.2827, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.3467, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.4331, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.2720, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.0248, device='cuda:0')
old_score: tensor(0.0082, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0052, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.901004791259766
Validation after dual ascent:
out_inf: tensor(1.5918, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.2479, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.2793, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.2559, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.1311, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.5000, device='cuda:0', dtype=torch.float16) tensor(0.3984, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.0888, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.0851, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0103, device='cuda:0')
tensor(0.1010, device='cuda:0')
old_score: tensor(0.0854, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0599, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.242128610610962
Validation after dual ascent:
out_inf: tensor(9.5000, device='cuda:0', dtype=torch.float16) tensor(0.3984, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.5938, device='cuda:0', dtype=torch.float16) tensor(0.1713, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0193, device='cuda:0')
tensor(0.3986, device='cuda:0')
old_score: tensor(0.0630, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0449, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7967541217803955
Validation after dual ascent:
out_inf: tensor(4.5938, device='cuda:0', dtype=torch.float16) tensor(0.1713, device='cuda:0', dtype=torch.float16)
tensor(0.5923, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.3125, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.1460, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.1753, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.1628, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.1660, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0030, device='cuda:0')
tensor(0.0184, device='cuda:0')
old_score: tensor(0.0138, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0100, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.56804895401001
Validation after dual ascent:
out_inf: tensor(4.3125, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.1573, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1566, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1538, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1678, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.6406, device='cuda:0', dtype=torch.float16) tensor(0.7368, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0141, device='cuda:0')
tensor(0.1175, device='cuda:0')
old_score: tensor(0.0945, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0645, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1964149475097656
Validation after dual ascent:
out_inf: tensor(16.6406, device='cuda:0', dtype=torch.float16) tensor(0.7368, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0700, device='cuda:0', dtype=torch.float16)
tensor(0.9272, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.1094, device='cuda:0', dtype=torch.float16) tensor(1.4883, device='cuda:0', dtype=torch.float16)
tensor(1.8496, device='cuda:0', dtype=torch.float16) tensor(0.1396, device='cuda:0', dtype=torch.float16)
tensor(1.6299, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
tensor(1.9238, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.6895, device='cuda:0', dtype=torch.float16) tensor(0.2196, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0702, device='cuda:0', dtype=torch.float16)
tensor(0.8955, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.6045, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0056, device='cuda:0')
tensor(0.1411, device='cuda:0')
old_score: tensor(0.0712, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0506, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7920558452606201
Validation after dual ascent:
out_inf: tensor(3.6895, device='cuda:0', dtype=torch.float16) tensor(0.2196, device='cuda:0', dtype=torch.float16)
tensor(0.5684, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.5552, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.4966, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0029, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.2812, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.3633, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.5972, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0148, device='cuda:0')
tensor(0.0296, device='cuda:0')
old_score: tensor(0.0113, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0064, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.242614269256592
Validation after dual ascent:
out_inf: tensor(1.0029, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.2539, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1660, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.5850, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.1924, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.9766, device='cuda:0', dtype=torch.float16) tensor(0.4380, device='cuda:0', dtype=torch.float16)
tensor(1.4805, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(1.6797, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(1.7617, device='cuda:0', dtype=torch.float16) tensor(0.0885, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0118, device='cuda:0')
tensor(0.1104, device='cuda:0')
old_score: tensor(0.0886, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0613, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.244720935821533
Validation after dual ascent:
out_inf: tensor(8.9766, device='cuda:0', dtype=torch.float16) tensor(0.4380, device='cuda:0', dtype=torch.float16)
tensor(1.2471, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4297, device='cuda:0', dtype=torch.float16) tensor(0.1842, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
tensor(0.6475, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0049, device='cuda:0')
tensor(0.0815, device='cuda:0')
old_score: tensor(0.0656, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0462, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.254263877868652
Validation after dual ascent:
out_inf: tensor(4.4297, device='cuda:0', dtype=torch.float16) tensor(0.1842, device='cuda:0', dtype=torch.float16)
tensor(0.6401, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.5024, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.0977, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.1880, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.1890, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.1982, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.2000, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0031, device='cuda:0')
tensor(0.0215, device='cuda:0')
old_score: tensor(0.0151, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.579235076904297
Validation after dual ascent:
out_inf: tensor(4.0977, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.1748, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.1761, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1654, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1887, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.q_proj
Validation after prune:
out_inf: tensor(21.8438, device='cuda:0', dtype=torch.float16) tensor(0.7295, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(2.1016, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(2.2266, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(0.0590, device='cuda:0')
old_score: tensor(0.1005, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0672, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.896896123886108
Validation after dual ascent:
out_inf: tensor(21.8438, device='cuda:0', dtype=torch.float16) tensor(0.7295, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.0639, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.9531, device='cuda:0', dtype=torch.float16) tensor(1.4639, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1562, device='cuda:0', dtype=torch.float16)
tensor(1.9883, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0166, device='cuda:0')
tensor(0.1408, device='cuda:0')
old_score: tensor(0.1510, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0989, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9790551662445068
Validation after dual ascent:
out_inf: tensor(18.9531, device='cuda:0', dtype=torch.float16) tensor(1.4639, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(1.2930, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0979, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.0352, device='cuda:0', dtype=torch.float16) tensor(0.3015, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.8887, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(0.7529, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0072, device='cuda:0')
tensor(0.0947, device='cuda:0')
old_score: tensor(0.0813, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0567, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9792017936706543
Validation after dual ascent:
out_inf: tensor(4.0352, device='cuda:0', dtype=torch.float16) tensor(0.3015, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.8081, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.6357, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.6201, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.7939, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.5542, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0301, device='cuda:0')
old_score: tensor(0.0101, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0061, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.901141881942749
Validation after dual ascent:
out_inf: tensor(1.7939, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.2278, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.4849, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.2715, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.1172, device='cuda:0', dtype=torch.float16) tensor(0.4924, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0134, device='cuda:0')
tensor(0.1301, device='cuda:0')
old_score: tensor(0.0939, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0647, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.250979661941528
Validation after dual ascent:
out_inf: tensor(9.1172, device='cuda:0', dtype=torch.float16) tensor(0.4924, device='cuda:0', dtype=torch.float16)
tensor(1.5293, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(1.4629, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.5859, device='cuda:0', dtype=torch.float16) tensor(0.2046, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0697, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0057, device='cuda:0')
tensor(0.0963, device='cuda:0')
old_score: tensor(0.0701, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0491, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.265301942825317
Validation after dual ascent:
out_inf: tensor(4.5859, device='cuda:0', dtype=torch.float16) tensor(0.2046, device='cuda:0', dtype=torch.float16)
tensor(0.7432, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.6553, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.5532, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.3477, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.1807, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.2218, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
tensor(0.2445, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
tensor(0.2074, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0042, device='cuda:0')
tensor(0.0270, device='cuda:0')
old_score: tensor(0.0173, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0121, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.49579405784607
Validation after dual ascent:
out_inf: tensor(6.3477, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.2131, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.2041, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.2556, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.2041, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.q_proj
Validation after prune:
out_inf: tensor(20.2969, device='cuda:0', dtype=torch.float16) tensor(0.7788, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
tensor(2.2812, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1032, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.1065, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0165, device='cuda:0')
tensor(0.1212, device='cuda:0')
old_score: tensor(0.1066, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0679, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.190561056137085
Validation after dual ascent:
out_inf: tensor(20.2969, device='cuda:0', dtype=torch.float16) tensor(0.7788, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.k_proj
Validation after prune:
out_inf: tensor(22.5781, device='cuda:0', dtype=torch.float16) tensor(1.4580, device='cuda:0', dtype=torch.float16)
tensor(2.1875, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
tensor(2.7344, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1516, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0152, device='cuda:0')
tensor(0.2575, device='cuda:0')
old_score: tensor(0.1565, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0978, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7885053157806396
Validation after dual ascent:
out_inf: tensor(22.5781, device='cuda:0', dtype=torch.float16) tensor(1.4580, device='cuda:0', dtype=torch.float16)
tensor(1.6797, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1073, device='cuda:0', dtype=torch.float16)
tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.2773, device='cuda:0', dtype=torch.float16) tensor(0.2700, device='cuda:0', dtype=torch.float16)
tensor(0.6826, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0888, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0843, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0068, device='cuda:0')
tensor(0.1785, device='cuda:0')
old_score: tensor(0.0862, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0600, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7899155616760254
Validation after dual ascent:
out_inf: tensor(5.2773, device='cuda:0', dtype=torch.float16) tensor(0.2700, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.6362, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.5132, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.5420, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0126, device='cuda:0')
tensor(0.0122, device='cuda:0')
old_score: tensor(0.0154, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0094, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.457798957824707
Validation after dual ascent:
out_inf: tensor(1.5420, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.3301, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.3281, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.gate_proj
Validation after prune:
out_inf: tensor(12.8047, device='cuda:0', dtype=torch.float16) tensor(0.5396, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(1.5898, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.0959, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0152, device='cuda:0')
tensor(0.1366, device='cuda:0')
old_score: tensor(0.0974, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0652, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.229602336883545
Validation after dual ascent:
out_inf: tensor(12.8047, device='cuda:0', dtype=torch.float16) tensor(0.5396, device='cuda:0', dtype=torch.float16)
tensor(1.3877, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0719, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.1758, device='cuda:0', dtype=torch.float16) tensor(0.2347, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
tensor(0.8320, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0071, device='cuda:0')
tensor(0.1040, device='cuda:0')
old_score: tensor(0.0745, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0510, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.256684303283691
Validation after dual ascent:
out_inf: tensor(5.1758, device='cuda:0', dtype=torch.float16) tensor(0.2347, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.7339, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.6323, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(0.2245, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.3113, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.2754, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.2363, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0053, device='cuda:0')
tensor(0.0354, device='cuda:0')
old_score: tensor(0.0201, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0137, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.513630390167236
Validation after dual ascent:
out_inf: tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(0.2046, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.2903, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.2261, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.2178, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.7656, device='cuda:0', dtype=torch.float16) tensor(0.7339, device='cuda:0', dtype=torch.float16)
tensor(3.6680, device='cuda:0', dtype=torch.float16) tensor(0.1239, device='cuda:0', dtype=torch.float16)
tensor(2.7344, device='cuda:0', dtype=torch.float16) tensor(0.1224, device='cuda:0', dtype=torch.float16)
tensor(2.6289, device='cuda:0', dtype=torch.float16) tensor(0.1161, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.1199, device='cuda:0', dtype=torch.float16)
tensor(0.0636, device='cuda:0')
old_score: tensor(0.1205, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0702, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.86191439628601
Validation after dual ascent:
out_inf: tensor(12.7656, device='cuda:0', dtype=torch.float16) tensor(0.7339, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.0677, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.k_proj
Validation after prune:
out_inf: tensor(34.9375, device='cuda:0', dtype=torch.float16) tensor(1.3867, device='cuda:0', dtype=torch.float16)
tensor(9.5469, device='cuda:0', dtype=torch.float16) tensor(0.1919, device='cuda:0', dtype=torch.float16)
tensor(7.5312, device='cuda:0', dtype=torch.float16) tensor(0.1896, device='cuda:0', dtype=torch.float16)
tensor(7.2500, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(7.7969, device='cuda:0', dtype=torch.float16) tensor(0.1869, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0132, device='cuda:0')
tensor(0.1138, device='cuda:0')
old_score: tensor(0.1866, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1064, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9835412502288818
Validation after dual ascent:
out_inf: tensor(34.9375, device='cuda:0', dtype=torch.float16) tensor(1.3867, device='cuda:0', dtype=torch.float16)
tensor(4.9844, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(2.5156, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(2.7188, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.5781, device='cuda:0', dtype=torch.float16) tensor(0.3035, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.0987, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(0.7329, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0026, device='cuda:0')
tensor(0.0931, device='cuda:0')
old_score: tensor(0.0963, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0648, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9784491062164307
Validation after dual ascent:
out_inf: tensor(5.5781, device='cuda:0', dtype=torch.float16) tensor(0.3035, device='cuda:0', dtype=torch.float16)
tensor(0.7764, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(0.6812, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(0.5376, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.6113, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0194, device='cuda:0')
tensor(0.0238, device='cuda:0')
old_score: tensor(0.0102, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0056, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.855244398117065
Validation after dual ascent:
out_inf: tensor(1.6113, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.gate_proj
Validation after prune:
out_inf: tensor(14.5156, device='cuda:0', dtype=torch.float16) tensor(0.5537, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(1.6914, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(1.7832, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(1.6289, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0162, device='cuda:0')
tensor(0.1416, device='cuda:0')
old_score: tensor(0.1014, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0650, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.252808332443237
Validation after dual ascent:
out_inf: tensor(14.5156, device='cuda:0', dtype=torch.float16) tensor(0.5537, device='cuda:0', dtype=torch.float16)
tensor(1.5928, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(1.5098, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(1.3027, device='cuda:0', dtype=torch.float16) tensor(0.0625, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.up_proj
Validation after prune:
out_inf: tensor(10.5938, device='cuda:0', dtype=torch.float16) tensor(0.2781, device='cuda:0', dtype=torch.float16)
tensor(2.8945, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
tensor(2.5352, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(2.4805, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0086, device='cuda:0')
tensor(0.1111, device='cuda:0')
old_score: tensor(0.0804, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.26565670967102
Validation after dual ascent:
out_inf: tensor(10.5938, device='cuda:0', dtype=torch.float16) tensor(0.2781, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.down_proj
Validation after prune:
out_inf: tensor(10.2031, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(0.3369, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.3633, device='cuda:0', dtype=torch.float16) tensor(0.0252, device='cuda:0', dtype=torch.float16)
tensor(0.3857, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.3003, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0088, device='cuda:0')
tensor(0.0517, device='cuda:0')
old_score: tensor(0.0238, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0163, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.50122380256653
Validation after dual ascent:
out_inf: tensor(10.2031, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(0.2827, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.3350, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.3704, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.2778, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.6250, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(2.2266, device='cuda:0', dtype=torch.float16) tensor(0.1098, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(2.3438, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0177, device='cuda:0')
tensor(0.1171, device='cuda:0')
old_score: tensor(0.1078, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0624, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1882312297821045
Validation after dual ascent:
out_inf: tensor(15.6250, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(1.6172, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.5781, device='cuda:0', dtype=torch.float16) tensor(1.5322, device='cuda:0', dtype=torch.float16)
tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(2.2812, device='cuda:0', dtype=torch.float16) tensor(0.1549, device='cuda:0', dtype=torch.float16)
tensor(2.5000, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1533, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0146, device='cuda:0')
tensor(0.2311, device='cuda:0')
old_score: tensor(0.1530, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0859, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7896401882171631
Validation after dual ascent:
out_inf: tensor(20.5781, device='cuda:0', dtype=torch.float16) tensor(1.5322, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
tensor(1.1465, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.4023, device='cuda:0', dtype=torch.float16) tensor(0.3274, device='cuda:0', dtype=torch.float16)
tensor(0.8613, device='cuda:0', dtype=torch.float16) tensor(0.1102, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(0.9072, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(1.0586, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0085, device='cuda:0')
tensor(0.2227, device='cuda:0')
old_score: tensor(0.1094, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0732, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7879889011383057
Validation after dual ascent:
out_inf: tensor(5.4023, device='cuda:0', dtype=torch.float16) tensor(0.3274, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.8188, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.7393, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.6865, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.2852, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.2031, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0111, device='cuda:0')
tensor(0.0776, device='cuda:0')
old_score: tensor(0.0265, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0149, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.735246181488037
Validation after dual ascent:
out_inf: tensor(3.2852, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0163, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.gate_proj
Validation after prune:
out_inf: tensor(18.2344, device='cuda:0', dtype=torch.float16) tensor(0.6230, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
tensor(2.0820, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.1084, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0158, device='cuda:0')
tensor(0.0413, device='cuda:0')
old_score: tensor(0.1113, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0685, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.646785259246826
Validation after dual ascent:
out_inf: tensor(18.2344, device='cuda:0', dtype=torch.float16) tensor(0.6230, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.0755, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.up_proj
Validation after prune:
out_inf: tensor(11.6406, device='cuda:0', dtype=torch.float16) tensor(0.3716, device='cuda:0', dtype=torch.float16)
tensor(2.5820, device='cuda:0', dtype=torch.float16) tensor(0.0895, device='cuda:0', dtype=torch.float16)
tensor(2.4023, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
tensor(2.4453, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0137, device='cuda:0')
tensor(0.1231, device='cuda:0')
old_score: tensor(0.0894, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0552, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.260546684265137
Validation after dual ascent:
out_inf: tensor(11.6406, device='cuda:0', dtype=torch.float16) tensor(0.3716, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.down_proj
Validation after prune:
out_inf: tensor(11.8203, device='cuda:0', dtype=torch.float16) tensor(0.2013, device='cuda:0', dtype=torch.float16)
tensor(0.4795, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.5317, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.5176, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0191, device='cuda:0')
tensor(0.0959, device='cuda:0')
old_score: tensor(0.0314, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0208, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.456087350845337
Validation after dual ascent:
out_inf: tensor(11.8203, device='cuda:0', dtype=torch.float16) tensor(0.2013, device='cuda:0', dtype=torch.float16)
tensor(0.3997, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
tensor(0.4297, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.4324, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.7812, device='cuda:0', dtype=torch.float16) tensor(0.9058, device='cuda:0', dtype=torch.float16)
tensor(4.2031, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
tensor(4.6250, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
tensor(4.6094, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
tensor(4.5781, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0121, device='cuda:0')
tensor(0.0293, device='cuda:0')
old_score: tensor(0.1498, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0619, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.658166885375977
Validation after dual ascent:
out_inf: tensor(16.7812, device='cuda:0', dtype=torch.float16) tensor(0.9058, device='cuda:0', dtype=torch.float16)
tensor(1.6797, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(1.3457, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.8281, device='cuda:0', dtype=torch.float16) tensor(1.4297, device='cuda:0', dtype=torch.float16)
tensor(5.5703, device='cuda:0', dtype=torch.float16) tensor(0.2190, device='cuda:0', dtype=torch.float16)
tensor(5.3203, device='cuda:0', dtype=torch.float16) tensor(0.2173, device='cuda:0', dtype=torch.float16)
tensor(5.2422, device='cuda:0', dtype=torch.float16) tensor(0.2104, device='cuda:0', dtype=torch.float16)
tensor(5.3750, device='cuda:0', dtype=torch.float16) tensor(0.2126, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0186, device='cuda:0')
tensor(0.1938, device='cuda:0')
old_score: tensor(0.2148, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0865, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7934689521789551
Validation after dual ascent:
out_inf: tensor(18.8281, device='cuda:0', dtype=torch.float16) tensor(1.4297, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(1.4297, device='cuda:0', dtype=torch.float16) tensor(0.0949, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.7500, device='cuda:0', dtype=torch.float16) tensor(0.4082, device='cuda:0', dtype=torch.float16)
tensor(1.6562, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.1057, device='cuda:0', dtype=torch.float16)
tensor(1.6680, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0078, device='cuda:0')
tensor(0.1370, device='cuda:0')
old_score: tensor(0.1061, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0582, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7933187484741211
Validation after dual ascent:
out_inf: tensor(6.7500, device='cuda:0', dtype=torch.float16) tensor(0.4082, device='cuda:0', dtype=torch.float16)
tensor(0.6558, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.7607, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.6538, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.5078, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(0.7412, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.4319, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.6772, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0157, device='cuda:0')
tensor(0.0199, device='cuda:0')
old_score: tensor(0.0270, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0149, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1615569591522217
Validation after dual ascent:
out_inf: tensor(4.5078, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(0.3154, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.3179, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.gate_proj
Validation after prune:
out_inf: tensor(19.6094, device='cuda:0', dtype=torch.float16) tensor(0.6440, device='cuda:0', dtype=torch.float16)
tensor(5.4219, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
tensor(3.9062, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(4.9453, device='cuda:0', dtype=torch.float16) tensor(0.1365, device='cuda:0', dtype=torch.float16)
tensor(4.2500, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0193, device='cuda:0')
tensor(0.0242, device='cuda:0')
old_score: tensor(0.1353, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0634, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.142091274261475
Validation after dual ascent:
out_inf: tensor(19.6094, device='cuda:0', dtype=torch.float16) tensor(0.6440, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(2.0352, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(2.1621, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.up_proj
Validation after prune:
out_inf: tensor(22.0781, device='cuda:0', dtype=torch.float16) tensor(0.5557, device='cuda:0', dtype=torch.float16)
tensor(4.5195, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(4.7227, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(5.5312, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
tensor(4.1992, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0128, device='cuda:0')
tensor(0.0160, device='cuda:0')
old_score: tensor(0.1070, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0512, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.212342262268066
Validation after dual ascent:
out_inf: tensor(22.0781, device='cuda:0', dtype=torch.float16) tensor(0.5557, device='cuda:0', dtype=torch.float16)
tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
tensor(3.9062, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(3.8594, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(3.9688, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.down_proj
Validation after prune:
out_inf: tensor(199.3750, device='cuda:0', dtype=torch.float16) tensor(0.4805, device='cuda:0', dtype=torch.float16)
tensor(1.0557, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
tensor(0.8867, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(1.1221, device='cuda:0', dtype=torch.float16) tensor(0.0437, device='cuda:0', dtype=torch.float16)
tensor(1.0889, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.52it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.33it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.62it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.88it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.63it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.600001
layer 1 sparsity 0.600001
layer 2 sparsity 0.600001
layer 3 sparsity 0.600001
layer 4 sparsity 0.600001
layer 5 sparsity 0.600001
layer 6 sparsity 0.600001
layer 7 sparsity 0.600001
layer 8 sparsity 0.600001
layer 9 sparsity 0.600001
layer 10 sparsity 0.600001
layer 11 sparsity 0.600001
layer 12 sparsity 0.600001
layer 13 sparsity 0.600001
layer 14 sparsity 0.600001
layer 15 sparsity 0.600001
layer 16 sparsity 0.600001
layer 17 sparsity 0.600001
layer 18 sparsity 0.600001
layer 19 sparsity 0.600001
layer 20 sparsity 0.600001
layer 21 sparsity 0.600001
layer 22 sparsity 0.600001
layer 23 sparsity 0.600001
layer 24 sparsity 0.600001
layer 25 sparsity 0.600001
layer 26 sparsity 0.600001
layer 27 sparsity 0.600001
layer 28 sparsity 0.600001
layer 29 sparsity 0.600001
layer 30 sparsity 0.600001
layer 31 sparsity 0.600001
sparsity sanity check 0.6000
******************************
evaluating on wikitext2
nsamples 35
sample 0
wikitext perplexity 12.920522689819336
sparsegpt_dual_3	0.6000	12.9205	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.6, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='sparsegpt_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.599882
layer 1 sparsity 0.599882
layer 2 sparsity 0.599882
layer 3 sparsity 0.599882
layer 4 sparsity 0.599882
layer 5 sparsity 0.599882
layer 6 sparsity 0.599882
layer 7 sparsity 0.599882
layer 8 sparsity 0.599882
layer 9 sparsity 0.599882
layer 10 sparsity 0.599882
layer 11 sparsity 0.599882
layer 12 sparsity 0.599882
layer 13 sparsity 0.599882
layer 14 sparsity 0.599882
layer 15 sparsity 0.599882
layer 16 sparsity 0.599882
layer 17 sparsity 0.599882
layer 18 sparsity 0.599882
layer 19 sparsity 0.599882
layer 20 sparsity 0.599882
layer 21 sparsity 0.599882
layer 22 sparsity 0.599882
layer 23 sparsity 0.599882
layer 24 sparsity 0.599882
layer 25 sparsity 0.599882
layer 26 sparsity 0.599882
layer 27 sparsity 0.599882
layer 28 sparsity 0.599882
layer 29 sparsity 0.599882
layer 30 sparsity 0.599882
layer 31 sparsity 0.599882
sparsity sanity check 0.5999
******************************
evaluating on wikitext2
nsamples 35
sample 0
wikitext perplexity 14.713764190673828
wanda_dual_3	0.5999	14.7138	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.6, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='wanda_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
2025-04-24 12:59:00.219902: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 12:59:00.409402: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 12:59:00.414956: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 12:59:00.414990: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 12:59:00.703352: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 12:59:00.906756: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 12:59:00.912049: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 12:59:00.912079: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 12:59:04.108205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 12:59:04.108764: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 12:59:04.108784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-24 12:59:04.626493: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 12:59:04.627064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 12:59:04.629447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.10it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.13it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.13it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.18it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.13it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.38it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.49it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.33it/s]
model.embed_tokens.weight torch.Size([128256, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([128256, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]model.embed_tokens.weight torch.Size([128256, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([128256, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:01<06:59,  1.65s/it]  0%|          | 1/256 [00:01<06:33,  1.54s/it]  1%|          | 2/256 [00:01<03:29,  1.21it/s]  1%|          | 2/256 [00:01<03:17,  1.29it/s]  1%|          | 3/256 [00:02<03:01,  1.39it/s]  2%|▏         | 4/256 [00:02<02:22,  1.77it/s]  1%|          | 3/256 [00:02<03:23,  1.24it/s]  2%|▏         | 5/256 [00:03<01:52,  2.23it/s]  2%|▏         | 4/256 [00:02<02:35,  1.62it/s]  2%|▏         | 5/256 [00:03<02:01,  2.07it/s]  2%|▏         | 6/256 [00:04<03:47,  1.10it/s]  2%|▏         | 6/256 [00:04<03:47,  1.10it/s]  3%|▎         | 7/256 [00:05<03:06,  1.34it/s]  3%|▎         | 8/256 [00:05<02:15,  1.83it/s]  3%|▎         | 7/256 [00:05<03:03,  1.36it/s]  3%|▎         | 8/256 [00:05<02:12,  1.87it/s]  4%|▎         | 9/256 [00:06<02:26,  1.68it/s]  4%|▎         | 9/256 [00:06<02:21,  1.75it/s]  4%|▍         | 10/256 [00:06<02:22,  1.73it/s]  4%|▍         | 10/256 [00:06<02:18,  1.77it/s]  4%|▍         | 11/256 [00:07<02:11,  1.86it/s]  4%|▍         | 11/256 [00:07<02:06,  1.94it/s]  5%|▍         | 12/256 [00:07<02:28,  1.65it/s]  5%|▍         | 12/256 [00:07<02:20,  1.74it/s]  5%|▌         | 13/256 [00:08<02:43,  1.48it/s]  5%|▌         | 13/256 [00:08<02:34,  1.57it/s]  5%|▌         | 14/256 [00:09<02:32,  1.59it/s]  5%|▌         | 14/256 [00:08<02:22,  1.69it/s]  6%|▌         | 15/256 [00:09<02:17,  1.75it/s]  6%|▌         | 15/256 [00:09<02:09,  1.86it/s]  6%|▋         | 16/256 [00:10<02:43,  1.47it/s]  6%|▋         | 16/256 [00:10<02:33,  1.56it/s]  7%|▋         | 17/256 [00:10<02:07,  1.87it/s]  7%|▋         | 17/256 [00:10<02:15,  1.76it/s]  7%|▋         | 18/256 [00:11<02:40,  1.49it/s]  7%|▋         | 18/256 [00:11<02:49,  1.40it/s]  7%|▋         | 19/256 [00:12<03:11,  1.24it/s]  7%|▋         | 19/256 [00:13<03:21,  1.18it/s]  8%|▊         | 20/256 [00:12<02:25,  1.62it/s]  8%|▊         | 20/256 [00:13<02:33,  1.54it/s]  9%|▊         | 22/256 [00:13<01:42,  2.29it/s]  9%|▊         | 22/256 [00:13<01:47,  2.17it/s]  9%|▉         | 23/256 [00:14<02:36,  1.49it/s]  9%|▉         | 24/256 [00:14<02:01,  1.91it/s]  9%|▉         | 23/256 [00:15<02:44,  1.42it/s]  9%|▉         | 24/256 [00:15<02:07,  1.82it/s] 10%|▉         | 25/256 [00:15<02:02,  1.88it/s] 10%|█         | 26/256 [00:15<01:44,  2.20it/s] 10%|▉         | 25/256 [00:15<02:10,  1.77it/s] 11%|█         | 27/256 [00:15<01:22,  2.77it/s] 10%|█         | 26/256 [00:16<01:50,  2.09it/s] 11%|█         | 27/256 [00:16<01:28,  2.60it/s] 11%|█         | 28/256 [00:16<01:56,  1.96it/s] 11%|█         | 28/256 [00:17<02:03,  1.85it/s] 12%|█▏        | 30/256 [00:18<02:44,  1.38it/s] 12%|█▏        | 31/256 [00:18<02:22,  1.58it/s] 12%|█▏        | 30/256 [00:19<02:53,  1.31it/s] 12%|█▎        | 32/256 [00:19<02:07,  1.76it/s] 12%|█▏        | 31/256 [00:19<02:29,  1.50it/s] 12%|█▎        | 32/256 [00:20<02:13,  1.68it/s] 13%|█▎        | 34/256 [00:20<02:25,  1.52it/s] 13%|█▎        | 34/256 [00:21<02:34,  1.44it/s] 14%|█▎        | 35/256 [00:21<02:27,  1.50it/s] 14%|█▍        | 36/256 [00:21<02:11,  1.67it/s] 14%|█▎        | 35/256 [00:22<02:35,  1.42it/s] 14%|█▍        | 37/256 [00:22<02:07,  1.72it/s] 14%|█▍        | 36/256 [00:22<02:18,  1.58it/s] 14%|█▍        | 37/256 [00:23<02:12,  1.65it/s] 15%|█▍        | 38/256 [00:23<02:46,  1.31it/s] 15%|█▌        | 39/256 [00:23<02:06,  1.71it/s] 15%|█▍        | 38/256 [00:24<02:55,  1.24it/s] 15%|█▌        | 39/256 [00:24<02:13,  1.62it/s] 16%|█▌        | 40/256 [00:24<02:31,  1.43it/s] 16%|█▌        | 40/256 [00:25<02:39,  1.36it/s] 16%|█▌        | 41/256 [00:26<03:55,  1.10s/it] 16%|█▋        | 42/256 [00:27<03:35,  1.01s/it] 16%|█▌        | 41/256 [00:28<04:07,  1.15s/it] 16%|█▋        | 42/256 [00:28<03:45,  1.06s/it] 17%|█▋        | 43/256 [00:28<03:40,  1.04s/it] 17%|█▋        | 43/256 [00:30<03:50,  1.08s/it] 17%|█▋        | 44/256 [00:30<03:49,  1.08s/it] 17%|█▋        | 44/256 [00:31<04:00,  1.13s/it] 18%|█▊        | 45/256 [00:32<05:08,  1.46s/it] 18%|█▊        | 45/256 [00:33<05:22,  1.53s/it] 18%|█▊        | 47/256 [00:35<04:53,  1.40s/it] 19%|█▉        | 48/256 [00:35<04:01,  1.16s/it] 19%|█▉        | 49/256 [00:36<03:29,  1.01s/it] 18%|█▊        | 47/256 [00:36<05:04,  1.46s/it] 19%|█▉        | 48/256 [00:36<04:10,  1.21s/it] 19%|█▉        | 49/256 [00:37<03:38,  1.06s/it] 20%|█▉        | 50/256 [00:37<04:07,  1.20s/it] 20%|██        | 52/256 [00:38<02:28,  1.37it/s] 20%|█▉        | 50/256 [00:39<04:19,  1.26s/it] 20%|█▉        | 51/256 [00:39<03:11,  1.07it/s] 20%|██        | 52/256 [00:39<02:24,  1.41it/s] 21%|██        | 53/256 [00:39<03:25,  1.01s/it] 21%|██        | 54/256 [00:40<02:42,  1.24it/s] 21%|██▏       | 55/256 [00:41<02:48,  1.19it/s] 21%|██        | 53/256 [00:41<03:40,  1.08s/it] 21%|██        | 54/256 [00:41<02:45,  1.22it/s] 21%|██▏       | 55/256 [00:42<02:57,  1.13it/s] 22%|██▏       | 56/256 [00:42<03:38,  1.09s/it] 22%|██▏       | 56/256 [00:44<03:48,  1.14s/it] 22%|██▏       | 57/256 [00:44<04:11,  1.26s/it] 23%|██▎       | 58/256 [00:44<03:10,  1.04it/s] 22%|██▏       | 57/256 [00:46<04:26,  1.34s/it] 23%|██▎       | 58/256 [00:46<03:20,  1.01s/it] 23%|██▎       | 59/256 [00:47<05:14,  1.60s/it] 23%|██▎       | 60/256 [00:48<04:06,  1.26s/it] 24%|██▍       | 61/256 [00:48<03:21,  1.03s/it] 24%|██▍       | 62/256 [00:49<03:01,  1.07it/s] 23%|██▎       | 59/256 [00:49<05:31,  1.69s/it] 23%|██▎       | 60/256 [00:50<04:16,  1.31s/it] 25%|██▍       | 63/256 [00:50<02:44,  1.17it/s] 25%|██▌       | 64/256 [00:50<02:08,  1.49it/s] 24%|██▍       | 61/256 [00:50<03:28,  1.07s/it] 25%|██▌       | 65/256 [00:50<02:01,  1.58it/s] 24%|██▍       | 62/256 [00:51<03:08,  1.03it/s] 25%|██▍       | 63/256 [00:52<02:51,  1.13it/s] 25%|██▌       | 64/256 [00:52<02:15,  1.42it/s] 26%|██▌       | 66/256 [00:52<02:50,  1.11it/s] 26%|██▌       | 67/256 [00:52<02:15,  1.40it/s] 25%|██▌       | 65/256 [00:53<02:07,  1.50it/s] 27%|██▋       | 68/256 [00:53<02:32,  1.23it/s] 27%|██▋       | 69/256 [00:53<01:54,  1.63it/s] 26%|██▌       | 66/256 [00:54<02:58,  1.07it/s] 26%|██▌       | 67/256 [00:55<02:21,  1.34it/s] 27%|██▋       | 68/256 [00:56<02:40,  1.17it/s] 27%|██▋       | 69/256 [00:56<02:00,  1.55it/s] 27%|██▋       | 70/256 [00:57<04:50,  1.56s/it] 28%|██▊       | 71/256 [00:58<03:52,  1.26s/it] 28%|██▊       | 72/256 [00:59<04:09,  1.36s/it] 27%|██▋       | 70/256 [01:00<05:07,  1.65s/it] 29%|██▊       | 73/256 [01:00<03:16,  1.07s/it] 29%|██▉       | 74/256 [01:00<02:30,  1.21it/s] 28%|██▊       | 71/256 [01:00<04:06,  1.33s/it] 29%|██▉       | 75/256 [01:01<02:22,  1.27it/s] 30%|██▉       | 76/256 [01:01<02:13,  1.34it/s] 28%|██▊       | 72/256 [01:02<04:24,  1.44s/it] 29%|██▊       | 73/256 [01:02<03:26,  1.13s/it] 29%|██▉       | 74/256 [01:03<02:37,  1.16it/s] 30%|███       | 77/256 [01:03<02:49,  1.06it/s] 29%|██▉       | 75/256 [01:03<02:31,  1.20it/s] 31%|███▏      | 80/256 [01:03<01:31,  1.92it/s] 32%|███▏      | 81/256 [01:04<01:19,  2.20it/s] 30%|██▉       | 76/256 [01:04<02:22,  1.26it/s] 32%|███▏      | 82/256 [01:04<01:25,  2.05it/s] 33%|███▎      | 84/256 [01:04<00:54,  3.15it/s] 33%|███▎      | 85/256 [01:05<01:00,  2.83it/s] 34%|███▎      | 86/256 [01:05<00:54,  3.14it/s] 30%|███       | 77/256 [01:06<02:57,  1.01it/s] 34%|███▍      | 88/256 [01:05<00:48,  3.45it/s] 31%|███▏      | 80/256 [01:06<01:36,  1.82it/s] 32%|███▏      | 81/256 [01:06<01:23,  2.09it/s] 32%|███▏      | 82/256 [01:07<01:29,  1.94it/s] 33%|███▎      | 84/256 [01:07<00:57,  2.99it/s] 35%|███▍      | 89/256 [01:07<01:46,  1.57it/s] 33%|███▎      | 85/256 [01:08<01:03,  2.70it/s] 34%|███▎      | 86/256 [01:08<00:56,  3.01it/s] 34%|███▍      | 88/256 [01:08<00:50,  3.32it/s] 35%|███▌      | 90/256 [01:08<02:07,  1.30it/s] 36%|███▌      | 92/256 [01:09<01:39,  1.65it/s] 35%|███▍      | 89/256 [01:10<01:50,  1.51it/s] 36%|███▋      | 93/256 [01:10<01:56,  1.40it/s] 37%|███▋      | 94/256 [01:11<01:59,  1.36it/s] 35%|███▌      | 90/256 [01:12<02:11,  1.26it/s] 36%|███▌      | 92/256 [01:12<01:41,  1.61it/s] 37%|███▋      | 95/256 [01:12<02:24,  1.12it/s] 38%|███▊      | 96/256 [01:13<02:12,  1.21it/s] 36%|███▋      | 93/256 [01:13<01:59,  1.36it/s] 37%|███▋      | 94/256 [01:14<02:03,  1.32it/s] 38%|███▊      | 97/256 [01:15<02:36,  1.01it/s] 37%|███▋      | 95/256 [01:16<02:30,  1.07it/s] 38%|███▊      | 98/256 [01:15<02:33,  1.03it/s] 39%|███▊      | 99/256 [01:16<02:12,  1.19it/s] 38%|███▊      | 96/256 [01:16<02:18,  1.16it/s] 39%|███▉      | 100/256 [01:17<02:21,  1.10it/s] 38%|███▊      | 97/256 [01:18<02:43,  1.03s/it] 39%|███▉      | 101/256 [01:18<02:11,  1.18it/s] 40%|███▉      | 102/256 [01:18<01:44,  1.48it/s] 38%|███▊      | 98/256 [01:19<02:38,  1.00s/it] 40%|████      | 103/256 [01:19<01:48,  1.41it/s] 39%|███▊      | 99/256 [01:19<02:17,  1.14it/s] 41%|████      | 104/256 [01:19<01:40,  1.51it/s] 41%|████      | 105/256 [01:19<01:15,  2.00it/s] 39%|███▉      | 100/256 [01:20<02:26,  1.07it/s] 41%|████▏     | 106/256 [01:21<01:45,  1.42it/s] 39%|███▉      | 101/256 [01:21<02:15,  1.15it/s] 40%|███▉      | 102/256 [01:21<01:47,  1.44it/s] 40%|████      | 103/256 [01:22<01:44,  1.47it/s] 41%|████      | 104/256 [01:22<01:30,  1.68it/s] 41%|████▏     | 106/256 [01:24<01:26,  1.73it/s] 42%|████▏     | 107/256 [01:24<03:31,  1.42s/it] 42%|████▏     | 108/256 [01:24<02:42,  1.10s/it] 43%|████▎     | 109/256 [01:25<02:13,  1.10it/s] 43%|████▎     | 110/256 [01:25<02:06,  1.15it/s] 43%|████▎     | 111/256 [01:26<01:59,  1.22it/s] 42%|████▏     | 107/256 [01:27<03:00,  1.21s/it] 44%|████▍     | 112/256 [01:26<01:40,  1.43it/s] 44%|████▍     | 113/256 [01:27<01:16,  1.87it/s] 42%|████▏     | 108/256 [01:27<02:26,  1.01it/s] 43%|████▎     | 109/256 [01:28<02:05,  1.17it/s] 43%|████▎     | 110/256 [01:28<02:01,  1.20it/s] 43%|████▎     | 111/256 [01:29<01:56,  1.25it/s] 44%|████▍     | 112/256 [01:29<01:40,  1.43it/s] 45%|████▍     | 114/256 [01:29<02:43,  1.15s/it] 44%|████▍     | 113/256 [01:30<01:17,  1.84it/s] 45%|████▍     | 115/256 [01:29<02:00,  1.17it/s] 45%|████▌     | 116/256 [01:30<01:31,  1.54it/s] 46%|████▌     | 117/256 [01:31<01:45,  1.32it/s] 46%|████▌     | 118/256 [01:31<01:45,  1.30it/s] 45%|████▍     | 114/256 [01:32<02:47,  1.18s/it] 45%|████▍     | 115/256 [01:33<02:03,  1.14it/s] 45%|████▌     | 116/256 [01:33<01:33,  1.49it/s] 46%|████▋     | 119/256 [01:33<02:15,  1.01it/s] 46%|████▌     | 117/256 [01:34<01:48,  1.28it/s] 46%|████▌     | 118/256 [01:35<01:50,  1.25it/s] 47%|████▋     | 120/256 [01:34<02:39,  1.18s/it] 46%|████▋     | 119/256 [01:36<02:19,  1.02s/it] 47%|████▋     | 121/256 [01:37<03:24,  1.52s/it] 47%|████▋     | 120/256 [01:38<02:44,  1.21s/it] 48%|████▊     | 122/256 [01:38<03:05,  1.38s/it] 48%|████▊     | 123/256 [01:38<02:21,  1.06s/it] 48%|████▊     | 124/256 [01:38<01:43,  1.28it/s] 49%|████▉     | 125/256 [01:38<01:16,  1.72it/s] 49%|████▉     | 126/256 [01:39<00:59,  2.18it/s] 50%|████▉     | 127/256 [01:39<00:56,  2.30it/s] 50%|█████     | 128/256 [01:39<00:43,  2.93it/s] 47%|████▋     | 121/256 [01:40<03:32,  1.57s/it] 50%|█████     | 129/256 [01:41<01:43,  1.23it/s] 48%|████▊     | 122/256 [01:41<03:12,  1.44s/it] 51%|█████     | 131/256 [01:41<00:59,  2.10it/s] 48%|████▊     | 123/256 [01:42<02:26,  1.10s/it] 52%|█████▏    | 132/256 [01:41<00:51,  2.41it/s] 48%|████▊     | 124/256 [01:42<01:46,  1.23it/s] 49%|████▉     | 125/256 [01:42<01:18,  1.66it/s] 49%|████▉     | 126/256 [01:42<01:02,  2.09it/s] 52%|█████▏    | 133/256 [01:42<00:54,  2.28it/s] 50%|████▉     | 127/256 [01:42<00:58,  2.20it/s] 50%|█████     | 128/256 [01:43<00:45,  2.81it/s] 50%|█████     | 129/256 [01:45<01:45,  1.20it/s] 51%|█████     | 131/256 [01:45<01:01,  2.04it/s] 52%|█████▏    | 132/256 [01:45<00:53,  2.32it/s] 52%|█████▏    | 134/256 [01:45<02:20,  1.15s/it] 53%|█████▎    | 135/256 [01:45<01:44,  1.16it/s] 52%|█████▏    | 133/256 [01:45<00:56,  2.19it/s] 54%|█████▎    | 137/256 [01:45<01:07,  1.77it/s] 54%|█████▍    | 138/256 [01:46<01:17,  1.52it/s] 55%|█████▍    | 140/256 [01:47<01:08,  1.69it/s] 55%|█████▌    | 141/256 [01:48<01:10,  1.62it/s] 52%|█████▏    | 134/256 [01:49<02:23,  1.18s/it] 53%|█████▎    | 135/256 [01:49<01:46,  1.14it/s] 55%|█████▌    | 142/256 [01:49<01:08,  1.67it/s] 54%|█████▎    | 137/256 [01:49<01:08,  1.73it/s] 54%|█████▍    | 138/256 [01:50<01:18,  1.50it/s] 55%|█████▍    | 140/256 [01:51<01:10,  1.65it/s] 56%|█████▌    | 143/256 [01:51<02:01,  1.08s/it] 56%|█████▋    | 144/256 [01:51<01:35,  1.18it/s] 55%|█████▌    | 141/256 [01:52<01:12,  1.58it/s] 55%|█████▌    | 142/256 [01:52<01:10,  1.62it/s] 57%|█████▋    | 145/256 [01:52<01:44,  1.07it/s] 57%|█████▋    | 146/256 [01:53<01:30,  1.21it/s] 57%|█████▋    | 147/256 [01:54<01:21,  1.34it/s] 58%|█████▊    | 148/256 [01:54<01:20,  1.34it/s] 56%|█████▌    | 143/256 [01:55<02:06,  1.12s/it] 56%|█████▋    | 144/256 [01:55<01:38,  1.13it/s] 57%|█████▋    | 145/256 [01:56<01:48,  1.02it/s] 57%|█████▋    | 146/256 [01:57<01:34,  1.16it/s] 57%|█████▋    | 147/256 [01:58<01:25,  1.28it/s] 58%|█████▊    | 149/256 [01:57<02:30,  1.41s/it] 59%|█████▊    | 150/256 [01:58<01:53,  1.07s/it] 58%|█████▊    | 148/256 [01:58<01:24,  1.28it/s] 59%|█████▉    | 151/256 [01:59<01:53,  1.08s/it] 59%|█████▉    | 152/256 [02:00<01:50,  1.07s/it] 60%|█████▉    | 153/256 [02:00<01:31,  1.13it/s] 60%|██████    | 154/256 [02:00<01:11,  1.43it/s] 61%|██████    | 155/256 [02:01<01:01,  1.64it/s] 58%|█████▊    | 149/256 [02:01<02:35,  1.45s/it] 59%|█████▊    | 150/256 [02:02<01:57,  1.11s/it] 61%|██████    | 156/256 [02:02<01:04,  1.56it/s] 62%|██████▏   | 158/256 [02:02<00:37,  2.59it/s] 62%|██████▏   | 159/256 [02:02<00:36,  2.66it/s] 62%|██████▎   | 160/256 [02:03<00:38,  2.52it/s] 59%|█████▉    | 151/256 [02:03<01:58,  1.13s/it] 63%|██████▎   | 161/256 [02:03<00:36,  2.62it/s] 63%|██████▎   | 162/256 [02:03<00:33,  2.84it/s] 64%|██████▎   | 163/256 [02:03<00:31,  2.97it/s] 59%|█████▉    | 152/256 [02:04<01:57,  1.13s/it] 60%|█████▉    | 153/256 [02:04<01:35,  1.08it/s] 60%|██████    | 154/256 [02:05<01:15,  1.36it/s] 64%|██████▍   | 164/256 [02:05<00:58,  1.57it/s] 61%|██████    | 155/256 [02:05<01:04,  1.57it/s] 61%|██████    | 156/256 [02:06<01:06,  1.50it/s] 62%|██████▏   | 158/256 [02:06<00:39,  2.48it/s] 62%|██████▏   | 159/256 [02:06<00:38,  2.54it/s] 64%|██████▍   | 165/256 [02:06<01:22,  1.11it/s] 62%|██████▎   | 160/256 [02:07<00:40,  2.38it/s] 63%|██████▎   | 161/256 [02:07<00:36,  2.57it/s] 63%|██████▎   | 162/256 [02:08<00:33,  2.78it/s] 64%|██████▎   | 163/256 [02:08<00:32,  2.90it/s] 65%|██████▍   | 166/256 [02:08<01:36,  1.08s/it] 65%|██████▌   | 167/256 [02:09<01:25,  1.04it/s] 66%|██████▌   | 168/256 [02:09<01:05,  1.35it/s] 64%|██████▍   | 164/256 [02:09<00:59,  1.54it/s] 66%|██████▌   | 169/256 [02:09<00:56,  1.55it/s] 66%|██████▋   | 170/256 [02:10<00:53,  1.61it/s] 67%|██████▋   | 171/256 [02:10<00:41,  2.07it/s] 64%|██████▍   | 165/256 [02:11<01:24,  1.08it/s] 68%|██████▊   | 173/256 [02:11<00:34,  2.42it/s] 68%|██████▊   | 174/256 [02:12<00:54,  1.52it/s] 65%|██████▍   | 166/256 [02:12<01:39,  1.11s/it] 68%|██████▊   | 175/256 [02:12<00:45,  1.76it/s] 65%|██████▌   | 167/256 [02:13<01:27,  1.02it/s] 66%|██████▌   | 168/256 [02:13<01:06,  1.32it/s] 66%|██████▌   | 169/256 [02:14<00:57,  1.52it/s] 69%|██████▉   | 176/256 [02:13<00:58,  1.38it/s] 66%|██████▋   | 170/256 [02:14<00:54,  1.58it/s] 67%|██████▋   | 171/256 [02:14<00:41,  2.04it/s] 67%|██████▋   | 172/256 [02:15<00:31,  2.65it/s] 69%|██████▉   | 177/256 [02:15<01:06,  1.18it/s] 68%|██████▊   | 173/256 [02:15<00:37,  2.23it/s] 70%|██████▉   | 178/256 [02:15<00:59,  1.31it/s] 70%|██████▉   | 179/256 [02:16<00:51,  1.51it/s] 68%|██████▊   | 174/256 [02:17<01:01,  1.34it/s] 68%|██████▊   | 175/256 [02:17<00:49,  1.63it/s] 70%|███████   | 180/256 [02:17<01:09,  1.09it/s] 69%|██████▉   | 176/256 [02:18<01:02,  1.27it/s] 71%|███████   | 181/256 [02:18<01:05,  1.14it/s] 71%|███████   | 182/256 [02:19<01:02,  1.19it/s] 69%|██████▉   | 177/256 [02:19<01:11,  1.10it/s] 70%|██████▉   | 178/256 [02:20<01:02,  1.25it/s] 70%|██████▉   | 179/256 [02:20<00:52,  1.47it/s] 71%|███████▏  | 183/256 [02:21<01:30,  1.23s/it] 70%|███████   | 180/256 [02:22<01:13,  1.04it/s] 72%|███████▏  | 184/256 [02:22<01:27,  1.21s/it] 71%|███████   | 181/256 [02:23<01:08,  1.09it/s] 72%|███████▏  | 185/256 [02:22<01:11,  1.00s/it] 71%|███████   | 182/256 [02:23<01:04,  1.15it/s] 73%|███████▎  | 186/256 [02:23<01:04,  1.08it/s] 73%|███████▎  | 187/256 [02:23<00:48,  1.44it/s] 71%|███████▏  | 183/256 [02:26<01:46,  1.45s/it] 73%|███████▎  | 188/256 [02:27<01:54,  1.69s/it] 72%|███████▏  | 184/256 [02:28<01:47,  1.50s/it] 74%|███████▍  | 189/256 [02:28<01:35,  1.43s/it] 72%|███████▏  | 185/256 [02:29<01:29,  1.25s/it] 74%|███████▍  | 190/256 [02:28<01:08,  1.04s/it] 73%|███████▎  | 186/256 [02:29<01:17,  1.11s/it] 73%|███████▎  | 187/256 [02:29<00:57,  1.20it/s] 75%|███████▍  | 191/256 [02:29<01:08,  1.06s/it] 75%|███████▌  | 192/256 [02:30<01:01,  1.04it/s] 75%|███████▌  | 193/256 [02:30<00:48,  1.31it/s] 76%|███████▌  | 194/256 [02:31<00:49,  1.25it/s] 76%|███████▌  | 195/256 [02:32<00:38,  1.57it/s] 77%|███████▋  | 196/256 [02:33<00:45,  1.32it/s] 73%|███████▎  | 188/256 [02:34<02:06,  1.86s/it] 77%|███████▋  | 197/256 [02:34<00:52,  1.12it/s] 74%|███████▍  | 189/256 [02:35<01:44,  1.56s/it] 77%|███████▋  | 198/256 [02:34<00:44,  1.32it/s] 74%|███████▍  | 190/256 [02:35<01:14,  1.13s/it] 78%|███████▊  | 200/256 [02:35<00:28,  2.00it/s] 79%|███████▊  | 201/256 [02:35<00:25,  2.15it/s] 75%|███████▍  | 191/256 [02:36<01:14,  1.14s/it] 79%|███████▉  | 202/256 [02:36<00:27,  1.93it/s] 79%|███████▉  | 203/256 [02:36<00:24,  2.17it/s] 75%|███████▌  | 192/256 [02:37<01:04,  1.01s/it] 80%|███████▉  | 204/256 [02:36<00:21,  2.40it/s] 80%|████████  | 205/256 [02:37<00:18,  2.79it/s] 75%|███████▌  | 193/256 [02:37<00:50,  1.24it/s] 76%|███████▌  | 194/256 [02:38<00:52,  1.19it/s] 76%|███████▌  | 195/256 [02:38<00:41,  1.48it/s] 80%|████████  | 206/256 [02:39<00:41,  1.20it/s] 77%|███████▋  | 196/256 [02:39<00:45,  1.31it/s] 81%|████████  | 207/256 [02:40<00:46,  1.04it/s] 77%|███████▋  | 197/256 [02:40<00:52,  1.13it/s] 81%|████████▏ | 208/256 [02:40<00:36,  1.31it/s] 77%|███████▋  | 198/256 [02:41<00:44,  1.31it/s] 78%|███████▊  | 200/256 [02:41<00:28,  1.98it/s] 82%|████████▏ | 209/256 [02:41<00:38,  1.22it/s] 79%|███████▊  | 201/256 [02:42<00:25,  2.14it/s] 79%|███████▉  | 202/256 [02:42<00:28,  1.91it/s] 79%|███████▉  | 203/256 [02:43<00:25,  2.11it/s] 80%|███████▉  | 204/256 [02:43<00:22,  2.34it/s] 80%|████████  | 205/256 [02:43<00:18,  2.74it/s] 82%|████████▏ | 210/256 [02:44<01:03,  1.38s/it] 82%|████████▏ | 211/256 [02:45<00:57,  1.27s/it] 80%|████████  | 206/256 [02:45<00:42,  1.17it/s] 83%|████████▎ | 212/256 [02:46<00:49,  1.12s/it] 81%|████████  | 207/256 [02:46<00:47,  1.02it/s] 81%|████████▏ | 208/256 [02:47<00:37,  1.28it/s] 84%|████████▎ | 214/256 [02:47<00:36,  1.14it/s] 82%|████████▏ | 209/256 [02:48<00:39,  1.19it/s] 84%|████████▍ | 215/256 [02:47<00:34,  1.18it/s] 84%|████████▍ | 216/256 [02:48<00:26,  1.51it/s] 85%|████████▍ | 217/256 [02:49<00:29,  1.31it/s] 85%|████████▌ | 218/256 [02:50<00:35,  1.07it/s] 82%|████████▏ | 210/256 [02:50<01:04,  1.40s/it] 82%|████████▏ | 211/256 [02:51<00:58,  1.30s/it] 83%|████████▎ | 212/256 [02:52<00:50,  1.14s/it] 86%|████████▌ | 219/256 [02:53<00:54,  1.46s/it] 84%|████████▎ | 214/256 [02:53<00:37,  1.12it/s] 86%|████████▌ | 220/256 [02:54<00:46,  1.29s/it] 86%|████████▋ | 221/256 [02:54<00:34,  1.01it/s] 84%|████████▍ | 215/256 [02:54<00:35,  1.15it/s] 84%|████████▍ | 216/256 [02:54<00:27,  1.46it/s] 85%|████████▍ | 217/256 [02:55<00:30,  1.28it/s] 87%|████████▋ | 222/256 [02:55<00:39,  1.15s/it] 87%|████████▋ | 223/256 [02:56<00:30,  1.09it/s] 88%|████████▊ | 224/256 [02:56<00:22,  1.45it/s] 85%|████████▌ | 218/256 [02:57<00:36,  1.05it/s] 88%|████████▊ | 225/256 [02:57<00:23,  1.33it/s] 89%|████████▊ | 227/256 [02:57<00:14,  1.98it/s] 89%|████████▉ | 228/256 [02:58<00:12,  2.21it/s] 86%|████████▌ | 219/256 [03:00<00:55,  1.50s/it] 89%|████████▉ | 229/256 [03:00<00:27,  1.02s/it] 86%|████████▌ | 220/256 [03:01<00:48,  1.34s/it] 86%|████████▋ | 221/256 [03:01<00:35,  1.02s/it] 90%|████████▉ | 230/256 [03:01<00:24,  1.07it/s] 87%|████████▋ | 222/256 [03:02<00:39,  1.17s/it] 87%|████████▋ | 223/256 [03:03<00:30,  1.07it/s] 90%|█████████ | 231/256 [03:03<00:28,  1.16s/it] 88%|████████▊ | 224/256 [03:03<00:22,  1.41it/s] 88%|████████▊ | 225/256 [03:04<00:24,  1.28it/s] 89%|████████▊ | 227/256 [03:04<00:15,  1.91it/s] 89%|████████▉ | 228/256 [03:05<00:13,  2.13it/s] 91%|█████████ | 232/256 [03:05<00:33,  1.41s/it] 91%|█████████▏| 234/256 [03:06<00:24,  1.11s/it] 89%|████████▉ | 229/256 [03:07<00:28,  1.07s/it] 92%|█████████▏| 235/256 [03:08<00:25,  1.22s/it] 90%|████████▉ | 230/256 [03:08<00:25,  1.02it/s] 92%|█████████▏| 236/256 [03:08<00:19,  1.01it/s] 93%|█████████▎| 237/256 [03:09<00:20,  1.09s/it] 90%|█████████ | 231/256 [03:10<00:30,  1.20s/it] 93%|█████████▎| 238/256 [03:10<00:16,  1.09it/s] 91%|█████████ | 232/256 [03:12<00:34,  1.44s/it] 91%|█████████ | 233/256 [03:12<00:24,  1.05s/it] 93%|█████████▎| 239/256 [03:12<00:20,  1.21s/it] 94%|█████████▍| 240/256 [03:12<00:14,  1.08it/s] 94%|█████████▍| 241/256 [03:13<00:14,  1.04it/s] 91%|█████████▏| 234/256 [03:14<00:25,  1.17s/it] 95%|█████████▍| 242/256 [03:13<00:10,  1.32it/s] 95%|█████████▍| 243/256 [03:14<00:10,  1.26it/s] 95%|█████████▌| 244/256 [03:15<00:08,  1.45it/s] 92%|█████████▏| 235/256 [03:15<00:26,  1.28s/it] 96%|█████████▌| 245/256 [03:15<00:06,  1.72it/s] 92%|█████████▏| 236/256 [03:15<00:20,  1.00s/it] 96%|█████████▌| 246/256 [03:16<00:05,  1.78it/s] 96%|█████████▋| 247/256 [03:16<00:04,  1.96it/s] 97%|█████████▋| 248/256 [03:16<00:03,  2.07it/s] 93%|█████████▎| 237/256 [03:17<00:21,  1.12s/it] 93%|█████████▎| 238/256 [03:17<00:16,  1.10it/s] 97%|█████████▋| 249/256 [03:18<00:05,  1.37it/s] 98%|█████████▊| 250/256 [03:18<00:03,  1.77it/s] 98%|█████████▊| 251/256 [03:18<00:02,  1.87it/s] 93%|█████████▎| 239/256 [03:19<00:21,  1.24s/it] 94%|█████████▍| 240/256 [03:20<00:15,  1.06it/s] 98%|█████████▊| 252/256 [03:19<00:02,  1.55it/s] 94%|█████████▍| 241/256 [03:21<00:14,  1.02it/s] 95%|█████████▍| 242/256 [03:21<00:10,  1.30it/s] 95%|█████████▍| 243/256 [03:22<00:10,  1.23it/s] 99%|█████████▉| 253/256 [03:22<00:03,  1.22s/it] 95%|█████████▌| 244/256 [03:22<00:08,  1.43it/s] 96%|█████████▌| 245/256 [03:23<00:06,  1.70it/s] 96%|█████████▌| 246/256 [03:23<00:05,  1.76it/s] 96%|█████████▋| 247/256 [03:23<00:04,  1.92it/s] 99%|█████████▉| 254/256 [03:23<00:02,  1.29s/it] 97%|█████████▋| 248/256 [03:24<00:03,  2.02it/s]100%|█████████▉| 255/256 [03:24<00:01,  1.24s/it]100%|██████████| 256/256 [03:25<00:00,  1.02s/it]100%|██████████| 256/256 [03:25<00:00,  1.25it/s]
 97%|█████████▋| 249/256 [03:25<00:05,  1.33it/s] 98%|█████████▊| 250/256 [03:25<00:03,  1.72it/s] 98%|█████████▊| 251/256 [03:26<00:02,  1.82it/s] 98%|█████████▊| 252/256 [03:27<00:02,  1.51it/s] 99%|█████████▉| 253/256 [03:30<00:03,  1.27s/it] 99%|█████████▉| 254/256 [03:32<00:02,  1.49s/it]100%|█████████▉| 255/256 [03:33<00:01,  1.43s/it]100%|██████████| 256/256 [03:33<00:00,  1.17s/it]100%|██████████| 256/256 [03:33<00:00,  1.20it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
0 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.8218, device='cuda:0', dtype=torch.float16)
tensor(0.0669, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.0630, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.0684, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.0625, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
0 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.5859, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(0.0804, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.0811, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.0939, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0835, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
0 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0288, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0317, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0329, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0311, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0183, device='cuda:0')
tensor(0.0379, device='cuda:0')
old_score: tensor(0.0027, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0021, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.210036277770996
Validation after dual ascent:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0277, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.0313, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0316, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0333, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
0 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0186, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0189, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0199, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0209, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0253, device='cuda:0')
old_score: tensor(0.0008, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0007, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.933459281921387
Validation after dual ascent:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0184, device='cuda:0', dtype=torch.float16) tensor(0.0006, device='cuda:0', dtype=torch.float16)
tensor(0.0180, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0176, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0222, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
0 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.4224, device='cuda:0', dtype=torch.float16) tensor(0.0185, device='cuda:0', dtype=torch.float16)
tensor(0.4116, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0157, device='cuda:0')
tensor(0.1744, device='cuda:0')
old_score: tensor(0.0198, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0175, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.327942371368408
Validation after dual ascent:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.4067, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.4106, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.3984, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
0 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0145, device='cuda:0')
tensor(0.1596, device='cuda:0')
old_score: tensor(0.0180, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0159, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.3295300006866455
Validation after dual ascent:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.4932, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
0 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0261, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0257, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0263, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0287, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0706, device='cuda:0')
old_score: tensor(0.0018, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0016, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.75373220443726
Validation after dual ascent:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0262, device='cuda:0', dtype=torch.float16) tensor(0.0014, device='cuda:0', dtype=torch.float16)
tensor(0.0251, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.0271, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0284, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
layer 0 done
1 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.7344, device='cuda:0', dtype=torch.float16) tensor(0.9995, device='cuda:0', dtype=torch.float16)
tensor(0.2783, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.4092, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.2998, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
1 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.3828, device='cuda:0', dtype=torch.float16) tensor(1.4951, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
1 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3223, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.0907, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.0951, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.0955, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.0891, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0077, device='cuda:0')
tensor(0.0318, device='cuda:0')
old_score: tensor(0.0096, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0084, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9571962356567383
Validation after dual ascent:
out_inf: tensor(2.3223, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.0885, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0979, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0916, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.0867, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
1 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.1670, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.0385, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0380, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0486, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0370, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0275, device='cuda:0')
old_score: tensor(0.0013, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0012, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.956823348999023
Validation after dual ascent:
out_inf: tensor(1.1670, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.0275, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0292, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0400, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0349, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
1 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.2969, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0254, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0268, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0172, device='cuda:0')
tensor(0.0335, device='cuda:0')
old_score: tensor(0.0273, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0248, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.12257194519043
Validation after dual ascent:
out_inf: tensor(18.2969, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0254, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
1 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6309, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0252, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0181, device='cuda:0')
tensor(0.0315, device='cuda:0')
old_score: tensor(0.0248, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0225, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.281036615371704
Validation after dual ascent:
out_inf: tensor(2.6309, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(0.3965, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
1 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(251.6250, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0300, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0382, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0334, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0317, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0805, device='cuda:0')
old_score: tensor(0.0024, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0023, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.2610366344452
Validation after dual ascent:
out_inf: tensor(251.6250, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0309, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
layer 1 done
2 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.7031, device='cuda:0', dtype=torch.float16) tensor(0.8496, device='cuda:0', dtype=torch.float16)
tensor(0.6587, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.0727, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.5791, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
2 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.7031, device='cuda:0', dtype=torch.float16) tensor(1.3965, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(0.8726, device='cuda:0', dtype=torch.float16) tensor(0.0993, device='cuda:0', dtype=torch.float16)
2 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.8721, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(0.2122, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.2812, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0284, device='cuda:0', dtype=torch.float16)
tensor(0.2240, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0162, device='cuda:0')
tensor(0.2552, device='cuda:0')
old_score: tensor(0.0279, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0257, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6111571788787842
Validation after dual ascent:
out_inf: tensor(1.8721, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(0.2195, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.2634, device='cuda:0', dtype=torch.float16) tensor(0.0279, device='cuda:0', dtype=torch.float16)
tensor(0.3506, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
tensor(0.2441, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
2 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.0262, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0281, device='cuda:0', dtype=torch.float16) tensor(0.0014, device='cuda:0', dtype=torch.float16)
tensor(0.0290, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0268, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0205, device='cuda:0')
old_score: tensor(0.0016, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0015, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.96171522140503
Validation after dual ascent:
out_inf: tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.0298, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0258, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0293, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0277, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
2 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.0547, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(0.3887, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.4600, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0083, device='cuda:0')
tensor(0.0607, device='cuda:0')
old_score: tensor(0.0357, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0328, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.793957471847534
Validation after dual ascent:
out_inf: tensor(3.0547, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(0.3687, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.4365, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0310, device='cuda:0', dtype=torch.float16)
2 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.3855, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.4541, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0065, device='cuda:0')
tensor(0.0533, device='cuda:0')
old_score: tensor(0.0315, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0290, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.808076858520508
Validation after dual ascent:
out_inf: tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(0.3745, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(0.3916, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.3984, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
2 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.4836, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.0384, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0408, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.0400, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0373, device='cuda:0', dtype=torch.float16) tensor(0.0033, device='cuda:0', dtype=torch.float16)
tensor(0.0630, device='cuda:0')
old_score: tensor(0.0035, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0033, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.79006266593933
Validation after dual ascent:
out_inf: tensor(0.4836, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.0367, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.0420, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.0421, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.0377, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
layer 2 done
3 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.0156, device='cuda:0', dtype=torch.float16) tensor(0.8208, device='cuda:0', dtype=torch.float16)
tensor(0.7485, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.0920, device='cuda:0', dtype=torch.float16)
tensor(0.7720, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
tensor(0.6787, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0184, device='cuda:0')
tensor(0.1492, device='cuda:0')
old_score: tensor(0.0870, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0794, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2350258827209473
Validation after dual ascent:
out_inf: tensor(13.0156, device='cuda:0', dtype=torch.float16) tensor(0.8208, device='cuda:0', dtype=torch.float16)
tensor(0.6597, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.8052, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
tensor(0.7944, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
3 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.9844, device='cuda:0', dtype=torch.float16) tensor(1.3184, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.1244, device='cuda:0', dtype=torch.float16)
tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
3 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7695, device='cuda:0', dtype=torch.float16) tensor(0.1448, device='cuda:0', dtype=torch.float16)
tensor(0.3530, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.3379, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.3672, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.0822, device='cuda:0')
old_score: tensor(0.0405, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0373, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.803830623626709
Validation after dual ascent:
out_inf: tensor(2.7695, device='cuda:0', dtype=torch.float16) tensor(0.1448, device='cuda:0', dtype=torch.float16)
tensor(0.3582, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(0.3765, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.3147, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
3 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.0349, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0328, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0403, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0334, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0187, device='cuda:0')
tensor(0.0373, device='cuda:0')
old_score: tensor(0.0025, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0022, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.257366418838501
Validation after dual ascent:
out_inf: tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.0334, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0306, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0399, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0355, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
3 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(0.3958, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.4604, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0162, device='cuda:0')
tensor(0.1309, device='cuda:0')
old_score: tensor(0.0461, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0425, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.809218406677246
Validation after dual ascent:
out_inf: tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(0.4143, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.4546, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
3 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.9805, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(0.3984, device='cuda:0', dtype=torch.float16) tensor(0.0348, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0098, device='cuda:0')
tensor(0.1041, device='cuda:0')
old_score: tensor(0.0377, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0348, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.818005323410034
Validation after dual ascent:
out_inf: tensor(3.9805, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.3936, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
3 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.5415, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.0525, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0630, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.0588, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.0522, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0117, device='cuda:0')
tensor(0.0285, device='cuda:0')
old_score: tensor(0.0053, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 109.53790187835693
Validation after dual ascent:
out_inf: tensor(0.5415, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.0482, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0618, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.0545, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.0481, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
layer 3 done
4 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.5859, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
4 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.1562, device='cuda:0', dtype=torch.float16) tensor(1.3896, device='cuda:0', dtype=torch.float16)
tensor(1.0088, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(0.9590, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(0.8838, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
4 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7783, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(0.2971, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.2979, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.3027, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(0.3008, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0179, device='cuda:0')
tensor(0.3758, device='cuda:0')
old_score: tensor(0.0389, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0359, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6108083724975586
Validation after dual ascent:
out_inf: tensor(1.7783, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(0.2688, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.2922, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.3125, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.2849, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
4 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.0457, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.0578, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.0438, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.0408, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0203, device='cuda:0')
old_score: tensor(0.0037, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0034, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.9708571434021
Validation after dual ascent:
out_inf: tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.0418, device='cuda:0', dtype=torch.float16) tensor(0.0033, device='cuda:0', dtype=torch.float16)
tensor(0.0505, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0405, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0372, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
4 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.9414, device='cuda:0', dtype=torch.float16) tensor(0.2295, device='cuda:0', dtype=torch.float16)
tensor(0.5474, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.6689, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
tensor(0.4673, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0196, device='cuda:0')
tensor(0.1968, device='cuda:0')
old_score: tensor(0.0530, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0487, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.81876802444458
Validation after dual ascent:
out_inf: tensor(6.9414, device='cuda:0', dtype=torch.float16) tensor(0.2295, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.6709, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0454, device='cuda:0', dtype=torch.float16)
4 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2695, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.4775, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.4604, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.4077, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0145, device='cuda:0')
tensor(0.1426, device='cuda:0')
old_score: tensor(0.0401, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0370, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.819850444793701
Validation after dual ascent:
out_inf: tensor(3.2695, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.4521, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.4736, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
4 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0648, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0674, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0755, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0836, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0096, device='cuda:0')
tensor(0.0203, device='cuda:0')
old_score: tensor(0.0070, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 77.41583180427551
Validation after dual ascent:
out_inf: tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0674, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.0659, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.0770, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.0845, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
layer 4 done
5 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.8828, device='cuda:0', dtype=torch.float16) tensor(0.8135, device='cuda:0', dtype=torch.float16)
tensor(0.7134, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.4859, device='cuda:0')
old_score: tensor(0.0866, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0793, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.492157459259033
Validation after dual ascent:
out_inf: tensor(14.8828, device='cuda:0', dtype=torch.float16) tensor(0.8135, device='cuda:0', dtype=torch.float16)
tensor(0.6802, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
tensor(1.0088, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
tensor(1.0166, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(0.9287, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
5 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20., device='cuda:0', dtype=torch.float16) tensor(1.4326, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.0889, device='cuda:0', dtype=torch.float16) tensor(0.1406, device='cuda:0', dtype=torch.float16)
tensor(1.5020, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1283, device='cuda:0', dtype=torch.float16)
5 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3223, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(0.2996, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.2812, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
tensor(0.3000, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.3079, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0180, device='cuda:0')
tensor(0.4112, device='cuda:0')
old_score: tensor(0.0375, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0349, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6147580146789551
Validation after dual ascent:
out_inf: tensor(2.3223, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(0.2852, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
tensor(0.2896, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.2935, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.2769, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
5 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3564, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.0504, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
tensor(0.0547, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0552, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
tensor(0.0542, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0135, device='cuda:0')
tensor(0.0262, device='cuda:0')
old_score: tensor(0.0046, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0041, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.354523420333862
Validation after dual ascent:
out_inf: tensor(1.3564, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.0431, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.0494, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.0529, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.0455, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
5 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0156, device='cuda:0', dtype=torch.float16) tensor(0.2705, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.7168, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.8857, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0126, device='cuda:0')
tensor(0.0569, device='cuda:0')
old_score: tensor(0.0549, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0502, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.288459777832031
Validation after dual ascent:
out_inf: tensor(4.0156, device='cuda:0', dtype=torch.float16) tensor(0.2705, device='cuda:0', dtype=torch.float16)
tensor(0.4756, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.8481, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
5 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6250, device='cuda:0', dtype=torch.float16) tensor(0.1270, device='cuda:0', dtype=torch.float16)
tensor(0.4404, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.4971, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0083, device='cuda:0')
tensor(0.0396, device='cuda:0')
old_score: tensor(0.0417, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0382, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.292411088943481
Validation after dual ascent:
out_inf: tensor(3.6250, device='cuda:0', dtype=torch.float16) tensor(0.1270, device='cuda:0', dtype=torch.float16)
tensor(0.3896, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.4893, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
5 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8667, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(0.0885, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0751, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.0870, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0839, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0149, device='cuda:0')
tensor(0.0232, device='cuda:0')
old_score: tensor(0.0076, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 69.21851968765259
Validation after dual ascent:
out_inf: tensor(0.8667, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(0.0811, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0732, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0838, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0861, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
layer 5 done
6 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.0781, device='cuda:0', dtype=torch.float16) tensor(0.7617, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(1.0020, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0193, device='cuda:0')
tensor(0.4038, device='cuda:0')
old_score: tensor(0.0908, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0825, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.490114450454712
Validation after dual ascent:
out_inf: tensor(15.0781, device='cuda:0', dtype=torch.float16) tensor(0.7617, device='cuda:0', dtype=torch.float16)
tensor(1.1582, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.7271, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
tensor(0.9302, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
6 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.9375, device='cuda:0', dtype=torch.float16) tensor(1.4619, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.1367, device='cuda:0', dtype=torch.float16)
tensor(1.1416, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(1.1865, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
6 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2793, device='cuda:0', dtype=torch.float16) tensor(0.1501, device='cuda:0', dtype=torch.float16)
tensor(0.3123, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.3235, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.3188, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.2842, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0194, device='cuda:0')
tensor(0.4339, device='cuda:0')
old_score: tensor(0.0411, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0378, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6108119487762451
Validation after dual ascent:
out_inf: tensor(2.2793, device='cuda:0', dtype=torch.float16) tensor(0.1501, device='cuda:0', dtype=torch.float16)
tensor(0.2959, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.2754, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
tensor(0.3022, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.2917, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
6 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7100, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
tensor(0.0659, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0896, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0574, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.1858, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0150, device='cuda:0')
tensor(0.0314, device='cuda:0')
old_score: tensor(0.0061, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0053, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.675286769866943
Validation after dual ascent:
out_inf: tensor(1.7100, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
tensor(0.0688, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.0766, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0579, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.1035, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
6 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.9727, device='cuda:0', dtype=torch.float16) tensor(0.3066, device='cuda:0', dtype=torch.float16)
tensor(0.6006, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
tensor(0.5713, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0100, device='cuda:0')
tensor(0.0414, device='cuda:0')
old_score: tensor(0.0559, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0510, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.282228946685791
Validation after dual ascent:
out_inf: tensor(5.9727, device='cuda:0', dtype=torch.float16) tensor(0.3066, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.5850, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
6 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.4473, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0164, device='cuda:0')
tensor(0.1554, device='cuda:0')
old_score: tensor(0.0426, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0390, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.818251371383667
Validation after dual ascent:
out_inf: tensor(3.4473, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
6 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
tensor(0.0753, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0778, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0798, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0930, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0136, device='cuda:0')
tensor(0.0211, device='cuda:0')
old_score: tensor(0.0081, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0076, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 69.13324236869812
Validation after dual ascent:
out_inf: tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
tensor(0.0784, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.0772, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0845, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.0853, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
layer 6 done
7 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.5312, device='cuda:0', dtype=torch.float16) tensor(0.7515, device='cuda:0', dtype=torch.float16)
tensor(0.8604, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.8076, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0147, device='cuda:0')
tensor(0.2001, device='cuda:0')
old_score: tensor(0.0891, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0807, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.226656436920166
Validation after dual ascent:
out_inf: tensor(16.5312, device='cuda:0', dtype=torch.float16) tensor(0.7515, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(0.6997, device='cuda:0', dtype=torch.float16) tensor(0.0835, device='cuda:0', dtype=torch.float16)
tensor(0.9229, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
7 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.0156, device='cuda:0', dtype=torch.float16) tensor(1.4824, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(1.1504, device='cuda:0', dtype=torch.float16) tensor(0.1493, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1506, device='cuda:0', dtype=torch.float16)
tensor(1.2012, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
7 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4883, device='cuda:0', dtype=torch.float16) tensor(0.1714, device='cuda:0', dtype=torch.float16)
tensor(0.2915, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.3188, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.3240, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0196, device='cuda:0')
tensor(0.4401, device='cuda:0')
old_score: tensor(0.0421, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0386, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6129443645477295
Validation after dual ascent:
out_inf: tensor(2.4883, device='cuda:0', dtype=torch.float16) tensor(0.1714, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.2917, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.2900, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(0.3120, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
7 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2715, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(0.0669, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0707, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0693, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.1230, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0099, device='cuda:0')
tensor(0.0251, device='cuda:0')
old_score: tensor(0.0068, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0059, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.347092151641846
Validation after dual ascent:
out_inf: tensor(2.2715, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(0.0657, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0571, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.0603, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.0964, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
7 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.7188, device='cuda:0', dtype=torch.float16) tensor(0.3105, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.2288, device='cuda:0')
old_score: tensor(0.0560, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0513, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.826074838638306
Validation after dual ascent:
out_inf: tensor(4.7188, device='cuda:0', dtype=torch.float16) tensor(0.3105, device='cuda:0', dtype=torch.float16)
tensor(0.5264, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
7 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.9023, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(0.3799, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0104, device='cuda:0')
tensor(0.1703, device='cuda:0')
old_score: tensor(0.0443, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0406, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.825536012649536
Validation after dual ascent:
out_inf: tensor(3.9023, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(0.3975, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.4756, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.4404, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
7 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.4248, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.0835, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.0800, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.0830, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.0811, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0069, device='cuda:0')
tensor(0.0132, device='cuda:0')
old_score: tensor(0.0086, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0081, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 69.16560459136963
Validation after dual ascent:
out_inf: tensor(1.4248, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0826, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.0814, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0845, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
layer 7 done
8 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.0703, device='cuda:0', dtype=torch.float16) tensor(0.7334, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.9746, device='cuda:0', dtype=torch.float16) tensor(0.0962, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(1.3223, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0195, device='cuda:0')
tensor(0.4876, device='cuda:0')
old_score: tensor(0.0962, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0875, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.491905927658081
Validation after dual ascent:
out_inf: tensor(13.0703, device='cuda:0', dtype=torch.float16) tensor(0.7334, device='cuda:0', dtype=torch.float16)
tensor(1.1504, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(0.7319, device='cuda:0', dtype=torch.float16) tensor(0.0901, device='cuda:0', dtype=torch.float16)
tensor(1.2842, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
8 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(1.5889, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(1.1924, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1547, device='cuda:0', dtype=torch.float16)
tensor(1.4355, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
8 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.9707, device='cuda:0', dtype=torch.float16) tensor(0.1660, device='cuda:0', dtype=torch.float16)
tensor(0.3252, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.3560, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(0.3477, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.3403, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0040, device='cuda:0')
tensor(0.1143, device='cuda:0')
old_score: tensor(0.0461, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0422, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7979989051818848
Validation after dual ascent:
out_inf: tensor(1.9707, device='cuda:0', dtype=torch.float16) tensor(0.1660, device='cuda:0', dtype=torch.float16)
tensor(0.2996, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.3584, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.3264, device='cuda:0', dtype=torch.float16) tensor(0.0437, device='cuda:0', dtype=torch.float16)
tensor(0.3235, device='cuda:0', dtype=torch.float16) tensor(0.0419, device='cuda:0', dtype=torch.float16)
8 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.0059, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.0734, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0765, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.0663, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.0798, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0147, device='cuda:0')
tensor(0.0209, device='cuda:0')
old_score: tensor(0.0074, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0064, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.407243013381958
Validation after dual ascent:
out_inf: tensor(2.0059, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.0629, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0607, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.0629, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0713, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
8 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5527, device='cuda:0', dtype=torch.float16) tensor(0.3057, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.6060, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.2469, device='cuda:0')
old_score: tensor(0.0577, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0530, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.821922779083252
Validation after dual ascent:
out_inf: tensor(3.5527, device='cuda:0', dtype=torch.float16) tensor(0.3057, device='cuda:0', dtype=torch.float16)
tensor(0.5186, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.5981, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.4795, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
8 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5566, device='cuda:0', dtype=torch.float16) tensor(0.1486, device='cuda:0', dtype=torch.float16)
tensor(0.4463, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.4956, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.5010, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0107, device='cuda:0')
tensor(0.1827, device='cuda:0')
old_score: tensor(0.0455, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.822753190994263
Validation after dual ascent:
out_inf: tensor(3.5566, device='cuda:0', dtype=torch.float16) tensor(0.1486, device='cuda:0', dtype=torch.float16)
tensor(0.4209, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.5186, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
8 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.0776, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0816, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0821, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0833, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0200, device='cuda:0')
tensor(0.0413, device='cuda:0')
old_score: tensor(0.0087, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0082, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.07748484611511
Validation after dual ascent:
out_inf: tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.0738, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0770, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.0815, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0750, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
layer 8 done
9 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.2031, device='cuda:0', dtype=torch.float16) tensor(0.7480, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
tensor(0.8843, device='cuda:0', dtype=torch.float16) tensor(0.0985, device='cuda:0', dtype=torch.float16)
tensor(0.8052, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0985, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0195, device='cuda:0')
tensor(0.5092, device='cuda:0')
old_score: tensor(0.0988, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0900, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.490765333175659
Validation after dual ascent:
out_inf: tensor(15.2031, device='cuda:0', dtype=torch.float16) tensor(0.7480, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.8315, device='cuda:0', dtype=torch.float16) tensor(0.0900, device='cuda:0', dtype=torch.float16)
tensor(0.7964, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
9 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.9375, device='cuda:0', dtype=torch.float16) tensor(1.4863, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.1570, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.1583, device='cuda:0', dtype=torch.float16)
tensor(1.2246, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.1588, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.4016, device='cuda:0')
old_score: tensor(0.1591, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1436, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7982823848724365
Validation after dual ascent:
out_inf: tensor(15.9375, device='cuda:0', dtype=torch.float16) tensor(1.4863, device='cuda:0', dtype=torch.float16)
tensor(1.0830, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.1488, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
9 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6602, device='cuda:0', dtype=torch.float16) tensor(0.1943, device='cuda:0', dtype=torch.float16)
tensor(0.4487, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
tensor(0.4260, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0047, device='cuda:0')
tensor(0.1383, device='cuda:0')
old_score: tensor(0.0532, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0489, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7979598045349121
Validation after dual ascent:
out_inf: tensor(2.6602, device='cuda:0', dtype=torch.float16) tensor(0.1943, device='cuda:0', dtype=torch.float16)
tensor(0.4155, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.3735, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
tensor(0.3850, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
9 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3008, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.0847, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0792, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.0884, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0896, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0196, device='cuda:0')
tensor(0.0244, device='cuda:0')
old_score: tensor(0.0090, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0077, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9469313621520996
Validation after dual ascent:
out_inf: tensor(2.3008, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.0734, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.0740, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.0745, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
9 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2852, device='cuda:0', dtype=torch.float16) tensor(0.3340, device='cuda:0', dtype=torch.float16)
tensor(0.5630, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.6904, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.2616, device='cuda:0')
old_score: tensor(0.0589, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0539, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.829324245452881
Validation after dual ascent:
out_inf: tensor(4.2852, device='cuda:0', dtype=torch.float16) tensor(0.3340, device='cuda:0', dtype=torch.float16)
tensor(0.5596, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.5088, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
9 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.9629, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(0.3999, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.4446, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4961, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0112, device='cuda:0')
tensor(0.1924, device='cuda:0')
old_score: tensor(0.0464, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0426, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.828223943710327
Validation after dual ascent:
out_inf: tensor(3.9629, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(0.3679, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.4434, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
9 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.1533, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.0812, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0904, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0900, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.0922, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0157, device='cuda:0')
tensor(0.0264, device='cuda:0')
old_score: tensor(0.0093, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.019309520721436
Validation after dual ascent:
out_inf: tensor(1.1533, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.0764, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.0872, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.0941, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.0834, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
layer 9 done
10 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.3281, device='cuda:0', dtype=torch.float16) tensor(0.7700, device='cuda:0', dtype=torch.float16)
tensor(1.2871, device='cuda:0', dtype=torch.float16) tensor(0.1022, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.9482, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1024, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0104, device='cuda:0')
tensor(0.3644, device='cuda:0')
old_score: tensor(0.1027, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0936, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2329466342926025
Validation after dual ascent:
out_inf: tensor(16.3281, device='cuda:0', dtype=torch.float16) tensor(0.7700, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
tensor(1.1201, device='cuda:0', dtype=torch.float16) tensor(0.0937, device='cuda:0', dtype=torch.float16)
tensor(0.9009, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0926, device='cuda:0', dtype=torch.float16)
10 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.1172, device='cuda:0', dtype=torch.float16) tensor(1.5703, device='cuda:0', dtype=torch.float16)
tensor(1.3066, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(1.3262, device='cuda:0', dtype=torch.float16) tensor(0.1669, device='cuda:0', dtype=torch.float16)
tensor(1.1787, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(1.2246, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0164, device='cuda:0')
tensor(0.4696, device='cuda:0')
old_score: tensor(0.1666, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1508, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8014390468597412
Validation after dual ascent:
out_inf: tensor(15.1172, device='cuda:0', dtype=torch.float16) tensor(1.5703, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(1.1699, device='cuda:0', dtype=torch.float16) tensor(0.1516, device='cuda:0', dtype=torch.float16)
tensor(1.0879, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
10 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.1887, device='cuda:0', dtype=torch.float16)
tensor(0.3647, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.3381, device='cuda:0', dtype=torch.float16) tensor(0.0487, device='cuda:0', dtype=torch.float16)
tensor(0.4189, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.3633, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0044, device='cuda:0')
tensor(0.1442, device='cuda:0')
old_score: tensor(0.0487, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0448, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8020286560058594
Validation after dual ascent:
out_inf: tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.1887, device='cuda:0', dtype=torch.float16)
tensor(0.3301, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
tensor(0.3162, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.3887, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.3328, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
10 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7129, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
tensor(0.0986, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.0895, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.0852, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.0975, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0110, device='cuda:0')
tensor(0.0256, device='cuda:0')
old_score: tensor(0.0095, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0085, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7412242889404297
Validation after dual ascent:
out_inf: tensor(2.7129, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
tensor(0.0831, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0954, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0797, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0939, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
10 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0898, device='cuda:0', dtype=torch.float16) tensor(0.3242, device='cuda:0', dtype=torch.float16)
tensor(0.5342, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0166, device='cuda:0')
tensor(0.2734, device='cuda:0')
old_score: tensor(0.0594, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0546, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.825911521911621
Validation after dual ascent:
out_inf: tensor(4.0898, device='cuda:0', dtype=torch.float16) tensor(0.3242, device='cuda:0', dtype=torch.float16)
tensor(0.4619, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.5664, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
10 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2539, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
tensor(0.4302, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
tensor(0.5068, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.5010, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.2116, device='cuda:0')
old_score: tensor(0.0487, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0448, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.827131271362305
Validation after dual ascent:
out_inf: tensor(3.2539, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4275, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
10 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.0817, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.0935, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0887, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.0875, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0145, device='cuda:0')
tensor(0.0131, device='cuda:0')
old_score: tensor(0.0097, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0091, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.06069850921631
Validation after dual ascent:
out_inf: tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.0840, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.0900, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.0863, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0862, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
layer 10 done
11 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.9844, device='cuda:0', dtype=torch.float16) tensor(0.7231, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.1029, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(0.8320, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0096, device='cuda:0')
tensor(0.3163, device='cuda:0')
old_score: tensor(0.1036, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0948, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.232771158218384
Validation after dual ascent:
out_inf: tensor(11.9844, device='cuda:0', dtype=torch.float16) tensor(0.7231, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0928, device='cuda:0', dtype=torch.float16)
tensor(0.8545, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0978, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
11 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.7812, device='cuda:0', dtype=torch.float16) tensor(1.5029, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1744, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.1765, device='cuda:0', dtype=torch.float16)
tensor(1.2041, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0168, device='cuda:0')
tensor(0.4862, device='cuda:0')
old_score: tensor(0.1741, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1580, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8028254508972168
Validation after dual ascent:
out_inf: tensor(16.7812, device='cuda:0', dtype=torch.float16) tensor(1.5029, device='cuda:0', dtype=torch.float16)
tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.1543, device='cuda:0', dtype=torch.float16)
tensor(1.2334, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(1.1982, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
11 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9082, device='cuda:0', dtype=torch.float16) tensor(0.2124, device='cuda:0', dtype=torch.float16)
tensor(0.3667, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.3799, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.3735, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.3740, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0047, device='cuda:0')
tensor(0.1413, device='cuda:0')
old_score: tensor(0.0524, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0482, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8024811744689941
Validation after dual ascent:
out_inf: tensor(2.9082, device='cuda:0', dtype=torch.float16) tensor(0.2124, device='cuda:0', dtype=torch.float16)
tensor(0.3289, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
tensor(0.3516, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.3477, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
11 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.5527, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.1025, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.0879, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.0824, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.0936, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0112, device='cuda:0')
tensor(0.0163, device='cuda:0')
old_score: tensor(0.0097, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0083, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.947355031967163
Validation after dual ascent:
out_inf: tensor(2.5527, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.0956, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.0848, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.0721, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0798, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
11 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.6094, device='cuda:0', dtype=torch.float16) tensor(0.3269, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.6357, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.6924, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.2738, device='cuda:0')
old_score: tensor(0.0597, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0548, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.82982873916626
Validation after dual ascent:
out_inf: tensor(6.6094, device='cuda:0', dtype=torch.float16) tensor(0.3269, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
tensor(0.6377, device='cuda:0', dtype=torch.float16) tensor(0.0563, device='cuda:0', dtype=torch.float16)
tensor(0.7744, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
11 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.4902, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.4590, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0122, device='cuda:0')
tensor(0.2176, device='cuda:0')
old_score: tensor(0.0500, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0460, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.831096410751343
Validation after dual ascent:
out_inf: tensor(3.4902, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.4771, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.4204, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
11 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.0863, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.0945, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1001, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.0880, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0188, device='cuda:0')
tensor(0.0357, device='cuda:0')
old_score: tensor(0.0103, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.937190532684326
Validation after dual ascent:
out_inf: tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.0830, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.0875, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0994, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.0919, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
layer 11 done
12 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.1016, device='cuda:0', dtype=torch.float16) tensor(0.7319, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0114, device='cuda:0')
tensor(0.2189, device='cuda:0')
old_score: tensor(0.1008, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0926, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2339744567871094
Validation after dual ascent:
out_inf: tensor(15.1016, device='cuda:0', dtype=torch.float16) tensor(0.7319, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(0.7495, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
12 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.6094, device='cuda:0', dtype=torch.float16) tensor(1.3477, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.1627, device='cuda:0', dtype=torch.float16)
tensor(1.1709, device='cuda:0', dtype=torch.float16) tensor(0.1633, device='cuda:0', dtype=torch.float16)
tensor(1.2236, device='cuda:0', dtype=torch.float16) tensor(0.1621, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0157, device='cuda:0')
tensor(0.3763, device='cuda:0')
old_score: tensor(0.1626, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1482, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.804844856262207
Validation after dual ascent:
out_inf: tensor(19.6094, device='cuda:0', dtype=torch.float16) tensor(1.3477, device='cuda:0', dtype=torch.float16)
tensor(1.0498, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
tensor(1.1504, device='cuda:0', dtype=torch.float16) tensor(0.1489, device='cuda:0', dtype=torch.float16)
tensor(1.0654, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
12 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.2087, device='cuda:0', dtype=torch.float16)
tensor(0.3955, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.4338, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(0.4092, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.1360, device='cuda:0')
old_score: tensor(0.0570, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8033134937286377
Validation after dual ascent:
out_inf: tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.2087, device='cuda:0', dtype=torch.float16)
tensor(0.3516, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(0.3970, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(0.4006, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
12 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7969, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.0998, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1072, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.0991, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.0961, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0145, device='cuda:0')
tensor(0.0340, device='cuda:0')
old_score: tensor(0.0105, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0090, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7437434196472168
Validation after dual ascent:
out_inf: tensor(2.7969, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.0886, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.0913, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0969, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0924, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
12 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2305, device='cuda:0', dtype=torch.float16) tensor(0.3335, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.5928, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.2695, device='cuda:0')
old_score: tensor(0.0583, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0538, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.82423996925354
Validation after dual ascent:
out_inf: tensor(4.2305, device='cuda:0', dtype=torch.float16) tensor(0.3335, device='cuda:0', dtype=torch.float16)
tensor(0.4521, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
tensor(0.6377, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
12 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4141, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.4287, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0122, device='cuda:0')
tensor(0.2194, device='cuda:0')
old_score: tensor(0.0508, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0470, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.8210625648498535
Validation after dual ascent:
out_inf: tensor(4.4141, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
tensor(0.3811, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.4270, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
12 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.0888, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1041, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1290, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1050, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0157, device='cuda:0')
tensor(0.0275, device='cuda:0')
old_score: tensor(0.0109, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.81841588020325
Validation after dual ascent:
out_inf: tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.0859, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1018, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1202, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.0947, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
layer 12 done
13 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.7573, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.1131, device='cuda:0', dtype=torch.float16)
tensor(0.8877, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(0.9390, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0097, device='cuda:0')
tensor(0.3885, device='cuda:0')
old_score: tensor(0.1129, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1037, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2385380268096924
Validation after dual ascent:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.7573, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(0.8784, device='cuda:0', dtype=torch.float16) tensor(0.1059, device='cuda:0', dtype=torch.float16)
tensor(0.8521, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
13 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.7656, device='cuda:0', dtype=torch.float16) tensor(1.5850, device='cuda:0', dtype=torch.float16)
tensor(1.3965, device='cuda:0', dtype=torch.float16) tensor(0.1840, device='cuda:0', dtype=torch.float16)
tensor(1.3818, device='cuda:0', dtype=torch.float16) tensor(0.1855, device='cuda:0', dtype=torch.float16)
tensor(1.4463, device='cuda:0', dtype=torch.float16) tensor(0.1882, device='cuda:0', dtype=torch.float16)
tensor(1.3193, device='cuda:0', dtype=torch.float16) tensor(0.1854, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0178, device='cuda:0')
tensor(0.5766, device='cuda:0')
old_score: tensor(0.1858, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1697, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8100602626800537
Validation after dual ascent:
out_inf: tensor(17.7656, device='cuda:0', dtype=torch.float16) tensor(1.5850, device='cuda:0', dtype=torch.float16)
tensor(1.2686, device='cuda:0', dtype=torch.float16) tensor(0.1661, device='cuda:0', dtype=torch.float16)
tensor(1.3037, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(1.3330, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
13 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.5156, device='cuda:0', dtype=torch.float16) tensor(0.2048, device='cuda:0', dtype=torch.float16)
tensor(0.4324, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.4685, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.4287, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.4761, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0055, device='cuda:0')
tensor(0.1734, device='cuda:0')
old_score: tensor(0.0607, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0562, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8089313507080078
Validation after dual ascent:
out_inf: tensor(2.5156, device='cuda:0', dtype=torch.float16) tensor(0.2048, device='cuda:0', dtype=torch.float16)
tensor(0.4060, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.4165, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.4668, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
13 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0156, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.1277, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1315, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1096, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1298, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0113, device='cuda:0')
tensor(0.0414, device='cuda:0')
old_score: tensor(0.0126, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7424273490905762
Validation after dual ascent:
out_inf: tensor(4.0156, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.1013, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1118, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.0934, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1076, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
13 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.3125, device='cuda:0', dtype=torch.float16) tensor(0.3425, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.6245, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0171, device='cuda:0')
tensor(0.2886, device='cuda:0')
old_score: tensor(0.0604, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0558, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.827796936035156
Validation after dual ascent:
out_inf: tensor(5.3125, device='cuda:0', dtype=torch.float16) tensor(0.3425, device='cuda:0', dtype=torch.float16)
tensor(0.4810, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.5825, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
13 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4688, device='cuda:0', dtype=torch.float16) tensor(0.1761, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.5615, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.5146, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0129, device='cuda:0')
tensor(0.2391, device='cuda:0')
old_score: tensor(0.0524, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0485, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.831634759902954
Validation after dual ascent:
out_inf: tensor(4.4688, device='cuda:0', dtype=torch.float16) tensor(0.1761, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.5127, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
13 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.0961, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1013, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1088, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1125, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.0115, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0107, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.85217332839966
Validation after dual ascent:
out_inf: tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.0917, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1094, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1118, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1083, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
layer 13 done
14 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.0078, device='cuda:0', dtype=torch.float16) tensor(0.7485, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(0.9614, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1084, device='cuda:0', dtype=torch.float16)
tensor(0.9385, device='cuda:0', dtype=torch.float16) tensor(0.1092, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0106, device='cuda:0')
tensor(0.3697, device='cuda:0')
old_score: tensor(0.1084, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0999, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.233637571334839
Validation after dual ascent:
out_inf: tensor(14.0078, device='cuda:0', dtype=torch.float16) tensor(0.7485, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(1.1123, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(0.9170, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
14 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.0781, device='cuda:0', dtype=torch.float16) tensor(1.5859, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1746, device='cuda:0', dtype=torch.float16)
tensor(1.3965, device='cuda:0', dtype=torch.float16) tensor(0.1748, device='cuda:0', dtype=torch.float16)
tensor(1.8711, device='cuda:0', dtype=torch.float16) tensor(0.1757, device='cuda:0', dtype=torch.float16)
tensor(1.2451, device='cuda:0', dtype=torch.float16) tensor(0.1768, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0171, device='cuda:0')
tensor(0.5104, device='cuda:0')
old_score: tensor(0.1754, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1602, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8026857376098633
Validation after dual ascent:
out_inf: tensor(22.0781, device='cuda:0', dtype=torch.float16) tensor(1.5859, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.1572, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1610, device='cuda:0', dtype=torch.float16)
14 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6934, device='cuda:0', dtype=torch.float16) tensor(0.2097, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.4167, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.4297, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0051, device='cuda:0')
tensor(0.1603, device='cuda:0')
old_score: tensor(0.0575, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0531, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8032987117767334
Validation after dual ascent:
out_inf: tensor(2.6934, device='cuda:0', dtype=torch.float16) tensor(0.2097, device='cuda:0', dtype=torch.float16)
tensor(0.3816, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.3748, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
14 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8828, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.1001, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1108, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1051, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1052, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0165, device='cuda:0')
tensor(0.0488, device='cuda:0')
old_score: tensor(0.0120, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.740875244140625
Validation after dual ascent:
out_inf: tensor(2.8828, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.0875, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.0955, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.0996, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1013, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
14 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.4492, device='cuda:0', dtype=torch.float16) tensor(0.3704, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.7588, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.3195, device='cuda:0')
old_score: tensor(0.0634, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0587, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.834020137786865
Validation after dual ascent:
out_inf: tensor(5.4492, device='cuda:0', dtype=torch.float16) tensor(0.3704, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
14 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.1757, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0135, device='cuda:0')
tensor(0.2582, device='cuda:0')
old_score: tensor(0.0537, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0497, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.832636594772339
Validation after dual ascent:
out_inf: tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.1757, device='cuda:0', dtype=torch.float16)
tensor(0.4009, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
tensor(0.5635, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
14 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2373, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.1119, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1282, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1605, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1146, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0082, device='cuda:0')
tensor(0.0159, device='cuda:0')
old_score: tensor(0.0120, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0112, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.79902625083923
Validation after dual ascent:
out_inf: tensor(1.2373, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.1033, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1379, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1647, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1058, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
layer 14 done
15 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.5938, device='cuda:0', dtype=torch.float16) tensor(0.8037, device='cuda:0', dtype=torch.float16)
tensor(1.3818, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(0.8457, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0108, device='cuda:0')
tensor(0.4056, device='cuda:0')
old_score: tensor(0.1114, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1025, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2387330532073975
Validation after dual ascent:
out_inf: tensor(19.5938, device='cuda:0', dtype=torch.float16) tensor(0.8037, device='cuda:0', dtype=torch.float16)
tensor(1.3584, device='cuda:0', dtype=torch.float16) tensor(0.1012, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.8735, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
15 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.7656, device='cuda:0', dtype=torch.float16) tensor(1.5801, device='cuda:0', dtype=torch.float16)
tensor(1.4473, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1780, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(1.2959, device='cuda:0', dtype=torch.float16) tensor(0.1819, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0171, device='cuda:0')
tensor(0.4810, device='cuda:0')
old_score: tensor(0.1794, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1637, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.808772087097168
Validation after dual ascent:
out_inf: tensor(21.7656, device='cuda:0', dtype=torch.float16) tensor(1.5801, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(1.2227, device='cuda:0', dtype=torch.float16) tensor(0.1631, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.1652, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
15 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2930, device='cuda:0', dtype=torch.float16) tensor(0.1965, device='cuda:0', dtype=torch.float16)
tensor(0.4707, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.4390, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.4785, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.1681, device='cuda:0')
old_score: tensor(0.0602, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0557, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8083367347717285
Validation after dual ascent:
out_inf: tensor(3.2930, device='cuda:0', dtype=torch.float16) tensor(0.1965, device='cuda:0', dtype=torch.float16)
tensor(0.4463, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
tensor(0.4282, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.4368, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
15 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6191, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.1215, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.1156, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1044, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1298, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0102, device='cuda:0')
tensor(0.0449, device='cuda:0')
old_score: tensor(0.0132, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7487735748291016
Validation after dual ascent:
out_inf: tensor(3.6191, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.1056, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1202, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.0950, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1138, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
15 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.4727, device='cuda:0', dtype=torch.float16) tensor(0.3848, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0675, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0112, device='cuda:0')
tensor(0.0756, device='cuda:0')
old_score: tensor(0.0668, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0615, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.297306299209595
Validation after dual ascent:
out_inf: tensor(7.4727, device='cuda:0', dtype=torch.float16) tensor(0.3848, device='cuda:0', dtype=torch.float16)
tensor(0.7061, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.6748, device='cuda:0', dtype=torch.float16) tensor(0.0619, device='cuda:0', dtype=torch.float16)
tensor(0.6138, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
15 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.1747, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.5610, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5635, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0146, device='cuda:0')
tensor(0.2875, device='cuda:0')
old_score: tensor(0.0547, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0504, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.832006931304932
Validation after dual ascent:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.1747, device='cuda:0', dtype=torch.float16)
tensor(0.4604, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.5435, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
15 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.9736, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.1245, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1279, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1577, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1515, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0064, device='cuda:0')
tensor(0.0098, device='cuda:0')
old_score: tensor(0.0126, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.906174421310425
Validation after dual ascent:
out_inf: tensor(1.9736, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.1184, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1283, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1414, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1646, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
layer 15 done
16 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.7969, device='cuda:0', dtype=torch.float16) tensor(0.7617, device='cuda:0', dtype=torch.float16)
tensor(1.0537, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(0.8696, device='cuda:0', dtype=torch.float16) tensor(0.1024, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0114, device='cuda:0')
tensor(0.3395, device='cuda:0')
old_score: tensor(0.1029, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0942, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2311997413635254
Validation after dual ascent:
out_inf: tensor(14.7969, device='cuda:0', dtype=torch.float16) tensor(0.7617, device='cuda:0', dtype=torch.float16)
tensor(0.9414, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(0.9033, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
tensor(0.7671, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
16 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.0156, device='cuda:0', dtype=torch.float16) tensor(1.5420, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1626, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.1595, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1587, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1627, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0155, device='cuda:0')
tensor(0.4051, device='cuda:0')
old_score: tensor(0.1609, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1465, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8007423877716064
Validation after dual ascent:
out_inf: tensor(22.0156, device='cuda:0', dtype=torch.float16) tensor(1.5420, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(1.1758, device='cuda:0', dtype=torch.float16) tensor(0.1460, device='cuda:0', dtype=torch.float16)
tensor(1.1270, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.1477, device='cuda:0', dtype=torch.float16)
16 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2305, device='cuda:0', dtype=torch.float16) tensor(0.1952, device='cuda:0', dtype=torch.float16)
tensor(0.3628, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.4961, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.3967, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0044, device='cuda:0')
tensor(0.1302, device='cuda:0')
old_score: tensor(0.0518, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0476, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8000013828277588
Validation after dual ascent:
out_inf: tensor(2.2305, device='cuda:0', dtype=torch.float16) tensor(0.1952, device='cuda:0', dtype=torch.float16)
tensor(0.3501, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.4683, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
tensor(0.3984, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
tensor(0.3755, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
16 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.1836, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.1117, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.1262, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1120, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1128, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0190, device='cuda:0')
tensor(0.0469, device='cuda:0')
old_score: tensor(0.0122, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7462899684906006
Validation after dual ascent:
out_inf: tensor(4.1836, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.1023, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.0945, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.0917, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1080, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
16 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.8359, device='cuda:0', dtype=torch.float16) tensor(0.3767, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0686, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.8691, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0109, device='cuda:0')
tensor(0.0803, device='cuda:0')
old_score: tensor(0.0691, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0637, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.29720425605774
Validation after dual ascent:
out_inf: tensor(7.8359, device='cuda:0', dtype=torch.float16) tensor(0.3767, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.7920, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
16 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3066, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5190, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.2977, device='cuda:0')
old_score: tensor(0.0545, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.834162473678589
Validation after dual ascent:
out_inf: tensor(3.3066, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(0.4756, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.6104, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.4966, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
16 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.1128, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1241, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1409, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1285, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0068, device='cuda:0')
tensor(0.0107, device='cuda:0')
old_score: tensor(0.0121, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0113, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.892526626586914
Validation after dual ascent:
out_inf: tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.1075, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1235, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1368, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.1302, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
layer 16 done
17 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.0938, device='cuda:0', dtype=torch.float16) tensor(0.7793, device='cuda:0', dtype=torch.float16)
tensor(0.9541, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(0.8286, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(0.9248, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0122, device='cuda:0')
tensor(0.3655, device='cuda:0')
old_score: tensor(0.1041, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0954, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2358314990997314
Validation after dual ascent:
out_inf: tensor(18.0938, device='cuda:0', dtype=torch.float16) tensor(0.7793, device='cuda:0', dtype=torch.float16)
tensor(0.8730, device='cuda:0', dtype=torch.float16) tensor(0.0946, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
17 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.4375, device='cuda:0', dtype=torch.float16) tensor(1.5107, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1639, device='cuda:0', dtype=torch.float16)
tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(1.3115, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.4250, device='cuda:0')
old_score: tensor(0.1639, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1495, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8055226802825928
Validation after dual ascent:
out_inf: tensor(20.4375, device='cuda:0', dtype=torch.float16) tensor(1.5107, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.1477, device='cuda:0', dtype=torch.float16)
tensor(1.2959, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(1.3623, device='cuda:0', dtype=torch.float16) tensor(0.1497, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
17 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2539, device='cuda:0', dtype=torch.float16) tensor(0.1807, device='cuda:0', dtype=torch.float16)
tensor(0.4263, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.4780, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.4790, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0050, device='cuda:0')
tensor(0.1612, device='cuda:0')
old_score: tensor(0.0585, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0540, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8059384822845459
Validation after dual ascent:
out_inf: tensor(2.2539, device='cuda:0', dtype=torch.float16) tensor(0.1807, device='cuda:0', dtype=torch.float16)
tensor(0.4331, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(0.4346, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.4468, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.4192, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
17 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.1719, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.1108, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1166, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1077, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1239, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0199, device='cuda:0')
tensor(0.0337, device='cuda:0')
old_score: tensor(0.0111, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0096, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.683430194854736
Validation after dual ascent:
out_inf: tensor(4.1719, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.0954, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1099, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1031, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0990, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
17 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.5977, device='cuda:0', dtype=torch.float16) tensor(0.3796, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.9160, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
tensor(0.9482, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0116, device='cuda:0')
tensor(0.0819, device='cuda:0')
old_score: tensor(0.0693, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0634, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.29391360282898
Validation after dual ascent:
out_inf: tensor(7.5977, device='cuda:0', dtype=torch.float16) tensor(0.3796, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.8223, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.9990, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
17 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0664, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(0.4854, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0149, device='cuda:0')
tensor(0.2979, device='cuda:0')
old_score: tensor(0.0540, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0494, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.833997011184692
Validation after dual ascent:
out_inf: tensor(4.0664, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(0.4771, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.6045, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0492, device='cuda:0', dtype=torch.float16)
17 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8462, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.1324, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1832, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.1346, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.1292, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0144, device='cuda:0')
tensor(0.0197, device='cuda:0')
old_score: tensor(0.0127, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0118, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.771147966384888
Validation after dual ascent:
out_inf: tensor(0.8462, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.1272, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1716, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1375, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1233, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
layer 17 done
18 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.9531, device='cuda:0', dtype=torch.float16) tensor(0.7266, device='cuda:0', dtype=torch.float16)
tensor(1.2705, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(1.2393, device='cuda:0', dtype=torch.float16) tensor(0.1024, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0127, device='cuda:0')
tensor(0.3087, device='cuda:0')
old_score: tensor(0.1032, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0942, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.235011339187622
Validation after dual ascent:
out_inf: tensor(15.9531, device='cuda:0', dtype=torch.float16) tensor(0.7266, device='cuda:0', dtype=torch.float16)
tensor(1.2705, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(1.2441, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
18 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.8750, device='cuda:0', dtype=torch.float16) tensor(1.5156, device='cuda:0', dtype=torch.float16)
tensor(1.3291, device='cuda:0', dtype=torch.float16) tensor(0.1626, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.1617, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.1621, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0159, device='cuda:0')
tensor(0.4161, device='cuda:0')
old_score: tensor(0.1630, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1482, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8076069355010986
Validation after dual ascent:
out_inf: tensor(19.8750, device='cuda:0', dtype=torch.float16) tensor(1.5156, device='cuda:0', dtype=torch.float16)
tensor(1.3506, device='cuda:0', dtype=torch.float16) tensor(0.1462, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
18 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6543, device='cuda:0', dtype=torch.float16) tensor(0.1821, device='cuda:0', dtype=torch.float16)
tensor(0.3843, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.4207, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.4067, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0044, device='cuda:0')
tensor(0.1329, device='cuda:0')
old_score: tensor(0.0509, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0468, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8068788051605225
Validation after dual ascent:
out_inf: tensor(2.6543, device='cuda:0', dtype=torch.float16) tensor(0.1821, device='cuda:0', dtype=torch.float16)
tensor(0.3818, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.4326, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.4014, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.3674, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
18 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8750, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.0974, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.0971, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0946, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.0991, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0183, device='cuda:0')
tensor(0.0432, device='cuda:0')
old_score: tensor(0.0081, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.03386378288269
Validation after dual ascent:
out_inf: tensor(2.8750, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.0988, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.0957, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.0939, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.0906, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
18 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.9727, device='cuda:0', dtype=torch.float16) tensor(0.3574, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.9678, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0109, device='cuda:0')
tensor(0.0817, device='cuda:0')
old_score: tensor(0.0698, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0638, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.310956716537476
Validation after dual ascent:
out_inf: tensor(7.9727, device='cuda:0', dtype=torch.float16) tensor(0.3574, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0625, device='cuda:0', dtype=torch.float16)
tensor(1.1201, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(1.1553, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
18 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7578, device='cuda:0', dtype=torch.float16) tensor(0.1632, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.6826, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.5493, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0151, device='cuda:0')
tensor(0.3042, device='cuda:0')
old_score: tensor(0.0537, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0491, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.8344080448150635
Validation after dual ascent:
out_inf: tensor(3.7578, device='cuda:0', dtype=torch.float16) tensor(0.1632, device='cuda:0', dtype=torch.float16)
tensor(0.4333, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.5386, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
18 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.9121, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.1410, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1343, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1451, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.0226, device='cuda:0')
old_score: tensor(0.0120, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0111, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.87857699394226
Validation after dual ascent:
out_inf: tensor(1.9121, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.1266, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1378, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1394, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1243, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
layer 18 done
19 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.4297, device='cuda:0', dtype=torch.float16) tensor(0.7637, device='cuda:0', dtype=torch.float16)
tensor(0.8994, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1029, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.1004, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0135, device='cuda:0')
tensor(0.3208, device='cuda:0')
old_score: tensor(0.1008, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0916, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.232330322265625
Validation after dual ascent:
out_inf: tensor(14.4297, device='cuda:0', dtype=torch.float16) tensor(0.7637, device='cuda:0', dtype=torch.float16)
tensor(0.8364, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(0.8154, device='cuda:0', dtype=torch.float16) tensor(0.0921, device='cuda:0', dtype=torch.float16)
tensor(0.9365, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
19 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.9219, device='cuda:0', dtype=torch.float16) tensor(1.4941, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1534, device='cuda:0', dtype=torch.float16)
tensor(1.2676, device='cuda:0', dtype=torch.float16) tensor(0.1578, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1541, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1534, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.3864, device='cuda:0')
old_score: tensor(0.1547, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1396, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8041510581970215
Validation after dual ascent:
out_inf: tensor(16.9219, device='cuda:0', dtype=torch.float16) tensor(1.4941, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.1368, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(1.1367, device='cuda:0', dtype=torch.float16) tensor(0.1405, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
19 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7422, device='cuda:0', dtype=torch.float16) tensor(0.2052, device='cuda:0', dtype=torch.float16)
tensor(0.4150, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.4756, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.4675, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0046, device='cuda:0')
tensor(0.1398, device='cuda:0')
old_score: tensor(0.0534, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0487, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8032341003417969
Validation after dual ascent:
out_inf: tensor(2.7422, device='cuda:0', dtype=torch.float16) tensor(0.2052, device='cuda:0', dtype=torch.float16)
tensor(0.3765, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.4526, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.3896, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
19 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7129, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
tensor(0.1102, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1069, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1056, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1038, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.0288, device='cuda:0')
old_score: tensor(0.0094, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0083, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.959721088409424
Validation after dual ascent:
out_inf: tensor(2.7129, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
tensor(0.0943, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1052, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.0880, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.1080, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
19 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.8906, device='cuda:0', dtype=torch.float16) tensor(0.3567, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.8223, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0112, device='cuda:0')
tensor(0.0837, device='cuda:0')
old_score: tensor(0.0710, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0647, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.308966398239136
Validation after dual ascent:
out_inf: tensor(10.8906, device='cuda:0', dtype=torch.float16) tensor(0.3567, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
tensor(0.7393, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
19 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6250, device='cuda:0', dtype=torch.float16) tensor(0.1627, device='cuda:0', dtype=torch.float16)
tensor(0.5493, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.3117, device='cuda:0')
old_score: tensor(0.0540, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0492, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.836192607879639
Validation after dual ascent:
out_inf: tensor(4.6250, device='cuda:0', dtype=torch.float16) tensor(0.1627, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.6455, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0487, device='cuda:0', dtype=torch.float16)
19 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5107, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(0.1316, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1544, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1541, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1307, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0124, device='cuda:0')
tensor(0.0191, device='cuda:0')
old_score: tensor(0.0119, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0111, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.886119604110718
Validation after dual ascent:
out_inf: tensor(1.5107, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(0.1256, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1593, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1478, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1235, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
layer 19 done
20 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.3594, device='cuda:0', dtype=torch.float16) tensor(0.7407, device='cuda:0', dtype=torch.float16)
tensor(0.8228, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
tensor(1.2373, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(0.9580, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0135, device='cuda:0')
tensor(0.3232, device='cuda:0')
old_score: tensor(0.0959, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0869, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2224843502044678
Validation after dual ascent:
out_inf: tensor(16.3594, device='cuda:0', dtype=torch.float16) tensor(0.7407, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0855, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
tensor(0.8574, device='cuda:0', dtype=torch.float16) tensor(0.0860, device='cuda:0', dtype=torch.float16)
20 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.2500, device='cuda:0', dtype=torch.float16) tensor(1.5205, device='cuda:0', dtype=torch.float16)
tensor(1.2930, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
tensor(1.2217, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(1.1572, device='cuda:0', dtype=torch.float16) tensor(0.1448, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1453, device='cuda:0', dtype=torch.float16)
20 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8711, device='cuda:0', dtype=torch.float16) tensor(0.2015, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.4365, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.4998, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.4146, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0047, device='cuda:0')
tensor(0.1459, device='cuda:0')
old_score: tensor(0.0551, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7966129779815674
Validation after dual ascent:
out_inf: tensor(2.8711, device='cuda:0', dtype=torch.float16) tensor(0.2015, device='cuda:0', dtype=torch.float16)
tensor(0.3865, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.4331, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.3662, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
20 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.1213, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1169, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1263, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1318, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0197, device='cuda:0')
tensor(0.0393, device='cuda:0')
old_score: tensor(0.0106, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0095, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.018272638320923
Validation after dual ascent:
out_inf: tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.1038, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.0989, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.1287, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.1177, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
20 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.9336, device='cuda:0', dtype=torch.float16) tensor(0.3630, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(1.1855, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(2.4180, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0113, device='cuda:0')
tensor(0.0893, device='cuda:0')
old_score: tensor(0.0728, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0660, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.293306589126587
Validation after dual ascent:
out_inf: tensor(7.9336, device='cuda:0', dtype=torch.float16) tensor(0.3630, device='cuda:0', dtype=torch.float16)
tensor(0.7920, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(2.6484, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.7324, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
20 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.8379, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(0.6182, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.7295, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.6357, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0160, device='cuda:0')
tensor(0.3271, device='cuda:0')
old_score: tensor(0.0554, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.83439040184021
Validation after dual ascent:
out_inf: tensor(3.8379, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.7754, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.6138, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.6255, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
20 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.1359, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1537, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.1544, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.1903, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0090, device='cuda:0')
tensor(0.0162, device='cuda:0')
old_score: tensor(0.0124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0115, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.804840087890625
Validation after dual ascent:
out_inf: tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.1410, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1484, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.1531, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.1631, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
layer 20 done
21 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.2500, device='cuda:0', dtype=torch.float16) tensor(0.7314, device='cuda:0', dtype=torch.float16)
tensor(0.8237, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0949, device='cuda:0', dtype=torch.float16)
tensor(1.2725, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0159, device='cuda:0')
tensor(0.2599, device='cuda:0')
old_score: tensor(0.0925, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0836, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2213847637176514
Validation after dual ascent:
out_inf: tensor(21.2500, device='cuda:0', dtype=torch.float16) tensor(0.7314, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(0.9346, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
tensor(1.2686, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.8169, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
21 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.2812, device='cuda:0', dtype=torch.float16) tensor(1.4629, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.1436, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1415, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
21 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3770, device='cuda:0', dtype=torch.float16) tensor(0.2119, device='cuda:0', dtype=torch.float16)
tensor(0.4390, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.4785, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.4795, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
tensor(0.4429, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0046, device='cuda:0')
tensor(0.1402, device='cuda:0')
old_score: tensor(0.0545, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0494, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.793907642364502
Validation after dual ascent:
out_inf: tensor(3.3770, device='cuda:0', dtype=torch.float16) tensor(0.2119, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.5435, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0492, device='cuda:0', dtype=torch.float16)
tensor(0.4346, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
21 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5166, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
tensor(0.1100, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1260, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1063, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1379, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0156, device='cuda:0')
tensor(0.0259, device='cuda:0')
old_score: tensor(0.0109, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0092, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.016866207122803
Validation after dual ascent:
out_inf: tensor(1.5166, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
tensor(0.1000, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1063, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.0956, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1166, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
21 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.7422, device='cuda:0', dtype=torch.float16) tensor(0.3796, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0727, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0123, device='cuda:0')
tensor(0.0892, device='cuda:0')
old_score: tensor(0.0734, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0665, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.282119274139404
Validation after dual ascent:
out_inf: tensor(7.7422, device='cuda:0', dtype=torch.float16) tensor(0.3796, device='cuda:0', dtype=torch.float16)
tensor(0.6724, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
21 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.8203, device='cuda:0', dtype=torch.float16) tensor(0.1700, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.7275, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0160, device='cuda:0')
tensor(0.3231, device='cuda:0')
old_score: tensor(0.0555, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.830222129821777
Validation after dual ascent:
out_inf: tensor(3.8203, device='cuda:0', dtype=torch.float16) tensor(0.1700, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.5498, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
21 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2197, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
tensor(0.1743, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1978, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1545, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.1460, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0130, device='cuda:0')
tensor(0.0206, device='cuda:0')
old_score: tensor(0.0124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0114, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.778679370880127
Validation after dual ascent:
out_inf: tensor(1.2197, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
tensor(0.1572, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1980, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.1509, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1665, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
layer 21 done
22 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.4219, device='cuda:0', dtype=torch.float16) tensor(0.6968, device='cuda:0', dtype=torch.float16)
tensor(0.9512, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0160, device='cuda:0')
tensor(0.2615, device='cuda:0')
old_score: tensor(0.0885, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0796, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2163538932800293
Validation after dual ascent:
out_inf: tensor(18.4219, device='cuda:0', dtype=torch.float16) tensor(0.6968, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(0.7915, device='cuda:0', dtype=torch.float16) tensor(0.0794, device='cuda:0', dtype=torch.float16)
tensor(1.1230, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
22 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.8281, device='cuda:0', dtype=torch.float16) tensor(1.4805, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
22 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.2122, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(0.4873, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0048, device='cuda:0')
tensor(0.1435, device='cuda:0')
old_score: tensor(0.0563, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7918689250946045
Validation after dual ascent:
out_inf: tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.2122, device='cuda:0', dtype=torch.float16)
tensor(0.4795, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.4961, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(0.4519, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
22 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5293, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
tensor(0.1572, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1594, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1407, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1819, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0197, device='cuda:0')
tensor(0.0401, device='cuda:0')
old_score: tensor(0.0125, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0111, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.013674974441528
Validation after dual ascent:
out_inf: tensor(1.5293, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
tensor(0.1307, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1349, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1284, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1411, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
22 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.6797, device='cuda:0', dtype=torch.float16) tensor(0.3660, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(0.9316, device='cuda:0', dtype=torch.float16) tensor(0.0761, device='cuda:0', dtype=torch.float16)
tensor(0.9111, device='cuda:0', dtype=torch.float16) tensor(0.0725, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0735, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0119, device='cuda:0')
tensor(0.0900, device='cuda:0')
old_score: tensor(0.0737, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0668, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.278189182281494
Validation after dual ascent:
out_inf: tensor(8.6797, device='cuda:0', dtype=torch.float16) tensor(0.3660, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.9004, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
22 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.9395, device='cuda:0', dtype=torch.float16) tensor(0.1656, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(0.6338, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.6660, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0162, device='cuda:0')
tensor(0.3280, device='cuda:0')
old_score: tensor(0.0557, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0504, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.833108901977539
Validation after dual ascent:
out_inf: tensor(3.9395, device='cuda:0', dtype=torch.float16) tensor(0.1656, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.5967, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
22 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7002, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.1549, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1526, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1693, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1390, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0138, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.0120, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0110, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.744637489318848
Validation after dual ascent:
out_inf: tensor(0.7002, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.1565, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1523, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1770, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1222, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
layer 22 done
23 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.1719, device='cuda:0', dtype=torch.float16) tensor(0.7207, device='cuda:0', dtype=torch.float16)
tensor(0.8032, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(0.8511, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0170, device='cuda:0')
tensor(0.2543, device='cuda:0')
old_score: tensor(0.0874, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0786, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2164371013641357
Validation after dual ascent:
out_inf: tensor(21.1719, device='cuda:0', dtype=torch.float16) tensor(0.7207, device='cuda:0', dtype=torch.float16)
tensor(0.7495, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.9233, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
23 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.6406, device='cuda:0', dtype=torch.float16) tensor(1.4082, device='cuda:0', dtype=torch.float16)
tensor(1.3584, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
23 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7422, device='cuda:0', dtype=torch.float16) tensor(0.2058, device='cuda:0', dtype=torch.float16)
tensor(0.6709, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.6274, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.5044, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0050, device='cuda:0')
tensor(0.1470, device='cuda:0')
old_score: tensor(0.0586, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0532, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7905769348144531
Validation after dual ascent:
out_inf: tensor(2.7422, device='cuda:0', dtype=torch.float16) tensor(0.2058, device='cuda:0', dtype=torch.float16)
tensor(0.5786, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.5073, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.5757, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
23 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7358, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.1355, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1337, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1479, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1294, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0194, device='cuda:0')
tensor(0.0251, device='cuda:0')
old_score: tensor(0.0109, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.019819259643555
Validation after dual ascent:
out_inf: tensor(0.7358, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.1306, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1230, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1306, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
23 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.8906, device='cuda:0', dtype=torch.float16) tensor(0.3652, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0725, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0118, device='cuda:0')
tensor(0.0875, device='cuda:0')
old_score: tensor(0.0732, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0662, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.281567811965942
Validation after dual ascent:
out_inf: tensor(8.8906, device='cuda:0', dtype=torch.float16) tensor(0.3652, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(1.3916, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
23 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6855, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0162, device='cuda:0')
tensor(0.3230, device='cuda:0')
old_score: tensor(0.0554, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0501, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.826670408248901
Validation after dual ascent:
out_inf: tensor(3.6855, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.5112, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
23 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8599, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.1399, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1655, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.1851, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1492, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.0254, device='cuda:0')
old_score: tensor(0.0116, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0107, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.745938301086426
Validation after dual ascent:
out_inf: tensor(0.8599, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.1331, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1711, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1792, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1337, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
layer 23 done
24 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.7344, device='cuda:0', dtype=torch.float16) tensor(0.7207, device='cuda:0', dtype=torch.float16)
tensor(0.8252, device='cuda:0', dtype=torch.float16) tensor(0.0827, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.7778, device='cuda:0', dtype=torch.float16) tensor(0.0830, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0194, device='cuda:0')
tensor(0.2311, device='cuda:0')
old_score: tensor(0.0829, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0744, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2150983810424805
Validation after dual ascent:
out_inf: tensor(22.7344, device='cuda:0', dtype=torch.float16) tensor(0.7207, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.0730, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
24 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.3818, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.1196, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.1224, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
24 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.8652, device='cuda:0', dtype=torch.float16) tensor(0.2371, device='cuda:0', dtype=torch.float16)
tensor(0.5015, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.6304, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0052, device='cuda:0')
tensor(0.1489, device='cuda:0')
old_score: tensor(0.0617, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0558, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7898247241973877
Validation after dual ascent:
out_inf: tensor(3.8652, device='cuda:0', dtype=torch.float16) tensor(0.2371, device='cuda:0', dtype=torch.float16)
tensor(0.4761, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.8418, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
24 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8716, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.1477, device='cuda:0', dtype=torch.float16) tensor(0.0136, device='cuda:0', dtype=torch.float16)
tensor(0.1730, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.1429, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1755, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.0176, device='cuda:0')
old_score: tensor(0.0134, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.94411826133728
Validation after dual ascent:
out_inf: tensor(0.8716, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.1387, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1541, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1365, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1523, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
24 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.7422, device='cuda:0', dtype=torch.float16) tensor(0.3682, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.0758, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0124, device='cuda:0')
tensor(0.0858, device='cuda:0')
old_score: tensor(0.0732, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0661, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.278769254684448
Validation after dual ascent:
out_inf: tensor(13.7422, device='cuda:0', dtype=torch.float16) tensor(0.3682, device='cuda:0', dtype=torch.float16)
tensor(1.1270, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
tensor(0.9033, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
24 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.9688, device='cuda:0', dtype=torch.float16) tensor(0.1650, device='cuda:0', dtype=torch.float16)
tensor(0.5303, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0162, device='cuda:0')
tensor(0.3194, device='cuda:0')
old_score: tensor(0.0554, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0499, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.828895568847656
Validation after dual ascent:
out_inf: tensor(3.9688, device='cuda:0', dtype=torch.float16) tensor(0.1650, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.9355, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
24 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.1636, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.2070, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1495, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1582, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0076, device='cuda:0')
tensor(0.0084, device='cuda:0')
old_score: tensor(0.0114, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.7229483127594
Validation after dual ascent:
out_inf: tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1875, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1584, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1735, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
layer 24 done
25 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(23.4062, device='cuda:0', dtype=torch.float16) tensor(0.7788, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(0.9189, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(0.8076, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0188, device='cuda:0')
tensor(0.1517, device='cuda:0')
old_score: tensor(0.0840, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0750, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.948716402053833
Validation after dual ascent:
out_inf: tensor(23.4062, device='cuda:0', dtype=torch.float16) tensor(0.7788, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0772, device='cuda:0', dtype=torch.float16)
tensor(0.9106, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
25 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.9375, device='cuda:0', dtype=torch.float16) tensor(1.3711, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
25 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.9492, device='cuda:0', dtype=torch.float16) tensor(0.2583, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.6138, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(0.5776, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.1528, device='cuda:0')
old_score: tensor(0.0641, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0577, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7905824184417725
Validation after dual ascent:
out_inf: tensor(3.9492, device='cuda:0', dtype=torch.float16) tensor(0.2583, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.5674, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
25 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.0437, device='cuda:0', dtype=torch.float16)
tensor(0.1782, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1752, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.1643, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
tensor(0.0232, device='cuda:0')
old_score: tensor(0.0147, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0133, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.93204951286316
Validation after dual ascent:
out_inf: tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.0437, device='cuda:0', dtype=torch.float16)
tensor(0.1466, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1735, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.1453, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1578, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
25 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.6172, device='cuda:0', dtype=torch.float16) tensor(0.3945, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0135, device='cuda:0')
tensor(0.0887, device='cuda:0')
old_score: tensor(0.0748, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0675, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.274198293685913
Validation after dual ascent:
out_inf: tensor(8.6172, device='cuda:0', dtype=torch.float16) tensor(0.3945, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(1.1230, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.7007, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
25 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3047, device='cuda:0', dtype=torch.float16) tensor(0.1722, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.7036, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0166, device='cuda:0')
tensor(0.3295, device='cuda:0')
old_score: tensor(0.0567, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0512, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.824027061462402
Validation after dual ascent:
out_inf: tensor(4.3047, device='cuda:0', dtype=torch.float16) tensor(0.1722, device='cuda:0', dtype=torch.float16)
tensor(0.5825, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(1.0371, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
25 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.4863, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.1615, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1868, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.1829, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0185, device='cuda:0')
tensor(0.0283, device='cuda:0')
old_score: tensor(0.0119, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0109, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.687758922576904
Validation after dual ascent:
out_inf: tensor(3.4863, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.1553, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1732, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1780, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1752, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
layer 25 done
26 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.9062, device='cuda:0', dtype=torch.float16) tensor(0.7427, device='cuda:0', dtype=torch.float16)
tensor(0.8213, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(0.7446, device='cuda:0', dtype=torch.float16) tensor(0.0832, device='cuda:0', dtype=torch.float16)
tensor(0.7314, device='cuda:0', dtype=torch.float16) tensor(0.0791, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0808, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0168, device='cuda:0')
tensor(0.1448, device='cuda:0')
old_score: tensor(0.0807, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0722, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9490833282470703
Validation after dual ascent:
out_inf: tensor(16.9062, device='cuda:0', dtype=torch.float16) tensor(0.7427, device='cuda:0', dtype=torch.float16)
tensor(0.8164, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
tensor(0.6709, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
26 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.3750, device='cuda:0', dtype=torch.float16) tensor(1.5059, device='cuda:0', dtype=torch.float16)
tensor(1.0967, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(0.9932, device='cuda:0', dtype=torch.float16) tensor(0.1170, device='cuda:0', dtype=torch.float16)
tensor(0.9565, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
26 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6172, device='cuda:0', dtype=torch.float16) tensor(0.2213, device='cuda:0', dtype=torch.float16)
tensor(0.6123, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(0.5786, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0053, device='cuda:0')
tensor(0.1546, device='cuda:0')
old_score: tensor(0.0640, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0580, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.788201093673706
Validation after dual ascent:
out_inf: tensor(3.6172, device='cuda:0', dtype=torch.float16) tensor(0.2213, device='cuda:0', dtype=torch.float16)
tensor(0.5986, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.6064, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
26 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.1826, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(0.1627, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1711, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.1680, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.1603, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0147, device='cuda:0')
tensor(0.0297, device='cuda:0')
old_score: tensor(0.0143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0124, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.208552598953247
Validation after dual ascent:
out_inf: tensor(1.1826, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(0.1302, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1680, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.1475, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1567, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
26 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.8828, device='cuda:0', dtype=torch.float16) tensor(0.4297, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0748, device='cuda:0', dtype=torch.float16)
tensor(1.3740, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0735, device='cuda:0', dtype=torch.float16)
tensor(0.8311, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0160, device='cuda:0')
tensor(0.0930, device='cuda:0')
old_score: tensor(0.0757, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0681, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.280724048614502
Validation after dual ascent:
out_inf: tensor(8.8828, device='cuda:0', dtype=torch.float16) tensor(0.4297, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(1.5615, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
26 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4375, device='cuda:0', dtype=torch.float16) tensor(0.1849, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(1.8613, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0174, device='cuda:0')
tensor(0.3422, device='cuda:0')
old_score: tensor(0.0579, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0521, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.8326334953308105
Validation after dual ascent:
out_inf: tensor(4.4375, device='cuda:0', dtype=torch.float16) tensor(0.1849, device='cuda:0', dtype=torch.float16)
tensor(0.5864, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
26 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.1609, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.2062, device='cuda:0', dtype=torch.float16) tensor(0.0136, device='cuda:0', dtype=torch.float16)
tensor(0.2012, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.1731, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0111, device='cuda:0')
tensor(0.0208, device='cuda:0')
old_score: tensor(0.0128, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0116, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.675923109054565
Validation after dual ascent:
out_inf: tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.1558, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1970, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.2024, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1638, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
layer 26 done
27 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.5938, device='cuda:0', dtype=torch.float16) tensor(0.7334, device='cuda:0', dtype=torch.float16)
tensor(0.9014, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.8481, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(0.7954, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(0.7710, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.0378, device='cuda:0')
old_score: tensor(0.0842, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0749, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.007888555526733
Validation after dual ascent:
out_inf: tensor(22.5938, device='cuda:0', dtype=torch.float16) tensor(0.7334, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0785, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.7256, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
27 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.8438, device='cuda:0', dtype=torch.float16) tensor(1.4766, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
27 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6953, device='cuda:0', dtype=torch.float16) tensor(0.3032, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.6733, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0695, device='cuda:0', dtype=torch.float16)
tensor(0.5757, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0113, device='cuda:0')
tensor(0.1136, device='cuda:0')
old_score: tensor(0.0716, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0645, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9780166149139404
Validation after dual ascent:
out_inf: tensor(4.6953, device='cuda:0', dtype=torch.float16) tensor(0.3032, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
tensor(0.6357, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0625, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
27 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.6758, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.2258, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.2637, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
tensor(0.2363, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
tensor(0.2476, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.0294, device='cuda:0')
old_score: tensor(0.0202, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0181, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.952542304992676
Validation after dual ascent:
out_inf: tensor(1.6758, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.2284, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.2505, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.2544, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.2124, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
27 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.5977, device='cuda:0', dtype=torch.float16) tensor(0.4829, device='cuda:0', dtype=torch.float16)
tensor(0.7720, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0832, device='cuda:0', dtype=torch.float16)
tensor(1.3262, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0184, device='cuda:0')
tensor(0.1077, device='cuda:0')
old_score: tensor(0.0793, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0712, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.296263933181763
Validation after dual ascent:
out_inf: tensor(7.5977, device='cuda:0', dtype=torch.float16) tensor(0.4829, device='cuda:0', dtype=torch.float16)
tensor(0.8618, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(1.6113, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(1.4082, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0713, device='cuda:0', dtype=torch.float16)
27 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.5156, device='cuda:0', dtype=torch.float16) tensor(0.2056, device='cuda:0', dtype=torch.float16)
tensor(0.6743, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.6079, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0191, device='cuda:0')
tensor(0.3833, device='cuda:0')
old_score: tensor(0.0614, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0551, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.845653772354126
Validation after dual ascent:
out_inf: tensor(4.5156, device='cuda:0', dtype=torch.float16) tensor(0.2056, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
27 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.5664, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.1985, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.2131, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
tensor(0.2200, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.2065, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0064, device='cuda:0')
tensor(0.0106, device='cuda:0')
old_score: tensor(0.0143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.61785316467285
Validation after dual ascent:
out_inf: tensor(5.5664, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.1887, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.2438, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.1957, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
layer 27 done
28 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.8438, device='cuda:0', dtype=torch.float16) tensor(0.7744, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0838, device='cuda:0', dtype=torch.float16)
tensor(1.1816, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.8037, device='cuda:0', dtype=torch.float16) tensor(0.0851, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0108, device='cuda:0')
tensor(0.1362, device='cuda:0')
old_score: tensor(0.0848, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0754, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.681661367416382
Validation after dual ascent:
out_inf: tensor(19.8438, device='cuda:0', dtype=torch.float16) tensor(0.7744, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(1.0879, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.7607, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.6938, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
28 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.4844, device='cuda:0', dtype=torch.float16) tensor(1.4531, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.1241, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
28 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.2891, device='cuda:0', dtype=torch.float16) tensor(0.2742, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0749, device='cuda:0', dtype=torch.float16)
tensor(0.6714, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.5923, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0763, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0064, device='cuda:0')
tensor(0.1847, device='cuda:0')
old_score: tensor(0.0759, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0685, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7877883911132812
Validation after dual ascent:
out_inf: tensor(5.2891, device='cuda:0', dtype=torch.float16) tensor(0.2742, device='cuda:0', dtype=torch.float16)
tensor(0.5923, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(0.6064, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(0.6411, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
28 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5166, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.2406, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.2177, device='cuda:0', dtype=torch.float16) tensor(0.0172, device='cuda:0', dtype=torch.float16)
tensor(0.2151, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.2118, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0106, device='cuda:0')
tensor(0.0131, device='cuda:0')
old_score: tensor(0.0174, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0151, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.203493118286133
Validation after dual ascent:
out_inf: tensor(1.5166, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.1890, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.2147, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
tensor(0.2190, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.2161, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
28 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.8750, device='cuda:0', dtype=torch.float16) tensor(0.5195, device='cuda:0', dtype=torch.float16)
tensor(1.0898, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0173, device='cuda:0')
tensor(0.0427, device='cuda:0')
old_score: tensor(0.0797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0712, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.726503133773804
Validation after dual ascent:
out_inf: tensor(10.8750, device='cuda:0', dtype=torch.float16) tensor(0.5195, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
28 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.1133, device='cuda:0', dtype=torch.float16) tensor(0.2360, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0617, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0874, device='cuda:0')
old_score: tensor(0.0637, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.298921346664429
Validation after dual ascent:
out_inf: tensor(5.1133, device='cuda:0', dtype=torch.float16) tensor(0.2360, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
28 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.2891, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.2437, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.3384, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
tensor(0.2266, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.2791, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0144, device='cuda:0')
tensor(0.0367, device='cuda:0')
old_score: tensor(0.0165, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0149, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.58385133743286
Validation after dual ascent:
out_inf: tensor(5.2891, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.2208, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.3540, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.2362, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.2744, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
layer 28 done
29 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.5625, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(0.9033, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0158, device='cuda:0')
tensor(0.0823, device='cuda:0')
old_score: tensor(0.0876, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0774, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.781940460205078
Validation after dual ascent:
out_inf: tensor(12.5625, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(0.8403, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(0.8926, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.7549, device='cuda:0', dtype=torch.float16) tensor(0.0747, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
29 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(34.9375, device='cuda:0', dtype=torch.float16) tensor(1.3818, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
tensor(1.2568, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(1.1514, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
29 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.6641, device='cuda:0', dtype=torch.float16) tensor(0.3074, device='cuda:0', dtype=torch.float16)
tensor(0.7183, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.7827, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
tensor(0.8257, device='cuda:0', dtype=torch.float16) tensor(0.0788, device='cuda:0', dtype=torch.float16)
tensor(0.6963, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0187, device='cuda:0')
tensor(0.1930, device='cuda:0')
old_score: tensor(0.0817, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0731, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7897121906280518
Validation after dual ascent:
out_inf: tensor(5.6641, device='cuda:0', dtype=torch.float16) tensor(0.3074, device='cuda:0', dtype=torch.float16)
tensor(0.7168, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(0.7471, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(0.6821, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.6509, device='cuda:0', dtype=torch.float16) tensor(0.0727, device='cuda:0', dtype=torch.float16)
29 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5498, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.2458, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.2661, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
tensor(0.2234, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.2155, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0133, device='cuda:0')
tensor(0.0228, device='cuda:0')
old_score: tensor(0.0177, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0138, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.332456827163696
Validation after dual ascent:
out_inf: tensor(1.5498, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.2374, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.2402, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.2050, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.2073, device='cuda:0', dtype=torch.float16) tensor(0.0136, device='cuda:0', dtype=torch.float16)
29 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.6172, device='cuda:0', dtype=torch.float16) tensor(0.5259, device='cuda:0', dtype=torch.float16)
tensor(0.9482, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(1.2227, device='cuda:0', dtype=torch.float16) tensor(0.0766, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0186, device='cuda:0')
tensor(0.0468, device='cuda:0')
old_score: tensor(0.0795, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0702, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.754274845123291
Validation after dual ascent:
out_inf: tensor(14.6172, device='cuda:0', dtype=torch.float16) tensor(0.5259, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(1.2314, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(1.1582, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(0.7666, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
29 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.4609, device='cuda:0', dtype=torch.float16) tensor(0.2778, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.8467, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.7310, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0118, device='cuda:0')
tensor(0.0947, device='cuda:0')
old_score: tensor(0.0659, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0583, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.31460428237915
Validation after dual ascent:
out_inf: tensor(10.4609, device='cuda:0', dtype=torch.float16) tensor(0.2778, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
29 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.1250, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
tensor(0.3005, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
tensor(0.3262, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.3667, device='cuda:0', dtype=torch.float16) tensor(0.0194, device='cuda:0', dtype=torch.float16)
tensor(0.3403, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0130, device='cuda:0')
tensor(0.0528, device='cuda:0')
old_score: tensor(0.0195, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0178, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.57537031173706
Validation after dual ascent:
out_inf: tensor(10.1250, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
tensor(0.2800, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.3086, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.2896, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.2715, device='cuda:0', dtype=torch.float16) tensor(0.0172, device='cuda:0', dtype=torch.float16)
layer 29 done
30 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.3359, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(0.7568, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.7764, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.0738, device='cuda:0', dtype=torch.float16)
tensor(0.8403, device='cuda:0', dtype=torch.float16) tensor(0.0761, device='cuda:0', dtype=torch.float16)
30 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.2812, device='cuda:0', dtype=torch.float16) tensor(1.5352, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.1092, device='cuda:0', dtype=torch.float16)
tensor(0.9512, device='cuda:0', dtype=torch.float16) tensor(0.1145, device='cuda:0', dtype=torch.float16)
tensor(0.9614, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(0.9761, device='cuda:0', dtype=torch.float16) tensor(0.1086, device='cuda:0', dtype=torch.float16)
30 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.3672, device='cuda:0', dtype=torch.float16) tensor(0.3301, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.0907, device='cuda:0', dtype=torch.float16)
tensor(0.8237, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(0.9561, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0907, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0079, device='cuda:0')
tensor(0.2300, device='cuda:0')
old_score: tensor(0.0917, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0820, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7878694534301758
Validation after dual ascent:
out_inf: tensor(5.3672, device='cuda:0', dtype=torch.float16) tensor(0.3301, device='cuda:0', dtype=torch.float16)
tensor(0.8428, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(0.7754, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
30 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2031, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(0.3833, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.3452, device='cuda:0', dtype=torch.float16) tensor(0.0311, device='cuda:0', dtype=torch.float16)
tensor(0.3481, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.4006, device='cuda:0', dtype=torch.float16) tensor(0.0279, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0127, device='cuda:0')
tensor(0.0233, device='cuda:0')
old_score: tensor(0.0282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0244, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.469494581222534
Validation after dual ascent:
out_inf: tensor(3.2031, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(0.3413, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
tensor(0.3381, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
tensor(0.3589, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
tensor(0.4099, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
30 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.2656, device='cuda:0', dtype=torch.float16) tensor(0.5972, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(1.1699, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.8950, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0123, device='cuda:0')
tensor(0.0311, device='cuda:0')
old_score: tensor(0.0836, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0736, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.215289115905762
Validation after dual ascent:
out_inf: tensor(18.2656, device='cuda:0', dtype=torch.float16) tensor(0.5972, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
30 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.3594, device='cuda:0', dtype=torch.float16) tensor(0.3672, device='cuda:0', dtype=torch.float16)
tensor(0.8481, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0196, device='cuda:0')
tensor(0.1111, device='cuda:0')
old_score: tensor(0.0693, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0609, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.317668914794922
Validation after dual ascent:
out_inf: tensor(11.3594, device='cuda:0', dtype=torch.float16) tensor(0.3672, device='cuda:0', dtype=torch.float16)
tensor(0.7939, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
30 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.9688, device='cuda:0', dtype=torch.float16) tensor(0.1976, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(0.4744, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.6108, device='cuda:0', dtype=torch.float16) tensor(0.0252, device='cuda:0', dtype=torch.float16)
tensor(0.4456, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0183, device='cuda:0')
tensor(0.0180, device='cuda:0')
old_score: tensor(0.0252, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0228, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.72760367393494
Validation after dual ascent:
out_inf: tensor(11.9688, device='cuda:0', dtype=torch.float16) tensor(0.1976, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
tensor(0.5142, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
tensor(0.4529, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
layer 30 done
31 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.7969, device='cuda:0', dtype=torch.float16) tensor(0.9077, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.7754, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0763, device='cuda:0', dtype=torch.float16)
31 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.9531, device='cuda:0', dtype=torch.float16) tensor(1.4258, device='cuda:0', dtype=torch.float16)
tensor(0.9248, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.1081, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
31 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.7109, device='cuda:0', dtype=torch.float16) tensor(0.4087, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(0.6196, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.6890, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0082, device='cuda:0')
tensor(0.1326, device='cuda:0')
old_score: tensor(0.0748, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0645, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7941184043884277
Validation after dual ascent:
out_inf: tensor(6.7109, device='cuda:0', dtype=torch.float16) tensor(0.4087, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(0.5864, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.6011, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
31 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0859, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(0.3599, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
tensor(0.2703, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.2874, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.3801, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0130, device='cuda:0')
tensor(0.0185, device='cuda:0')
old_score: tensor(0.0269, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.648339748382568
Validation after dual ascent:
out_inf: tensor(4.0859, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(0.3015, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.2607, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.2588, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.3262, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
31 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.0938, device='cuda:0', dtype=torch.float16) tensor(0.6260, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.0231, device='cuda:0')
old_score: tensor(0.0781, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0673, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.90188264846802
Validation after dual ascent:
out_inf: tensor(20.0938, device='cuda:0', dtype=torch.float16) tensor(0.6260, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0650, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0725, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
31 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(25.5156, device='cuda:0', dtype=torch.float16) tensor(0.5488, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0164, device='cuda:0')
tensor(0.0198, device='cuda:0')
old_score: tensor(0.0650, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0559, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.698288917541504
Validation after dual ascent:
out_inf: tensor(25.5156, device='cuda:0', dtype=torch.float16) tensor(0.5488, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
31 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(343.2500, device='cuda:0', dtype=torch.float16) tensor(0.4863, device='cuda:0', dtype=torch.float16)
tensor(0.6675, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.6899, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.8164, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
layer 31 done
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.78it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.70it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.87it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.20it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.700001
layer 1 sparsity 0.700001
layer 2 sparsity 0.700001
layer 3 sparsity 0.700001
layer 4 sparsity 0.700001
layer 5 sparsity 0.700001
layer 6 sparsity 0.700001
layer 7 sparsity 0.700001
layer 8 sparsity 0.700001
layer 9 sparsity 0.700001
layer 10 sparsity 0.700001
layer 11 sparsity 0.700001
layer 12 sparsity 0.700001
layer 13 sparsity 0.700001
layer 14 sparsity 0.700001
layer 15 sparsity 0.700001
layer 16 sparsity 0.700001
layer 17 sparsity 0.700001
layer 18 sparsity 0.700001
layer 19 sparsity 0.700001
layer 20 sparsity 0.700001
layer 21 sparsity 0.700001
layer 22 sparsity 0.700001
layer 23 sparsity 0.700001
layer 24 sparsity 0.700001
layer 25 sparsity 0.700001
layer 26 sparsity 0.700001
layer 27 sparsity 0.700001
layer 28 sparsity 0.700001
layer 29 sparsity 0.700001
layer 30 sparsity 0.700001
layer 31 sparsity 0.700001
sparsity sanity check 0.7000
******************************
evaluating on wikitext2
nsamples 35
sample 0
wikitext perplexity 33.05452346801758
sparsegpt_dual_3	0.7000	33.0545	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.7, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='sparsegpt_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
dataset loading complete
pruning layer 0 name self_attn.q_proj
Validation after prune:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.8218, device='cuda:0', dtype=torch.float16)
tensor(0.2188, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.2461, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.2461, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.2188, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.k_proj
Validation after prune:
out_inf: tensor(10.5859, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.v_proj
Validation after prune:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0400, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.0461, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.0507, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.0461, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0187, device='cuda:0')
tensor(0.0383, device='cuda:0')
old_score: tensor(0.0040, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0023, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.216140031814575
Validation after dual ascent:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0331, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0379, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0451, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0379, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0450, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0454, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0620, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0379, device='cuda:0', dtype=torch.float16) tensor(0.0006, device='cuda:0', dtype=torch.float16)
tensor(0.0217, device='cuda:0')
old_score: tensor(0.0006, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0003, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.804260015487671
Validation after dual ascent:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0445, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0417, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
tensor(0.0343, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0331, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(1.0605, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0156, device='cuda:0')
tensor(0.2133, device='cuda:0')
old_score: tensor(0.0270, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0194, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.294241666793823
Validation after dual ascent:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(1.0332, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.up_proj
Validation after prune:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.4326, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0145, device='cuda:0')
tensor(0.1942, device='cuda:0')
old_score: tensor(0.0242, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0176, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.294825792312622
Validation after dual ascent:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0542, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0594, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0547, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0510, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0726, device='cuda:0')
old_score: tensor(0.0023, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0017, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.68596935272217
Validation after dual ascent:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0310, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0359, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0386, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0309, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.7578, device='cuda:0', dtype=torch.float16) tensor(1.0029, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.k_proj
Validation after prune:
out_inf: tensor(10.5391, device='cuda:0', dtype=torch.float16) tensor(1.4980, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.7881, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.1577, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1375, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.2402, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.1836, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0107, device='cuda:0')
tensor(0.0476, device='cuda:0')
old_score: tensor(0.0130, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0094, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9555094242095947
Validation after dual ascent:
out_inf: tensor(1.7881, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.2598, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1533, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.8735, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.2188, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.2319, device='cuda:0', dtype=torch.float16) tensor(0.0014, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0014, device='cuda:0', dtype=torch.float16)
tensor(0.3413, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0312, device='cuda:0')
old_score: tensor(0.0015, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0010, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.838720321655273
Validation after dual ascent:
out_inf: tensor(0.8735, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.0532, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0586, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0854, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0456, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.gate_proj
Validation after prune:
out_inf: tensor(16.2031, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0184, device='cuda:0')
tensor(0.0400, device='cuda:0')
old_score: tensor(0.0360, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0272, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.737764835357666
Validation after dual ascent:
out_inf: tensor(16.2031, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.5596, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(2.2812, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
tensor(2.5000, device='cuda:0', dtype=torch.float16) tensor(0.0318, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0149, device='cuda:0')
tensor(0.0347, device='cuda:0')
old_score: tensor(0.0319, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7437584400177
Validation after dual ascent:
out_inf: tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.down_proj
Validation after prune:
out_inf: tensor(205.3750, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.0402, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.0806, device='cuda:0')
old_score: tensor(0.0028, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0024, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.31962132453918
Validation after dual ascent:
out_inf: tensor(205.3750, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0351, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0388, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.8281, device='cuda:0', dtype=torch.float16) tensor(0.8491, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.1709, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.3057, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.1062, device='cuda:0', dtype=torch.float16)
tensor(0.1733, device='cuda:0')
old_score: tensor(0.1057, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0709, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.90090298652649
Validation after dual ascent:
out_inf: tensor(13.8281, device='cuda:0', dtype=torch.float16) tensor(0.8491, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
tensor(1.2041, device='cuda:0', dtype=torch.float16) tensor(0.0725, device='cuda:0', dtype=torch.float16)
tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.5781, device='cuda:0', dtype=torch.float16) tensor(1.3984, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1610, device='cuda:0', dtype=torch.float16)
tensor(1.6797, device='cuda:0', dtype=torch.float16) tensor(0.1625, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(0.1651, device='cuda:0')
old_score: tensor(0.1632, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1056, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9675350189208984
Validation after dual ascent:
out_inf: tensor(15.5781, device='cuda:0', dtype=torch.float16) tensor(1.3984, device='cuda:0', dtype=torch.float16)
tensor(1.4053, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(1.3076, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.8428, device='cuda:0', dtype=torch.float16) tensor(0.1126, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.3184, device='cuda:0', dtype=torch.float16) tensor(0.0366, device='cuda:0', dtype=torch.float16)
tensor(0.3179, device='cuda:0', dtype=torch.float16) tensor(0.0367, device='cuda:0', dtype=torch.float16)
tensor(0.3120, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0108, device='cuda:0')
tensor(0.0561, device='cuda:0')
old_score: tensor(0.0368, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0280, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9835951328277588
Validation after dual ascent:
out_inf: tensor(1.8428, device='cuda:0', dtype=torch.float16) tensor(0.1126, device='cuda:0', dtype=torch.float16)
tensor(0.2700, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(0.3020, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.3635, device='cuda:0', dtype=torch.float16) tensor(0.0286, device='cuda:0', dtype=torch.float16)
tensor(0.2605, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0969, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0702, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0815, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.0898, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0214, device='cuda:0')
old_score: tensor(0.0021, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0015, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.86114239692688
Validation after dual ascent:
out_inf: tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0593, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0579, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0670, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0510, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.2266, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(2.1055, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0135, device='cuda:0')
tensor(0.0734, device='cuda:0')
old_score: tensor(0.0464, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0353, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.746407508850098
Validation after dual ascent:
out_inf: tensor(3.2266, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(0.5635, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.7783, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.7798, device='cuda:0', dtype=torch.float16) tensor(0.0373, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.8926, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0110, device='cuda:0')
tensor(0.0649, device='cuda:0')
old_score: tensor(0.0399, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0310, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7388105392456055
Validation after dual ascent:
out_inf: tensor(2.8926, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.3931, device='cuda:0', dtype=torch.float16) tensor(0.0285, device='cuda:0', dtype=torch.float16)
tensor(0.3604, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.4365, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
tensor(0.3853, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.0697, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0772, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
tensor(0.0859, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0859, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.0604, device='cuda:0')
old_score: tensor(0.0042, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0035, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.76201963424683
Validation after dual ascent:
out_inf: tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.0423, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0718, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0572, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.7734, device='cuda:0', dtype=torch.float16) tensor(0.8105, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1265, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1265, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0165, device='cuda:0')
tensor(0.1018, device='cuda:0')
old_score: tensor(0.1254, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0879, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.215224266052246
Validation after dual ascent:
out_inf: tensor(12.7734, device='cuda:0', dtype=torch.float16) tensor(0.8105, device='cuda:0', dtype=torch.float16)
tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(1.1006, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.2031, device='cuda:0', dtype=torch.float16) tensor(1.3154, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1976, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.1949, device='cuda:0', dtype=torch.float16)
tensor(2.0684, device='cuda:0', dtype=torch.float16) tensor(0.1901, device='cuda:0', dtype=torch.float16)
tensor(2.0273, device='cuda:0', dtype=torch.float16) tensor(0.1963, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0125, device='cuda:0')
tensor(0.0793, device='cuda:0')
old_score: tensor(0.1947, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1329, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9857370853424072
Validation after dual ascent:
out_inf: tensor(20.2031, device='cuda:0', dtype=torch.float16) tensor(1.3154, device='cuda:0', dtype=torch.float16)
tensor(1.6768, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(1.8320, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.2988, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(0.4229, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(0.4580, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.4600, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.4529, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0050, device='cuda:0')
tensor(0.0938, device='cuda:0')
old_score: tensor(0.0527, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0400, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7996730804443359
Validation after dual ascent:
out_inf: tensor(2.2988, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(0.3933, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.4780, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.4167, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.3857, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.0906, device='cuda:0', dtype=torch.float16) tensor(0.0033, device='cuda:0', dtype=torch.float16)
tensor(0.0996, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.1328, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0981, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0274, device='cuda:0')
old_score: tensor(0.0031, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0021, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.876813650131226
Validation after dual ascent:
out_inf: tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.0552, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0782, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0851, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0503, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.8926, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0139, device='cuda:0')
tensor(0.1559, device='cuda:0')
old_score: tensor(0.0594, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0447, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.768929719924927
Validation after dual ascent:
out_inf: tensor(3.8926, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0487, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.3281, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.5537, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.1258, device='cuda:0')
old_score: tensor(0.0471, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0363, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.773735284805298
Validation after dual ascent:
out_inf: tensor(4.3281, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(0.4521, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.5093, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.0839, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.1357, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.1196, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0812, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0168, device='cuda:0')
tensor(0.0346, device='cuda:0')
old_score: tensor(0.0061, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0052, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 109.32326126098633
Validation after dual ascent:
out_inf: tensor(0.5093, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.0497, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
tensor(0.0801, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0826, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.0538, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.1641, device='cuda:0', dtype=torch.float16) tensor(0.8110, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(0.0941, device='cuda:0')
old_score: tensor(0.1115, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0765, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.880675077438354
Validation after dual ascent:
out_inf: tensor(12.1641, device='cuda:0', dtype=torch.float16) tensor(0.8110, device='cuda:0', dtype=torch.float16)
tensor(0.9380, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(1.0020, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.9189, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.7188, device='cuda:0', dtype=torch.float16) tensor(1.3984, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.1798, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1804, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1714, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1771, device='cuda:0', dtype=torch.float16)
tensor(0.0500, device='cuda:0')
old_score: tensor(0.1772, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1165, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9641363620758057
Validation after dual ascent:
out_inf: tensor(21.7188, device='cuda:0', dtype=torch.float16) tensor(1.3984, device='cuda:0', dtype=torch.float16)
tensor(1.2129, device='cuda:0', dtype=torch.float16) tensor(0.1065, device='cuda:0', dtype=torch.float16)
tensor(1.4346, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.2939, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.8486, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(0.4387, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(0.4836, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(0.4536, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0058, device='cuda:0')
tensor(0.0418, device='cuda:0')
old_score: tensor(0.0512, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0381, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9787747859954834
Validation after dual ascent:
out_inf: tensor(1.8486, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.4436, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.3857, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(0.3455, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0869, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.1390, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.1343, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.1108, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.0962, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.0268, device='cuda:0')
old_score: tensor(0.0045, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0030, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.851035594940186
Validation after dual ascent:
out_inf: tensor(1.0869, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.0837, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0859, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0947, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0630, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.9375, device='cuda:0', dtype=torch.float16) tensor(0.2297, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(1.6680, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0111, device='cuda:0')
tensor(0.0502, device='cuda:0')
old_score: tensor(0.0707, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0517, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.214747905731201
Validation after dual ascent:
out_inf: tensor(6.9375, device='cuda:0', dtype=torch.float16) tensor(0.2297, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.8135, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.1758, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0072, device='cuda:0')
tensor(0.0363, device='cuda:0')
old_score: tensor(0.0516, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0388, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.201561689376831
Validation after dual ascent:
out_inf: tensor(3.1758, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.5811, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.9019, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
tensor(0.1343, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.1501, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1239, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1196, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0129, device='cuda:0')
tensor(0.0317, device='cuda:0')
old_score: tensor(0.0083, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0067, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 76.94863486289978
Validation after dual ascent:
out_inf: tensor(0.9019, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
tensor(0.0861, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.1292, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0972, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.0801, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.4453, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1329, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
tensor(1.8984, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0131, device='cuda:0')
tensor(0.2114, device='cuda:0')
old_score: tensor(0.1296, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0872, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.204084634780884
Validation after dual ascent:
out_inf: tensor(14.4453, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(1.1270, device='cuda:0', dtype=torch.float16) tensor(0.0937, device='cuda:0', dtype=torch.float16)
tensor(1.0684, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.6406, device='cuda:0', dtype=torch.float16) tensor(1.4346, device='cuda:0', dtype=torch.float16)
tensor(2.3125, device='cuda:0', dtype=torch.float16) tensor(0.2047, device='cuda:0', dtype=torch.float16)
tensor(2.5312, device='cuda:0', dtype=torch.float16) tensor(0.2113, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.2023, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.2023, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.3515, device='cuda:0')
old_score: tensor(0.2051, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1332, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7968037128448486
Validation after dual ascent:
out_inf: tensor(19.6406, device='cuda:0', dtype=torch.float16) tensor(1.4346, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.3838, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(1.3828, device='cuda:0', dtype=torch.float16) tensor(0.1396, device='cuda:0', dtype=torch.float16)
tensor(1.3965, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3535, device='cuda:0', dtype=torch.float16) tensor(0.1422, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0038, device='cuda:0')
tensor(0.1072, device='cuda:0')
old_score: tensor(0.0496, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0366, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7971458435058594
Validation after dual ascent:
out_inf: tensor(2.3535, device='cuda:0', dtype=torch.float16) tensor(0.1422, device='cuda:0', dtype=torch.float16)
tensor(0.3176, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.3135, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.3267, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.3303, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
tensor(0.2114, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.1572, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.1807, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.1318, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0139, device='cuda:0')
tensor(0.0285, device='cuda:0')
old_score: tensor(0.0071, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0044, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.278446912765503
Validation after dual ascent:
out_inf: tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
tensor(0.1338, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.1328, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.1204, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0869, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.7520, device='cuda:0', dtype=torch.float16) tensor(0.2803, device='cuda:0', dtype=torch.float16)
tensor(1.4297, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0788, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.2505, device='cuda:0')
old_score: tensor(0.0759, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0530, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.758467674255371
Validation after dual ascent:
out_inf: tensor(3.7520, device='cuda:0', dtype=torch.float16) tensor(0.2803, device='cuda:0', dtype=torch.float16)
tensor(0.8896, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.8721, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.9902, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.8433, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.9531, device='cuda:0', dtype=torch.float16) tensor(0.1270, device='cuda:0', dtype=torch.float16)
tensor(0.9023, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0125, device='cuda:0')
tensor(0.1859, device='cuda:0')
old_score: tensor(0.0554, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0399, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.761093854904175
Validation after dual ascent:
out_inf: tensor(3.9531, device='cuda:0', dtype=torch.float16) tensor(0.1270, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.5732, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.9380, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.1553, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1469, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1450, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0139, device='cuda:0')
tensor(0.0321, device='cuda:0')
old_score: tensor(0.0095, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0072, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 76.70267128944397
Validation after dual ascent:
out_inf: tensor(0.9380, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.1021, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.1045, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0994, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.1025, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.3125, device='cuda:0', dtype=torch.float16) tensor(0.7573, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.1453, device='cuda:0', dtype=torch.float16)
tensor(2.3828, device='cuda:0', dtype=torch.float16) tensor(0.1405, device='cuda:0', dtype=torch.float16)
tensor(2.5156, device='cuda:0', dtype=torch.float16) tensor(0.1406, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0158, device='cuda:0')
tensor(0.1165, device='cuda:0')
old_score: tensor(0.1426, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0896, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1940548419952393
Validation after dual ascent:
out_inf: tensor(15.3125, device='cuda:0', dtype=torch.float16) tensor(0.7573, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.5938, device='cuda:0', dtype=torch.float16) tensor(1.4639, device='cuda:0', dtype=torch.float16)
tensor(2.5312, device='cuda:0', dtype=torch.float16) tensor(0.2291, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.2291, device='cuda:0', dtype=torch.float16)
tensor(2.4922, device='cuda:0', dtype=torch.float16) tensor(0.2227, device='cuda:0', dtype=torch.float16)
tensor(2.9297, device='cuda:0', dtype=torch.float16) tensor(0.2242, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0175, device='cuda:0')
tensor(0.3094, device='cuda:0')
old_score: tensor(0.2262, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1359, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7907602787017822
Validation after dual ascent:
out_inf: tensor(17.5938, device='cuda:0', dtype=torch.float16) tensor(1.4639, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.1415, device='cuda:0', dtype=torch.float16)
tensor(1.4053, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.6289, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
tensor(0.4971, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.4792, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0041, device='cuda:0')
tensor(0.0960, device='cuda:0')
old_score: tensor(0.0569, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0395, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7925453186035156
Validation after dual ascent:
out_inf: tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
tensor(0.3440, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.3591, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.3330, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.3369, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.6660, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.2158, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.1826, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1875, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.2051, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0160, device='cuda:0')
tensor(0.0189, device='cuda:0')
old_score: tensor(0.0090, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0056, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.811694383621216
Validation after dual ascent:
out_inf: tensor(1.6660, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.1323, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.1523, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.1216, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.1323, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.6992, device='cuda:0', dtype=torch.float16) tensor(0.3108, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(1.3926, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(0.1024, device='cuda:0')
old_score: tensor(0.0776, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0540, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.3903546333313
Validation after dual ascent:
out_inf: tensor(5.6992, device='cuda:0', dtype=torch.float16) tensor(0.3108, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.8618, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.9102, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0182, device='cuda:0')
tensor(0.0797, device='cuda:0')
old_score: tensor(0.0571, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0407, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 41.980390787124634
Validation after dual ascent:
out_inf: tensor(3.9102, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.7490, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.5991, device='cuda:0', dtype=torch.float16) tensor(0.0268, device='cuda:0', dtype=torch.float16)
tensor(0.2249, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.2163, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1821, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.2012, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0132, device='cuda:0')
tensor(0.0303, device='cuda:0')
old_score: tensor(0.0103, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0076, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 76.60997486114502
Validation after dual ascent:
out_inf: tensor(0.5991, device='cuda:0', dtype=torch.float16) tensor(0.0268, device='cuda:0', dtype=torch.float16)
tensor(0.1230, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.1506, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.1404, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.1160, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.3594, device='cuda:0', dtype=torch.float16) tensor(0.7407, device='cuda:0', dtype=torch.float16)
tensor(2.7500, device='cuda:0', dtype=torch.float16) tensor(0.1488, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
tensor(2.4688, device='cuda:0', dtype=torch.float16) tensor(0.1453, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0165, device='cuda:0')
tensor(0.1101, device='cuda:0')
old_score: tensor(0.1453, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0875, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2016658782958984
Validation after dual ascent:
out_inf: tensor(16.3594, device='cuda:0', dtype=torch.float16) tensor(0.7407, device='cuda:0', dtype=torch.float16)
tensor(1.1855, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.0900, device='cuda:0', dtype=torch.float16)
tensor(1.1064, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6406, device='cuda:0', dtype=torch.float16) tensor(1.4668, device='cuda:0', dtype=torch.float16)
tensor(2.8984, device='cuda:0', dtype=torch.float16) tensor(0.2542, device='cuda:0', dtype=torch.float16)
tensor(3.0469, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.2444, device='cuda:0', dtype=torch.float16)
tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.2482, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0191, device='cuda:0')
tensor(0.3308, device='cuda:0')
old_score: tensor(0.2498, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1412, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.792111873626709
Validation after dual ascent:
out_inf: tensor(15.6406, device='cuda:0', dtype=torch.float16) tensor(1.4668, device='cuda:0', dtype=torch.float16)
tensor(1.3135, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(1.4160, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3730, device='cuda:0', dtype=torch.float16) tensor(0.1726, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.4775, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0043, device='cuda:0')
tensor(0.0952, device='cuda:0')
old_score: tensor(0.0594, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0401, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7936217784881592
Validation after dual ascent:
out_inf: tensor(2.3730, device='cuda:0', dtype=torch.float16) tensor(0.1726, device='cuda:0', dtype=torch.float16)
tensor(0.3318, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.3792, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.3208, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.3550, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
tensor(0.2510, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1504, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1885, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0122, device='cuda:0')
tensor(0.0247, device='cuda:0')
old_score: tensor(0.0105, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0062, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.270480155944824
Validation after dual ascent:
out_inf: tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
tensor(0.1221, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.1323, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0991, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.1162, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.3203, device='cuda:0', dtype=torch.float16)
tensor(1.1230, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0101, device='cuda:0')
tensor(0.0364, device='cuda:0')
old_score: tensor(0.0762, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0535, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.211034297943115
Validation after dual ascent:
out_inf: tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.3203, device='cuda:0', dtype=torch.float16)
tensor(0.8228, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.7407, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.4258, device='cuda:0', dtype=torch.float16) tensor(0.1466, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.9473, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.2093, device='cuda:0')
old_score: tensor(0.0582, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.761849641799927
Validation after dual ascent:
out_inf: tensor(5.4258, device='cuda:0', dtype=torch.float16) tensor(0.1466, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.4463, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.5176, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.4775, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.3311, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.2705, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.2393, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.3135, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0082, device='cuda:0')
tensor(0.0178, device='cuda:0')
old_score: tensor(0.0109, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0081, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 76.72283172607422
Validation after dual ascent:
out_inf: tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.1567, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.1694, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1697, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1401, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.7290, device='cuda:0', dtype=torch.float16)
tensor(2.3672, device='cuda:0', dtype=torch.float16) tensor(0.1515, device='cuda:0', dtype=torch.float16)
tensor(2.7656, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
tensor(2.4922, device='cuda:0', dtype=torch.float16) tensor(0.1479, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0137, device='cuda:0')
tensor(0.1753, device='cuda:0')
old_score: tensor(0.1465, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0944, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1979269981384277
Validation after dual ascent:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.7290, device='cuda:0', dtype=torch.float16)
tensor(1.4238, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
tensor(1.3311, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.0937, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.2188, device='cuda:0', dtype=torch.float16) tensor(1.5625, device='cuda:0', dtype=torch.float16)
tensor(2.8984, device='cuda:0', dtype=torch.float16) tensor(0.2561, device='cuda:0', dtype=torch.float16)
tensor(2.7969, device='cuda:0', dtype=torch.float16) tensor(0.2491, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.2395, device='cuda:0', dtype=torch.float16)
tensor(2.9766, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0196, device='cuda:0')
tensor(0.3961, device='cuda:0')
old_score: tensor(0.2495, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1481, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7919549942016602
Validation after dual ascent:
out_inf: tensor(17.2188, device='cuda:0', dtype=torch.float16) tensor(1.5625, device='cuda:0', dtype=torch.float16)
tensor(2.0371, device='cuda:0', dtype=torch.float16) tensor(0.1472, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1505, device='cuda:0', dtype=torch.float16)
tensor(1.7461, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.1659, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.5581, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.1248, device='cuda:0')
old_score: tensor(0.0636, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0442, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7924950122833252
Validation after dual ascent:
out_inf: tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.1659, device='cuda:0', dtype=torch.float16)
tensor(0.5493, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.4592, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.4265, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.9521, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.2842, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1680, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.2471, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.2373, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0113, device='cuda:0')
tensor(0.0260, device='cuda:0')
old_score: tensor(0.0108, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0063, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.268066167831421
Validation after dual ascent:
out_inf: tensor(1.9521, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.1298, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.1504, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.1475, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.6523, device='cuda:0', dtype=torch.float16) tensor(0.3113, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0138, device='cuda:0')
tensor(0.0720, device='cuda:0')
old_score: tensor(0.0771, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0548, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.20939326286316
Validation after dual ascent:
out_inf: tensor(3.6523, device='cuda:0', dtype=torch.float16) tensor(0.3113, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.8071, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.9473, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.9570, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0083, device='cuda:0')
tensor(0.0529, device='cuda:0')
old_score: tensor(0.0590, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0426, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.205629587173462
Validation after dual ascent:
out_inf: tensor(3.9570, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
tensor(0.4932, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.5928, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0419, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1055, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.2856, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.2563, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.2437, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.2852, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0089, device='cuda:0')
tensor(0.0168, device='cuda:0')
old_score: tensor(0.0107, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0080, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 76.8479220867157
Validation after dual ascent:
out_inf: tensor(1.1055, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.1565, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1616, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1735, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.5234, device='cuda:0', dtype=torch.float16) tensor(0.7495, device='cuda:0', dtype=torch.float16)
tensor(3.2109, device='cuda:0', dtype=torch.float16) tensor(0.1583, device='cuda:0', dtype=torch.float16)
tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.1548, device='cuda:0', dtype=torch.float16)
tensor(2.6445, device='cuda:0', dtype=torch.float16) tensor(0.1482, device='cuda:0', dtype=torch.float16)
tensor(3.0234, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0130, device='cuda:0')
tensor(0.1823, device='cuda:0')
old_score: tensor(0.1542, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0970, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.200038433074951
Validation after dual ascent:
out_inf: tensor(14.5234, device='cuda:0', dtype=torch.float16) tensor(0.7495, device='cuda:0', dtype=torch.float16)
tensor(1.7295, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(1.4668, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.2578, device='cuda:0', dtype=torch.float16) tensor(1.4688, device='cuda:0', dtype=torch.float16)
tensor(2.4766, device='cuda:0', dtype=torch.float16) tensor(0.2537, device='cuda:0', dtype=torch.float16)
tensor(2.4766, device='cuda:0', dtype=torch.float16) tensor(0.2494, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.2382, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.2491, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0199, device='cuda:0')
tensor(0.4275, device='cuda:0')
old_score: tensor(0.2476, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1530, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7918660640716553
Validation after dual ascent:
out_inf: tensor(15.2578, device='cuda:0', dtype=torch.float16) tensor(1.4688, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1537, device='cuda:0', dtype=torch.float16)
tensor(1.6758, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(1.6621, device='cuda:0', dtype=torch.float16) tensor(0.1520, device='cuda:0', dtype=torch.float16)
tensor(1.9336, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3125, device='cuda:0', dtype=torch.float16) tensor(0.1918, device='cuda:0', dtype=torch.float16)
tensor(0.7979, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.8115, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(0.9185, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0061, device='cuda:0')
tensor(0.1588, device='cuda:0')
old_score: tensor(0.0748, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0520, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7926657199859619
Validation after dual ascent:
out_inf: tensor(2.3125, device='cuda:0', dtype=torch.float16) tensor(0.1918, device='cuda:0', dtype=torch.float16)
tensor(0.5986, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.5728, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.6826, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.1895, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.2642, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.2466, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.3052, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0103, device='cuda:0')
tensor(0.0203, device='cuda:0')
old_score: tensor(0.0137, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.637927293777466
Validation after dual ascent:
out_inf: tensor(2.1895, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.2349, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.1680, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.1992, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.2656, device='cuda:0', dtype=torch.float16) tensor(0.3320, device='cuda:0', dtype=torch.float16)
tensor(1.3574, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
tensor(1.2676, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(1.2354, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.0802, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0106, device='cuda:0')
tensor(0.0438, device='cuda:0')
old_score: tensor(0.0812, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0558, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.2083899974823
Validation after dual ascent:
out_inf: tensor(4.2656, device='cuda:0', dtype=torch.float16) tensor(0.3320, device='cuda:0', dtype=torch.float16)
tensor(0.8643, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.5586, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.2377, device='cuda:0')
old_score: tensor(0.0617, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0434, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7661638259887695
Validation after dual ascent:
out_inf: tensor(4.5586, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.4980, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.3647, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.4431, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.3447, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0169, device='cuda:0')
tensor(0.0243, device='cuda:0')
old_score: tensor(0.0116, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0084, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 68.73537516593933
Validation after dual ascent:
out_inf: tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.2625, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.2134, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1323, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2812, device='cuda:0', dtype=torch.float16) tensor(0.7651, device='cuda:0', dtype=torch.float16)
tensor(3.3984, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(2.7500, device='cuda:0', dtype=torch.float16) tensor(0.1610, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
tensor(3.2031, device='cuda:0', dtype=torch.float16) tensor(0.1631, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0130, device='cuda:0')
tensor(0.2599, device='cuda:0')
old_score: tensor(0.1604, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1011, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2072460651397705
Validation after dual ascent:
out_inf: tensor(17.2812, device='cuda:0', dtype=torch.float16) tensor(0.7651, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1023, device='cuda:0', dtype=torch.float16)
tensor(1.3252, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(1.6143, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.k_proj
Validation after prune:
out_inf: tensor(14.8359, device='cuda:0', dtype=torch.float16) tensor(1.5381, device='cuda:0', dtype=torch.float16)
tensor(3.9531, device='cuda:0', dtype=torch.float16) tensor(0.2722, device='cuda:0', dtype=torch.float16)
tensor(3.2656, device='cuda:0', dtype=torch.float16) tensor(0.2659, device='cuda:0', dtype=torch.float16)
tensor(2.3730, device='cuda:0', dtype=torch.float16) tensor(0.2472, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0101, device='cuda:0')
tensor(0.1790, device='cuda:0')
old_score: tensor(0.2632, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1586, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9775149822235107
Validation after dual ascent:
out_inf: tensor(14.8359, device='cuda:0', dtype=torch.float16) tensor(1.5381, device='cuda:0', dtype=torch.float16)
tensor(1.5479, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1595, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1559, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1586, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.1719, device='cuda:0', dtype=torch.float16) tensor(0.1864, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.6787, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(0.6694, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.1563, device='cuda:0')
old_score: tensor(0.0679, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0469, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7937347888946533
Validation after dual ascent:
out_inf: tensor(2.1719, device='cuda:0', dtype=torch.float16) tensor(0.1864, device='cuda:0', dtype=torch.float16)
tensor(0.5581, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.4951, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.8184, device='cuda:0', dtype=torch.float16) tensor(0.0312, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.2080, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1602, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.3179, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0155, device='cuda:0')
tensor(0.0176, device='cuda:0')
old_score: tensor(0.0140, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0084, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1891326904296875
Validation after dual ascent:
out_inf: tensor(2.8184, device='cuda:0', dtype=torch.float16) tensor(0.0312, device='cuda:0', dtype=torch.float16)
tensor(0.1582, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1426, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.1819, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.2578, device='cuda:0', dtype=torch.float16) tensor(0.3242, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0106, device='cuda:0')
tensor(0.0461, device='cuda:0')
old_score: tensor(0.0811, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0561, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.226021766662598
Validation after dual ascent:
out_inf: tensor(5.2578, device='cuda:0', dtype=torch.float16) tensor(0.3242, device='cuda:0', dtype=torch.float16)
tensor(0.7939, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.3594, device='cuda:0', dtype=torch.float16) tensor(0.1592, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.7275, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0619, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.2578, device='cuda:0')
old_score: tensor(0.0638, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0453, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.774175405502319
Validation after dual ascent:
out_inf: tensor(3.3594, device='cuda:0', dtype=torch.float16) tensor(0.1592, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0713, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.2793, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.2849, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.2217, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.2554, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0122, device='cuda:0')
tensor(0.0206, device='cuda:0')
old_score: tensor(0.0120, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0087, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 68.85035133361816
Validation after dual ascent:
out_inf: tensor(1.0713, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.1465, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1750, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1943, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1406, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.q_proj
Validation after prune:
out_inf: tensor(11.7422, device='cuda:0', dtype=torch.float16) tensor(0.7222, device='cuda:0', dtype=torch.float16)
tensor(2.6484, device='cuda:0', dtype=torch.float16) tensor(0.1633, device='cuda:0', dtype=torch.float16)
tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.1576, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.1506, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.1604, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0123, device='cuda:0')
tensor(0.2207, device='cuda:0')
old_score: tensor(0.1580, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.198864459991455
Validation after dual ascent:
out_inf: tensor(11.7422, device='cuda:0', dtype=torch.float16) tensor(0.7222, device='cuda:0', dtype=torch.float16)
tensor(1.3848, device='cuda:0', dtype=torch.float16) tensor(0.1020, device='cuda:0', dtype=torch.float16)
tensor(1.3145, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(1.2725, device='cuda:0', dtype=torch.float16) tensor(0.0982, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.9922, device='cuda:0', dtype=torch.float16) tensor(1.4854, device='cuda:0', dtype=torch.float16)
tensor(3.4531, device='cuda:0', dtype=torch.float16) tensor(0.2832, device='cuda:0', dtype=torch.float16)
tensor(3.2344, device='cuda:0', dtype=torch.float16) tensor(0.2734, device='cuda:0', dtype=torch.float16)
tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.2578, device='cuda:0', dtype=torch.float16)
tensor(3.2500, device='cuda:0', dtype=torch.float16) tensor(0.2786, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0095, device='cuda:0')
tensor(0.1691, device='cuda:0')
old_score: tensor(0.2732, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1642, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9785027503967285
Validation after dual ascent:
out_inf: tensor(15.9922, device='cuda:0', dtype=torch.float16) tensor(1.4854, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(1.8613, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(1.5977, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(1.6582, device='cuda:0', dtype=torch.float16) tensor(0.1641, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.8770, device='cuda:0', dtype=torch.float16) tensor(0.2130, device='cuda:0', dtype=torch.float16)
tensor(0.6240, device='cuda:0', dtype=torch.float16) tensor(0.0738, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.1487, device='cuda:0')
old_score: tensor(0.0721, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0491, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7955093383789062
Validation after dual ascent:
out_inf: tensor(2.8770, device='cuda:0', dtype=torch.float16) tensor(0.2130, device='cuda:0', dtype=torch.float16)
tensor(0.4087, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.3940, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
tensor(0.4341, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.4302, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.3354, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.3799, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0146, device='cuda:0')
tensor(0.0276, device='cuda:0')
old_score: tensor(0.0156, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0083, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.630305051803589
Validation after dual ascent:
out_inf: tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.2349, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1816, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1982, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.8789, device='cuda:0', dtype=torch.float16) tensor(0.3333, device='cuda:0', dtype=torch.float16)
tensor(2.0371, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(1.5674, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0109, device='cuda:0')
tensor(0.0461, device='cuda:0')
old_score: tensor(0.0817, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0558, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.208308696746826
Validation after dual ascent:
out_inf: tensor(6.8789, device='cuda:0', dtype=torch.float16) tensor(0.3333, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.1953, device='cuda:0', dtype=torch.float16) tensor(0.1685, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0164, device='cuda:0')
tensor(0.2588, device='cuda:0')
old_score: tensor(0.0656, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0461, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.759214639663696
Validation after dual ascent:
out_inf: tensor(3.1953, device='cuda:0', dtype=torch.float16) tensor(0.1685, device='cuda:0', dtype=torch.float16)
tensor(0.4893, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.4775, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.4360, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.3623, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.3076, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.3215, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.3398, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0132, device='cuda:0')
tensor(0.0213, device='cuda:0')
old_score: tensor(0.0126, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0092, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 68.80753493309021
Validation after dual ascent:
out_inf: tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.2278, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.2114, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1891, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.4297, device='cuda:0', dtype=torch.float16) tensor(0.7319, device='cuda:0', dtype=torch.float16)
tensor(2.7578, device='cuda:0', dtype=torch.float16) tensor(0.1594, device='cuda:0', dtype=torch.float16)
tensor(2.4688, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
tensor(2.4688, device='cuda:0', dtype=torch.float16) tensor(0.1560, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0154, device='cuda:0')
tensor(0.1490, device='cuda:0')
old_score: tensor(0.1526, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0952, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2005958557128906
Validation after dual ascent:
out_inf: tensor(14.4297, device='cuda:0', dtype=torch.float16) tensor(0.7319, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0977, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0960, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.2188, device='cuda:0', dtype=torch.float16) tensor(1.3457, device='cuda:0', dtype=torch.float16)
tensor(3.2344, device='cuda:0', dtype=torch.float16) tensor(0.2681, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.2524, device='cuda:0', dtype=torch.float16)
tensor(3.0703, device='cuda:0', dtype=torch.float16) tensor(0.2399, device='cuda:0', dtype=torch.float16)
tensor(3.0469, device='cuda:0', dtype=torch.float16) tensor(0.2603, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0198, device='cuda:0')
tensor(0.3957, device='cuda:0')
old_score: tensor(0.2551, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1506, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7927606105804443
Validation after dual ascent:
out_inf: tensor(19.2188, device='cuda:0', dtype=torch.float16) tensor(1.3457, device='cuda:0', dtype=torch.float16)
tensor(1.4912, device='cuda:0', dtype=torch.float16) tensor(0.1548, device='cuda:0', dtype=torch.float16)
tensor(1.4824, device='cuda:0', dtype=torch.float16) tensor(0.1516, device='cuda:0', dtype=torch.float16)
tensor(1.3701, device='cuda:0', dtype=torch.float16) tensor(0.1431, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1531, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.1680, device='cuda:0', dtype=torch.float16) tensor(0.2072, device='cuda:0', dtype=torch.float16)
tensor(0.6626, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.6201, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0059, device='cuda:0')
tensor(0.1437, device='cuda:0')
old_score: tensor(0.0759, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0528, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.794227123260498
Validation after dual ascent:
out_inf: tensor(2.1680, device='cuda:0', dtype=torch.float16) tensor(0.2072, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
tensor(0.4292, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.4209, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.4419, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.2227, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0093, device='cuda:0')
tensor(0.0167, device='cuda:0')
old_score: tensor(0.0163, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0089, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9069762229919434
Validation after dual ascent:
out_inf: tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.1494, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1299, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1235, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1611, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.6094, device='cuda:0', dtype=torch.float16) tensor(0.3364, device='cuda:0', dtype=torch.float16)
tensor(1.2207, device='cuda:0', dtype=torch.float16) tensor(0.0819, device='cuda:0', dtype=torch.float16)
tensor(1.2607, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0755, device='cuda:0', dtype=torch.float16)
tensor(1.1357, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0116, device='cuda:0')
tensor(0.0462, device='cuda:0')
old_score: tensor(0.0787, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0546, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.216917276382446
Validation after dual ascent:
out_inf: tensor(4.6094, device='cuda:0', dtype=torch.float16) tensor(0.3364, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
tensor(1.0020, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.9854, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0820, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
tensor(0.9160, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(0.8574, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(1.0137, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.2564, device='cuda:0')
old_score: tensor(0.0652, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0468, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.762832403182983
Validation after dual ascent:
out_inf: tensor(4.0820, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.4780, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.6260, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1787, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.3643, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.3438, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.3215, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3179, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0111, device='cuda:0')
tensor(0.0182, device='cuda:0')
old_score: tensor(0.0133, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 68.74029517173767
Validation after dual ascent:
out_inf: tensor(1.1787, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.2122, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.2153, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.2280, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.2295, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.6016, device='cuda:0', dtype=torch.float16) tensor(0.7520, device='cuda:0', dtype=torch.float16)
tensor(3.0781, device='cuda:0', dtype=torch.float16) tensor(0.1790, device='cuda:0', dtype=torch.float16)
tensor(3.1719, device='cuda:0', dtype=torch.float16) tensor(0.1702, device='cuda:0', dtype=torch.float16)
tensor(2.7188, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1765, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0126, device='cuda:0')
tensor(0.2797, device='cuda:0')
old_score: tensor(0.1721, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1100, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.200223684310913
Validation after dual ascent:
out_inf: tensor(14.6016, device='cuda:0', dtype=torch.float16) tensor(0.7520, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(1.4473, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
tensor(1.5645, device='cuda:0', dtype=torch.float16) tensor(0.1124, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.9844, device='cuda:0', dtype=torch.float16) tensor(1.5635, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.3000, device='cuda:0', dtype=torch.float16)
tensor(2.9219, device='cuda:0', dtype=torch.float16) tensor(0.2861, device='cuda:0', dtype=torch.float16)
tensor(3.0781, device='cuda:0', dtype=torch.float16) tensor(0.2761, device='cuda:0', dtype=torch.float16)
tensor(3.1875, device='cuda:0', dtype=torch.float16) tensor(0.2964, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0095, device='cuda:0')
tensor(0.1938, device='cuda:0')
old_score: tensor(0.2896, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1765, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9808483123779297
Validation after dual ascent:
out_inf: tensor(17.9844, device='cuda:0', dtype=torch.float16) tensor(1.5635, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1797, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1772, device='cuda:0', dtype=torch.float16)
tensor(1.7939, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(1.7461, device='cuda:0', dtype=torch.float16) tensor(0.1804, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.4082, device='cuda:0', dtype=torch.float16) tensor(0.2024, device='cuda:0', dtype=torch.float16)
tensor(0.6606, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(0.6108, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.6069, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0061, device='cuda:0')
tensor(0.1794, device='cuda:0')
old_score: tensor(0.0798, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0565, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7973246574401855
Validation after dual ascent:
out_inf: tensor(2.4082, device='cuda:0', dtype=torch.float16) tensor(0.2024, device='cuda:0', dtype=torch.float16)
tensor(0.4792, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.4634, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.4541, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.4883, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.2881, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(0.2754, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.3345, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0124, device='cuda:0')
tensor(0.0130, device='cuda:0')
old_score: tensor(0.0180, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.176077127456665
Validation after dual ascent:
out_inf: tensor(3.4883, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.1587, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1465, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1689, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1533, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.8906, device='cuda:0', dtype=torch.float16) tensor(0.3447, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(1.7695, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(1.6035, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0121, device='cuda:0')
tensor(0.0507, device='cuda:0')
old_score: tensor(0.0807, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0566, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.210067987442017
Validation after dual ascent:
out_inf: tensor(5.8906, device='cuda:0', dtype=torch.float16) tensor(0.3447, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(1.1006, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(1.2168, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.5938, device='cuda:0', dtype=torch.float16) tensor(0.1749, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0168, device='cuda:0')
tensor(0.2715, device='cuda:0')
old_score: tensor(0.0668, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0484, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.7587902545928955
Validation after dual ascent:
out_inf: tensor(4.5938, device='cuda:0', dtype=torch.float16) tensor(0.1749, device='cuda:0', dtype=torch.float16)
tensor(0.4761, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.9780, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.2939, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.2920, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.3320, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0077, device='cuda:0')
tensor(0.0146, device='cuda:0')
old_score: tensor(0.0141, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 68.76445388793945
Validation after dual ascent:
out_inf: tensor(0.9780, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.1433, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1602, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1377, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.8438, device='cuda:0', dtype=torch.float16) tensor(0.7378, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.1718, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.1609, device='cuda:0', dtype=torch.float16)
tensor(2.0898, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(2.4609, device='cuda:0', dtype=torch.float16) tensor(0.1683, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0145, device='cuda:0')
tensor(0.2548, device='cuda:0')
old_score: tensor(0.1630, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1025, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.19796085357666
Validation after dual ascent:
out_inf: tensor(13.8438, device='cuda:0', dtype=torch.float16) tensor(0.7378, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.1024, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.5469, device='cuda:0', dtype=torch.float16) tensor(1.5566, device='cuda:0', dtype=torch.float16)
tensor(4.3828, device='cuda:0', dtype=torch.float16) tensor(0.2864, device='cuda:0', dtype=torch.float16)
tensor(3.6328, device='cuda:0', dtype=torch.float16) tensor(0.2683, device='cuda:0', dtype=torch.float16)
tensor(2.9375, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.2820, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0109, device='cuda:0')
tensor(0.1794, device='cuda:0')
old_score: tensor(0.2725, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1638, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9757461547851562
Validation after dual ascent:
out_inf: tensor(21.5469, device='cuda:0', dtype=torch.float16) tensor(1.5566, device='cuda:0', dtype=torch.float16)
tensor(1.8574, device='cuda:0', dtype=torch.float16) tensor(0.1693, device='cuda:0', dtype=torch.float16)
tensor(1.9766, device='cuda:0', dtype=torch.float16) tensor(0.1635, device='cuda:0', dtype=torch.float16)
tensor(1.8848, device='cuda:0', dtype=torch.float16) tensor(0.1526, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1698, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.6992, device='cuda:0', dtype=torch.float16) tensor(0.2063, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0057, device='cuda:0')
tensor(0.1614, device='cuda:0')
old_score: tensor(0.0747, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7929613590240479
Validation after dual ascent:
out_inf: tensor(2.6992, device='cuda:0', dtype=torch.float16) tensor(0.2063, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.4585, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.4692, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.9668, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.3623, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.2988, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.2139, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.3252, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0187, device='cuda:0')
tensor(0.0293, device='cuda:0')
old_score: tensor(0.0170, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0093, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.904208183288574
Validation after dual ascent:
out_inf: tensor(2.9668, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.1982, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1826, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1475, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.2207, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.4336, device='cuda:0', dtype=torch.float16) tensor(0.3674, device='cuda:0', dtype=torch.float16)
tensor(1.9668, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(1.6738, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(1.6445, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(1.6572, device='cuda:0', dtype=torch.float16) tensor(0.0851, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0148, device='cuda:0')
tensor(0.0585, device='cuda:0')
old_score: tensor(0.0835, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0582, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.2078115940094
Validation after dual ascent:
out_inf: tensor(5.4336, device='cuda:0', dtype=torch.float16) tensor(0.3674, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.1914, device='cuda:0', dtype=torch.float16) tensor(0.1720, device='cuda:0', dtype=torch.float16)
tensor(0.9453, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(0.7666, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(0.7520, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0170, device='cuda:0')
tensor(0.2796, device='cuda:0')
old_score: tensor(0.0672, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0486, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.761502504348755
Validation after dual ascent:
out_inf: tensor(5.1914, device='cuda:0', dtype=torch.float16) tensor(0.1720, device='cuda:0', dtype=torch.float16)
tensor(0.4949, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.5229, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.8696, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.2874, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.2871, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0152, device='cuda:0')
tensor(0.0235, device='cuda:0')
old_score: tensor(0.0142, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 68.67721557617188
Validation after dual ascent:
out_inf: tensor(0.8696, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.1393, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1714, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1479, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.3281, device='cuda:0', dtype=torch.float16) tensor(0.7837, device='cuda:0', dtype=torch.float16)
tensor(3.5469, device='cuda:0', dtype=torch.float16) tensor(0.1746, device='cuda:0', dtype=torch.float16)
tensor(3.3516, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(2.8047, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(3.5703, device='cuda:0', dtype=torch.float16) tensor(0.1713, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0147, device='cuda:0')
tensor(0.2394, device='cuda:0')
old_score: tensor(0.1653, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1094, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1977953910827637
Validation after dual ascent:
out_inf: tensor(17.3281, device='cuda:0', dtype=torch.float16) tensor(0.7837, device='cuda:0', dtype=torch.float16)
tensor(1.9082, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(1.4785, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.7793, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.4844, device='cuda:0', dtype=torch.float16) tensor(1.5342, device='cuda:0', dtype=torch.float16)
tensor(3.2344, device='cuda:0', dtype=torch.float16) tensor(0.2773, device='cuda:0', dtype=torch.float16)
tensor(3.4062, device='cuda:0', dtype=torch.float16) tensor(0.2556, device='cuda:0', dtype=torch.float16)
tensor(2.9297, device='cuda:0', dtype=torch.float16) tensor(0.2378, device='cuda:0', dtype=torch.float16)
tensor(3.1641, device='cuda:0', dtype=torch.float16) tensor(0.2695, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0100, device='cuda:0')
tensor(0.1541, device='cuda:0')
old_score: tensor(0.2603, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1647, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9791715145111084
Validation after dual ascent:
out_inf: tensor(20.4844, device='cuda:0', dtype=torch.float16) tensor(1.5342, device='cuda:0', dtype=torch.float16)
tensor(1.6523, device='cuda:0', dtype=torch.float16) tensor(0.1715, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1633, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(1.6973, device='cuda:0', dtype=torch.float16) tensor(0.1714, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.2773, device='cuda:0', dtype=torch.float16) tensor(0.1930, device='cuda:0', dtype=torch.float16)
tensor(0.8018, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.7085, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(0.6694, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.8320, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0061, device='cuda:0')
tensor(0.1664, device='cuda:0')
old_score: tensor(0.0769, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0555, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7952353954315186
Validation after dual ascent:
out_inf: tensor(3.2773, device='cuda:0', dtype=torch.float16) tensor(0.1930, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.5103, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.5854, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.5615, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.7832, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.3936, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.3564, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.3027, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.3691, device='cuda:0', dtype=torch.float16) tensor(0.0194, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0113, device='cuda:0')
tensor(0.0153, device='cuda:0')
old_score: tensor(0.0185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0112, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1832330226898193
Validation after dual ascent:
out_inf: tensor(3.7832, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1938, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1680, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.8867, device='cuda:0', dtype=torch.float16) tensor(0.3850, device='cuda:0', dtype=torch.float16)
tensor(1.8145, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(2.5195, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(2.1289, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0162, device='cuda:0')
tensor(0.0718, device='cuda:0')
old_score: tensor(0.0897, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0610, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.205772399902344
Validation after dual ascent:
out_inf: tensor(7.8867, device='cuda:0', dtype=torch.float16) tensor(0.3850, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(1.3340, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(1.1367, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.1707, device='cuda:0', dtype=torch.float16)
tensor(0.9004, device='cuda:0', dtype=torch.float16) tensor(0.0725, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.8623, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0186, device='cuda:0')
tensor(0.3192, device='cuda:0')
old_score: tensor(0.0695, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0492, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.759851455688477
Validation after dual ascent:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.1707, device='cuda:0', dtype=torch.float16)
tensor(0.5342, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(0.6943, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.5811, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.3369, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.2861, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.2988, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.2800, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0066, device='cuda:0')
tensor(0.0130, device='cuda:0')
old_score: tensor(0.0151, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0107, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 68.78668785095215
Validation after dual ascent:
out_inf: tensor(1.3369, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.1709, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1858, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1643, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1812, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.0234, device='cuda:0', dtype=torch.float16) tensor(0.7476, device='cuda:0', dtype=torch.float16)
tensor(2.5234, device='cuda:0', dtype=torch.float16) tensor(0.1617, device='cuda:0', dtype=torch.float16)
tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
tensor(2.3906, device='cuda:0', dtype=torch.float16) tensor(0.1572, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0161, device='cuda:0')
tensor(0.2241, device='cuda:0')
old_score: tensor(0.1516, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0974, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1918413639068604
Validation after dual ascent:
out_inf: tensor(15.0234, device='cuda:0', dtype=torch.float16) tensor(0.7476, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1024, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.1299, device='cuda:0', dtype=torch.float16) tensor(0.0893, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.2344, device='cuda:0', dtype=torch.float16) tensor(1.5107, device='cuda:0', dtype=torch.float16)
tensor(3.5547, device='cuda:0', dtype=torch.float16) tensor(0.2571, device='cuda:0', dtype=torch.float16)
tensor(3.0312, device='cuda:0', dtype=torch.float16) tensor(0.2308, device='cuda:0', dtype=torch.float16)
tensor(2.7500, device='cuda:0', dtype=torch.float16) tensor(0.2196, device='cuda:0', dtype=torch.float16)
tensor(3.3281, device='cuda:0', dtype=torch.float16) tensor(0.2490, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0200, device='cuda:0')
tensor(0.3897, device='cuda:0')
old_score: tensor(0.2391, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1479, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7892422676086426
Validation after dual ascent:
out_inf: tensor(21.2344, device='cuda:0', dtype=torch.float16) tensor(1.5107, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(1.7900, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
tensor(1.5215, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
tensor(1.6963, device='cuda:0', dtype=torch.float16) tensor(0.1537, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.1917, device='cuda:0', dtype=torch.float16)
tensor(0.6030, device='cuda:0', dtype=torch.float16) tensor(0.0702, device='cuda:0', dtype=torch.float16)
tensor(0.6509, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
tensor(0.5615, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0051, device='cuda:0')
tensor(0.1294, device='cuda:0')
old_score: tensor(0.0669, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0469, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7910075187683105
Validation after dual ascent:
out_inf: tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.1917, device='cuda:0', dtype=torch.float16)
tensor(0.4897, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.4751, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.4509, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.7637, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.3262, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.3525, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.3457, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0153, device='cuda:0')
tensor(0.0318, device='cuda:0')
old_score: tensor(0.0166, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0096, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.650053977966309
Validation after dual ascent:
out_inf: tensor(3.7637, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.2051, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1880, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1675, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.5000, device='cuda:0', dtype=torch.float16) tensor(0.3806, device='cuda:0', dtype=torch.float16)
tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(2.7266, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0157, device='cuda:0')
tensor(0.0782, device='cuda:0')
old_score: tensor(0.0928, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0635, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.228355884552002
Validation after dual ascent:
out_inf: tensor(8.5000, device='cuda:0', dtype=torch.float16) tensor(0.3806, device='cuda:0', dtype=torch.float16)
tensor(1.4805, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.4102, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0186, device='cuda:0')
tensor(0.3286, device='cuda:0')
old_score: tensor(0.0688, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0493, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.780952215194702
Validation after dual ascent:
out_inf: tensor(3.4102, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(0.4604, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.5459, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.2915, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.3169, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.2944, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0081, device='cuda:0')
tensor(0.0157, device='cuda:0')
old_score: tensor(0.0146, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 68.77874803543091
Validation after dual ascent:
out_inf: tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.1547, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1628, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.2021, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1614, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.4688, device='cuda:0', dtype=torch.float16) tensor(0.7666, device='cuda:0', dtype=torch.float16)
tensor(3.2109, device='cuda:0', dtype=torch.float16) tensor(0.1650, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.1530, device='cuda:0', dtype=torch.float16)
tensor(2.5000, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0175, device='cuda:0')
tensor(0.2292, device='cuda:0')
old_score: tensor(0.1556, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0996, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.197216272354126
Validation after dual ascent:
out_inf: tensor(18.4688, device='cuda:0', dtype=torch.float16) tensor(0.7666, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(1.2012, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(1.2832, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.5000, device='cuda:0', dtype=torch.float16) tensor(1.4756, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.2576, device='cuda:0', dtype=torch.float16)
tensor(2.8672, device='cuda:0', dtype=torch.float16) tensor(0.2379, device='cuda:0', dtype=torch.float16)
tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.2255, device='cuda:0', dtype=torch.float16)
tensor(3.2734, device='cuda:0', dtype=torch.float16) tensor(0.2507, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0198, device='cuda:0')
tensor(0.4021, device='cuda:0')
old_score: tensor(0.2429, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1504, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7948691844940186
Validation after dual ascent:
out_inf: tensor(20.5000, device='cuda:0', dtype=torch.float16) tensor(1.4756, device='cuda:0', dtype=torch.float16)
tensor(1.6895, device='cuda:0', dtype=torch.float16) tensor(0.1571, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1501, device='cuda:0', dtype=torch.float16)
tensor(1.5996, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.2598, device='cuda:0', dtype=torch.float16) tensor(0.1775, device='cuda:0', dtype=torch.float16)
tensor(0.6792, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(0.6636, device='cuda:0', dtype=torch.float16) tensor(0.0748, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0766, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0059, device='cuda:0')
tensor(0.1589, device='cuda:0')
old_score: tensor(0.0754, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0536, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7959144115447998
Validation after dual ascent:
out_inf: tensor(2.2598, device='cuda:0', dtype=torch.float16) tensor(0.1775, device='cuda:0', dtype=torch.float16)
tensor(0.4951, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
tensor(0.4631, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.4797, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.4731, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.0938, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0130, device='cuda:0')
tensor(0.0317, device='cuda:0')
old_score: tensor(0.0149, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0085, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.228016376495361
Validation after dual ascent:
out_inf: tensor(4.0938, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.2852, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1968, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1875, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.2098, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.2852, device='cuda:0', dtype=torch.float16) tensor(0.3835, device='cuda:0', dtype=torch.float16)
tensor(2.1055, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
tensor(2.1719, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
tensor(2.2812, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(1.6895, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0171, device='cuda:0')
tensor(0.0787, device='cuda:0')
old_score: tensor(0.0953, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0632, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.23398208618164
Validation after dual ascent:
out_inf: tensor(7.2852, device='cuda:0', dtype=torch.float16) tensor(0.3835, device='cuda:0', dtype=torch.float16)
tensor(1.3770, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(1.9375, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(1.3730, device='cuda:0', dtype=torch.float16) tensor(0.0650, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.4922, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.8223, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.0705, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0187, device='cuda:0')
tensor(0.3232, device='cuda:0')
old_score: tensor(0.0699, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0484, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.784897565841675
Validation after dual ascent:
out_inf: tensor(3.4922, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.8193, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.5493, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.9521, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.3037, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.3306, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.3289, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.2744, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0176, device='cuda:0')
tensor(0.0358, device='cuda:0')
old_score: tensor(0.0154, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0107, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.673062324523926
Validation after dual ascent:
out_inf: tensor(0.9521, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.2034, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.2461, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1899, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.2493, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.2344, device='cuda:0', dtype=torch.float16) tensor(0.7129, device='cuda:0', dtype=torch.float16)
tensor(2.3828, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(3.1484, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(2.9453, device='cuda:0', dtype=torch.float16) tensor(0.1381, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0180, device='cuda:0')
tensor(0.2106, device='cuda:0')
old_score: tensor(0.1478, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0948, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1851961612701416
Validation after dual ascent:
out_inf: tensor(16.2344, device='cuda:0', dtype=torch.float16) tensor(0.7129, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.0995, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
tensor(1.3252, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.5781, device='cuda:0', dtype=torch.float16) tensor(1.4785, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.2488, device='cuda:0', dtype=torch.float16)
tensor(3.2188, device='cuda:0', dtype=torch.float16) tensor(0.2327, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.2191, device='cuda:0', dtype=torch.float16)
tensor(2.7656, device='cuda:0', dtype=torch.float16) tensor(0.2402, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0123, device='cuda:0')
tensor(0.1346, device='cuda:0')
old_score: tensor(0.2352, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1469, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9740700721740723
Validation after dual ascent:
out_inf: tensor(19.5781, device='cuda:0', dtype=torch.float16) tensor(1.4785, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.1541, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(1.2920, device='cuda:0', dtype=torch.float16) tensor(0.1350, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.2031, device='cuda:0', dtype=torch.float16) tensor(0.1799, device='cuda:0', dtype=torch.float16)
tensor(0.7212, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(0.6665, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.5850, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0051, device='cuda:0')
tensor(0.1272, device='cuda:0')
old_score: tensor(0.0654, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0454, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7880845069885254
Validation after dual ascent:
out_inf: tensor(3.2031, device='cuda:0', dtype=torch.float16) tensor(0.1799, device='cuda:0', dtype=torch.float16)
tensor(0.4885, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.4739, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.4165, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.4663, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.8848, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.4424, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.3291, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.3252, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0266, device='cuda:0')
old_score: tensor(0.0097, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0055, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.820449352264404
Validation after dual ascent:
out_inf: tensor(2.8848, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.2529, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.2261, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.3203, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.2500, device='cuda:0', dtype=torch.float16) tensor(0.3584, device='cuda:0', dtype=torch.float16)
tensor(1.8008, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
tensor(2.2695, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
tensor(2.3945, device='cuda:0', dtype=torch.float16) tensor(0.0951, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0161, device='cuda:0')
tensor(0.0789, device='cuda:0')
old_score: tensor(0.0947, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0626, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.225727081298828
Validation after dual ascent:
out_inf: tensor(8.2500, device='cuda:0', dtype=torch.float16) tensor(0.3584, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(1.5410, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(1.2227, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.6914, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.3234, device='cuda:0')
old_score: tensor(0.0690, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0475, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.785197734832764
Validation after dual ascent:
out_inf: tensor(3.6914, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.4829, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.7773, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.2402, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.2397, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.2568, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.2744, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0176, device='cuda:0')
tensor(0.0373, device='cuda:0')
old_score: tensor(0.0143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.64008164405823
Validation after dual ascent:
out_inf: tensor(1.7773, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.1416, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1709, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1592, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.7578, device='cuda:0', dtype=torch.float16) tensor(0.7500, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1549, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1477, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(2.0977, device='cuda:0', dtype=torch.float16) tensor(0.1503, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0192, device='cuda:0')
tensor(0.2086, device='cuda:0')
old_score: tensor(0.1488, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0926, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1865718364715576
Validation after dual ascent:
out_inf: tensor(12.7578, device='cuda:0', dtype=torch.float16) tensor(0.7500, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(1.1855, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(1.1816, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.9688, device='cuda:0', dtype=torch.float16) tensor(1.4600, device='cuda:0', dtype=torch.float16)
tensor(2.5234, device='cuda:0', dtype=torch.float16) tensor(0.2358, device='cuda:0', dtype=torch.float16)
tensor(2.7656, device='cuda:0', dtype=torch.float16) tensor(0.2255, device='cuda:0', dtype=torch.float16)
tensor(2.6016, device='cuda:0', dtype=torch.float16) tensor(0.2191, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.2295, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0126, device='cuda:0')
tensor(0.1386, device='cuda:0')
old_score: tensor(0.2275, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1384, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9734599590301514
Validation after dual ascent:
out_inf: tensor(16.9688, device='cuda:0', dtype=torch.float16) tensor(1.4600, device='cuda:0', dtype=torch.float16)
tensor(1.5615, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
tensor(1.6465, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.2020, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.6382, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0055, device='cuda:0')
tensor(0.1366, device='cuda:0')
old_score: tensor(0.0707, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0477, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7889769077301025
Validation after dual ascent:
out_inf: tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.2020, device='cuda:0', dtype=torch.float16)
tensor(0.5186, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.5015, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.4619, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.4668, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.6309, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.3984, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.2695, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.0299, device='cuda:0')
old_score: tensor(0.0110, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.828892707824707
Validation after dual ascent:
out_inf: tensor(2.6309, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.2256, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1855, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.2578, device='cuda:0', dtype=torch.float16) tensor(0.3530, device='cuda:0', dtype=torch.float16)
tensor(3.2617, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(2.0352, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(3.2266, device='cuda:0', dtype=torch.float16) tensor(0.0960, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0161, device='cuda:0')
tensor(0.0814, device='cuda:0')
old_score: tensor(0.0961, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0634, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.224802255630493
Validation after dual ascent:
out_inf: tensor(11.2578, device='cuda:0', dtype=torch.float16) tensor(0.3530, device='cuda:0', dtype=torch.float16)
tensor(1.8184, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.0647, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.3984, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0675, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0191, device='cuda:0')
tensor(0.3292, device='cuda:0')
old_score: tensor(0.0696, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0475, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.782217502593994
Validation after dual ascent:
out_inf: tensor(4.3984, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.1895, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.2654, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.1990, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.1982, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0156, device='cuda:0')
tensor(0.0278, device='cuda:0')
old_score: tensor(0.0141, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0098, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.61069464683533
Validation after dual ascent:
out_inf: tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.1641, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1390, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1233, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.9453, device='cuda:0', dtype=torch.float16) tensor(0.7222, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.1462, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.1393, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0193, device='cuda:0')
tensor(0.2084, device='cuda:0')
old_score: tensor(0.1404, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0880, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1888508796691895
Validation after dual ascent:
out_inf: tensor(15.9453, device='cuda:0', dtype=torch.float16) tensor(0.7222, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.0920, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
tensor(1.1699, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.9844, device='cuda:0', dtype=torch.float16) tensor(1.4863, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.2225, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.2107, device='cuda:0', dtype=torch.float16)
tensor(2.0625, device='cuda:0', dtype=torch.float16) tensor(0.2063, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.2137, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0198, device='cuda:0')
tensor(0.3334, device='cuda:0')
old_score: tensor(0.2134, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1305, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7879104614257812
Validation after dual ascent:
out_inf: tensor(18.9844, device='cuda:0', dtype=torch.float16) tensor(1.4863, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.3574, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.1204, device='cuda:0', dtype=torch.float16)
tensor(1.4053, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.9160, device='cuda:0', dtype=torch.float16) tensor(0.1986, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0713, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0056, device='cuda:0')
tensor(0.1395, device='cuda:0')
old_score: tensor(0.0720, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0486, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7884409427642822
Validation after dual ascent:
out_inf: tensor(2.9160, device='cuda:0', dtype=torch.float16) tensor(0.1986, device='cuda:0', dtype=torch.float16)
tensor(0.4832, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.5010, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.4187, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.4834, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.3027, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.3262, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.3135, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.3628, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.0242, device='cuda:0')
old_score: tensor(0.0120, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0072, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.860192775726318
Validation after dual ascent:
out_inf: tensor(2.3027, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.1973, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.2646, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.2539, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1807, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1992, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(2.3672, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(2.2070, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(2.2070, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0164, device='cuda:0')
tensor(0.0900, device='cuda:0')
old_score: tensor(0.1003, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0649, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.233882665634155
Validation after dual ascent:
out_inf: tensor(7.1992, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(1.6963, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.8730, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0755, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0055, device='cuda:0')
tensor(0.0662, device='cuda:0')
old_score: tensor(0.0724, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0487, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.239965677261353
Validation after dual ascent:
out_inf: tensor(3.8730, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.5498, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.1946, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.2012, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.1816, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.1895, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0143, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.0150, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.642335176467896
Validation after dual ascent:
out_inf: tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.1577, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1519, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1426, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1802, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.q_proj
Validation after prune:
out_inf: tensor(21.1719, device='cuda:0', dtype=torch.float16) tensor(0.7295, device='cuda:0', dtype=torch.float16)
tensor(2.8828, device='cuda:0', dtype=torch.float16) tensor(0.1409, device='cuda:0', dtype=torch.float16)
tensor(2.8984, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
tensor(2.3359, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(2.8125, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0199, device='cuda:0')
tensor(0.1231, device='cuda:0')
old_score: tensor(0.1357, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0834, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.912402391433716
Validation after dual ascent:
out_inf: tensor(21.1719, device='cuda:0', dtype=torch.float16) tensor(0.7295, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.k_proj
Validation after prune:
out_inf: tensor(22.6250, device='cuda:0', dtype=torch.float16) tensor(1.4502, device='cuda:0', dtype=torch.float16)
tensor(2.7344, device='cuda:0', dtype=torch.float16) tensor(0.2207, device='cuda:0', dtype=torch.float16)
tensor(2.7695, device='cuda:0', dtype=torch.float16) tensor(0.2090, device='cuda:0', dtype=torch.float16)
tensor(2.3438, device='cuda:0', dtype=torch.float16) tensor(0.2034, device='cuda:0', dtype=torch.float16)
tensor(2.6016, device='cuda:0', dtype=torch.float16) tensor(0.2153, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0142, device='cuda:0')
tensor(0.1166, device='cuda:0')
old_score: tensor(0.2120, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1267, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9710144996643066
Validation after dual ascent:
out_inf: tensor(22.6250, device='cuda:0', dtype=torch.float16) tensor(1.4502, device='cuda:0', dtype=torch.float16)
tensor(1.2725, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.4248, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.7070, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.2598, device='cuda:0', dtype=torch.float16) tensor(0.2087, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(0.6177, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0055, device='cuda:0')
tensor(0.1304, device='cuda:0')
old_score: tensor(0.0725, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0477, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7862284183502197
Validation after dual ascent:
out_inf: tensor(3.2598, device='cuda:0', dtype=torch.float16) tensor(0.2087, device='cuda:0', dtype=torch.float16)
tensor(0.4536, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.4556, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.5229, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.4836, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.5361, device='cuda:0', dtype=torch.float16) tensor(0.0366, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.4072, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.3076, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.0219, device='cuda:0')
old_score: tensor(0.0139, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0078, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.847302198410034
Validation after dual ascent:
out_inf: tensor(1.5361, device='cuda:0', dtype=torch.float16) tensor(0.0366, device='cuda:0', dtype=torch.float16)
tensor(0.1465, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.2361, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.2039, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1313, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.3242, device='cuda:0', dtype=torch.float16) tensor(0.3799, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(2.2559, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(2.5508, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0176, device='cuda:0')
tensor(0.0878, device='cuda:0')
old_score: tensor(0.1012, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0651, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.22193455696106
Validation after dual ascent:
out_inf: tensor(7.3242, device='cuda:0', dtype=torch.float16) tensor(0.3799, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(1.4805, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.1659, device='cuda:0', dtype=torch.float16)
tensor(0.7354, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.0719, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(0.8691, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0200, device='cuda:0')
tensor(0.3420, device='cuda:0')
old_score: tensor(0.0727, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0486, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.784489393234253
Validation after dual ascent:
out_inf: tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.1659, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.4932, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(0.5674, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.2012, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.2432, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.2339, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.2627, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0154, device='cuda:0')
tensor(0.0278, device='cuda:0')
old_score: tensor(0.0155, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.60972881317139
Validation after dual ascent:
out_inf: tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.1382, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.2073, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.7969, device='cuda:0', dtype=torch.float16) tensor(0.6929, device='cuda:0', dtype=torch.float16)
tensor(2.8594, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
tensor(2.4219, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(2.3125, device='cuda:0', dtype=torch.float16) tensor(0.1233, device='cuda:0', dtype=torch.float16)
tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0118, device='cuda:0')
tensor(0.0956, device='cuda:0')
old_score: tensor(0.1267, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0786, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.637956142425537
Validation after dual ascent:
out_inf: tensor(18.7969, device='cuda:0', dtype=torch.float16) tensor(0.6929, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.0806, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.6250, device='cuda:0', dtype=torch.float16) tensor(1.4648, device='cuda:0', dtype=torch.float16)
tensor(2.1016, device='cuda:0', dtype=torch.float16) tensor(0.2008, device='cuda:0', dtype=torch.float16)
tensor(2.3359, device='cuda:0', dtype=torch.float16) tensor(0.1918, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1907, device='cuda:0', dtype=torch.float16)
tensor(2.2422, device='cuda:0', dtype=torch.float16) tensor(0.1956, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0152, device='cuda:0')
tensor(0.1077, device='cuda:0')
old_score: tensor(0.1946, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1180, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9665753841400146
Validation after dual ascent:
out_inf: tensor(18.6250, device='cuda:0', dtype=torch.float16) tensor(1.4648, device='cuda:0', dtype=torch.float16)
tensor(1.3457, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.3340, device='cuda:0', dtype=torch.float16) tensor(0.2083, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.6860, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0057, device='cuda:0')
tensor(0.1288, device='cuda:0')
old_score: tensor(0.0743, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0491, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7827062606811523
Validation after dual ascent:
out_inf: tensor(3.3340, device='cuda:0', dtype=torch.float16) tensor(0.2083, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(0.5278, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.4595, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.3252, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.2852, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.3076, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.0298, device='cuda:0')
old_score: tensor(0.0119, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0075, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.823193073272705
Validation after dual ascent:
out_inf: tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.2017, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.2175, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.2024, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.1646, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.6641, device='cuda:0', dtype=torch.float16) tensor(0.3613, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(1.8418, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(2.2285, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0165, device='cuda:0')
tensor(0.0868, device='cuda:0')
old_score: tensor(0.0993, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0650, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.229772806167603
Validation after dual ascent:
out_inf: tensor(8.6641, device='cuda:0', dtype=torch.float16) tensor(0.3613, device='cuda:0', dtype=torch.float16)
tensor(1.1064, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(1.2930, device='cuda:0', dtype=torch.float16) tensor(0.0672, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.7715, device='cuda:0', dtype=torch.float16) tensor(0.1595, device='cuda:0', dtype=torch.float16)
tensor(0.8926, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(0.9023, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0055, device='cuda:0')
tensor(0.0636, device='cuda:0')
old_score: tensor(0.0719, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0486, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.238284349441528
Validation after dual ascent:
out_inf: tensor(3.7715, device='cuda:0', dtype=torch.float16) tensor(0.1595, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.5913, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.1455, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.2236, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.1904, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
tensor(0.1836, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0166, device='cuda:0')
tensor(0.0345, device='cuda:0')
old_score: tensor(0.0145, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.66509413719177
Validation after dual ascent:
out_inf: tensor(0.5913, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.1324, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1389, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1241, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1746, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.7812, device='cuda:0', dtype=torch.float16) tensor(0.7158, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
tensor(2.1875, device='cuda:0', dtype=torch.float16) tensor(0.1196, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.1233, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0120, device='cuda:0')
tensor(0.0798, device='cuda:0')
old_score: tensor(0.1215, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0774, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.6366190910339355
Validation after dual ascent:
out_inf: tensor(19.7812, device='cuda:0', dtype=torch.float16) tensor(0.7158, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.0808, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(0.9321, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0802, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.8125, device='cuda:0', dtype=torch.float16) tensor(1.3848, device='cuda:0', dtype=torch.float16)
tensor(2.5156, device='cuda:0', dtype=torch.float16) tensor(0.1931, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1802, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1755, device='cuda:0', dtype=torch.float16)
tensor(2.3984, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0196, device='cuda:0')
tensor(0.2544, device='cuda:0')
old_score: tensor(0.1841, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1161, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7846307754516602
Validation after dual ascent:
out_inf: tensor(20.8125, device='cuda:0', dtype=torch.float16) tensor(1.3848, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.1211, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.1170, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1059, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1204, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.6699, device='cuda:0', dtype=torch.float16) tensor(0.2006, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(0.6377, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0057, device='cuda:0')
tensor(0.1292, device='cuda:0')
old_score: tensor(0.0755, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0508, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7840480804443359
Validation after dual ascent:
out_inf: tensor(2.6699, device='cuda:0', dtype=torch.float16) tensor(0.2006, device='cuda:0', dtype=torch.float16)
tensor(0.5400, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(0.4709, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.4668, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.6724, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
tensor(0.3076, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.2871, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.3057, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.0266, device='cuda:0')
old_score: tensor(0.0111, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0067, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.775426864624023
Validation after dual ascent:
out_inf: tensor(0.6724, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
tensor(0.1904, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.1895, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.9688, device='cuda:0', dtype=torch.float16) tensor(0.3564, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(2.3867, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(2.5625, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0161, device='cuda:0')
tensor(0.0814, device='cuda:0')
old_score: tensor(0.0975, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0643, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.164060115814209
Validation after dual ascent:
out_inf: tensor(7.9688, device='cuda:0', dtype=torch.float16) tensor(0.3564, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.1567, device='cuda:0', dtype=torch.float16)
tensor(0.7520, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0700, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0680, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0196, device='cuda:0')
tensor(0.3291, device='cuda:0')
old_score: tensor(0.0712, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0481, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.774138450622559
Validation after dual ascent:
out_inf: tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.1567, device='cuda:0', dtype=torch.float16)
tensor(0.5015, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.4944, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.1470, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.1377, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.1626, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.1931, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0194, device='cuda:0')
tensor(0.0174, device='cuda:0')
old_score: tensor(0.0138, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0092, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 60.647181034088135
Validation after dual ascent:
out_inf: tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.1182, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1197, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1459, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1400, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.q_proj
Validation after prune:
out_inf: tensor(22.5000, device='cuda:0', dtype=torch.float16) tensor(0.7207, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1156, device='cuda:0', dtype=torch.float16)
tensor(2.4531, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0132, device='cuda:0')
tensor(0.0760, device='cuda:0')
old_score: tensor(0.1177, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0741, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.642639636993408
Validation after dual ascent:
out_inf: tensor(22.5000, device='cuda:0', dtype=torch.float16) tensor(0.7207, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.0748, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4375, device='cuda:0', dtype=torch.float16) tensor(1.3682, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1781, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1663, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1626, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1721, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0167, device='cuda:0')
tensor(0.0913, device='cuda:0')
old_score: tensor(0.1697, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1055, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9670565128326416
Validation after dual ascent:
out_inf: tensor(19.4375, device='cuda:0', dtype=torch.float16) tensor(1.3682, device='cuda:0', dtype=torch.float16)
tensor(1.3789, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(1.3154, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(1.3564, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.8926, device='cuda:0', dtype=torch.float16) tensor(0.2322, device='cuda:0', dtype=torch.float16)
tensor(0.7710, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.7881, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.7744, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(0.6528, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.1306, device='cuda:0')
old_score: tensor(0.0809, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0537, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7836101055145264
Validation after dual ascent:
out_inf: tensor(3.8926, device='cuda:0', dtype=torch.float16) tensor(0.2322, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.6465, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0492, device='cuda:0', dtype=torch.float16)
tensor(0.5537, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.8369, device='cuda:0', dtype=torch.float16) tensor(0.0387, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.3643, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.4604, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.0363, device='cuda:0')
old_score: tensor(0.0114, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0070, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.793120861053467
Validation after dual ascent:
out_inf: tensor(0.8369, device='cuda:0', dtype=torch.float16) tensor(0.0387, device='cuda:0', dtype=torch.float16)
tensor(0.3330, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1553, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.2466, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.1980, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.8359, device='cuda:0', dtype=torch.float16) tensor(0.3621, device='cuda:0', dtype=torch.float16)
tensor(3.2500, device='cuda:0', dtype=torch.float16) tensor(0.1022, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
tensor(2.8164, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0162, device='cuda:0')
tensor(0.0821, device='cuda:0')
old_score: tensor(0.0981, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0646, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.237011671066284
Validation after dual ascent:
out_inf: tensor(10.8359, device='cuda:0', dtype=torch.float16) tensor(0.3621, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(1.9375, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0430, device='cuda:0', dtype=torch.float16) tensor(0.1575, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.9541, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0199, device='cuda:0')
tensor(0.3326, device='cuda:0')
old_score: tensor(0.0718, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0484, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.79313063621521
Validation after dual ascent:
out_inf: tensor(4.0430, device='cuda:0', dtype=torch.float16) tensor(0.1575, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.3232, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.1444, device='cuda:0', dtype=torch.float16) tensor(0.0136, device='cuda:0', dtype=torch.float16)
tensor(0.1548, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.1377, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.1631, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0066, device='cuda:0')
tensor(0.0145, device='cuda:0')
old_score: tensor(0.0138, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0092, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 68.64271116256714
Validation after dual ascent:
out_inf: tensor(1.3232, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.1353, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1465, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.1260, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1526, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.q_proj
Validation after prune:
out_inf: tensor(23.3125, device='cuda:0', dtype=torch.float16) tensor(0.7695, device='cuda:0', dtype=torch.float16)
tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0147, device='cuda:0')
tensor(0.0695, device='cuda:0')
old_score: tensor(0.1204, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0748, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.645142555236816
Validation after dual ascent:
out_inf: tensor(23.3125, device='cuda:0', dtype=torch.float16) tensor(0.7695, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.k_proj
Validation after prune:
out_inf: tensor(22.4219, device='cuda:0', dtype=torch.float16) tensor(1.3418, device='cuda:0', dtype=torch.float16)
tensor(3.0391, device='cuda:0', dtype=torch.float16) tensor(0.1873, device='cuda:0', dtype=torch.float16)
tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.1659, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.1816, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0174, device='cuda:0')
tensor(0.0920, device='cuda:0')
old_score: tensor(0.1763, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1077, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.97080397605896
Validation after dual ascent:
out_inf: tensor(22.4219, device='cuda:0', dtype=torch.float16) tensor(1.3418, device='cuda:0', dtype=torch.float16)
tensor(1.6387, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(1.1885, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(1.4482, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.8828, device='cuda:0', dtype=torch.float16) tensor(0.2532, device='cuda:0', dtype=torch.float16)
tensor(0.7573, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
tensor(0.7803, device='cuda:0', dtype=torch.float16) tensor(0.0843, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(0.8350, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0064, device='cuda:0')
tensor(0.1354, device='cuda:0')
old_score: tensor(0.0860, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0563, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7844207286834717
Validation after dual ascent:
out_inf: tensor(3.8828, device='cuda:0', dtype=torch.float16) tensor(0.2532, device='cuda:0', dtype=torch.float16)
tensor(0.4971, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.5088, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.5786, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.4014, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.3486, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.3623, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.0344, device='cuda:0')
old_score: tensor(0.0111, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0067, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.794811725616455
Validation after dual ascent:
out_inf: tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.2070, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.1973, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.1992, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.2090, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.5234, device='cuda:0', dtype=torch.float16) tensor(0.3877, device='cuda:0', dtype=torch.float16)
tensor(2.5508, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(2.2266, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0172, device='cuda:0')
tensor(0.0877, device='cuda:0')
old_score: tensor(0.1006, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0670, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.189374208450317
Validation after dual ascent:
out_inf: tensor(9.5234, device='cuda:0', dtype=torch.float16) tensor(0.3877, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
tensor(1.4297, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.7959, device='cuda:0', dtype=torch.float16) tensor(0.0725, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0060, device='cuda:0')
tensor(0.0644, device='cuda:0')
old_score: tensor(0.0739, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0502, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.243892669677734
Validation after dual ascent:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.7520, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.1587, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.1604, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.1552, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.1576, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0194, device='cuda:0')
tensor(0.0460, device='cuda:0')
old_score: tensor(0.0147, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.4729368686676
Validation after dual ascent:
out_inf: tensor(3.7520, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.1499, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1345, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1260, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1360, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.7188, device='cuda:0', dtype=torch.float16) tensor(0.7427, device='cuda:0', dtype=torch.float16)
tensor(2.4219, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1148, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0126, device='cuda:0')
tensor(0.0641, device='cuda:0')
old_score: tensor(0.1172, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0743, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.640315055847168
Validation after dual ascent:
out_inf: tensor(16.7188, device='cuda:0', dtype=torch.float16) tensor(0.7427, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.0758, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.6094, device='cuda:0', dtype=torch.float16) tensor(1.4951, device='cuda:0', dtype=torch.float16)
tensor(2.1582, device='cuda:0', dtype=torch.float16) tensor(0.1843, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1720, device='cuda:0', dtype=torch.float16)
tensor(2.5742, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.1798, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0176, device='cuda:0')
tensor(0.0812, device='cuda:0')
old_score: tensor(0.1760, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1093, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.96590256690979
Validation after dual ascent:
out_inf: tensor(21.6094, device='cuda:0', dtype=torch.float16) tensor(1.4951, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1005, device='cuda:0', dtype=torch.float16)
tensor(1.6113, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.5840, device='cuda:0', dtype=torch.float16) tensor(0.2179, device='cuda:0', dtype=torch.float16)
tensor(0.7324, device='cuda:0', dtype=torch.float16) tensor(0.0893, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.0849, device='cuda:0', dtype=torch.float16)
tensor(0.9307, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0063, device='cuda:0')
tensor(0.1425, device='cuda:0')
old_score: tensor(0.0862, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0580, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7820806503295898
Validation after dual ascent:
out_inf: tensor(3.5840, device='cuda:0', dtype=torch.float16) tensor(0.2179, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.5996, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0166, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.4961, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.0309, device='cuda:0')
old_score: tensor(0.0144, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0080, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.779543399810791
Validation after dual ascent:
out_inf: tensor(1.0166, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1875, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.2461, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.1865, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.7617, device='cuda:0', dtype=torch.float16) tensor(0.4263, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(2.4492, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(2.5742, device='cuda:0', dtype=torch.float16) tensor(0.1001, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0198, device='cuda:0')
tensor(0.0985, device='cuda:0')
old_score: tensor(0.1052, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0692, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.174102783203125
Validation after dual ascent:
out_inf: tensor(7.7617, device='cuda:0', dtype=torch.float16) tensor(0.4263, device='cuda:0', dtype=torch.float16)
tensor(1.9941, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
tensor(1.8242, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.1776, device='cuda:0', dtype=torch.float16)
tensor(0.9902, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0068, device='cuda:0')
tensor(0.0722, device='cuda:0')
old_score: tensor(0.0775, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0522, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.238650560379028
Validation after dual ascent:
out_inf: tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.1776, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.5469, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.2305, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.2051, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.2070, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0171, device='cuda:0')
tensor(0.0247, device='cuda:0')
old_score: tensor(0.0164, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 44.47834873199463
Validation after dual ascent:
out_inf: tensor(3.5469, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.1472, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1721, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1565, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1781, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.q_proj
Validation after prune:
out_inf: tensor(22.2188, device='cuda:0', dtype=torch.float16) tensor(0.7339, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(3.2109, device='cuda:0', dtype=torch.float16) tensor(0.1244, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0112, device='cuda:0')
tensor(0.1290, device='cuda:0')
old_score: tensor(0.1257, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0776, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.829458475112915
Validation after dual ascent:
out_inf: tensor(22.2188, device='cuda:0', dtype=torch.float16) tensor(0.7339, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.1875, device='cuda:0', dtype=torch.float16) tensor(1.4688, device='cuda:0', dtype=torch.float16)
tensor(2.7578, device='cuda:0', dtype=torch.float16) tensor(0.2020, device='cuda:0', dtype=torch.float16)
tensor(3.0312, device='cuda:0', dtype=torch.float16) tensor(0.1874, device='cuda:0', dtype=torch.float16)
tensor(2.3828, device='cuda:0', dtype=torch.float16) tensor(0.1771, device='cuda:0', dtype=torch.float16)
tensor(2.8438, device='cuda:0', dtype=torch.float16) tensor(0.1927, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0068, device='cuda:0')
tensor(0.0981, device='cuda:0')
old_score: tensor(0.1898, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1139, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.8957042694091797
Validation after dual ascent:
out_inf: tensor(19.1875, device='cuda:0', dtype=torch.float16) tensor(1.4688, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(1.3965, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(1.3887, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.5195, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(1.0488, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0127, device='cuda:0')
tensor(0.0761, device='cuda:0')
old_score: tensor(0.0994, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0654, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1549043655395508
Validation after dual ascent:
out_inf: tensor(4.5195, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(0.7476, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
tensor(0.6104, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.6138, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.5645, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.0520, device='cuda:0')
old_score: tensor(0.0143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0085, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.791163682937622
Validation after dual ascent:
out_inf: tensor(1.5645, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.3335, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.7900, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.4707, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.2363, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.3828, device='cuda:0', dtype=torch.float16) tensor(0.4802, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(2.0820, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(2.2617, device='cuda:0', dtype=torch.float16) tensor(0.1072, device='cuda:0', dtype=torch.float16)
tensor(2.3008, device='cuda:0', dtype=torch.float16) tensor(0.1143, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0181, device='cuda:0')
tensor(0.0322, device='cuda:0')
old_score: tensor(0.1132, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0734, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.676173686981201
Validation after dual ascent:
out_inf: tensor(8.3828, device='cuda:0', dtype=torch.float16) tensor(0.4802, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(1.7695, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.0672, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.1984, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0794, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0083, device='cuda:0')
tensor(0.0894, device='cuda:0')
old_score: tensor(0.0839, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0558, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.245529651641846
Validation after dual ascent:
out_inf: tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.1984, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.0781, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(0.1965, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.2179, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
tensor(0.2230, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.2078, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0162, device='cuda:0')
tensor(0.0332, device='cuda:0')
old_score: tensor(0.0192, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.40609288215637
Validation after dual ascent:
out_inf: tensor(6.0781, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(0.1704, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1998, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.1794, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1761, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.q_proj
Validation after prune:
out_inf: tensor(20.6875, device='cuda:0', dtype=torch.float16) tensor(0.7822, device='cuda:0', dtype=torch.float16)
tensor(3.0234, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(2.8125, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(2.5625, device='cuda:0', dtype=torch.float16) tensor(0.1270, device='cuda:0', dtype=torch.float16)
tensor(2.9531, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0140, device='cuda:0')
tensor(0.0666, device='cuda:0')
old_score: tensor(0.1364, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0791, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.636744737625122
Validation after dual ascent:
out_inf: tensor(20.6875, device='cuda:0', dtype=torch.float16) tensor(0.7822, device='cuda:0', dtype=torch.float16)
tensor(1.1758, device='cuda:0', dtype=torch.float16) tensor(0.0804, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.9385, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.k_proj
Validation after prune:
out_inf: tensor(22.6719, device='cuda:0', dtype=torch.float16) tensor(1.4570, device='cuda:0', dtype=torch.float16)
tensor(3.2266, device='cuda:0', dtype=torch.float16) tensor(0.2158, device='cuda:0', dtype=torch.float16)
tensor(2.9609, device='cuda:0', dtype=torch.float16) tensor(0.2004, device='cuda:0', dtype=torch.float16)
tensor(2.8203, device='cuda:0', dtype=torch.float16) tensor(0.1886, device='cuda:0', dtype=torch.float16)
tensor(3.0234, device='cuda:0', dtype=torch.float16) tensor(0.2126, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0190, device='cuda:0')
tensor(0.0888, device='cuda:0')
old_score: tensor(0.2043, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1145, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9650602340698242
Validation after dual ascent:
out_inf: tensor(22.6719, device='cuda:0', dtype=torch.float16) tensor(1.4570, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1167, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1183, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
tensor(1.2930, device='cuda:0', dtype=torch.float16) tensor(0.1178, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.3281, device='cuda:0', dtype=torch.float16) tensor(0.2664, device='cuda:0', dtype=torch.float16)
tensor(0.9956, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.1005, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.1073, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0080, device='cuda:0')
tensor(0.1880, device='cuda:0')
old_score: tensor(0.1060, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0697, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7810161113739014
Validation after dual ascent:
out_inf: tensor(5.3281, device='cuda:0', dtype=torch.float16) tensor(0.2664, device='cuda:0', dtype=torch.float16)
tensor(0.6865, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(0.6323, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(0.6938, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.7490, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.5322, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(1.5410, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0178, device='cuda:0')
tensor(0.0392, device='cuda:0')
old_score: tensor(0.0199, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.628277063369751
Validation after dual ascent:
out_inf: tensor(1.5322, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.3203, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.3281, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.1094, device='cuda:0', dtype=torch.float16) tensor(0.5254, device='cuda:0', dtype=torch.float16)
tensor(3.0312, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0112, device='cuda:0')
tensor(0.0156, device='cuda:0')
old_score: tensor(0.1185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0743, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.060427188873291
Validation after dual ascent:
out_inf: tensor(11.1094, device='cuda:0', dtype=torch.float16) tensor(0.5254, device='cuda:0', dtype=torch.float16)
tensor(1.8398, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(2.6445, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(1.5176, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.0761, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.0117, device='cuda:0', dtype=torch.float16) tensor(0.2279, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0888, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0109, device='cuda:0')
tensor(0.0979, device='cuda:0')
old_score: tensor(0.0898, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0581, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.240761518478394
Validation after dual ascent:
out_inf: tensor(5.0117, device='cuda:0', dtype=torch.float16) tensor(0.2279, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.6934, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.7344, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(0.2676, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.2556, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.2969, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.2986, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0102, device='cuda:0')
tensor(0.0178, device='cuda:0')
old_score: tensor(0.0225, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0140, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.46422791481018
Validation after dual ascent:
out_inf: tensor(4.7344, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(0.2202, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.2554, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.2134, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.2593, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.2031, device='cuda:0', dtype=torch.float16) tensor(0.7349, device='cuda:0', dtype=torch.float16)
tensor(3.2266, device='cuda:0', dtype=torch.float16) tensor(0.1669, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
tensor(3.0977, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(3.1387, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(0.0895, device='cuda:0')
old_score: tensor(0.1554, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0819, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.841287851333618
Validation after dual ascent:
out_inf: tensor(13.2031, device='cuda:0', dtype=torch.float16) tensor(0.7349, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0834, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.k_proj
Validation after prune:
out_inf: tensor(35.4375, device='cuda:0', dtype=torch.float16) tensor(1.3867, device='cuda:0', dtype=torch.float16)
tensor(10.5312, device='cuda:0', dtype=torch.float16) tensor(0.2612, device='cuda:0', dtype=torch.float16)
tensor(9.4375, device='cuda:0', dtype=torch.float16) tensor(0.2385, device='cuda:0', dtype=torch.float16)
tensor(9.6094, device='cuda:0', dtype=torch.float16) tensor(0.2234, device='cuda:0', dtype=torch.float16)
tensor(10.0469, device='cuda:0', dtype=torch.float16) tensor(0.2500, device='cuda:0', dtype=torch.float16)
tensor(0.0695, device='cuda:0')
old_score: tensor(0.2433, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.943573474884033
Validation after dual ascent:
out_inf: tensor(35.4375, device='cuda:0', dtype=torch.float16) tensor(1.3867, device='cuda:0', dtype=torch.float16)
tensor(2.2812, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1139, device='cuda:0', dtype=torch.float16)
tensor(2.5625, device='cuda:0', dtype=torch.float16) tensor(0.1265, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
tensor(0.9824, device='cuda:0', dtype=torch.float16) tensor(0.1133, device='cuda:0', dtype=torch.float16)
tensor(1.0205, device='cuda:0', dtype=torch.float16) tensor(0.1204, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0140, device='cuda:0')
tensor(0.1152, device='cuda:0')
old_score: tensor(0.1194, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0755, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9706494808197021
Validation after dual ascent:
out_inf: tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.6958, device='cuda:0', dtype=torch.float16) tensor(0.0695, device='cuda:0', dtype=torch.float16)
tensor(0.7676, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.5986, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0150, device='cuda:0')
tensor(0.0297, device='cuda:0')
old_score: tensor(0.0148, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0075, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.092689275741577
Validation after dual ascent:
out_inf: tensor(1.5986, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.3730, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.4297, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.gate_proj
Validation after prune:
out_inf: tensor(14.4531, device='cuda:0', dtype=torch.float16) tensor(0.5322, device='cuda:0', dtype=torch.float16)
tensor(2.4883, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.1233, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(2.8223, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0118, device='cuda:0')
tensor(0.0167, device='cuda:0')
old_score: tensor(0.1250, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0742, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.15089750289917
Validation after dual ascent:
out_inf: tensor(14.4531, device='cuda:0', dtype=torch.float16) tensor(0.5322, device='cuda:0', dtype=torch.float16)
tensor(1.8086, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(1.7598, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.up_proj
Validation after prune:
out_inf: tensor(10.6953, device='cuda:0', dtype=torch.float16) tensor(0.2690, device='cuda:0', dtype=torch.float16)
tensor(3.6406, device='cuda:0', dtype=torch.float16) tensor(0.1032, device='cuda:0', dtype=torch.float16)
tensor(3.2227, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(3.3320, device='cuda:0', dtype=torch.float16) tensor(0.0923, device='cuda:0', dtype=torch.float16)
tensor(3.1992, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.1074, device='cuda:0')
old_score: tensor(0.0981, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0601, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.258452653884888
Validation after dual ascent:
out_inf: tensor(10.6953, device='cuda:0', dtype=torch.float16) tensor(0.2690, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.down_proj
Validation after prune:
out_inf: tensor(9.7656, device='cuda:0', dtype=torch.float16) tensor(0.1117, device='cuda:0', dtype=torch.float16)
tensor(0.4263, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.3386, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
tensor(0.3450, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.3447, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0133, device='cuda:0')
tensor(0.0155, device='cuda:0')
old_score: tensor(0.0265, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0168, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.464253187179565
Validation after dual ascent:
out_inf: tensor(9.7656, device='cuda:0', dtype=torch.float16) tensor(0.1117, device='cuda:0', dtype=torch.float16)
tensor(0.3623, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.2861, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.2991, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.2874, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(0.7969, device='cuda:0', dtype=torch.float16)
tensor(3.6250, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(3.3516, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(3.3672, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
tensor(3.8594, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0150, device='cuda:0')
tensor(0.0661, device='cuda:0')
old_score: tensor(0.1427, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0737, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.641398191452026
Validation after dual ascent:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(0.7969, device='cuda:0', dtype=torch.float16)
tensor(1.6406, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.0312, device='cuda:0', dtype=torch.float16) tensor(1.5254, device='cuda:0', dtype=torch.float16)
tensor(3.2031, device='cuda:0', dtype=torch.float16) tensor(0.2175, device='cuda:0', dtype=torch.float16)
tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.1998, device='cuda:0', dtype=torch.float16)
tensor(3.3047, device='cuda:0', dtype=torch.float16) tensor(0.1893, device='cuda:0', dtype=torch.float16)
tensor(3.2656, device='cuda:0', dtype=torch.float16) tensor(0.2095, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0182, device='cuda:0')
tensor(0.0851, device='cuda:0')
old_score: tensor(0.2041, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1016, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9691121578216553
Validation after dual ascent:
out_inf: tensor(21.0312, device='cuda:0', dtype=torch.float16) tensor(1.5254, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(1.2031, device='cuda:0', dtype=torch.float16) tensor(0.0940, device='cuda:0', dtype=torch.float16)
tensor(1.2227, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.4570, device='cuda:0', dtype=torch.float16) tensor(0.3274, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0104, device='cuda:0')
tensor(0.2479, device='cuda:0')
old_score: tensor(0.1364, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0865, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7853565216064453
Validation after dual ascent:
out_inf: tensor(5.4570, device='cuda:0', dtype=torch.float16) tensor(0.3274, device='cuda:0', dtype=torch.float16)
tensor(0.8120, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(0.8799, device='cuda:0', dtype=torch.float16) tensor(0.0806, device='cuda:0', dtype=torch.float16)
tensor(0.9072, device='cuda:0', dtype=torch.float16) tensor(0.0871, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.4531, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
tensor(1.6172, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0129, device='cuda:0')
tensor(0.0197, device='cuda:0')
old_score: tensor(0.0377, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0204, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.903002977371216
Validation after dual ascent:
out_inf: tensor(3.4531, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.7676, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.gate_proj
Validation after prune:
out_inf: tensor(18.1719, device='cuda:0', dtype=torch.float16) tensor(0.5986, device='cuda:0', dtype=torch.float16)
tensor(2.8164, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
tensor(2.8125, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(2.7109, device='cuda:0', dtype=torch.float16) tensor(0.1329, device='cuda:0', dtype=torch.float16)
tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0150, device='cuda:0')
tensor(0.0213, device='cuda:0')
old_score: tensor(0.1398, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0793, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.087875604629517
Validation after dual ascent:
out_inf: tensor(18.1719, device='cuda:0', dtype=torch.float16) tensor(0.5986, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(2.0586, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.0744, device='cuda:0', dtype=torch.float16)
tensor(1.7617, device='cuda:0', dtype=torch.float16) tensor(0.0796, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.up_proj
Validation after prune:
out_inf: tensor(11.0859, device='cuda:0', dtype=torch.float16) tensor(0.3586, device='cuda:0', dtype=torch.float16)
tensor(3.4922, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(3.4844, device='cuda:0', dtype=torch.float16) tensor(0.1133, device='cuda:0', dtype=torch.float16)
tensor(3.0625, device='cuda:0', dtype=torch.float16) tensor(0.1066, device='cuda:0', dtype=torch.float16)
tensor(3.1445, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0178, device='cuda:0')
tensor(0.0352, device='cuda:0')
old_score: tensor(0.1119, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0638, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.68630838394165
Validation after dual ascent:
out_inf: tensor(11.0859, device='cuda:0', dtype=torch.float16) tensor(0.3586, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.down_proj
Validation after prune:
out_inf: tensor(11.8281, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0357, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0357, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.0257, device='cuda:0')
old_score: tensor(0.0359, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0221, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 163.8411407470703
Validation after dual ascent:
out_inf: tensor(11.8281, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(0.4810, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0214, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(0.9033, device='cuda:0', dtype=torch.float16)
tensor(6.8125, device='cuda:0', dtype=torch.float16) tensor(0.2190, device='cuda:0', dtype=torch.float16)
tensor(7.1875, device='cuda:0', dtype=torch.float16) tensor(0.2096, device='cuda:0', dtype=torch.float16)
tensor(6.9219, device='cuda:0', dtype=torch.float16) tensor(0.2003, device='cuda:0', dtype=torch.float16)
tensor(6.9219, device='cuda:0', dtype=torch.float16) tensor(0.2090, device='cuda:0', dtype=torch.float16)
tensor(0.0211, device='cuda:0')
old_score: tensor(0.2095, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0737, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.849509477615356
Validation after dual ascent:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(0.9033, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.9844, device='cuda:0', dtype=torch.float16) tensor(1.4229, device='cuda:0', dtype=torch.float16)
tensor(7.7656, device='cuda:0', dtype=torch.float16) tensor(0.3176, device='cuda:0', dtype=torch.float16)
tensor(7.5547, device='cuda:0', dtype=torch.float16) tensor(0.3003, device='cuda:0', dtype=torch.float16)
tensor(7.7891, device='cuda:0', dtype=torch.float16) tensor(0.2864, device='cuda:0', dtype=torch.float16)
tensor(7.3516, device='cuda:0', dtype=torch.float16) tensor(0.3042, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0129, device='cuda:0')
tensor(0.0232, device='cuda:0')
old_score: tensor(0.3022, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1033, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3505523204803467
Validation after dual ascent:
out_inf: tensor(18.9844, device='cuda:0', dtype=torch.float16) tensor(1.4229, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1079, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.0968, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.7305, device='cuda:0', dtype=torch.float16) tensor(0.4058, device='cuda:0', dtype=torch.float16)
tensor(2.6680, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(2.5156, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(2.4922, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0107, device='cuda:0')
tensor(0.1576, device='cuda:0')
old_score: tensor(0.1392, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0697, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7892742156982422
Validation after dual ascent:
out_inf: tensor(6.7305, device='cuda:0', dtype=torch.float16) tensor(0.4058, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.7549, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.7012, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.1914, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.7891, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0128, device='cuda:0')
tensor(0.0237, device='cuda:0')
old_score: tensor(0.0404, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0216, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.8916831016540527
Validation after dual ascent:
out_inf: tensor(4.1914, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
tensor(0.5269, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
tensor(0.4185, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.3245, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.4526, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.gate_proj
Validation after prune:
out_inf: tensor(20.5312, device='cuda:0', dtype=torch.float16) tensor(0.6250, device='cuda:0', dtype=torch.float16)
tensor(6.6953, device='cuda:0', dtype=torch.float16) tensor(0.1831, device='cuda:0', dtype=torch.float16)
tensor(6.7812, device='cuda:0', dtype=torch.float16) tensor(0.1840, device='cuda:0', dtype=torch.float16)
tensor(6.6641, device='cuda:0', dtype=torch.float16) tensor(0.1772, device='cuda:0', dtype=torch.float16)
tensor(5.6406, device='cuda:0', dtype=torch.float16) tensor(0.1746, device='cuda:0', dtype=torch.float16)
tensor(0.0326, device='cuda:0')
old_score: tensor(0.1797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0734, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.48221826553345
Validation after dual ascent:
out_inf: tensor(20.5312, device='cuda:0', dtype=torch.float16) tensor(0.6250, device='cuda:0', dtype=torch.float16)
tensor(2.4219, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
tensor(3.3750, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(4.1875, device='cuda:0', dtype=torch.float16) tensor(0.0695, device='cuda:0', dtype=torch.float16)
tensor(3.4531, device='cuda:0', dtype=torch.float16) tensor(0.0725, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.up_proj
Validation after prune:
out_inf: tensor(16.5000, device='cuda:0', dtype=torch.float16) tensor(0.5420, device='cuda:0', dtype=torch.float16)
tensor(6.2188, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
tensor(5.1406, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
tensor(5.5938, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(5.0625, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(0.0215, device='cuda:0')
old_score: tensor(0.1447, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0594, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.542409896850586
Validation after dual ascent:
out_inf: tensor(16.5000, device='cuda:0', dtype=torch.float16) tensor(0.5420, device='cuda:0', dtype=torch.float16)
tensor(4.8672, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(2.7578, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(6.4219, device='cuda:0', dtype=torch.float16) tensor(0.0563, device='cuda:0', dtype=torch.float16)
tensor(6.0859, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.down_proj
Validation after prune:
out_inf: tensor(112.6875, device='cuda:0', dtype=torch.float16) tensor(0.4795, device='cuda:0', dtype=torch.float16)
tensor(1.3721, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(1.2168, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(1.2158, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.0706, device='cuda:0')
old_score: tensor(0.0509, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0286, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 163.95749497413635
Validation after dual ascent:
out_inf: tensor(112.6875, device='cuda:0', dtype=torch.float16) tensor(0.4795, device='cuda:0', dtype=torch.float16)
tensor(0.8311, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.8701, device='cuda:0', dtype=torch.float16) tensor(0.0280, device='cuda:0', dtype=torch.float16)
tensor(0.8545, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.21it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  4.00it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.66it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.36it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.699961
layer 1 sparsity 0.699961
layer 2 sparsity 0.699961
layer 3 sparsity 0.699961
layer 4 sparsity 0.699961
layer 5 sparsity 0.699961
layer 6 sparsity 0.699961
layer 7 sparsity 0.699961
layer 8 sparsity 0.699961
layer 9 sparsity 0.699961
layer 10 sparsity 0.699961
layer 11 sparsity 0.699961
layer 12 sparsity 0.699961
layer 13 sparsity 0.699961
layer 14 sparsity 0.699961
layer 15 sparsity 0.699961
layer 16 sparsity 0.699961
layer 17 sparsity 0.699961
layer 18 sparsity 0.699961
layer 19 sparsity 0.699961
layer 20 sparsity 0.699961
layer 21 sparsity 0.699961
layer 22 sparsity 0.699961
layer 23 sparsity 0.699961
layer 24 sparsity 0.699961
layer 25 sparsity 0.699961
layer 26 sparsity 0.699961
layer 27 sparsity 0.699961
layer 28 sparsity 0.699961
layer 29 sparsity 0.699961
layer 30 sparsity 0.699961
layer 31 sparsity 0.699961
sparsity sanity check 0.7000
******************************
evaluating on wikitext2
nsamples 35
sample 0
wikitext perplexity 34.02585220336914
wanda_dual_3	0.7000	34.0259	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.7, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='wanda_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
2025-04-24 15:40:09.772357: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 15:40:09.772752: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 15:40:09.951096: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 15:40:09.951096: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 15:40:09.956455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 15:40:09.956457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 15:40:09.956484: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 15:40:09.956490: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 15:40:13.091187: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 15:40:13.091187: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 15:40:13.091740: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 15:40:13.091743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 15:40:13.091779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-24 15:40:13.091789: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.15s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.38s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.55s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.72s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.45s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.56s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.75s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.35s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.77s/it]
model.embed_tokens.weight torch.Size([128256, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([128256, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]model.embed_tokens.weight torch.Size([128256, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([1024, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([14336, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 14336])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([128256, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:01<06:53,  1.62s/it]  0%|          | 1/256 [00:01<06:56,  1.63s/it]  1%|          | 2/256 [00:01<03:28,  1.22it/s]  1%|          | 2/256 [00:01<03:29,  1.21it/s]  1%|          | 3/256 [00:02<03:32,  1.19it/s]  1%|          | 3/256 [00:02<03:34,  1.18it/s]  2%|▏         | 4/256 [00:03<02:54,  1.45it/s]  2%|▏         | 4/256 [00:03<02:57,  1.42it/s]  2%|▏         | 5/256 [00:03<02:21,  1.77it/s]  2%|▏         | 5/256 [00:03<02:22,  1.76it/s]  2%|▏         | 6/256 [00:05<04:01,  1.03it/s]  2%|▏         | 6/256 [00:05<04:04,  1.02it/s]  3%|▎         | 7/256 [00:05<03:11,  1.30it/s]  3%|▎         | 8/256 [00:05<02:17,  1.80it/s]  3%|▎         | 7/256 [00:05<03:13,  1.29it/s]  3%|▎         | 8/256 [00:05<02:19,  1.78it/s]  4%|▎         | 9/256 [00:06<02:28,  1.67it/s]  4%|▎         | 9/256 [00:06<02:31,  1.63it/s]  4%|▍         | 10/256 [00:06<02:22,  1.72it/s]  4%|▍         | 10/256 [00:07<02:25,  1.69it/s]  4%|▍         | 11/256 [00:07<02:09,  1.89it/s]  4%|▍         | 11/256 [00:07<02:11,  1.86it/s]  5%|▍         | 12/256 [00:08<02:23,  1.70it/s]  5%|▍         | 12/256 [00:08<02:26,  1.67it/s]  5%|▌         | 13/256 [00:08<02:40,  1.52it/s]  5%|▌         | 13/256 [00:09<02:45,  1.47it/s]  5%|▌         | 14/256 [00:09<02:29,  1.62it/s]  5%|▌         | 14/256 [00:09<02:31,  1.60it/s]  6%|▌         | 15/256 [00:09<02:15,  1.78it/s]  6%|▌         | 15/256 [00:10<02:17,  1.75it/s]  6%|▋         | 16/256 [00:10<02:37,  1.52it/s]  6%|▋         | 16/256 [00:10<02:39,  1.50it/s]  7%|▋         | 17/256 [00:11<02:12,  1.81it/s]  7%|▋         | 17/256 [00:11<02:14,  1.78it/s]  7%|▋         | 18/256 [00:12<02:45,  1.44it/s]  7%|▋         | 18/256 [00:12<02:49,  1.40it/s]  7%|▋         | 19/256 [00:13<03:17,  1.20it/s]  8%|▊         | 20/256 [00:13<02:29,  1.57it/s]  7%|▋         | 19/256 [00:13<03:21,  1.18it/s]  8%|▊         | 20/256 [00:13<02:33,  1.53it/s]  9%|▊         | 22/256 [00:13<01:45,  2.23it/s]  9%|▊         | 22/256 [00:14<01:47,  2.17it/s]  9%|▉         | 23/256 [00:15<02:45,  1.41it/s]  9%|▉         | 24/256 [00:15<02:07,  1.81it/s]  9%|▉         | 23/256 [00:15<02:46,  1.40it/s]  9%|▉         | 24/256 [00:15<02:10,  1.78it/s] 10%|▉         | 25/256 [00:16<02:08,  1.80it/s] 10%|█         | 26/256 [00:16<01:48,  2.13it/s] 10%|▉         | 25/256 [00:16<02:10,  1.77it/s] 11%|█         | 27/256 [00:16<01:25,  2.68it/s] 10%|█         | 26/256 [00:16<01:50,  2.09it/s] 11%|█         | 27/256 [00:16<01:26,  2.64it/s] 11%|█         | 28/256 [00:17<02:00,  1.90it/s] 11%|█         | 28/256 [00:17<02:01,  1.88it/s] 12%|█▏        | 30/256 [00:19<02:55,  1.29it/s] 12%|█▏        | 31/256 [00:19<02:30,  1.50it/s] 12%|█▏        | 30/256 [00:19<02:58,  1.27it/s] 12%|█▎        | 32/256 [00:20<02:12,  1.69it/s] 12%|█▏        | 31/256 [00:20<02:32,  1.48it/s] 12%|█▎        | 32/256 [00:20<02:16,  1.65it/s] 13%|█▎        | 34/256 [00:21<02:32,  1.46it/s] 13%|█▎        | 34/256 [00:22<02:36,  1.42it/s] 14%|█▎        | 35/256 [00:22<02:32,  1.45it/s] 14%|█▍        | 36/256 [00:22<02:15,  1.62it/s] 14%|█▎        | 35/256 [00:22<02:35,  1.42it/s] 14%|█▍        | 36/256 [00:23<02:18,  1.59it/s] 14%|█▍        | 37/256 [00:23<02:09,  1.69it/s] 14%|█▍        | 37/256 [00:23<02:12,  1.66it/s] 15%|█▍        | 38/256 [00:24<02:52,  1.27it/s] 15%|█▌        | 39/256 [00:24<02:11,  1.65it/s] 15%|█▍        | 38/256 [00:25<02:55,  1.24it/s] 15%|█▌        | 39/256 [00:25<02:13,  1.63it/s] 16%|█▌        | 40/256 [00:25<02:35,  1.39it/s] 16%|█▌        | 40/256 [00:26<02:37,  1.37it/s] 16%|█▌        | 41/256 [00:28<04:01,  1.12s/it] 16%|█▌        | 41/256 [00:28<04:05,  1.14s/it] 16%|█▋        | 42/256 [00:28<03:40,  1.03s/it] 16%|█▋        | 42/256 [00:29<03:43,  1.05s/it] 17%|█▋        | 43/256 [00:29<03:44,  1.05s/it] 17%|█▋        | 43/256 [00:30<03:47,  1.07s/it] 17%|█▋        | 44/256 [00:31<03:55,  1.11s/it] 17%|█▋        | 44/256 [00:31<03:56,  1.12s/it] 18%|█▊        | 45/256 [00:33<05:18,  1.51s/it] 18%|█▊        | 45/256 [00:34<05:18,  1.51s/it] 18%|█▊        | 47/256 [00:36<05:02,  1.45s/it] 19%|█▉        | 48/256 [00:36<04:08,  1.20s/it] 18%|█▊        | 47/256 [00:36<05:00,  1.44s/it] 19%|█▉        | 48/256 [00:37<04:07,  1.19s/it] 19%|█▉        | 49/256 [00:37<03:36,  1.05s/it] 19%|█▉        | 49/256 [00:37<03:35,  1.04s/it] 20%|█▉        | 50/256 [00:39<04:15,  1.24s/it] 20%|██        | 52/256 [00:39<02:32,  1.34it/s] 20%|█▉        | 50/256 [00:39<04:15,  1.24s/it] 20%|█▉        | 51/256 [00:39<03:09,  1.08it/s] 20%|██        | 52/256 [00:39<02:22,  1.43it/s] 21%|██        | 53/256 [00:41<03:29,  1.03s/it] 21%|██        | 54/256 [00:41<02:44,  1.23it/s] 21%|██        | 53/256 [00:41<03:35,  1.06s/it] 21%|██        | 54/256 [00:42<02:44,  1.23it/s] 21%|██▏       | 55/256 [00:42<02:52,  1.17it/s] 21%|██▏       | 55/256 [00:43<02:52,  1.16it/s] 22%|██▏       | 56/256 [00:44<03:41,  1.11s/it] 22%|██▏       | 56/256 [00:44<03:46,  1.13s/it] 22%|██▏       | 57/256 [00:46<04:17,  1.30s/it] 23%|██▎       | 58/256 [00:46<03:16,  1.01it/s] 22%|██▏       | 57/256 [00:46<04:22,  1.32s/it] 23%|██▎       | 58/256 [00:46<03:16,  1.01it/s] 23%|██▎       | 59/256 [00:49<05:26,  1.66s/it] 23%|██▎       | 60/256 [00:50<04:13,  1.29s/it] 23%|██▎       | 59/256 [00:50<05:31,  1.68s/it] 24%|██▍       | 61/256 [00:50<03:26,  1.06s/it] 23%|██▎       | 60/256 [00:50<04:16,  1.31s/it] 24%|██▍       | 61/256 [00:51<03:29,  1.07s/it] 24%|██▍       | 62/256 [00:51<03:06,  1.04it/s] 24%|██▍       | 62/256 [00:51<03:09,  1.03it/s] 25%|██▍       | 63/256 [00:51<02:49,  1.14it/s] 25%|██▌       | 64/256 [00:52<02:13,  1.44it/s] 25%|██▍       | 63/256 [00:52<02:51,  1.13it/s] 25%|██▌       | 65/256 [00:52<02:05,  1.53it/s] 25%|██▌       | 64/256 [00:52<02:13,  1.43it/s] 25%|██▌       | 65/256 [00:53<02:07,  1.50it/s] 26%|██▌       | 66/256 [00:54<02:56,  1.07it/s] 26%|██▌       | 67/256 [00:54<02:20,  1.34it/s] 26%|██▌       | 66/256 [00:54<02:59,  1.06it/s] 26%|██▌       | 67/256 [00:55<02:21,  1.34it/s] 27%|██▋       | 68/256 [00:55<02:40,  1.17it/s] 27%|██▋       | 69/256 [00:55<02:01,  1.54it/s] 27%|██▋       | 68/256 [00:56<02:42,  1.16it/s] 27%|██▋       | 69/256 [00:56<02:01,  1.54it/s] 27%|██▋       | 70/256 [00:59<05:02,  1.63s/it] 28%|██▊       | 71/256 [01:00<04:02,  1.31s/it] 27%|██▋       | 70/256 [01:00<05:16,  1.70s/it] 28%|██▊       | 71/256 [01:01<04:23,  1.42s/it] 28%|██▊       | 72/256 [01:02<04:19,  1.41s/it] 29%|██▊       | 73/256 [01:02<03:22,  1.11s/it] 29%|██▉       | 74/256 [01:02<02:34,  1.18it/s] 28%|██▊       | 72/256 [01:03<04:34,  1.49s/it] 29%|██▉       | 75/256 [01:03<02:26,  1.23it/s] 29%|██▊       | 73/256 [01:03<03:33,  1.17s/it] 29%|██▉       | 74/256 [01:03<02:42,  1.12it/s] 30%|██▉       | 76/256 [01:04<02:19,  1.29it/s] 29%|██▉       | 75/256 [01:04<02:31,  1.20it/s] 30%|██▉       | 76/256 [01:05<02:20,  1.28it/s] 30%|███       | 77/256 [01:05<02:52,  1.04it/s] 31%|███▏      | 80/256 [01:06<01:33,  1.89it/s] 32%|███▏      | 81/256 [01:06<01:20,  2.18it/s] 30%|███       | 77/256 [01:06<02:53,  1.03it/s] 32%|███▏      | 82/256 [01:06<01:26,  2.01it/s] 33%|███▎      | 84/256 [01:07<00:55,  3.09it/s] 31%|███▏      | 80/256 [01:07<01:34,  1.86it/s] 32%|███▏      | 81/256 [01:07<01:21,  2.14it/s] 33%|███▎      | 85/256 [01:07<01:01,  2.79it/s] 34%|███▎      | 86/256 [01:07<00:54,  3.11it/s] 32%|███▏      | 82/256 [01:07<01:26,  2.00it/s] 33%|███▎      | 84/256 [01:08<00:56,  3.06it/s] 34%|███▍      | 88/256 [01:08<00:48,  3.44it/s] 33%|███▎      | 85/256 [01:08<01:01,  2.77it/s] 34%|███▎      | 86/256 [01:08<00:55,  3.09it/s] 34%|███▍      | 88/256 [01:09<00:51,  3.29it/s] 35%|███▍      | 89/256 [01:10<01:47,  1.56it/s] 35%|███▌      | 90/256 [01:11<02:07,  1.30it/s] 35%|███▍      | 89/256 [01:11<01:47,  1.55it/s] 36%|███▌      | 92/256 [01:11<01:38,  1.67it/s] 35%|███▌      | 90/256 [01:12<02:09,  1.29it/s] 36%|███▋      | 93/256 [01:13<01:56,  1.41it/s] 36%|███▌      | 92/256 [01:13<01:39,  1.65it/s] 37%|███▋      | 94/256 [01:13<01:59,  1.36it/s] 36%|███▋      | 93/256 [01:14<01:55,  1.41it/s] 37%|███▋      | 94/256 [01:14<02:00,  1.34it/s] 37%|███▋      | 95/256 [01:15<02:24,  1.11it/s] 38%|███▊      | 96/256 [01:15<02:12,  1.21it/s] 37%|███▋      | 95/256 [01:16<02:26,  1.10it/s] 38%|███▊      | 96/256 [01:16<02:13,  1.20it/s] 38%|███▊      | 97/256 [01:17<02:37,  1.01it/s] 38%|███▊      | 98/256 [01:18<02:34,  1.03it/s] 38%|███▊      | 97/256 [01:18<02:39,  1.01s/it] 39%|███▊      | 99/256 [01:18<02:12,  1.19it/s] 38%|███▊      | 98/256 [01:19<02:34,  1.02it/s] 39%|███▉      | 100/256 [01:19<02:22,  1.10it/s] 39%|███▊      | 99/256 [01:19<02:12,  1.18it/s] 39%|███▉      | 101/256 [01:20<02:11,  1.18it/s] 40%|███▉      | 102/256 [01:20<01:43,  1.48it/s] 39%|███▉      | 100/256 [01:20<02:22,  1.10it/s] 40%|████      | 103/256 [01:21<01:40,  1.53it/s] 39%|███▉      | 101/256 [01:21<02:11,  1.18it/s] 41%|████      | 104/256 [01:21<01:26,  1.75it/s] 40%|███▉      | 102/256 [01:21<01:44,  1.47it/s] 40%|████      | 103/256 [01:22<01:40,  1.53it/s] 41%|████▏     | 106/256 [01:22<01:23,  1.80it/s] 41%|████      | 104/256 [01:22<01:27,  1.74it/s] 41%|████▏     | 106/256 [01:23<01:24,  1.77it/s] 42%|████▏     | 107/256 [01:25<02:53,  1.17s/it] 42%|████▏     | 108/256 [01:26<02:20,  1.05it/s] 43%|████▎     | 109/256 [01:26<02:00,  1.22it/s] 42%|████▏     | 107/256 [01:27<02:56,  1.19s/it] 43%|████▎     | 110/256 [01:27<01:57,  1.24it/s] 42%|████▏     | 108/256 [01:27<02:22,  1.04it/s] 43%|████▎     | 109/256 [01:27<02:03,  1.19it/s] 43%|████▎     | 111/256 [01:28<01:52,  1.29it/s] 44%|████▍     | 112/256 [01:28<01:37,  1.47it/s] 44%|████▍     | 113/256 [01:28<01:14,  1.91it/s] 43%|████▎     | 110/256 [01:28<01:58,  1.23it/s] 43%|████▎     | 111/256 [01:29<01:53,  1.28it/s] 44%|████▍     | 112/256 [01:29<01:38,  1.47it/s] 44%|████▍     | 113/256 [01:29<01:15,  1.89it/s] 45%|████▍     | 114/256 [01:31<02:41,  1.14s/it] 45%|████▍     | 115/256 [01:31<01:59,  1.18it/s] 45%|████▌     | 116/256 [01:31<01:30,  1.55it/s] 46%|████▌     | 117/256 [01:32<01:43,  1.35it/s] 45%|████▍     | 114/256 [01:32<02:42,  1.14s/it] 45%|████▍     | 115/256 [01:32<02:00,  1.17it/s] 45%|████▌     | 116/256 [01:32<01:32,  1.51it/s] 46%|████▌     | 118/256 [01:33<01:47,  1.29it/s] 46%|████▌     | 117/256 [01:33<01:46,  1.31it/s] 46%|████▌     | 118/256 [01:34<01:46,  1.30it/s] 46%|████▋     | 119/256 [01:34<02:14,  1.02it/s] 46%|████▋     | 119/256 [01:36<02:14,  1.02it/s] 47%|████▋     | 120/256 [01:36<02:37,  1.16s/it] 47%|████▋     | 120/256 [01:37<02:38,  1.16s/it] 47%|████▋     | 121/256 [01:38<03:21,  1.49s/it] 48%|████▊     | 122/256 [01:39<03:04,  1.38s/it] 48%|████▊     | 123/256 [01:40<02:20,  1.06s/it] 47%|████▋     | 121/256 [01:40<03:24,  1.51s/it] 48%|████▊     | 124/256 [01:40<01:43,  1.28it/s] 49%|████▉     | 125/256 [01:40<01:16,  1.72it/s] 49%|████▉     | 126/256 [01:40<00:59,  2.18it/s] 50%|████▉     | 127/256 [01:40<00:55,  2.34it/s] 50%|█████     | 128/256 [01:41<00:42,  2.99it/s] 48%|████▊     | 122/256 [01:41<03:06,  1.39s/it] 48%|████▊     | 123/256 [01:41<02:21,  1.07s/it] 48%|████▊     | 124/256 [01:41<01:43,  1.27it/s] 49%|████▉     | 125/256 [01:41<01:16,  1.71it/s] 49%|████▉     | 126/256 [01:41<01:00,  2.15it/s] 50%|████▉     | 127/256 [01:42<00:56,  2.28it/s] 50%|█████     | 128/256 [01:42<00:44,  2.89it/s] 50%|█████     | 129/256 [01:43<01:43,  1.23it/s] 51%|█████     | 131/256 [01:43<00:59,  2.09it/s] 52%|█████▏    | 132/256 [01:43<00:52,  2.38it/s] 52%|█████▏    | 133/256 [01:43<00:53,  2.29it/s] 50%|█████     | 129/256 [01:44<01:43,  1.23it/s] 51%|█████     | 131/256 [01:44<01:00,  2.07it/s] 52%|█████▏    | 132/256 [01:44<00:52,  2.37it/s] 52%|█████▏    | 133/256 [01:45<00:55,  2.22it/s] 52%|█████▏    | 134/256 [01:46<02:20,  1.15s/it] 53%|█████▎    | 135/256 [01:47<01:44,  1.16it/s] 54%|█████▎    | 137/256 [01:47<01:07,  1.76it/s] 54%|█████▍    | 138/256 [01:48<01:18,  1.51it/s] 52%|█████▏    | 134/256 [01:48<02:22,  1.16s/it] 53%|█████▎    | 135/256 [01:48<01:45,  1.15it/s] 54%|█████▎    | 137/256 [01:48<01:07,  1.76it/s] 55%|█████▍    | 140/256 [01:49<01:09,  1.66it/s] 54%|█████▍    | 138/256 [01:49<01:17,  1.53it/s] 55%|█████▌    | 141/256 [01:50<01:11,  1.62it/s] 55%|█████▌    | 142/256 [01:50<01:07,  1.68it/s] 55%|█████▍    | 140/256 [01:50<01:09,  1.68it/s] 55%|█████▌    | 141/256 [01:51<01:10,  1.62it/s] 55%|█████▌    | 142/256 [01:52<01:08,  1.67it/s] 56%|█████▌    | 143/256 [01:53<02:01,  1.07s/it] 56%|█████▋    | 144/256 [01:53<01:34,  1.18it/s] 57%|█████▋    | 145/256 [01:54<01:43,  1.07it/s] 56%|█████▌    | 143/256 [01:54<02:02,  1.08s/it] 56%|█████▋    | 144/256 [01:54<01:36,  1.17it/s] 57%|█████▋    | 146/256 [01:55<01:30,  1.21it/s] 57%|█████▋    | 147/256 [01:55<01:19,  1.36it/s] 57%|█████▋    | 145/256 [01:55<01:43,  1.07it/s] 58%|█████▊    | 148/256 [01:56<01:19,  1.36it/s] 57%|█████▋    | 146/256 [01:56<01:31,  1.21it/s] 57%|█████▋    | 147/256 [01:57<01:20,  1.35it/s] 58%|█████▊    | 148/256 [01:57<01:21,  1.33it/s] 58%|█████▊    | 149/256 [01:59<02:28,  1.39s/it] 59%|█████▊    | 150/256 [01:59<01:52,  1.06s/it] 59%|█████▉    | 151/256 [02:00<01:54,  1.09s/it] 58%|█████▊    | 149/256 [02:00<02:30,  1.40s/it] 59%|█████▊    | 150/256 [02:01<01:53,  1.07s/it] 59%|█████▉    | 152/256 [02:01<01:51,  1.07s/it] 60%|█████▉    | 153/256 [02:02<01:31,  1.12it/s] 59%|█████▉    | 151/256 [02:02<01:54,  1.09s/it] 60%|██████    | 154/256 [02:02<01:12,  1.41it/s] 61%|██████    | 155/256 [02:02<01:01,  1.64it/s] 59%|█████▉    | 152/256 [02:03<01:52,  1.08s/it] 61%|██████    | 156/256 [02:03<01:04,  1.54it/s] 62%|██████▏   | 158/256 [02:03<00:38,  2.56it/s] 60%|█████▉    | 153/256 [02:03<01:32,  1.11it/s] 60%|██████    | 154/256 [02:04<01:12,  1.40it/s] 62%|██████▏   | 159/256 [02:04<00:36,  2.63it/s] 61%|██████    | 155/256 [02:04<01:02,  1.62it/s] 62%|██████▎   | 160/256 [02:04<00:38,  2.49it/s] 63%|██████▎   | 161/256 [02:04<00:35,  2.68it/s] 63%|██████▎   | 162/256 [02:05<00:32,  2.89it/s] 61%|██████    | 156/256 [02:05<01:04,  1.55it/s] 62%|██████▏   | 158/256 [02:05<00:38,  2.57it/s] 64%|██████▎   | 163/256 [02:05<00:31,  2.99it/s] 62%|██████▏   | 159/256 [02:05<00:36,  2.65it/s] 62%|██████▎   | 160/256 [02:06<00:38,  2.49it/s] 63%|██████▎   | 161/256 [02:06<00:35,  2.67it/s] 63%|██████▎   | 162/256 [02:06<00:32,  2.87it/s] 64%|██████▍   | 164/256 [02:06<00:57,  1.59it/s] 64%|██████▎   | 163/256 [02:06<00:31,  2.97it/s] 64%|██████▍   | 165/256 [02:08<01:21,  1.12it/s] 64%|██████▍   | 164/256 [02:08<00:58,  1.57it/s] 65%|██████▍   | 166/256 [02:09<01:36,  1.08s/it] 64%|██████▍   | 165/256 [02:09<01:22,  1.10it/s] 65%|██████▌   | 167/256 [02:10<01:24,  1.05it/s] 66%|██████▌   | 168/256 [02:10<01:05,  1.35it/s] 66%|██████▌   | 169/256 [02:11<00:56,  1.53it/s] 65%|██████▍   | 166/256 [02:11<01:39,  1.10s/it] 66%|██████▋   | 170/256 [02:11<00:53,  1.60it/s] 67%|██████▋   | 171/256 [02:11<00:41,  2.07it/s] 67%|██████▋   | 172/256 [02:12<00:31,  2.71it/s] 65%|██████▌   | 167/256 [02:12<01:27,  1.02it/s] 66%|██████▌   | 168/256 [02:12<01:06,  1.32it/s] 68%|██████▊   | 173/256 [02:12<00:36,  2.28it/s] 66%|██████▌   | 169/256 [02:12<00:57,  1.51it/s] 66%|██████▋   | 170/256 [02:13<00:54,  1.59it/s] 67%|██████▋   | 171/256 [02:13<00:41,  2.05it/s] 68%|██████▊   | 174/256 [02:13<00:58,  1.40it/s] 68%|██████▊   | 175/256 [02:14<00:47,  1.70it/s] 68%|██████▊   | 173/256 [02:14<00:34,  2.40it/s] 69%|██████▉   | 176/256 [02:15<01:01,  1.30it/s] 68%|██████▊   | 174/256 [02:15<00:54,  1.49it/s] 68%|██████▊   | 175/256 [02:15<00:46,  1.75it/s] 69%|██████▉   | 177/256 [02:16<01:10,  1.13it/s] 70%|██████▉   | 178/256 [02:17<01:01,  1.27it/s] 69%|██████▉   | 176/256 [02:17<00:58,  1.37it/s] 70%|██████▉   | 179/256 [02:17<00:51,  1.49it/s] 69%|██████▉   | 177/256 [02:18<01:08,  1.16it/s] 70%|██████▉   | 178/256 [02:18<01:00,  1.30it/s] 70%|███████   | 180/256 [02:19<01:12,  1.05it/s] 70%|██████▉   | 179/256 [02:19<00:51,  1.50it/s] 71%|███████   | 181/256 [02:19<01:07,  1.12it/s] 71%|███████   | 182/256 [02:20<01:02,  1.18it/s] 70%|███████   | 180/256 [02:20<01:09,  1.09it/s] 71%|███████   | 181/256 [02:21<01:05,  1.14it/s] 71%|███████   | 182/256 [02:22<01:01,  1.20it/s] 71%|███████▏  | 183/256 [02:22<01:30,  1.24s/it] 72%|███████▏  | 184/256 [02:23<01:26,  1.21s/it] 72%|███████▏  | 185/256 [02:24<01:11,  1.00s/it] 71%|███████▏  | 183/256 [02:24<01:30,  1.23s/it] 73%|███████▎  | 186/256 [02:25<01:04,  1.09it/s] 73%|███████▎  | 187/256 [02:25<00:47,  1.44it/s] 72%|███████▏  | 184/256 [02:25<01:27,  1.21s/it] 72%|███████▏  | 185/256 [02:26<01:10,  1.00it/s] 73%|███████▎  | 186/256 [02:26<01:04,  1.09it/s] 73%|███████▎  | 187/256 [02:27<00:48,  1.43it/s] 73%|███████▎  | 188/256 [02:29<01:51,  1.65s/it] 74%|███████▍  | 189/256 [02:30<01:33,  1.40s/it] 74%|███████▍  | 190/256 [02:30<01:07,  1.02s/it] 73%|███████▎  | 188/256 [02:31<01:54,  1.68s/it] 75%|███████▍  | 191/256 [02:31<01:07,  1.04s/it] 74%|███████▍  | 189/256 [02:31<01:35,  1.42s/it] 75%|███████▌  | 192/256 [02:31<00:59,  1.07it/s] 74%|███████▍  | 190/256 [02:31<01:07,  1.03s/it] 75%|███████▌  | 193/256 [02:32<00:46,  1.35it/s] 76%|███████▌  | 194/256 [02:33<00:48,  1.28it/s] 75%|███████▍  | 191/256 [02:33<01:08,  1.05s/it] 76%|███████▌  | 195/256 [02:33<00:38,  1.59it/s] 75%|███████▌  | 192/256 [02:33<01:00,  1.06it/s] 75%|███████▌  | 193/256 [02:34<00:47,  1.33it/s] 77%|███████▋  | 196/256 [02:34<00:43,  1.37it/s] 76%|███████▌  | 194/256 [02:34<00:48,  1.28it/s] 76%|███████▌  | 195/256 [02:35<00:38,  1.60it/s] 77%|███████▋  | 197/256 [02:35<00:49,  1.19it/s] 77%|███████▋  | 198/256 [02:35<00:41,  1.40it/s] 77%|███████▋  | 196/256 [02:36<00:43,  1.38it/s] 78%|███████▊  | 200/256 [02:36<00:26,  2.08it/s] 79%|███████▊  | 201/256 [02:36<00:24,  2.24it/s] 79%|███████▉  | 202/256 [02:37<00:26,  2.01it/s] 77%|███████▋  | 197/256 [02:37<00:49,  1.19it/s] 79%|███████▉  | 203/256 [02:37<00:23,  2.25it/s] 77%|███████▋  | 198/256 [02:37<00:41,  1.39it/s] 80%|███████▉  | 204/256 [02:37<00:21,  2.47it/s] 80%|████████  | 205/256 [02:38<00:17,  2.90it/s] 78%|███████▊  | 200/256 [02:38<00:26,  2.08it/s] 79%|███████▊  | 201/256 [02:38<00:24,  2.24it/s] 79%|███████▉  | 202/256 [02:39<00:26,  2.00it/s] 79%|███████▉  | 203/256 [02:39<00:24,  2.20it/s] 80%|███████▉  | 204/256 [02:39<00:21,  2.45it/s] 80%|████████  | 205/256 [02:39<00:17,  2.85it/s] 80%|████████  | 206/256 [02:40<00:40,  1.22it/s] 81%|████████  | 207/256 [02:41<00:45,  1.08it/s] 81%|████████▏ | 208/256 [02:41<00:35,  1.36it/s] 80%|████████  | 206/256 [02:41<00:41,  1.22it/s] 82%|████████▏ | 209/256 [02:42<00:37,  1.25it/s] 81%|████████  | 207/256 [02:43<00:45,  1.07it/s] 81%|████████▏ | 208/256 [02:43<00:35,  1.34it/s] 82%|████████▏ | 209/256 [02:44<00:37,  1.24it/s] 82%|████████▏ | 210/256 [02:45<01:01,  1.34s/it] 82%|████████▏ | 211/256 [02:46<00:56,  1.25s/it] 83%|████████▎ | 212/256 [02:46<00:48,  1.10s/it] 82%|████████▏ | 210/256 [02:47<01:02,  1.36s/it] 84%|████████▎ | 214/256 [02:48<00:36,  1.14it/s] 82%|████████▏ | 211/256 [02:48<00:57,  1.28s/it] 84%|████████▍ | 215/256 [02:48<00:35,  1.17it/s] 83%|████████▎ | 212/256 [02:48<00:49,  1.13s/it] 84%|████████▍ | 216/256 [02:49<00:26,  1.49it/s] 85%|████████▍ | 217/256 [02:50<00:29,  1.31it/s] 84%|████████▎ | 214/256 [02:50<00:37,  1.13it/s] 84%|████████▍ | 215/256 [02:50<00:34,  1.18it/s] 84%|████████▍ | 216/256 [02:50<00:26,  1.50it/s] 85%|████████▌ | 218/256 [02:51<00:35,  1.07it/s] 85%|████████▍ | 217/256 [02:51<00:29,  1.31it/s] 85%|████████▌ | 218/256 [02:53<00:35,  1.08it/s] 86%|████████▌ | 219/256 [02:54<00:53,  1.45s/it] 86%|████████▌ | 220/256 [02:55<00:46,  1.29s/it] 86%|████████▋ | 221/256 [02:55<00:34,  1.02it/s] 86%|████████▌ | 219/256 [02:56<00:53,  1.45s/it] 87%|████████▋ | 222/256 [02:56<00:38,  1.12s/it] 86%|████████▌ | 220/256 [02:56<00:46,  1.29s/it] 87%|████████▋ | 223/256 [02:57<00:29,  1.11it/s] 88%|████████▊ | 224/256 [02:57<00:21,  1.47it/s] 86%|████████▋ | 221/256 [02:57<00:34,  1.01it/s] 88%|████████▊ | 225/256 [02:58<00:23,  1.34it/s] 89%|████████▊ | 227/256 [02:58<00:14,  2.00it/s] 87%|████████▋ | 222/256 [02:58<00:38,  1.15s/it] 89%|████████▉ | 228/256 [02:58<00:12,  2.24it/s] 87%|████████▋ | 223/256 [02:59<00:30,  1.10it/s] 88%|████████▊ | 224/256 [02:59<00:22,  1.45it/s] 88%|████████▊ | 225/256 [03:00<00:23,  1.32it/s] 89%|████████▊ | 227/256 [03:00<00:14,  1.95it/s] 89%|████████▉ | 228/256 [03:00<00:12,  2.16it/s] 89%|████████▉ | 229/256 [03:01<00:27,  1.02s/it] 90%|████████▉ | 230/256 [03:02<00:24,  1.07it/s] 89%|████████▉ | 229/256 [03:03<00:27,  1.03s/it] 90%|█████████ | 231/256 [03:03<00:28,  1.15s/it] 90%|████████▉ | 230/256 [03:04<00:24,  1.05it/s] 91%|█████████ | 232/256 [03:05<00:32,  1.37s/it] 90%|█████████ | 231/256 [03:05<00:28,  1.15s/it] 91%|█████████▏| 234/256 [03:07<00:23,  1.09s/it] 91%|█████████ | 232/256 [03:07<00:33,  1.38s/it] 91%|█████████ | 233/256 [03:08<00:23,  1.01s/it] 92%|█████████▏| 235/256 [03:08<00:24,  1.19s/it] 92%|█████████▏| 236/256 [03:09<00:19,  1.03it/s] 91%|█████████▏| 234/256 [03:09<00:24,  1.13s/it] 93%|█████████▎| 237/256 [03:10<00:20,  1.07s/it] 93%|█████████▎| 238/256 [03:10<00:15,  1.13it/s] 92%|█████████▏| 235/256 [03:10<00:26,  1.25s/it] 92%|█████████▏| 236/256 [03:11<00:19,  1.03it/s] 93%|█████████▎| 237/256 [03:12<00:20,  1.09s/it] 93%|█████████▎| 239/256 [03:12<00:20,  1.18s/it] 94%|█████████▍| 240/256 [03:13<00:14,  1.11it/s] 93%|█████████▎| 238/256 [03:13<00:16,  1.12it/s] 94%|█████████▍| 241/256 [03:14<00:13,  1.08it/s] 95%|█████████▍| 242/256 [03:14<00:10,  1.36it/s] 93%|█████████▎| 239/256 [03:15<00:20,  1.21s/it] 95%|█████████▍| 243/256 [03:15<00:10,  1.28it/s] 94%|█████████▍| 240/256 [03:15<00:14,  1.09it/s] 95%|█████████▌| 244/256 [03:15<00:08,  1.48it/s] 96%|█████████▌| 245/256 [03:16<00:06,  1.75it/s] 94%|█████████▍| 241/256 [03:16<00:14,  1.05it/s] 96%|█████████▌| 246/256 [03:16<00:05,  1.83it/s] 95%|█████████▍| 242/256 [03:16<00:10,  1.33it/s] 96%|█████████▋| 247/256 [03:16<00:04,  2.01it/s] 97%|█████████▋| 248/256 [03:17<00:03,  2.11it/s] 95%|█████████▍| 243/256 [03:17<00:10,  1.26it/s] 95%|█████████▌| 244/256 [03:17<00:08,  1.46it/s] 96%|█████████▌| 245/256 [03:18<00:06,  1.70it/s] 97%|█████████▋| 249/256 [03:18<00:05,  1.36it/s] 98%|█████████▊| 250/256 [03:18<00:03,  1.77it/s] 96%|█████████▌| 246/256 [03:18<00:05,  1.76it/s] 96%|█████████▋| 247/256 [03:19<00:04,  1.95it/s] 98%|█████████▊| 251/256 [03:19<00:02,  1.85it/s] 97%|█████████▋| 248/256 [03:19<00:03,  2.05it/s] 98%|█████████▊| 252/256 [03:20<00:02,  1.56it/s] 97%|█████████▋| 249/256 [03:20<00:05,  1.37it/s] 98%|█████████▊| 250/256 [03:21<00:03,  1.77it/s] 98%|█████████▊| 251/256 [03:21<00:02,  1.69it/s] 99%|█████████▉| 253/256 [03:22<00:03,  1.21s/it] 98%|█████████▊| 252/256 [03:23<00:03,  1.22it/s] 99%|█████████▉| 254/256 [03:24<00:02,  1.29s/it]100%|█████████▉| 255/256 [03:25<00:01,  1.24s/it]100%|██████████| 256/256 [03:25<00:00,  1.01s/it]100%|██████████| 256/256 [03:25<00:00,  1.24it/s]
 99%|█████████▉| 253/256 [03:25<00:04,  1.39s/it] 99%|█████████▉| 254/256 [03:27<00:03,  1.53s/it]100%|█████████▉| 255/256 [03:29<00:01,  1.63s/it]100%|██████████| 256/256 [03:30<00:00,  1.31s/it]100%|██████████| 256/256 [03:30<00:00,  1.22it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
0 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.8218, device='cuda:0', dtype=torch.float16)
tensor(0.1240, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1313, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.1641, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1288, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
0 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.5859, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.2432, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.2061, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.1587, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
0 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0562, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0579, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.0579, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0573, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0199, device='cuda:0')
old_score: tensor(0.0045, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0037, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.952265501022339
Validation after dual ascent:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0459, device='cuda:0', dtype=torch.float16) tensor(0.0033, device='cuda:0', dtype=torch.float16)
tensor(0.0491, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0528, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0475, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
0 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0266, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0258, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0291, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0288, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0324, device='cuda:0')
old_score: tensor(0.0010, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0010, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.9164457321167
Validation after dual ascent:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0260, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0240, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0288, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0293, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
0 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.6455, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.6934, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
tensor(0.6934, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0149, device='cuda:0')
tensor(0.0250, device='cuda:0')
old_score: tensor(0.0267, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0241, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.779993295669556
Validation after dual ascent:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
0 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.7529, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0129, device='cuda:0')
tensor(0.0230, device='cuda:0')
old_score: tensor(0.0241, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0218, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.789539813995361
Validation after dual ascent:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.7754, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.7979, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
0 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0314, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0370, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0344, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0350, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0905, device='cuda:0')
old_score: tensor(0.0024, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0022, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.84254813194275
Validation after dual ascent:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0335, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.0383, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0347, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0359, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
layer 0 done
1 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.1328, device='cuda:0', dtype=torch.float16) tensor(1.0205, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
tensor(0.5537, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.4004, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
1 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.1016, device='cuda:0', dtype=torch.float16) tensor(1.5186, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
1 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2598, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.1194, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.1235, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.1377, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1149, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0093, device='cuda:0')
tensor(0.0376, device='cuda:0')
old_score: tensor(0.0128, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0114, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9563431739807129
Validation after dual ascent:
out_inf: tensor(2.2598, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.1467, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1550, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.1561, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1213, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
1 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.1943, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0518, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0536, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0600, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0443, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0361, device='cuda:0')
old_score: tensor(0.0016, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0015, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.957688331604004
Validation after dual ascent:
out_inf: tensor(1.1943, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0453, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0406, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0436, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0361, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
1 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.4062, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0348, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0184, device='cuda:0')
tensor(0.0239, device='cuda:0')
old_score: tensor(0.0353, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0325, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 32.44236350059509
Validation after dual ascent:
out_inf: tensor(18.4062, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
1 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6348, device='cuda:0', dtype=torch.float16) tensor(0.0738, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
tensor(0.8691, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0166, device='cuda:0')
tensor(0.0285, device='cuda:0')
old_score: tensor(0.0319, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0294, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 20.065361261367798
Validation after dual ascent:
out_inf: tensor(2.6348, device='cuda:0', dtype=torch.float16) tensor(0.0738, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
1 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(249.2500, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.0374, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0448, device='cuda:0', dtype=torch.float16) tensor(0.0033, device='cuda:0', dtype=torch.float16)
tensor(0.0410, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0954, device='cuda:0')
old_score: tensor(0.0030, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0028, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.40305471420288
Validation after dual ascent:
out_inf: tensor(249.2500, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.0398, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0431, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0407, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
layer 1 done
2 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.4766, device='cuda:0', dtype=torch.float16) tensor(0.8579, device='cuda:0', dtype=torch.float16)
tensor(0.8223, device='cuda:0', dtype=torch.float16) tensor(0.0893, device='cuda:0', dtype=torch.float16)
tensor(0.9365, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(0.1918, device='cuda:0')
old_score: tensor(0.0919, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0834, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.010825395584106
Validation after dual ascent:
out_inf: tensor(14.4766, device='cuda:0', dtype=torch.float16) tensor(0.8579, device='cuda:0', dtype=torch.float16)
tensor(0.7939, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
tensor(0.8213, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
2 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16., device='cuda:0', dtype=torch.float16) tensor(1.3936, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.1420, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.1748, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
2 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.0020, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
tensor(0.2778, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.4458, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.4434, device='cuda:0', dtype=torch.float16) tensor(0.0362, device='cuda:0', dtype=torch.float16)
tensor(0.2803, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0122, device='cuda:0')
tensor(0.0910, device='cuda:0')
old_score: tensor(0.0358, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0331, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9816970825195312
Validation after dual ascent:
out_inf: tensor(2.0020, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
tensor(0.2866, device='cuda:0', dtype=torch.float16) tensor(0.0312, device='cuda:0', dtype=torch.float16)
tensor(0.4204, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.4243, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
tensor(0.2793, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
2 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.6636, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0342, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0323, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0351, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.0351, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0324, device='cuda:0')
old_score: tensor(0.0020, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0018, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.970746755599976
Validation after dual ascent:
out_inf: tensor(0.6636, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0314, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0296, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0356, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0295, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
2 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
tensor(0.5933, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
tensor(0.6479, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.6030, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0176, device='cuda:0')
tensor(0.1135, device='cuda:0')
old_score: tensor(0.0453, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0420, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.805477857589722
Validation after dual ascent:
out_inf: tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.6470, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.6226, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
2 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3203, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.6982, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.0981, device='cuda:0')
old_score: tensor(0.0399, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0370, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.813722372055054
Validation after dual ascent:
out_inf: tensor(3.3203, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.5698, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.5864, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.6104, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
2 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.4661, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.0400, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.0484, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0513, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0489, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.0997, device='cuda:0')
old_score: tensor(0.0042, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0040, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.8918969631195
Validation after dual ascent:
out_inf: tensor(0.4661, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.0428, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.0475, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0510, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0494, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
layer 2 done
3 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.4531, device='cuda:0', dtype=torch.float16) tensor(0.8379, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.0205, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
tensor(0.9639, device='cuda:0', dtype=torch.float16) tensor(0.1128, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.1102, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0185, device='cuda:0')
tensor(0.2922, device='cuda:0')
old_score: tensor(0.1123, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1024, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2285568714141846
Validation after dual ascent:
out_inf: tensor(14.4531, device='cuda:0', dtype=torch.float16) tensor(0.8379, device='cuda:0', dtype=torch.float16)
tensor(0.8447, device='cuda:0', dtype=torch.float16) tensor(0.0968, device='cuda:0', dtype=torch.float16)
tensor(1.0518, device='cuda:0', dtype=torch.float16) tensor(0.1091, device='cuda:0', dtype=torch.float16)
tensor(1.0146, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(0.9575, device='cuda:0', dtype=torch.float16) tensor(0.0993, device='cuda:0', dtype=torch.float16)
3 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.1250, device='cuda:0', dtype=torch.float16) tensor(1.3242, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.1676, device='cuda:0', dtype=torch.float16)
tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1799, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1737, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.1702, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0178, device='cuda:0')
tensor(0.4399, device='cuda:0')
old_score: tensor(0.1729, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1562, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7992513179779053
Validation after dual ascent:
out_inf: tensor(20.1250, device='cuda:0', dtype=torch.float16) tensor(1.3242, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1476, device='cuda:0', dtype=torch.float16)
tensor(1.5215, device='cuda:0', dtype=torch.float16) tensor(0.1663, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
3 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.0742, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(0.3845, device='cuda:0', dtype=torch.float16) tensor(0.0487, device='cuda:0', dtype=torch.float16)
tensor(0.4155, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.4072, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.1238, device='cuda:0')
old_score: tensor(0.0505, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0467, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7992925643920898
Validation after dual ascent:
out_inf: tensor(3.0742, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(0.3977, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.4392, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.4150, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.4114, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
3 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0453, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0445, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0517, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0418, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0321, device='cuda:0')
old_score: tensor(0.0030, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0026, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.951966524124146
Validation after dual ascent:
out_inf: tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0443, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0407, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0475, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0350, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
3 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4414, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0617, device='cuda:0', dtype=torch.float16)
tensor(0.7490, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0189, device='cuda:0')
tensor(0.0769, device='cuda:0')
old_score: tensor(0.0580, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0534, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.277566909790039
Validation after dual ascent:
out_inf: tensor(4.4414, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(0.5200, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
tensor(0.8926, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
3 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7910, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0121, device='cuda:0')
tensor(0.0526, device='cuda:0')
old_score: tensor(0.0469, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0434, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.290043354034424
Validation after dual ascent:
out_inf: tensor(3.7910, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.6357, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.5405, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
3 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8550, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.0523, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.0886, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.0657, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.0577, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0135, device='cuda:0')
tensor(0.0202, device='cuda:0')
old_score: tensor(0.0065, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0062, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 149.7033815383911
Validation after dual ascent:
out_inf: tensor(0.8550, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.0515, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.0814, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.0646, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.0527, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
layer 3 done
4 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.2969, device='cuda:0', dtype=torch.float16) tensor(0.8237, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(1.3564, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0200, device='cuda:0')
tensor(0.2685, device='cuda:0')
old_score: tensor(0.0975, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0878, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2217109203338623
Validation after dual ascent:
out_inf: tensor(12.2969, device='cuda:0', dtype=torch.float16) tensor(0.8237, device='cuda:0', dtype=torch.float16)
tensor(0.8730, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(0.8604, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
4 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.6406, device='cuda:0', dtype=torch.float16) tensor(1.3887, device='cuda:0', dtype=torch.float16)
tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
tensor(1.4209, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1526, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.3408, device='cuda:0')
old_score: tensor(0.1526, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1360, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.794731616973877
Validation after dual ascent:
out_inf: tensor(20.6406, device='cuda:0', dtype=torch.float16) tensor(1.3887, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
tensor(1.1729, device='cuda:0', dtype=torch.float16) tensor(0.1438, device='cuda:0', dtype=torch.float16)
tensor(1.1006, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
tensor(1.0605, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
4 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.1460, device='cuda:0', dtype=torch.float16)
tensor(0.4292, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
tensor(0.3760, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.3740, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0050, device='cuda:0')
tensor(0.1082, device='cuda:0')
old_score: tensor(0.0482, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0439, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7934041023254395
Validation after dual ascent:
out_inf: tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.1460, device='cuda:0', dtype=torch.float16)
tensor(0.4001, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.3994, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.3518, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.3679, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
4 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2979, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.0605, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0682, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.0581, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.0663, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.0286, device='cuda:0')
old_score: tensor(0.0051, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0045, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.939210891723633
Validation after dual ascent:
out_inf: tensor(1.2979, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.0508, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
tensor(0.0544, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0540, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
tensor(0.0602, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
4 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.8750, device='cuda:0', dtype=torch.float16) tensor(0.2262, device='cuda:0', dtype=torch.float16)
tensor(0.6260, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.6943, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0196, device='cuda:0')
tensor(0.0332, device='cuda:0')
old_score: tensor(0.0621, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0559, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 22.61968493461609
Validation after dual ascent:
out_inf: tensor(5.8750, device='cuda:0', dtype=torch.float16) tensor(0.2262, device='cuda:0', dtype=torch.float16)
tensor(0.5869, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.6465, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(0.6279, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
4 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3711, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.5581, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0128, device='cuda:0')
tensor(0.0446, device='cuda:0')
old_score: tensor(0.0461, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0419, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.254318952560425
Validation after dual ascent:
out_inf: tensor(3.3711, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.5439, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.5225, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.5303, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
4 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8721, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
tensor(0.0815, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0842, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0765, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.0938, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0174, device='cuda:0')
tensor(0.0372, device='cuda:0')
old_score: tensor(0.0079, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0074, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 117.3094391822815
Validation after dual ascent:
out_inf: tensor(0.8721, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
tensor(0.0811, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0803, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0833, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
tensor(0.0893, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
layer 4 done
5 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.6250, device='cuda:0', dtype=torch.float16) tensor(0.8076, device='cuda:0', dtype=torch.float16)
tensor(1.0088, device='cuda:0', dtype=torch.float16) tensor(0.1081, device='cuda:0', dtype=torch.float16)
tensor(1.2295, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(1.1045, device='cuda:0', dtype=torch.float16) tensor(0.1045, device='cuda:0', dtype=torch.float16)
tensor(1.0488, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0196, device='cuda:0')
tensor(0.3432, device='cuda:0')
old_score: tensor(0.1068, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0943, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9602200984954834
Validation after dual ascent:
out_inf: tensor(15.6250, device='cuda:0', dtype=torch.float16) tensor(0.8076, device='cuda:0', dtype=torch.float16)
tensor(0.8706, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
tensor(1.1465, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0928, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
5 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.4062, device='cuda:0', dtype=torch.float16) tensor(1.4365, device='cuda:0', dtype=torch.float16)
tensor(1.2568, device='cuda:0', dtype=torch.float16) tensor(0.1674, device='cuda:0', dtype=torch.float16)
tensor(1.4121, device='cuda:0', dtype=torch.float16) tensor(0.1652, device='cuda:0', dtype=torch.float16)
tensor(1.4385, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(1.4043, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0156, device='cuda:0')
tensor(0.3230, device='cuda:0')
old_score: tensor(0.1656, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1458, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.98101806640625
Validation after dual ascent:
out_inf: tensor(19.4062, device='cuda:0', dtype=torch.float16) tensor(1.4365, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.1436, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
5 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4102, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(0.3638, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.3386, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.3379, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.3320, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0190, device='cuda:0')
tensor(0.4116, device='cuda:0')
old_score: tensor(0.0442, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0400, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.6074326038360596
Validation after dual ascent:
out_inf: tensor(2.4102, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(0.3215, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.3293, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(0.3052, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.3196, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
5 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.4414, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
tensor(0.0850, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0680, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.0592, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0192, device='cuda:0')
tensor(0.0376, device='cuda:0')
old_score: tensor(0.0060, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0052, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.283466577529907
Validation after dual ascent:
out_inf: tensor(1.4414, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
tensor(0.0704, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.0544, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0629, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.0577, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
5 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.5234, device='cuda:0', dtype=torch.float16) tensor(0.2954, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.8486, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.7646, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0170, device='cuda:0')
tensor(0.0841, device='cuda:0')
old_score: tensor(0.0641, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0571, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 42.401185750961304
Validation after dual ascent:
out_inf: tensor(4.5234, device='cuda:0', dtype=torch.float16) tensor(0.2954, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.7529, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
5 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5000, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0170, device='cuda:0')
tensor(0.0684, device='cuda:0')
old_score: tensor(0.0478, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0429, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.26410722732544
Validation after dual ascent:
out_inf: tensor(3.5000, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.7158, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
5 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.6401, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
tensor(0.0842, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0961, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.0854, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0991, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0112, device='cuda:0')
tensor(0.0213, device='cuda:0')
old_score: tensor(0.0085, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0078, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 149.432382106781
Validation after dual ascent:
out_inf: tensor(0.6401, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
tensor(0.0795, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0972, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0815, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.1031, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
layer 5 done
6 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.4766, device='cuda:0', dtype=torch.float16) tensor(0.7544, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1151, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(2.2832, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0132, device='cuda:0')
tensor(0.1960, device='cuda:0')
old_score: tensor(0.1152, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1017, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.696213722229004
Validation after dual ascent:
out_inf: tensor(13.4766, device='cuda:0', dtype=torch.float16) tensor(0.7544, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(2.1426, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
6 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.0625, device='cuda:0', dtype=torch.float16) tensor(1.4561, device='cuda:0', dtype=torch.float16)
tensor(1.2842, device='cuda:0', dtype=torch.float16) tensor(0.1830, device='cuda:0', dtype=torch.float16)
tensor(1.5684, device='cuda:0', dtype=torch.float16) tensor(0.1799, device='cuda:0', dtype=torch.float16)
tensor(1.3730, device='cuda:0', dtype=torch.float16) tensor(0.1768, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1829, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0165, device='cuda:0')
tensor(0.2080, device='cuda:0')
old_score: tensor(0.1807, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1577, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9812159538269043
Validation after dual ascent:
out_inf: tensor(18.0625, device='cuda:0', dtype=torch.float16) tensor(1.4561, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1588, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.1561, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.1580, device='cuda:0', dtype=torch.float16)
6 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.1465, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.3887, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.3892, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.1098, device='cuda:0')
old_score: tensor(0.0500, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0449, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7934041023254395
Validation after dual ascent:
out_inf: tensor(2.1465, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
tensor(0.3472, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.3259, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.3394, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.3823, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
6 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.1063, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.1107, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0724, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0801, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0185, device='cuda:0')
tensor(0.0293, device='cuda:0')
old_score: tensor(0.0072, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0062, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.338843584060669
Validation after dual ascent:
out_inf: tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.0746, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.0789, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0648, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.0732, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
6 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(0.7002, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.8760, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0175, device='cuda:0')
tensor(0.0630, device='cuda:0')
old_score: tensor(0.0675, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0606, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 42.355506896972656
Validation after dual ascent:
out_inf: tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(0.5791, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.8740, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
6 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2402, device='cuda:0', dtype=torch.float16) tensor(0.1359, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.5791, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.8691, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0148, device='cuda:0')
tensor(0.0681, device='cuda:0')
old_score: tensor(0.0507, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0457, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.259158611297607
Validation after dual ascent:
out_inf: tensor(3.2402, device='cuda:0', dtype=torch.float16) tensor(0.1359, device='cuda:0', dtype=torch.float16)
tensor(0.5103, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.6553, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.9209, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.5596, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
6 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.5537, device='cuda:0', dtype=torch.float16) tensor(0.0262, device='cuda:0', dtype=torch.float16)
tensor(0.0968, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1014, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0917, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.0963, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0166, device='cuda:0')
tensor(0.0284, device='cuda:0')
old_score: tensor(0.0091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0084, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 117.17030763626099
Validation after dual ascent:
out_inf: tensor(0.5537, device='cuda:0', dtype=torch.float16) tensor(0.0262, device='cuda:0', dtype=torch.float16)
tensor(0.0944, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1085, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.0850, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.0948, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
layer 6 done
7 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.6875, device='cuda:0', dtype=torch.float16) tensor(0.7578, device='cuda:0', dtype=torch.float16)
tensor(1.2861, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
tensor(1.1465, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0134, device='cuda:0')
tensor(0.2229, device='cuda:0')
old_score: tensor(0.1140, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1010, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.701342821121216
Validation after dual ascent:
out_inf: tensor(16.6875, device='cuda:0', dtype=torch.float16) tensor(0.7578, device='cuda:0', dtype=torch.float16)
tensor(1.1279, device='cuda:0', dtype=torch.float16) tensor(0.1024, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
tensor(0.8384, device='cuda:0', dtype=torch.float16) tensor(0.0982, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
7 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.3984, device='cuda:0', dtype=torch.float16) tensor(1.5039, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1947, device='cuda:0', dtype=torch.float16)
tensor(1.4941, device='cuda:0', dtype=torch.float16) tensor(0.1854, device='cuda:0', dtype=torch.float16)
tensor(1.4482, device='cuda:0', dtype=torch.float16) tensor(0.1829, device='cuda:0', dtype=torch.float16)
tensor(1.5918, device='cuda:0', dtype=torch.float16) tensor(0.1951, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0179, device='cuda:0')
tensor(0.2384, device='cuda:0')
old_score: tensor(0.1895, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1659, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9830236434936523
Validation after dual ascent:
out_inf: tensor(15.3984, device='cuda:0', dtype=torch.float16) tensor(1.5039, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1680, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.1639, device='cuda:0', dtype=torch.float16)
tensor(1.2949, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1699, device='cuda:0', dtype=torch.float16)
7 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3770, device='cuda:0', dtype=torch.float16) tensor(0.1685, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
tensor(0.3999, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.3806, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.4006, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0044, device='cuda:0')
tensor(0.1079, device='cuda:0')
old_score: tensor(0.0519, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0465, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7970559597015381
Validation after dual ascent:
out_inf: tensor(2.3770, device='cuda:0', dtype=torch.float16) tensor(0.1685, device='cuda:0', dtype=torch.float16)
tensor(0.3569, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.3706, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.3608, device='cuda:0', dtype=torch.float16) tensor(0.0454, device='cuda:0', dtype=torch.float16)
tensor(0.3513, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
7 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2520, device='cuda:0', dtype=torch.float16) tensor(0.0254, device='cuda:0', dtype=torch.float16)
tensor(0.0844, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.0854, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0972, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0814, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0158, device='cuda:0')
tensor(0.0326, device='cuda:0')
old_score: tensor(0.0083, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0072, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.023343086242676
Validation after dual ascent:
out_inf: tensor(2.2520, device='cuda:0', dtype=torch.float16) tensor(0.0254, device='cuda:0', dtype=torch.float16)
tensor(0.0759, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.0721, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0899, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0761, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
7 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4766, device='cuda:0', dtype=torch.float16) tensor(0.2964, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0137, device='cuda:0')
tensor(0.0697, device='cuda:0')
old_score: tensor(0.0670, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0604, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.301049709320068
Validation after dual ascent:
out_inf: tensor(4.4766, device='cuda:0', dtype=torch.float16) tensor(0.2964, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
7 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5137, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.9160, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0143, device='cuda:0')
tensor(0.2142, device='cuda:0')
old_score: tensor(0.0522, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0472, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.833616256713867
Validation after dual ascent:
out_inf: tensor(3.5137, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
7 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8955, device='cuda:0', dtype=torch.float16) tensor(0.0292, device='cuda:0', dtype=torch.float16)
tensor(0.0950, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0939, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1079, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1038, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0190, device='cuda:0')
tensor(0.0352, device='cuda:0')
old_score: tensor(0.0097, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0090, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 109.16033601760864
Validation after dual ascent:
out_inf: tensor(0.8955, device='cuda:0', dtype=torch.float16) tensor(0.0292, device='cuda:0', dtype=torch.float16)
tensor(0.0958, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.0918, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1084, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1014, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
layer 7 done
8 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.9531, device='cuda:0', dtype=torch.float16) tensor(0.7266, device='cuda:0', dtype=torch.float16)
tensor(1.2100, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(1.3682, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
tensor(1.3145, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0175, device='cuda:0')
tensor(0.3257, device='cuda:0')
old_score: tensor(0.1207, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1071, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9579873085021973
Validation after dual ascent:
out_inf: tensor(13.9531, device='cuda:0', dtype=torch.float16) tensor(0.7266, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(1.3691, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(1.0654, device='cuda:0', dtype=torch.float16) tensor(0.1043, device='cuda:0', dtype=torch.float16)
tensor(1.3467, device='cuda:0', dtype=torch.float16) tensor(0.1106, device='cuda:0', dtype=torch.float16)
8 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.5000, device='cuda:0', dtype=torch.float16) tensor(1.6094, device='cuda:0', dtype=torch.float16)
tensor(1.6826, device='cuda:0', dtype=torch.float16) tensor(0.1992, device='cuda:0', dtype=torch.float16)
tensor(1.4551, device='cuda:0', dtype=torch.float16) tensor(0.1873, device='cuda:0', dtype=torch.float16)
tensor(1.5215, device='cuda:0', dtype=torch.float16) tensor(0.1871, device='cuda:0', dtype=torch.float16)
tensor(1.7930, device='cuda:0', dtype=torch.float16) tensor(0.2001, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0169, device='cuda:0')
tensor(0.3312, device='cuda:0')
old_score: tensor(0.1935, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1702, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9820449352264404
Validation after dual ascent:
out_inf: tensor(16.5000, device='cuda:0', dtype=torch.float16) tensor(1.6094, device='cuda:0', dtype=torch.float16)
tensor(1.3682, device='cuda:0', dtype=torch.float16) tensor(0.1737, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(1.3828, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(1.7178, device='cuda:0', dtype=torch.float16) tensor(0.1755, device='cuda:0', dtype=torch.float16)
8 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.9404, device='cuda:0', dtype=torch.float16) tensor(0.1674, device='cuda:0', dtype=torch.float16)
tensor(0.4597, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.4341, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.1464, device='cuda:0')
old_score: tensor(0.0558, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7963008880615234
Validation after dual ascent:
out_inf: tensor(1.9404, device='cuda:0', dtype=torch.float16) tensor(0.1674, device='cuda:0', dtype=torch.float16)
tensor(0.4614, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.4072, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.4434, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
8 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.0836, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.0840, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.0963, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.0856, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0185, device='cuda:0')
tensor(0.0283, device='cuda:0')
old_score: tensor(0.0093, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0080, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.217578649520874
Validation after dual ascent:
out_inf: tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.0747, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.0718, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0728, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
8 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2578, device='cuda:0', dtype=torch.float16) tensor(0.3057, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.8838, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.9521, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.7173, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0138, device='cuda:0')
tensor(0.1803, device='cuda:0')
old_score: tensor(0.0665, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0599, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.299895286560059
Validation after dual ascent:
out_inf: tensor(3.2578, device='cuda:0', dtype=torch.float16) tensor(0.3057, device='cuda:0', dtype=torch.float16)
tensor(0.7256, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.6987, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
8 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9004, device='cuda:0', dtype=torch.float16) tensor(0.1453, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.6396, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.7080, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.5869, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0064, device='cuda:0')
tensor(0.1280, device='cuda:0')
old_score: tensor(0.0515, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0466, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.297133445739746
Validation after dual ascent:
out_inf: tensor(2.9004, device='cuda:0', dtype=torch.float16) tensor(0.1453, device='cuda:0', dtype=torch.float16)
tensor(0.5342, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.6943, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
8 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0732, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.1072, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1082, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1071, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1067, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0178, device='cuda:0')
tensor(0.0298, device='cuda:0')
old_score: tensor(0.0092, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0085, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 117.0880172252655
Validation after dual ascent:
out_inf: tensor(1.0732, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.0956, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1024, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.1154, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1052, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
layer 8 done
9 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.5078, device='cuda:0', dtype=torch.float16) tensor(0.7593, device='cuda:0', dtype=torch.float16)
tensor(1.5527, device='cuda:0', dtype=torch.float16) tensor(0.1260, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(1.3340, device='cuda:0', dtype=torch.float16) tensor(0.1200, device='cuda:0', dtype=torch.float16)
tensor(1.4902, device='cuda:0', dtype=torch.float16) tensor(0.1265, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0196, device='cuda:0')
tensor(0.4477, device='cuda:0')
old_score: tensor(0.1229, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1089, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2257490158081055
Validation after dual ascent:
out_inf: tensor(14.5078, device='cuda:0', dtype=torch.float16) tensor(0.7593, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.1109, device='cuda:0', dtype=torch.float16)
tensor(0.9453, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(0.9824, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
9 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.5938, device='cuda:0', dtype=torch.float16) tensor(1.5176, device='cuda:0', dtype=torch.float16)
tensor(1.7285, device='cuda:0', dtype=torch.float16) tensor(0.2042, device='cuda:0', dtype=torch.float16)
tensor(1.4082, device='cuda:0', dtype=torch.float16) tensor(0.1926, device='cuda:0', dtype=torch.float16)
tensor(1.4990, device='cuda:0', dtype=torch.float16) tensor(0.1942, device='cuda:0', dtype=torch.float16)
tensor(1.5225, device='cuda:0', dtype=torch.float16) tensor(0.2043, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0155, device='cuda:0')
tensor(0.3477, device='cuda:0')
old_score: tensor(0.1990, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1743, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9822449684143066
Validation after dual ascent:
out_inf: tensor(15.5938, device='cuda:0', dtype=torch.float16) tensor(1.5176, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1776, device='cuda:0', dtype=torch.float16)
tensor(1.3818, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(1.3955, device='cuda:0', dtype=torch.float16) tensor(0.1714, device='cuda:0', dtype=torch.float16)
tensor(1.5215, device='cuda:0', dtype=torch.float16) tensor(0.1791, device='cuda:0', dtype=torch.float16)
9 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1917, device='cuda:0', dtype=torch.float16)
tensor(0.4719, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.5015, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.5747, device='cuda:0', dtype=torch.float16) tensor(0.0653, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0056, device='cuda:0')
tensor(0.1747, device='cuda:0')
old_score: tensor(0.0636, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0574, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.795156717300415
Validation after dual ascent:
out_inf: tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1917, device='cuda:0', dtype=torch.float16)
tensor(0.4517, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.4958, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.5327, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.5439, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
9 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4316, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.1088, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1053, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1099, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1048, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0184, device='cuda:0')
tensor(0.0342, device='cuda:0')
old_score: tensor(0.0111, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0095, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.344112634658813
Validation after dual ascent:
out_inf: tensor(2.4316, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.0937, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.0881, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1127, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.0956, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
9 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3594, device='cuda:0', dtype=torch.float16) tensor(0.3340, device='cuda:0', dtype=torch.float16)
tensor(0.6729, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(0.8447, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0151, device='cuda:0')
tensor(0.0807, device='cuda:0')
old_score: tensor(0.0676, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0608, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.293799877166748
Validation after dual ascent:
out_inf: tensor(4.3594, device='cuda:0', dtype=torch.float16) tensor(0.3340, device='cuda:0', dtype=torch.float16)
tensor(0.5933, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.7549, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
9 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.8223, device='cuda:0', dtype=torch.float16) tensor(0.1530, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
tensor(0.7241, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.2231, device='cuda:0')
old_score: tensor(0.0525, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0474, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.831518650054932
Validation after dual ascent:
out_inf: tensor(3.8223, device='cuda:0', dtype=torch.float16) tensor(0.1530, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.8198, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.6138, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
9 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.0901, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1073, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1403, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1133, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0171, device='cuda:0')
tensor(0.0310, device='cuda:0')
old_score: tensor(0.0096, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0088, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 117.0794186592102
Validation after dual ascent:
out_inf: tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.0917, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1022, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1355, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1094, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
layer 9 done
10 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.7686, device='cuda:0', dtype=torch.float16)
tensor(1.6260, device='cuda:0', dtype=torch.float16) tensor(0.1321, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
tensor(1.7041, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0193, device='cuda:0')
tensor(0.5983, device='cuda:0')
old_score: tensor(0.1289, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1151, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2238962650299072
Validation after dual ascent:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.7686, device='cuda:0', dtype=torch.float16)
tensor(1.4385, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(1.1855, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.5420, device='cuda:0', dtype=torch.float16) tensor(0.1181, device='cuda:0', dtype=torch.float16)
10 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.5000, device='cuda:0', dtype=torch.float16) tensor(1.5898, device='cuda:0', dtype=torch.float16)
tensor(1.6729, device='cuda:0', dtype=torch.float16) tensor(0.2148, device='cuda:0', dtype=torch.float16)
tensor(1.6973, device='cuda:0', dtype=torch.float16) tensor(0.2058, device='cuda:0', dtype=torch.float16)
tensor(1.4805, device='cuda:0', dtype=torch.float16) tensor(0.2019, device='cuda:0', dtype=torch.float16)
tensor(1.7861, device='cuda:0', dtype=torch.float16) tensor(0.2148, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0160, device='cuda:0')
tensor(0.4220, device='cuda:0')
old_score: tensor(0.2094, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1842, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9814026355743408
Validation after dual ascent:
out_inf: tensor(15.5000, device='cuda:0', dtype=torch.float16) tensor(1.5898, device='cuda:0', dtype=torch.float16)
tensor(1.4746, device='cuda:0', dtype=torch.float16) tensor(0.1873, device='cuda:0', dtype=torch.float16)
tensor(1.3887, device='cuda:0', dtype=torch.float16) tensor(0.1815, device='cuda:0', dtype=torch.float16)
tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.1792, device='cuda:0', dtype=torch.float16)
tensor(1.5596, device='cuda:0', dtype=torch.float16) tensor(0.1890, device='cuda:0', dtype=torch.float16)
10 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.0410, device='cuda:0', dtype=torch.float16) tensor(0.1857, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(0.4590, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.4380, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.1855, device='cuda:0')
old_score: tensor(0.0586, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0530, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7951533794403076
Validation after dual ascent:
out_inf: tensor(2.0410, device='cuda:0', dtype=torch.float16) tensor(0.1857, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4016, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.4744, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.4268, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
10 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
tensor(0.1282, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1268, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1145, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1025, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0167, device='cuda:0')
tensor(0.0365, device='cuda:0')
old_score: tensor(0.0111, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0100, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.668777942657471
Validation after dual ascent:
out_inf: tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
tensor(0.1130, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1299, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1074, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1008, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
10 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6230, device='cuda:0', dtype=torch.float16) tensor(0.3154, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(0.7354, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0141, device='cuda:0')
tensor(0.0724, device='cuda:0')
old_score: tensor(0.0680, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0616, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.29167652130127
Validation after dual ascent:
out_inf: tensor(3.6230, device='cuda:0', dtype=torch.float16) tensor(0.3154, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.7061, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.7471, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
10 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2207, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
tensor(0.6201, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0151, device='cuda:0')
tensor(0.2400, device='cuda:0')
old_score: tensor(0.0551, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0500, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.823737859725952
Validation after dual ascent:
out_inf: tensor(3.2207, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
tensor(0.4980, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
tensor(0.5986, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
10 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.1039, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1160, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1202, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1102, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0167, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.0099, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0091, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 117.1226053237915
Validation after dual ascent:
out_inf: tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.0968, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1158, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1213, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0996, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
layer 10 done
11 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.0156, device='cuda:0', dtype=torch.float16) tensor(0.7266, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
tensor(1.1240, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.2393, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.6426, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0185, device='cuda:0')
tensor(0.5250, device='cuda:0')
old_score: tensor(0.1282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1147, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.224102258682251
Validation after dual ascent:
out_inf: tensor(12.0156, device='cuda:0', dtype=torch.float16) tensor(0.7266, device='cuda:0', dtype=torch.float16)
tensor(1.7637, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
tensor(1.1025, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(1.1982, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
tensor(1.6377, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
11 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.8438, device='cuda:0', dtype=torch.float16) tensor(1.5430, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.2218, device='cuda:0', dtype=torch.float16)
tensor(1.6426, device='cuda:0', dtype=torch.float16) tensor(0.2124, device='cuda:0', dtype=torch.float16)
tensor(1.5742, device='cuda:0', dtype=torch.float16) tensor(0.2074, device='cuda:0', dtype=torch.float16)
tensor(1.6631, device='cuda:0', dtype=torch.float16) tensor(0.2206, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0148, device='cuda:0')
tensor(0.4109, device='cuda:0')
old_score: tensor(0.2156, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1904, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9831957817077637
Validation after dual ascent:
out_inf: tensor(15.8438, device='cuda:0', dtype=torch.float16) tensor(1.5430, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1941, device='cuda:0', dtype=torch.float16)
tensor(1.5635, device='cuda:0', dtype=torch.float16) tensor(0.1884, device='cuda:0', dtype=torch.float16)
tensor(1.6582, device='cuda:0', dtype=torch.float16) tensor(0.1844, device='cuda:0', dtype=torch.float16)
tensor(1.6504, device='cuda:0', dtype=torch.float16) tensor(0.1946, device='cuda:0', dtype=torch.float16)
11 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.0703, device='cuda:0', dtype=torch.float16) tensor(0.2106, device='cuda:0', dtype=torch.float16)
tensor(0.5264, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.4749, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0055, device='cuda:0')
tensor(0.1710, device='cuda:0')
old_score: tensor(0.0622, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0562, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7968289852142334
Validation after dual ascent:
out_inf: tensor(3.0703, device='cuda:0', dtype=torch.float16) tensor(0.2106, device='cuda:0', dtype=torch.float16)
tensor(0.4548, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.4333, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.4478, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.4326, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
11 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9707, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.1317, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1240, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1100, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1174, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0142, device='cuda:0')
tensor(0.0264, device='cuda:0')
old_score: tensor(0.0120, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.3291597366333
Validation after dual ascent:
out_inf: tensor(2.9707, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.1246, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.0930, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0864, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.0973, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
11 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.9258, device='cuda:0', dtype=torch.float16) tensor(0.3193, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(0.7295, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(0.8145, device='cuda:0', dtype=torch.float16) tensor(0.0702, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0146, device='cuda:0')
tensor(0.0686, device='cuda:0')
old_score: tensor(0.0676, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0610, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.292138814926147
Validation after dual ascent:
out_inf: tensor(5.9258, device='cuda:0', dtype=torch.float16) tensor(0.3193, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.7363, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
11 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2930, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.5596, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.2415, device='cuda:0')
old_score: tensor(0.0561, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0508, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.826001167297363
Validation after dual ascent:
out_inf: tensor(3.2930, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.8223, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
11 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2314, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.1066, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1133, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1196, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1006, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0177, device='cuda:0')
tensor(0.0342, device='cuda:0')
old_score: tensor(0.0106, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 109.04215407371521
Validation after dual ascent:
out_inf: tensor(1.2314, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.0997, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.0993, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1186, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0935, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
layer 11 done
12 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.2344, device='cuda:0', dtype=torch.float16) tensor(0.7319, device='cuda:0', dtype=torch.float16)
tensor(1.1006, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.2881, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0197, device='cuda:0')
tensor(0.2571, device='cuda:0')
old_score: tensor(0.1210, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1081, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.959578037261963
Validation after dual ascent:
out_inf: tensor(14.2344, device='cuda:0', dtype=torch.float16) tensor(0.7319, device='cuda:0', dtype=torch.float16)
tensor(0.9365, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(1.0986, device='cuda:0', dtype=torch.float16) tensor(0.1071, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
12 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.8594, device='cuda:0', dtype=torch.float16) tensor(1.3701, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.2045, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.1923, device='cuda:0', dtype=torch.float16)
tensor(1.5361, device='cuda:0', dtype=torch.float16) tensor(0.1833, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.2018, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0159, device='cuda:0')
tensor(0.2389, device='cuda:0')
old_score: tensor(0.1954, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1731, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9814069271087646
Validation after dual ascent:
out_inf: tensor(19.8594, device='cuda:0', dtype=torch.float16) tensor(1.3701, device='cuda:0', dtype=torch.float16)
tensor(1.4346, device='cuda:0', dtype=torch.float16) tensor(0.1796, device='cuda:0', dtype=torch.float16)
tensor(1.3818, device='cuda:0', dtype=torch.float16) tensor(0.1709, device='cuda:0', dtype=torch.float16)
tensor(1.4180, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1786, device='cuda:0', dtype=torch.float16)
12 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3984, device='cuda:0', dtype=torch.float16) tensor(0.2114, device='cuda:0', dtype=torch.float16)
tensor(0.5659, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(0.4653, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0057, device='cuda:0')
tensor(0.1531, device='cuda:0')
old_score: tensor(0.0670, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0604, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7951850891113281
Validation after dual ascent:
out_inf: tensor(2.3984, device='cuda:0', dtype=torch.float16) tensor(0.2114, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.4536, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.4414, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.4680, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
12 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6836, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.1168, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.1182, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.1135, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1119, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0168, device='cuda:0')
tensor(0.0340, device='cuda:0')
old_score: tensor(0.0129, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0110, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.6614203453063965
Validation after dual ascent:
out_inf: tensor(3.6836, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.0975, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1072, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1010, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1069, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
12 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2852, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.7676, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(0.7583, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0168, device='cuda:0')
tensor(0.0795, device='cuda:0')
old_score: tensor(0.0647, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0586, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.284155368804932
Validation after dual ascent:
out_inf: tensor(4.2852, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.7407, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
12 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.8730, device='cuda:0', dtype=torch.float16) tensor(0.1692, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.6650, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.5635, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.2292, device='cuda:0')
old_score: tensor(0.0557, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0506, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.818610191345215
Validation after dual ascent:
out_inf: tensor(3.8730, device='cuda:0', dtype=torch.float16) tensor(0.1692, device='cuda:0', dtype=torch.float16)
tensor(0.5688, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
12 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8228, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.1078, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1091, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1194, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1118, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0163, device='cuda:0')
tensor(0.0236, device='cuda:0')
old_score: tensor(0.0109, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 116.99734497070312
Validation after dual ascent:
out_inf: tensor(0.8228, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.0988, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1071, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1171, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1039, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
layer 12 done
13 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.4844, device='cuda:0', dtype=torch.float16) tensor(0.7705, device='cuda:0', dtype=torch.float16)
tensor(1.3486, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(1.3467, device='cuda:0', dtype=torch.float16) tensor(0.1360, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.1415, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0197, device='cuda:0')
tensor(0.6386, device='cuda:0')
old_score: tensor(0.1372, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.229909896850586
Validation after dual ascent:
out_inf: tensor(14.4844, device='cuda:0', dtype=torch.float16) tensor(0.7705, device='cuda:0', dtype=torch.float16)
tensor(1.1689, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.2412, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
13 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.7656, device='cuda:0', dtype=torch.float16) tensor(1.6689, device='cuda:0', dtype=torch.float16)
tensor(1.6738, device='cuda:0', dtype=torch.float16) tensor(0.2369, device='cuda:0', dtype=torch.float16)
tensor(1.6279, device='cuda:0', dtype=torch.float16) tensor(0.2256, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.2164, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.2351, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0155, device='cuda:0')
tensor(0.5312, device='cuda:0')
old_score: tensor(0.2285, device='cuda:0', dtype=torch.float16) new_score: tensor(0.2026, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9894492626190186
Validation after dual ascent:
out_inf: tensor(17.7656, device='cuda:0', dtype=torch.float16) tensor(1.6689, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.2087, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.2015, device='cuda:0', dtype=torch.float16)
tensor(1.6055, device='cuda:0', dtype=torch.float16) tensor(0.1915, device='cuda:0', dtype=torch.float16)
tensor(1.5098, device='cuda:0', dtype=torch.float16) tensor(0.2091, device='cuda:0', dtype=torch.float16)
13 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8535, device='cuda:0', dtype=torch.float16) tensor(0.2057, device='cuda:0', dtype=torch.float16)
tensor(0.5464, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.5400, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(0.5908, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0061, device='cuda:0')
tensor(0.1990, device='cuda:0')
old_score: tensor(0.0704, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0637, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.8024730682373047
Validation after dual ascent:
out_inf: tensor(2.8535, device='cuda:0', dtype=torch.float16) tensor(0.2057, device='cuda:0', dtype=torch.float16)
tensor(0.4985, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.5181, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
13 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7695, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
tensor(0.1528, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.1422, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.1567, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.1570, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0177, device='cuda:0')
tensor(0.0357, device='cuda:0')
old_score: tensor(0.0151, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0128, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.660790205001831
Validation after dual ascent:
out_inf: tensor(3.7695, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
tensor(0.1296, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.1260, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1471, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1318, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
13 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.5547, device='cuda:0', dtype=torch.float16) tensor(0.3315, device='cuda:0', dtype=torch.float16)
tensor(0.7686, device='cuda:0', dtype=torch.float16) tensor(0.0713, device='cuda:0', dtype=torch.float16)
tensor(0.7900, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(0.7920, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(0.7080, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0158, device='cuda:0')
tensor(0.0800, device='cuda:0')
old_score: tensor(0.0682, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0619, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.282270908355713
Validation after dual ascent:
out_inf: tensor(4.5547, device='cuda:0', dtype=torch.float16) tensor(0.3315, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.7324, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.7490, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
13 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4023, device='cuda:0', dtype=torch.float16) tensor(0.1708, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.6143, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.9629, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0161, device='cuda:0')
tensor(0.2596, device='cuda:0')
old_score: tensor(0.0587, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0534, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.821583986282349
Validation after dual ascent:
out_inf: tensor(4.4023, device='cuda:0', dtype=torch.float16) tensor(0.1708, device='cuda:0', dtype=torch.float16)
tensor(0.7314, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
tensor(0.6182, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
13 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.1008, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1241, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1628, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1199, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0151, device='cuda:0')
tensor(0.0301, device='cuda:0')
old_score: tensor(0.0115, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 109.01671051979065
Validation after dual ascent:
out_inf: tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.0977, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1182, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1649, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1194, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
layer 13 done
14 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.4062, device='cuda:0', dtype=torch.float16) tensor(0.7578, device='cuda:0', dtype=torch.float16)
tensor(1.1279, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.2021, device='cuda:0', dtype=torch.float16) tensor(0.1295, device='cuda:0', dtype=torch.float16)
tensor(1.0400, device='cuda:0', dtype=torch.float16) tensor(0.1247, device='cuda:0', dtype=torch.float16)
tensor(1.1855, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0179, device='cuda:0')
tensor(0.4449, device='cuda:0')
old_score: tensor(0.1321, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1193, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9618895053863525
Validation after dual ascent:
out_inf: tensor(13.4062, device='cuda:0', dtype=torch.float16) tensor(0.7578, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
tensor(1.1367, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(0.9077, device='cuda:0', dtype=torch.float16) tensor(0.1124, device='cuda:0', dtype=torch.float16)
tensor(1.1494, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
14 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.0625, device='cuda:0', dtype=torch.float16) tensor(1.6416, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.2256, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.2108, device='cuda:0', dtype=torch.float16)
tensor(1.6064, device='cuda:0', dtype=torch.float16) tensor(0.2031, device='cuda:0', dtype=torch.float16)
tensor(1.6289, device='cuda:0', dtype=torch.float16) tensor(0.2230, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0165, device='cuda:0')
tensor(0.4413, device='cuda:0')
old_score: tensor(0.2157, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1919, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9841177463531494
Validation after dual ascent:
out_inf: tensor(21.0625, device='cuda:0', dtype=torch.float16) tensor(1.6416, device='cuda:0', dtype=torch.float16)
tensor(1.7559, device='cuda:0', dtype=torch.float16) tensor(0.1991, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.1884, device='cuda:0', dtype=torch.float16)
tensor(1.4805, device='cuda:0', dtype=torch.float16) tensor(0.1808, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1995, device='cuda:0', dtype=torch.float16)
14 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.5820, device='cuda:0', dtype=torch.float16) tensor(0.2089, device='cuda:0', dtype=torch.float16)
tensor(0.5884, device='cuda:0', dtype=torch.float16) tensor(0.0702, device='cuda:0', dtype=torch.float16)
tensor(0.4683, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.5708, device='cuda:0', dtype=torch.float16) tensor(0.0702, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0059, device='cuda:0')
tensor(0.1891, device='cuda:0')
old_score: tensor(0.0677, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0615, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.798222541809082
Validation after dual ascent:
out_inf: tensor(2.5820, device='cuda:0', dtype=torch.float16) tensor(0.2089, device='cuda:0', dtype=torch.float16)
tensor(0.5200, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.4575, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.5049, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.5278, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
14 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2969, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.1262, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.1328, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.1164, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1276, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0133, device='cuda:0')
tensor(0.0287, device='cuda:0')
old_score: tensor(0.0141, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0121, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.603361129760742
Validation after dual ascent:
out_inf: tensor(3.2969, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.1069, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1239, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.0966, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1171, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
14 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.3506, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.8408, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0182, device='cuda:0')
tensor(0.0941, device='cuda:0')
old_score: tensor(0.0705, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0640, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.296314239501953
Validation after dual ascent:
out_inf: tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.3506, device='cuda:0', dtype=torch.float16)
tensor(0.6675, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.8608, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
14 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.1671, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.5996, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.2678, device='cuda:0')
old_score: tensor(0.0591, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0538, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.82828950881958
Validation after dual ascent:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.1671, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.6196, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
14 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0322, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.1039, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1276, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1268, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1249, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0159, device='cuda:0')
tensor(0.0325, device='cuda:0')
old_score: tensor(0.0118, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 109.01234698295593
Validation after dual ascent:
out_inf: tensor(1.0322, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.1179, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1170, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1229, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1279, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
layer 14 done
15 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.2188, device='cuda:0', dtype=torch.float16) tensor(0.8091, device='cuda:0', dtype=torch.float16)
tensor(1.3682, device='cuda:0', dtype=torch.float16) tensor(0.1431, device='cuda:0', dtype=torch.float16)
tensor(1.6191, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.1296, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0179, device='cuda:0')
tensor(0.5172, device='cuda:0')
old_score: tensor(0.1367, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1236, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9614953994750977
Validation after dual ascent:
out_inf: tensor(18.2188, device='cuda:0', dtype=torch.float16) tensor(0.8091, device='cuda:0', dtype=torch.float16)
tensor(1.3252, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(1.6768, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.1170, device='cuda:0', dtype=torch.float16)
tensor(1.4600, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
15 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.9219, device='cuda:0', dtype=torch.float16) tensor(1.6201, device='cuda:0', dtype=torch.float16)
tensor(1.8496, device='cuda:0', dtype=torch.float16) tensor(0.2297, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.2120, device='cuda:0', dtype=torch.float16)
tensor(1.4727, device='cuda:0', dtype=torch.float16) tensor(0.2065, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.2264, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0148, device='cuda:0')
tensor(0.3745, device='cuda:0')
old_score: tensor(0.2188, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1949, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9839801788330078
Validation after dual ascent:
out_inf: tensor(20.9219, device='cuda:0', dtype=torch.float16) tensor(1.6201, device='cuda:0', dtype=torch.float16)
tensor(1.8633, device='cuda:0', dtype=torch.float16) tensor(0.2036, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1893, device='cuda:0', dtype=torch.float16)
tensor(1.4160, device='cuda:0', dtype=torch.float16) tensor(0.1843, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.2026, device='cuda:0', dtype=torch.float16)
15 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.0840, device='cuda:0', dtype=torch.float16) tensor(0.1947, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0730, device='cuda:0', dtype=torch.float16)
tensor(0.5142, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0677, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0061, device='cuda:0')
tensor(0.2036, device='cuda:0')
old_score: tensor(0.0706, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0645, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7968811988830566
Validation after dual ascent:
out_inf: tensor(3.0840, device='cuda:0', dtype=torch.float16) tensor(0.1947, device='cuda:0', dtype=torch.float16)
tensor(0.5190, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.4968, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0617, device='cuda:0', dtype=torch.float16)
tensor(0.5435, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
15 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6836, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
tensor(0.1616, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.1429, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.1312, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.1525, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0118, device='cuda:0')
tensor(0.0280, device='cuda:0')
old_score: tensor(0.0161, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0144, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.672628402709961
Validation after dual ascent:
out_inf: tensor(3.6836, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
tensor(0.1367, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.1313, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.1161, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.1399, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
15 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.5898, device='cuda:0', dtype=torch.float16) tensor(0.3621, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.0775, device='cuda:0', dtype=torch.float16)
tensor(1.1748, device='cuda:0', dtype=torch.float16) tensor(0.0725, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0766, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0193, device='cuda:0')
tensor(0.1094, device='cuda:0')
old_score: tensor(0.0744, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0675, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.286235094070435
Validation after dual ascent:
out_inf: tensor(6.5898, device='cuda:0', dtype=torch.float16) tensor(0.3621, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.8647, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
15 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.5469, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.8545, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.7290, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(0.6226, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.3003, device='cuda:0')
old_score: tensor(0.0604, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0548, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.820295333862305
Validation after dual ascent:
out_inf: tensor(4.5469, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(0.6431, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.8950, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.7998, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.6128, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
15 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(0.1189, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1219, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1387, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1382, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0097, device='cuda:0')
tensor(0.0219, device='cuda:0')
old_score: tensor(0.0123, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0112, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 109.08766674995422
Validation after dual ascent:
out_inf: tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(0.1196, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1151, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1377, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1531, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
layer 15 done
16 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.7422, device='cuda:0', dtype=torch.float16) tensor(0.7515, device='cuda:0', dtype=torch.float16)
tensor(1.2881, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(1.6396, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0187, device='cuda:0')
tensor(0.4008, device='cuda:0')
old_score: tensor(0.1234, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1114, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.958444833755493
Validation after dual ascent:
out_inf: tensor(14.7422, device='cuda:0', dtype=torch.float16) tensor(0.7515, device='cuda:0', dtype=torch.float16)
tensor(1.1436, device='cuda:0', dtype=torch.float16) tensor(0.1180, device='cuda:0', dtype=torch.float16)
tensor(1.5791, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.1025, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
16 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.6406, device='cuda:0', dtype=torch.float16) tensor(1.5586, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.2073, device='cuda:0', dtype=torch.float16)
tensor(1.6680, device='cuda:0', dtype=torch.float16) tensor(0.1862, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.1813, device='cuda:0', dtype=torch.float16)
tensor(1.8145, device='cuda:0', dtype=torch.float16) tensor(0.2004, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0162, device='cuda:0')
tensor(0.3250, device='cuda:0')
old_score: tensor(0.1938, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1731, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9778203964233398
Validation after dual ascent:
out_inf: tensor(21.6406, device='cuda:0', dtype=torch.float16) tensor(1.5586, device='cuda:0', dtype=torch.float16)
tensor(1.5840, device='cuda:0', dtype=torch.float16) tensor(0.1836, device='cuda:0', dtype=torch.float16)
tensor(1.4111, device='cuda:0', dtype=torch.float16) tensor(0.1669, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.1797, device='cuda:0', dtype=torch.float16)
16 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1902, device='cuda:0', dtype=torch.float16)
tensor(0.5562, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.4470, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.4385, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0051, device='cuda:0')
tensor(0.1530, device='cuda:0')
old_score: tensor(0.0602, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0547, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7917606830596924
Validation after dual ascent:
out_inf: tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1902, device='cuda:0', dtype=torch.float16)
tensor(0.5674, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(0.4360, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.4780, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
16 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.7461, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.1429, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.1504, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.1186, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1389, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0135, device='cuda:0')
tensor(0.0271, device='cuda:0')
old_score: tensor(0.0140, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0120, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.340298652648926
Validation after dual ascent:
out_inf: tensor(4.7461, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.1238, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.1346, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1022, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1171, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
16 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.0117, device='cuda:0', dtype=torch.float16) tensor(0.3445, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0785, device='cuda:0', dtype=torch.float16)
tensor(1.0098, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(1.0088, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0185, device='cuda:0')
tensor(0.1018, device='cuda:0')
old_score: tensor(0.0748, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0682, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.293151617050171
Validation after dual ascent:
out_inf: tensor(7.0117, device='cuda:0', dtype=torch.float16) tensor(0.3445, device='cuda:0', dtype=torch.float16)
tensor(0.7646, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(0.8965, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(1.2100, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
16 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6465, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(0.5674, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.6465, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
tensor(0.6880, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.2853, device='cuda:0')
old_score: tensor(0.0585, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0535, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.8246190547943115
Validation after dual ascent:
out_inf: tensor(3.6465, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(0.5244, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
16 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8882, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.1144, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1279, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1147, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1688, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0107, device='cuda:0')
tensor(0.0247, device='cuda:0')
old_score: tensor(0.0115, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 109.00448083877563
Validation after dual ascent:
out_inf: tensor(0.8882, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.1058, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1174, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1254, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1744, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
layer 16 done
17 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.6875, device='cuda:0', dtype=torch.float16) tensor(0.7700, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.1312, device='cuda:0', dtype=torch.float16)
tensor(1.6836, device='cuda:0', dtype=torch.float16) tensor(0.1203, device='cuda:0', dtype=torch.float16)
tensor(1.2021, device='cuda:0', dtype=torch.float16) tensor(0.1161, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0124, device='cuda:0')
tensor(0.3671, device='cuda:0')
old_score: tensor(0.1238, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1121, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.691740036010742
Validation after dual ascent:
out_inf: tensor(17.6875, device='cuda:0', dtype=torch.float16) tensor(0.7700, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.1183, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(0.9873, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.1156, device='cuda:0', dtype=torch.float16)
17 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.3125, device='cuda:0', dtype=torch.float16) tensor(1.5264, device='cuda:0', dtype=torch.float16)
tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.2062, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.1891, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.1831, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.2010, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0151, device='cuda:0')
tensor(0.3269, device='cuda:0')
old_score: tensor(0.1948, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1748, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.980992317199707
Validation after dual ascent:
out_inf: tensor(21.3125, device='cuda:0', dtype=torch.float16) tensor(1.5264, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1843, device='cuda:0', dtype=torch.float16)
tensor(1.3584, device='cuda:0', dtype=torch.float16) tensor(0.1699, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(1.5352, device='cuda:0', dtype=torch.float16) tensor(0.1807, device='cuda:0', dtype=torch.float16)
17 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1724, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
tensor(0.5659, device='cuda:0', dtype=torch.float16) tensor(0.0677, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0055, device='cuda:0')
tensor(0.1831, device='cuda:0')
old_score: tensor(0.0662, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0607, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7950506210327148
Validation after dual ascent:
out_inf: tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1724, device='cuda:0', dtype=torch.float16)
tensor(0.4634, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.5239, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(0.5171, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.6929, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
17 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.1875, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.1186, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.1387, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1161, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1505, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0183, device='cuda:0')
tensor(0.0369, device='cuda:0')
old_score: tensor(0.0119, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.998835325241089
Validation after dual ascent:
out_inf: tensor(4.1875, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.1273, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1196, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1116, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1365, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
17 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.8555, device='cuda:0', dtype=torch.float16) tensor(0.3481, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0730, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(0.9170, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0194, device='cuda:0')
tensor(0.0954, device='cuda:0')
old_score: tensor(0.0747, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0678, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.30209231376648
Validation after dual ascent:
out_inf: tensor(6.8555, device='cuda:0', dtype=torch.float16) tensor(0.3481, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.9590, device='cuda:0', dtype=torch.float16) tensor(0.0695, device='cuda:0', dtype=torch.float16)
17 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6133, device='cuda:0', dtype=torch.float16) tensor(0.1559, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.6729, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.2758, device='cuda:0')
old_score: tensor(0.0576, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0524, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.821858167648315
Validation after dual ascent:
out_inf: tensor(3.6133, device='cuda:0', dtype=torch.float16) tensor(0.1559, device='cuda:0', dtype=torch.float16)
tensor(0.6079, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.5889, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.5908, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.6714, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
17 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8232, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.1274, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1218, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1333, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1636, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0081, device='cuda:0')
tensor(0.0171, device='cuda:0')
old_score: tensor(0.0117, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0107, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 108.99011945724487
Validation after dual ascent:
out_inf: tensor(0.8232, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.1188, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1125, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1344, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1537, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
layer 17 done
18 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.1562, device='cuda:0', dtype=torch.float16) tensor(0.7246, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
tensor(1.1318, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(0.9536, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0133, device='cuda:0')
tensor(0.2786, device='cuda:0')
old_score: tensor(0.1182, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1064, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.689417362213135
Validation after dual ascent:
out_inf: tensor(15.1562, device='cuda:0', dtype=torch.float16) tensor(0.7246, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.1128, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1032, device='cuda:0', dtype=torch.float16)
tensor(0.9316, device='cuda:0', dtype=torch.float16) tensor(0.1001, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
18 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.3281, device='cuda:0', dtype=torch.float16) tensor(1.5293, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1995, device='cuda:0', dtype=torch.float16)
tensor(1.5381, device='cuda:0', dtype=torch.float16) tensor(0.1826, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1780, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1936, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0172, device='cuda:0')
tensor(0.3062, device='cuda:0')
old_score: tensor(0.1885, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1689, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9800567626953125
Validation after dual ascent:
out_inf: tensor(20.3281, device='cuda:0', dtype=torch.float16) tensor(1.5293, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1785, device='cuda:0', dtype=torch.float16)
tensor(1.3223, device='cuda:0', dtype=torch.float16) tensor(0.1639, device='cuda:0', dtype=torch.float16)
tensor(1.4678, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(1.5332, device='cuda:0', dtype=torch.float16) tensor(0.1742, device='cuda:0', dtype=torch.float16)
18 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.1328, device='cuda:0', dtype=torch.float16) tensor(0.1752, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(0.5537, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.1477, device='cuda:0')
old_score: tensor(0.0573, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0522, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7923429012298584
Validation after dual ascent:
out_inf: tensor(2.1328, device='cuda:0', dtype=torch.float16) tensor(0.1752, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.4341, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
18 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.8496, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.1228, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1185, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1187, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1271, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.0316, device='cuda:0')
old_score: tensor(0.0086, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0075, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.926083087921143
Validation after dual ascent:
out_inf: tensor(2.8496, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.1223, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1047, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.1174, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.1208, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
18 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.6094, device='cuda:0', dtype=torch.float16) tensor(0.3315, device='cuda:0', dtype=torch.float16)
tensor(0.9316, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0186, device='cuda:0')
tensor(0.0901, device='cuda:0')
old_score: tensor(0.0746, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0674, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.278624057769775
Validation after dual ascent:
out_inf: tensor(8.6094, device='cuda:0', dtype=torch.float16) tensor(0.3315, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0639, device='cuda:0', dtype=torch.float16)
tensor(1.0840, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
18 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.4316, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
tensor(0.7891, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.7573, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0164, device='cuda:0')
tensor(0.2789, device='cuda:0')
old_score: tensor(0.0569, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0516, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.812349557876587
Validation after dual ascent:
out_inf: tensor(3.4316, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
18 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.1342, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1365, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1846, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1771, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0181, device='cuda:0')
tensor(0.0225, device='cuda:0')
old_score: tensor(0.0111, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 100.9322121143341
Validation after dual ascent:
out_inf: tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.1292, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1311, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1841, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1770, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
layer 18 done
19 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.5547, device='cuda:0', dtype=torch.float16) tensor(0.7603, device='cuda:0', dtype=torch.float16)
tensor(1.2930, device='cuda:0', dtype=torch.float16) tensor(0.1219, device='cuda:0', dtype=torch.float16)
tensor(1.1943, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1086, device='cuda:0', dtype=torch.float16)
tensor(1.2471, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0144, device='cuda:0')
tensor(0.2859, device='cuda:0')
old_score: tensor(0.1151, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1029, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.685670375823975
Validation after dual ascent:
out_inf: tensor(13.5547, device='cuda:0', dtype=torch.float16) tensor(0.7603, device='cuda:0', dtype=torch.float16)
tensor(1.1357, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.9561, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(1.2432, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
19 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.5469, device='cuda:0', dtype=torch.float16) tensor(1.5176, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.1884, device='cuda:0', dtype=torch.float16)
tensor(1.4775, device='cuda:0', dtype=torch.float16) tensor(0.1733, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(1.7695, device='cuda:0', dtype=torch.float16) tensor(0.1821, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0177, device='cuda:0')
tensor(0.2722, device='cuda:0')
old_score: tensor(0.1779, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1576, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9762711524963379
Validation after dual ascent:
out_inf: tensor(17.5469, device='cuda:0', dtype=torch.float16) tensor(1.5176, device='cuda:0', dtype=torch.float16)
tensor(1.6914, device='cuda:0', dtype=torch.float16) tensor(0.1664, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.1538, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
tensor(1.6895, device='cuda:0', dtype=torch.float16) tensor(0.1616, device='cuda:0', dtype=torch.float16)
19 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6738, device='cuda:0', dtype=torch.float16) tensor(0.2001, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.5728, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.4917, device='cuda:0', dtype=torch.float16) tensor(0.0615, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.1586, device='cuda:0')
old_score: tensor(0.0605, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0545, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7902262210845947
Validation after dual ascent:
out_inf: tensor(2.6738, device='cuda:0', dtype=torch.float16) tensor(0.2001, device='cuda:0', dtype=torch.float16)
tensor(0.4546, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.5708, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(0.4424, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
19 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.1255, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.1279, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1704, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1219, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.0471, device='cuda:0')
old_score: tensor(0.0106, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0094, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.926707029342651
Validation after dual ascent:
out_inf: tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.1251, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1142, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1116, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1166, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
19 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.6172, device='cuda:0', dtype=torch.float16) tensor(0.3350, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(1.2832, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0189, device='cuda:0')
tensor(0.0920, device='cuda:0')
old_score: tensor(0.0759, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0684, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.278936862945557
Validation after dual ascent:
out_inf: tensor(8.6172, device='cuda:0', dtype=torch.float16) tensor(0.3350, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
tensor(1.1465, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
19 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6016, device='cuda:0', dtype=torch.float16) tensor(0.1503, device='cuda:0', dtype=torch.float16)
tensor(0.5679, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.8223, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0168, device='cuda:0')
tensor(0.2901, device='cuda:0')
old_score: tensor(0.0573, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0518, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.820608615875244
Validation after dual ascent:
out_inf: tensor(4.6016, device='cuda:0', dtype=torch.float16) tensor(0.1503, device='cuda:0', dtype=torch.float16)
tensor(0.5181, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.5596, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.6982, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
19 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.6309, device='cuda:0', dtype=torch.float16) tensor(0.0357, device='cuda:0', dtype=torch.float16)
tensor(0.1183, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1390, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1212, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1409, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0179, device='cuda:0')
tensor(0.0408, device='cuda:0')
old_score: tensor(0.0110, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 76.83514881134033
Validation after dual ascent:
out_inf: tensor(1.6309, device='cuda:0', dtype=torch.float16) tensor(0.0357, device='cuda:0', dtype=torch.float16)
tensor(0.1140, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1287, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1176, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1350, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
layer 19 done
20 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.7344, device='cuda:0', dtype=torch.float16) tensor(0.7495, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
tensor(0.9902, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(0.9204, device='cuda:0', dtype=torch.float16) tensor(0.1018, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0151, device='cuda:0')
tensor(0.2942, device='cuda:0')
old_score: tensor(0.1094, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0973, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.6857311725616455
Validation after dual ascent:
out_inf: tensor(16.7344, device='cuda:0', dtype=torch.float16) tensor(0.7495, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(0.8877, device='cuda:0', dtype=torch.float16) tensor(0.0951, device='cuda:0', dtype=torch.float16)
tensor(0.8271, device='cuda:0', dtype=torch.float16) tensor(0.0902, device='cuda:0', dtype=torch.float16)
tensor(0.9365, device='cuda:0', dtype=torch.float16) tensor(0.1001, device='cuda:0', dtype=torch.float16)
20 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.2500, device='cuda:0', dtype=torch.float16) tensor(1.5420, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1650, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0192, device='cuda:0')
tensor(0.2647, device='cuda:0')
old_score: tensor(0.1687, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1487, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9742686748504639
Validation after dual ascent:
out_inf: tensor(19.2500, device='cuda:0', dtype=torch.float16) tensor(1.5420, device='cuda:0', dtype=torch.float16)
tensor(1.1943, device='cuda:0', dtype=torch.float16) tensor(0.1578, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1534, device='cuda:0', dtype=torch.float16)
20 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4316, device='cuda:0', dtype=torch.float16) tensor(0.1962, device='cuda:0', dtype=torch.float16)
tensor(0.5571, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.5776, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0055, device='cuda:0')
tensor(0.1636, device='cuda:0')
old_score: tensor(0.0615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0555, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7885401248931885
Validation after dual ascent:
out_inf: tensor(2.4316, device='cuda:0', dtype=torch.float16) tensor(0.1962, device='cuda:0', dtype=torch.float16)
tensor(0.4709, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.5298, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.4346, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.5132, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
20 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.1530, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.1455, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1455, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1388, device='cuda:0', dtype=torch.float16) tensor(0.0136, device='cuda:0', dtype=torch.float16)
tensor(0.0288, device='cuda:0')
old_score: tensor(0.0123, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0110, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.925578117370605
Validation after dual ascent:
out_inf: tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.1398, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1337, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1169, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1287, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
20 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.1602, device='cuda:0', dtype=torch.float16) tensor(0.3457, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.9697, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0178, device='cuda:0')
tensor(0.0375, device='cuda:0')
old_score: tensor(0.0779, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0696, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.747129201889038
Validation after dual ascent:
out_inf: tensor(7.1602, device='cuda:0', dtype=torch.float16) tensor(0.3457, device='cuda:0', dtype=torch.float16)
tensor(0.7026, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
tensor(0.7324, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
20 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6562, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.6245, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0176, device='cuda:0')
tensor(0.3020, device='cuda:0')
old_score: tensor(0.0590, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0528, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.819369077682495
Validation after dual ascent:
out_inf: tensor(3.6562, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.9419, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
20 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.1465, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.1392, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1296, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1482, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0159, device='cuda:0')
tensor(0.0368, device='cuda:0')
old_score: tensor(0.0117, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 76.80489420890808
Validation after dual ascent:
out_inf: tensor(1.1465, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.1443, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1348, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1230, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1536, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
layer 20 done
21 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.1719, device='cuda:0', dtype=torch.float16) tensor(0.7383, device='cuda:0', dtype=torch.float16)
tensor(1.2041, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.0244, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.9316, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
tensor(1.2441, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0176, device='cuda:0')
tensor(0.2259, device='cuda:0')
old_score: tensor(0.1050, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0928, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.6821393966674805
Validation after dual ascent:
out_inf: tensor(21.1719, device='cuda:0', dtype=torch.float16) tensor(0.7383, device='cuda:0', dtype=torch.float16)
tensor(1.0332, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
tensor(0.9175, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0857, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
21 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.4844, device='cuda:0', dtype=torch.float16) tensor(1.4766, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.1759, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.1526, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.1692, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0184, device='cuda:0')
tensor(0.1730, device='cuda:0')
old_score: tensor(0.1644, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1438, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.162635326385498
Validation after dual ascent:
out_inf: tensor(21.4844, device='cuda:0', dtype=torch.float16) tensor(1.4766, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.1405, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1326, device='cuda:0', dtype=torch.float16)
tensor(1.3545, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
21 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2305, device='cuda:0', dtype=torch.float16) tensor(0.2087, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.4907, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.5225, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5664, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0055, device='cuda:0')
tensor(0.1564, device='cuda:0')
old_score: tensor(0.0604, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0539, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7840113639831543
Validation after dual ascent:
out_inf: tensor(3.2305, device='cuda:0', dtype=torch.float16) tensor(0.2087, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.4932, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(0.4758, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.6470, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
21 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7275, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.1351, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.1511, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.1576, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1445, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.0328, device='cuda:0')
old_score: tensor(0.0135, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0113, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.91571831703186
Validation after dual ascent:
out_inf: tensor(1.7275, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.1294, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1427, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1460, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
21 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.3125, device='cuda:0', dtype=torch.float16) tensor(0.3662, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(1.5020, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0199, device='cuda:0')
tensor(0.0370, device='cuda:0')
old_score: tensor(0.0782, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0699, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.744890213012695
Validation after dual ascent:
out_inf: tensor(8.3125, device='cuda:0', dtype=torch.float16) tensor(0.3662, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0735, device='cuda:0', dtype=torch.float16)
tensor(0.9482, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(1.3965, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
21 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.8574, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0619, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.7363, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0177, device='cuda:0')
tensor(0.2955, device='cuda:0')
old_score: tensor(0.0588, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0527, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.823708772659302
Validation after dual ascent:
out_inf: tensor(3.8574, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.5791, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
21 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2041, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.1360, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1541, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1420, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1917, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0154, device='cuda:0')
tensor(0.0204, device='cuda:0')
old_score: tensor(0.0117, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 100.90010070800781
Validation after dual ascent:
out_inf: tensor(1.2041, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1361, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1313, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1671, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
layer 21 done
22 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.3750, device='cuda:0', dtype=torch.float16) tensor(0.7021, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(0.9722, device='cuda:0', dtype=torch.float16) tensor(0.0932, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.1023, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0183, device='cuda:0')
tensor(0.2263, device='cuda:0')
old_score: tensor(0.0997, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0878, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.681210994720459
Validation after dual ascent:
out_inf: tensor(19.3750, device='cuda:0', dtype=torch.float16) tensor(0.7021, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(0.8843, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
tensor(0.9946, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(1.6074, device='cuda:0', dtype=torch.float16) tensor(0.0902, device='cuda:0', dtype=torch.float16)
22 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.4883, device='cuda:0', dtype=torch.float16)
tensor(1.2725, device='cuda:0', dtype=torch.float16) tensor(0.1631, device='cuda:0', dtype=torch.float16)
tensor(1.4590, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
tensor(1.4082, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0199, device='cuda:0')
tensor(0.1686, device='cuda:0')
old_score: tensor(0.1538, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1342, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1627423763275146
Validation after dual ascent:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.4883, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.2998, device='cuda:0', dtype=torch.float16) tensor(0.1378, device='cuda:0', dtype=torch.float16)
22 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2852, device='cuda:0', dtype=torch.float16) tensor(0.2067, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
tensor(0.5815, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.6411, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0057, device='cuda:0')
tensor(0.1601, device='cuda:0')
old_score: tensor(0.0626, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0559, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7831799983978271
Validation after dual ascent:
out_inf: tensor(3.2852, device='cuda:0', dtype=torch.float16) tensor(0.2067, device='cuda:0', dtype=torch.float16)
tensor(0.5498, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.5210, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.5850, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
22 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.1937, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.2036, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.1877, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.2095, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
tensor(0.0366, device='cuda:0')
old_score: tensor(0.0158, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0140, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.9332914352417
Validation after dual ascent:
out_inf: tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.1733, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.1858, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.1619, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1953, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
22 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.5312, device='cuda:0', dtype=torch.float16) tensor(0.3489, device='cuda:0', dtype=torch.float16)
tensor(0.9355, device='cuda:0', dtype=torch.float16) tensor(0.0834, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0184, device='cuda:0')
tensor(0.0342, device='cuda:0')
old_score: tensor(0.0790, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0707, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.743330717086792
Validation after dual ascent:
out_inf: tensor(7.5312, device='cuda:0', dtype=torch.float16) tensor(0.3489, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(0.7783, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.9624, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
22 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6387, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.6318, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.9463, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0177, device='cuda:0')
tensor(0.3026, device='cuda:0')
old_score: tensor(0.0594, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0533, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.82165002822876
Validation after dual ascent:
out_inf: tensor(3.6387, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0492, device='cuda:0', dtype=torch.float16)
tensor(0.9111, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
22 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.6743, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.1484, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1373, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1411, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1771, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0139, device='cuda:0')
tensor(0.0198, device='cuda:0')
old_score: tensor(0.0112, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 100.98540759086609
Validation after dual ascent:
out_inf: tensor(0.6743, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.1188, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1317, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1267, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1718, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
layer 22 done
23 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.8594, device='cuda:0', dtype=torch.float16) tensor(0.7339, device='cuda:0', dtype=torch.float16)
tensor(1.0127, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(0.9370, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0193, device='cuda:0')
tensor(0.2149, device='cuda:0')
old_score: tensor(0.0983, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0865, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.679388761520386
Validation after dual ascent:
out_inf: tensor(20.8594, device='cuda:0', dtype=torch.float16) tensor(0.7339, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0921, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.7964, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
tensor(1.0928, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
23 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.5000, device='cuda:0', dtype=torch.float16) tensor(1.4238, device='cuda:0', dtype=torch.float16)
tensor(1.3340, device='cuda:0', dtype=torch.float16) tensor(0.1609, device='cuda:0', dtype=torch.float16)
tensor(1.3428, device='cuda:0', dtype=torch.float16) tensor(0.1479, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1569, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0198, device='cuda:0')
tensor(0.1356, device='cuda:0')
old_score: tensor(0.1514, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1323, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1624815464019775
Validation after dual ascent:
out_inf: tensor(21.5000, device='cuda:0', dtype=torch.float16) tensor(1.4238, device='cuda:0', dtype=torch.float16)
tensor(1.1582, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
23 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7344, device='cuda:0', dtype=torch.float16) tensor(0.2009, device='cuda:0', dtype=torch.float16)
tensor(0.6196, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(0.5942, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0058, device='cuda:0')
tensor(0.1600, device='cuda:0')
old_score: tensor(0.0645, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0578, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7827708721160889
Validation after dual ascent:
out_inf: tensor(2.7344, device='cuda:0', dtype=torch.float16) tensor(0.2009, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.5347, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.4973, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.6743, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
23 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.8076, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.1589, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.1523, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.1498, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1809, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.0446, device='cuda:0')
old_score: tensor(0.0138, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0124, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.927880048751831
Validation after dual ascent:
out_inf: tensor(0.8076, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.1433, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1528, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.1614, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1648, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
23 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.0938, device='cuda:0', dtype=torch.float16) tensor(0.3440, device='cuda:0', dtype=torch.float16)
tensor(0.9316, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
tensor(1.0381, device='cuda:0', dtype=torch.float16) tensor(0.0774, device='cuda:0', dtype=torch.float16)
tensor(1.0020, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0179, device='cuda:0')
tensor(0.0309, device='cuda:0')
old_score: tensor(0.0785, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0702, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.74514389038086
Validation after dual ascent:
out_inf: tensor(7.0938, device='cuda:0', dtype=torch.float16) tensor(0.3440, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(1.0332, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
23 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2500, device='cuda:0', dtype=torch.float16) tensor(0.1544, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0176, device='cuda:0')
tensor(0.2966, device='cuda:0')
old_score: tensor(0.0592, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0531, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.822705507278442
Validation after dual ascent:
out_inf: tensor(3.2500, device='cuda:0', dtype=torch.float16) tensor(0.1544, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0487, device='cuda:0', dtype=torch.float16)
tensor(0.6196, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
23 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.1219, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1354, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1211, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1630, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0147, device='cuda:0')
tensor(0.0212, device='cuda:0')
old_score: tensor(0.0108, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0098, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 100.94662356376648
Validation after dual ascent:
out_inf: tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.1101, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1392, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1335, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
layer 23 done
24 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.8750, device='cuda:0', dtype=torch.float16) tensor(0.7222, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.0917, device='cuda:0', dtype=torch.float16)
tensor(1.0488, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(0.9106, device='cuda:0', dtype=torch.float16) tensor(0.0968, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0182, device='cuda:0')
tensor(0.1641, device='cuda:0')
old_score: tensor(0.0938, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0823, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.417050361633301
Validation after dual ascent:
out_inf: tensor(22.8750, device='cuda:0', dtype=torch.float16) tensor(0.7222, device='cuda:0', dtype=torch.float16)
tensor(0.7632, device='cuda:0', dtype=torch.float16) tensor(0.0874, device='cuda:0', dtype=torch.float16)
tensor(0.8545, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.8926, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(0.8638, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
24 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.8438, device='cuda:0', dtype=torch.float16) tensor(1.3779, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.1260, device='cuda:0', dtype=torch.float16)
tensor(1.3486, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0141, device='cuda:0')
tensor(0.1140, device='cuda:0')
old_score: tensor(0.1362, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1187, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3461859226226807
Validation after dual ascent:
out_inf: tensor(19.8438, device='cuda:0', dtype=torch.float16) tensor(1.3779, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.1260, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(1.5195, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.1807, device='cuda:0', dtype=torch.float16) tensor(0.1231, device='cuda:0', dtype=torch.float16)
24 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6152, device='cuda:0', dtype=torch.float16) tensor(0.2318, device='cuda:0', dtype=torch.float16)
tensor(0.6499, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(0.7212, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0062, device='cuda:0')
tensor(0.1648, device='cuda:0')
old_score: tensor(0.0687, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0612, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7803113460540771
Validation after dual ascent:
out_inf: tensor(3.6152, device='cuda:0', dtype=torch.float16) tensor(0.2318, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.6587, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5596, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
24 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7856, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(0.2051, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
tensor(0.2050, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
tensor(0.1810, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
tensor(0.2302, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.0396, device='cuda:0')
old_score: tensor(0.0177, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0157, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.924354314804077
Validation after dual ascent:
out_inf: tensor(0.7856, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.1993, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.1694, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.1868, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
24 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.3672, device='cuda:0', dtype=torch.float16) tensor(0.3564, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0188, device='cuda:0')
tensor(0.0296, device='cuda:0')
old_score: tensor(0.0786, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0701, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.747732639312744
Validation after dual ascent:
out_inf: tensor(10.3672, device='cuda:0', dtype=torch.float16) tensor(0.3564, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
tensor(0.8418, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
24 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5723, device='cuda:0', dtype=torch.float16) tensor(0.1559, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.6606, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0178, device='cuda:0')
tensor(0.2932, device='cuda:0')
old_score: tensor(0.0593, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0529, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.824397563934326
Validation after dual ascent:
out_inf: tensor(3.5723, device='cuda:0', dtype=torch.float16) tensor(0.1559, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
24 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.2646, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.1169, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1390, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1400, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1775, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0084, device='cuda:0')
tensor(0.0173, device='cuda:0')
old_score: tensor(0.0107, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 108.99517750740051
Validation after dual ascent:
out_inf: tensor(1.2646, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.1082, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1376, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1346, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1736, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
layer 24 done
25 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(23.1875, device='cuda:0', dtype=torch.float16) tensor(0.7778, device='cuda:0', dtype=torch.float16)
tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(0.9902, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(0.9136, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0199, device='cuda:0')
tensor(0.0791, device='cuda:0')
old_score: tensor(0.0952, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0830, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.631617784500122
Validation after dual ascent:
out_inf: tensor(23.1875, device='cuda:0', dtype=torch.float16) tensor(0.7778, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0883, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.8979, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
25 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(23.0312, device='cuda:0', dtype=torch.float16) tensor(1.3574, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.1489, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.3525, device='cuda:0', dtype=torch.float16) tensor(0.1445, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0150, device='cuda:0')
tensor(0.1371, device='cuda:0')
old_score: tensor(0.1387, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1205, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3501296043395996
Validation after dual ascent:
out_inf: tensor(23.0312, device='cuda:0', dtype=torch.float16) tensor(1.3574, device='cuda:0', dtype=torch.float16)
tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(1.0986, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.1086, device='cuda:0', dtype=torch.float16)
tensor(1.4316, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
25 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7324, device='cuda:0', dtype=torch.float16) tensor(0.2522, device='cuda:0', dtype=torch.float16)
tensor(0.6104, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.6157, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0065, device='cuda:0')
tensor(0.1669, device='cuda:0')
old_score: tensor(0.0709, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0629, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.78265380859375
Validation after dual ascent:
out_inf: tensor(3.7324, device='cuda:0', dtype=torch.float16) tensor(0.2522, device='cuda:0', dtype=torch.float16)
tensor(0.5908, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.5122, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
25 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3877, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.2134, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
tensor(0.2563, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
tensor(0.2429, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.2029, device='cuda:0', dtype=torch.float16) tensor(0.0214, device='cuda:0', dtype=torch.float16)
tensor(0.0484, device='cuda:0')
old_score: tensor(0.0205, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0188, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.92669153213501
Validation after dual ascent:
out_inf: tensor(1.3877, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.2058, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.2417, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.2072, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.2073, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
25 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.2500, device='cuda:0', dtype=torch.float16) tensor(0.3799, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(1.0098, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0122, device='cuda:0')
tensor(0.0172, device='cuda:0')
old_score: tensor(0.0810, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0723, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.223439693450928
Validation after dual ascent:
out_inf: tensor(7.2500, device='cuda:0', dtype=torch.float16) tensor(0.3799, device='cuda:0', dtype=torch.float16)
tensor(0.7603, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.7842, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.9873, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
25 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7598, device='cuda:0', dtype=torch.float16) tensor(0.1633, device='cuda:0', dtype=torch.float16)
tensor(0.6865, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.9746, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
tensor(0.8062, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0185, device='cuda:0')
tensor(0.3066, device='cuda:0')
old_score: tensor(0.0612, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0547, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.83027720451355
Validation after dual ascent:
out_inf: tensor(3.7598, device='cuda:0', dtype=torch.float16) tensor(0.1633, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.6743, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
25 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3164, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.1305, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.1582, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1433, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.2057, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0158, device='cuda:0')
tensor(0.0223, device='cuda:0')
old_score: tensor(0.0114, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 100.90982580184937
Validation after dual ascent:
out_inf: tensor(3.3164, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.1265, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1414, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1467, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.2035, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
layer 25 done
26 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.2656, device='cuda:0', dtype=torch.float16) tensor(0.7378, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(0.8857, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(0.8271, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(0.8188, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0192, device='cuda:0')
tensor(0.1328, device='cuda:0')
old_score: tensor(0.0925, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0810, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.417937517166138
Validation after dual ascent:
out_inf: tensor(17.2656, device='cuda:0', dtype=torch.float16) tensor(0.7378, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.8472, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.7212, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
26 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.6094, device='cuda:0', dtype=torch.float16) tensor(1.5049, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1453, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
tensor(1.0322, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1431, device='cuda:0', dtype=torch.float16)
26 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6211, device='cuda:0', dtype=torch.float16) tensor(0.2198, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0713, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(0.7124, device='cuda:0', dtype=torch.float16) tensor(0.0730, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0065, device='cuda:0')
tensor(0.1714, device='cuda:0')
old_score: tensor(0.0709, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0638, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7805671691894531
Validation after dual ascent:
out_inf: tensor(3.6211, device='cuda:0', dtype=torch.float16) tensor(0.2198, device='cuda:0', dtype=torch.float16)
tensor(0.5073, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0647, device='cuda:0', dtype=torch.float16)
tensor(0.5620, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
26 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.1934, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.2411, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.2150, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
tensor(0.2235, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.0468, device='cuda:0')
old_score: tensor(0.0186, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0164, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.925985097885132
Validation after dual ascent:
out_inf: tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.1805, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.2141, device='cuda:0', dtype=torch.float16) tensor(0.0185, device='cuda:0', dtype=torch.float16)
tensor(0.2004, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.2269, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
26 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.2031, device='cuda:0', dtype=torch.float16) tensor(0.4165, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(0.9199, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0150, device='cuda:0')
tensor(0.0207, device='cuda:0')
old_score: tensor(0.0820, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0729, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.213444948196411
Validation after dual ascent:
out_inf: tensor(8.2031, device='cuda:0', dtype=torch.float16) tensor(0.4165, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(0.7627, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
26 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0625, device='cuda:0', dtype=torch.float16) tensor(0.1768, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0198, device='cuda:0')
tensor(0.3157, device='cuda:0')
old_score: tensor(0.0624, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0555, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.830093622207642
Validation after dual ascent:
out_inf: tensor(4.0625, device='cuda:0', dtype=torch.float16) tensor(0.1768, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
tensor(0.6304, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
26 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3359, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.1487, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.1735, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.1678, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1716, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0134, device='cuda:0')
tensor(0.0194, device='cuda:0')
old_score: tensor(0.0124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0110, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 100.95797491073608
Validation after dual ascent:
out_inf: tensor(4.3359, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.1510, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1885, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.1478, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1746, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
layer 26 done
27 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.2031, device='cuda:0', dtype=torch.float16) tensor(0.7305, device='cuda:0', dtype=torch.float16)
tensor(0.8433, device='cuda:0', dtype=torch.float16) tensor(0.1012, device='cuda:0', dtype=torch.float16)
tensor(0.8540, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0192, device='cuda:0')
tensor(0.1018, device='cuda:0')
old_score: tensor(0.0960, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0836, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.097899675369263
Validation after dual ascent:
out_inf: tensor(22.2031, device='cuda:0', dtype=torch.float16) tensor(0.7305, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0871, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(0.7212, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(1.0137, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
27 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.3125, device='cuda:0', dtype=torch.float16) tensor(1.4658, device='cuda:0', dtype=torch.float16)
tensor(1.2705, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
tensor(1.1787, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0141, device='cuda:0')
tensor(0.1227, device='cuda:0')
old_score: tensor(0.1433, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7195227146148682
Validation after dual ascent:
out_inf: tensor(19.3125, device='cuda:0', dtype=torch.float16) tensor(1.4658, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
27 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.3000, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0838, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
tensor(0.6226, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0043, device='cuda:0')
tensor(0.1411, device='cuda:0')
old_score: tensor(0.0802, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0710, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9717755317687988
Validation after dual ascent:
out_inf: tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.3000, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.7842, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.7139, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
27 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.9175, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.3010, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(0.3262, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.3118, device='cuda:0', dtype=torch.float16) tensor(0.0229, device='cuda:0', dtype=torch.float16)
tensor(0.2571, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
tensor(0.0807, device='cuda:0')
old_score: tensor(0.0254, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0229, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.92535948753357
Validation after dual ascent:
out_inf: tensor(0.9175, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.2800, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
tensor(0.3042, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
tensor(0.2866, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.2800, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
27 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.5977, device='cuda:0', dtype=torch.float16) tensor(0.4705, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(1.0137, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0174, device='cuda:0')
tensor(0.0293, device='cuda:0')
old_score: tensor(0.0870, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0769, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.219277381896973
Validation after dual ascent:
out_inf: tensor(7.5977, device='cuda:0', dtype=torch.float16) tensor(0.4705, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0697, device='cuda:0', dtype=torch.float16)
tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.0791, device='cuda:0', dtype=torch.float16)
27 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6953, device='cuda:0', dtype=torch.float16) tensor(0.1989, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(1.0684, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0125, device='cuda:0')
tensor(0.0788, device='cuda:0')
old_score: tensor(0.0670, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0593, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.314870595932007
Validation after dual ascent:
out_inf: tensor(4.6953, device='cuda:0', dtype=torch.float16) tensor(0.1989, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.9824, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
27 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.4609, device='cuda:0', dtype=torch.float16) tensor(0.0695, device='cuda:0', dtype=torch.float16)
tensor(0.1566, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.1906, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.1750, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1857, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0182, device='cuda:0')
tensor(0.0239, device='cuda:0')
old_score: tensor(0.0143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0126, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 76.75037956237793
Validation after dual ascent:
out_inf: tensor(5.4609, device='cuda:0', dtype=torch.float16) tensor(0.0695, device='cuda:0', dtype=torch.float16)
tensor(0.1477, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1934, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.1710, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1848, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
layer 27 done
28 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.2500, device='cuda:0', dtype=torch.float16) tensor(0.7759, device='cuda:0', dtype=torch.float16)
tensor(1.0947, device='cuda:0', dtype=torch.float16) tensor(0.1024, device='cuda:0', dtype=torch.float16)
tensor(0.9194, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.8369, device='cuda:0', dtype=torch.float16) tensor(0.0890, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(0.0462, device='cuda:0')
old_score: tensor(0.0981, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0849, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.981616497039795
Validation after dual ascent:
out_inf: tensor(20.2500, device='cuda:0', dtype=torch.float16) tensor(0.7759, device='cuda:0', dtype=torch.float16)
tensor(0.9077, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(0.7920, device='cuda:0', dtype=torch.float16) tensor(0.0879, device='cuda:0', dtype=torch.float16)
tensor(0.8408, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(0.8779, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
28 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.5781, device='cuda:0', dtype=torch.float16) tensor(1.4482, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.1534, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1478, device='cuda:0', dtype=torch.float16)
tensor(1.2334, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
tensor(1.2646, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0178, device='cuda:0')
tensor(0.0928, device='cuda:0')
old_score: tensor(0.1461, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1252, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3455755710601807
Validation after dual ascent:
out_inf: tensor(21.5781, device='cuda:0', dtype=torch.float16) tensor(1.4482, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1296, device='cuda:0', dtype=torch.float16)
tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(1.1475, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
28 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8281, device='cuda:0', dtype=torch.float16) tensor(0.2717, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0885, device='cuda:0', dtype=torch.float16)
tensor(0.7529, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
tensor(0.7529, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(0.8145, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0079, device='cuda:0')
tensor(0.2052, device='cuda:0')
old_score: tensor(0.0853, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0758, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7786626815795898
Validation after dual ascent:
out_inf: tensor(4.8281, device='cuda:0', dtype=torch.float16) tensor(0.2717, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.7593, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
28 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.4434, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.2363, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.2039, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.2202, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.2590, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0119, device='cuda:0')
tensor(0.0241, device='cuda:0')
old_score: tensor(0.0198, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0171, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.593740224838257
Validation after dual ascent:
out_inf: tensor(1.4434, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.2314, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.1941, device='cuda:0', dtype=torch.float16) tensor(0.0172, device='cuda:0', dtype=torch.float16)
tensor(0.2073, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.2292, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
28 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.6250, device='cuda:0', dtype=torch.float16) tensor(0.5063, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.0920, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.0905, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0180, device='cuda:0')
tensor(0.0265, device='cuda:0')
old_score: tensor(0.0881, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.676129579544067
Validation after dual ascent:
out_inf: tensor(10.6250, device='cuda:0', dtype=torch.float16) tensor(0.5063, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.8447, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
28 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.1172, device='cuda:0', dtype=torch.float16) tensor(0.2317, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.9443, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.0719, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0178, device='cuda:0')
tensor(0.0905, device='cuda:0')
old_score: tensor(0.0698, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0613, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.305837392807007
Validation after dual ascent:
out_inf: tensor(5.1172, device='cuda:0', dtype=torch.float16) tensor(0.2317, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
tensor(0.7676, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
tensor(0.9619, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
tensor(0.8564, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
28 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6328, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(0.2466, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.2769, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.2427, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.2219, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0186, device='cuda:0')
tensor(0.0187, device='cuda:0')
old_score: tensor(0.0167, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0147, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 76.752521276474
Validation after dual ascent:
out_inf: tensor(4.6328, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(0.2556, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.2610, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.2214, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.2407, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
layer 28 done
29 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13., device='cuda:0', dtype=torch.float16) tensor(0.7388, device='cuda:0', dtype=torch.float16)
tensor(1.1006, device='cuda:0', dtype=torch.float16) tensor(0.1066, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(1.0605, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(0.1050, device='cuda:0')
old_score: tensor(0.1008, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0865, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.979514122009277
Validation after dual ascent:
out_inf: tensor(13., device='cuda:0', dtype=torch.float16) tensor(0.7388, device='cuda:0', dtype=torch.float16)
tensor(1.0088, device='cuda:0', dtype=torch.float16) tensor(0.0901, device='cuda:0', dtype=torch.float16)
tensor(0.8618, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(0.9502, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
29 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(35.5625, device='cuda:0', dtype=torch.float16) tensor(1.3926, device='cuda:0', dtype=torch.float16)
tensor(1.4121, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.1562, device='cuda:0', dtype=torch.float16)
tensor(1.4082, device='cuda:0', dtype=torch.float16) tensor(0.1381, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(0.0657, device='cuda:0')
old_score: tensor(0.1541, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1316, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9725725650787354
Validation after dual ascent:
out_inf: tensor(35.5625, device='cuda:0', dtype=torch.float16) tensor(1.3926, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.1180, device='cuda:0', dtype=torch.float16)
tensor(1.3154, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
29 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6., device='cuda:0', dtype=torch.float16) tensor(0.3088, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0172, device='cuda:0')
tensor(0.1570, device='cuda:0')
old_score: tensor(0.0916, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0800, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9685492515563965
Validation after dual ascent:
out_inf: tensor(6., device='cuda:0', dtype=torch.float16) tensor(0.3088, device='cuda:0', dtype=torch.float16)
tensor(0.6782, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(0.7300, device='cuda:0', dtype=torch.float16) tensor(0.0830, device='cuda:0', dtype=torch.float16)
tensor(0.6904, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(0.7280, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
29 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.6904, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.3303, device='cuda:0', dtype=torch.float16) tensor(0.0237, device='cuda:0', dtype=torch.float16)
tensor(0.3455, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.2822, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.2808, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.0260, device='cuda:0')
old_score: tensor(0.0212, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0170, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.928927183151245
Validation after dual ascent:
out_inf: tensor(1.6904, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.2642, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
tensor(0.3010, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.2842, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.2544, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
29 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.6406, device='cuda:0', dtype=torch.float16) tensor(0.5088, device='cuda:0', dtype=torch.float16)
tensor(1.0723, device='cuda:0', dtype=torch.float16) tensor(0.0921, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.0895, device='cuda:0', dtype=torch.float16)
tensor(1.1494, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0198, device='cuda:0')
tensor(0.0311, device='cuda:0')
old_score: tensor(0.0877, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0758, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.715656757354736
Validation after dual ascent:
out_inf: tensor(14.6406, device='cuda:0', dtype=torch.float16) tensor(0.5088, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0783, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
29 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.8828, device='cuda:0', dtype=torch.float16) tensor(0.2715, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0758, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.0879, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0198, device='cuda:0')
tensor(0.0437, device='cuda:0')
old_score: tensor(0.0723, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0625, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.80136513710022
Validation after dual ascent:
out_inf: tensor(9.8828, device='cuda:0', dtype=torch.float16) tensor(0.2715, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
29 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.7031, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(0.2998, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(0.3452, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.3030, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.2856, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0278, device='cuda:0')
old_score: tensor(0.0194, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0173, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.98429322242737
Validation after dual ascent:
out_inf: tensor(8.7031, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(0.2527, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
tensor(0.3247, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.3049, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
tensor(0.2783, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
layer 29 done
30 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.0469, device='cuda:0', dtype=torch.float16) tensor(0.7949, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(1.0947, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
tensor(0.0601, device='cuda:0')
old_score: tensor(0.0897, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0757, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.978893518447876
Validation after dual ascent:
out_inf: tensor(16.0469, device='cuda:0', dtype=torch.float16) tensor(0.7949, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.8037, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(0.8994, device='cuda:0', dtype=torch.float16) tensor(0.0775, device='cuda:0', dtype=torch.float16)
30 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(21., device='cuda:0', dtype=torch.float16) tensor(1.5107, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.1310, device='cuda:0', dtype=torch.float16)
tensor(1.1367, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
30 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.3438, device='cuda:0', dtype=torch.float16) tensor(0.3347, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.1073, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1073, device='cuda:0', dtype=torch.float16)
tensor(1.0967, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0100, device='cuda:0')
tensor(0.2618, device='cuda:0')
old_score: tensor(0.1036, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0907, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7774612903594971
Validation after dual ascent:
out_inf: tensor(6.3438, device='cuda:0', dtype=torch.float16) tensor(0.3347, device='cuda:0', dtype=torch.float16)
tensor(0.7939, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(0.9053, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(0.8213, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
30 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3945, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
tensor(0.3782, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.3792, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.3643, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.3899, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0152, device='cuda:0')
tensor(0.0174, device='cuda:0')
old_score: tensor(0.0352, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0303, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.869419097900391
Validation after dual ascent:
out_inf: tensor(3.3945, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
tensor(0.3442, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.3484, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.3035, device='cuda:0', dtype=torch.float16) tensor(0.0290, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
30 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.3125, device='cuda:0', dtype=torch.float16) tensor(0.5693, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.0962, device='cuda:0', dtype=torch.float16)
tensor(1.5801, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(1.3828, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(0.0246, device='cuda:0')
old_score: tensor(0.0930, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0797, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.82395696640015
Validation after dual ascent:
out_inf: tensor(18.3125, device='cuda:0', dtype=torch.float16) tensor(0.5693, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(1.4463, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
30 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.2812, device='cuda:0', dtype=torch.float16) tensor(0.3562, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0177, device='cuda:0')
tensor(0.0305, device='cuda:0')
old_score: tensor(0.0764, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0654, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.68375849723816
Validation after dual ascent:
out_inf: tensor(11.2812, device='cuda:0', dtype=torch.float16) tensor(0.3562, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(1.0596, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.9561, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(1.0332, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
30 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.1719, device='cuda:0', dtype=torch.float16) tensor(0.1873, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.5049, device='cuda:0', dtype=torch.float16) tensor(0.0268, device='cuda:0', dtype=torch.float16)
tensor(0.4729, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
tensor(0.4353, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
tensor(0.0491, device='cuda:0')
old_score: tensor(0.0254, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0225, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.17861032485962
Validation after dual ascent:
out_inf: tensor(11.1719, device='cuda:0', dtype=torch.float16) tensor(0.1873, device='cuda:0', dtype=torch.float16)
tensor(0.3545, device='cuda:0', dtype=torch.float16) tensor(0.0229, device='cuda:0', dtype=torch.float16)
tensor(0.4756, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.3940, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(0.4026, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
layer 30 done
31 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.6875, device='cuda:0', dtype=torch.float16) tensor(0.8906, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
tensor(0.9473, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.0917, device='cuda:0', dtype=torch.float16)
tensor(0.0593, device='cuda:0')
old_score: tensor(0.0905, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0743, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.970889329910278
Validation after dual ascent:
out_inf: tensor(16.6875, device='cuda:0', dtype=torch.float16) tensor(0.8906, device='cuda:0', dtype=torch.float16)
tensor(0.8896, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(0.7842, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(0.7749, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
31 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.2656, device='cuda:0', dtype=torch.float16) tensor(1.3896, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.1188, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
31 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.3047, device='cuda:0', dtype=torch.float16) tensor(0.3955, device='cuda:0', dtype=torch.float16)
tensor(0.7197, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(0.7183, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0128, device='cuda:0')
tensor(0.1528, device='cuda:0')
old_score: tensor(0.0864, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0717, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7806973457336426
Validation after dual ascent:
out_inf: tensor(6.3047, device='cuda:0', dtype=torch.float16) tensor(0.3955, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.6226, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.6396, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
31 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4414, device='cuda:0', dtype=torch.float16) tensor(0.1365, device='cuda:0', dtype=torch.float16)
tensor(0.4087, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
tensor(0.2974, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.3440, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
tensor(0.4561, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0198, device='cuda:0')
tensor(0.0343, device='cuda:0')
old_score: tensor(0.0316, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0270, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.475902557373047
Validation after dual ascent:
out_inf: tensor(4.4414, device='cuda:0', dtype=torch.float16) tensor(0.1365, device='cuda:0', dtype=torch.float16)
tensor(0.3477, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
tensor(0.2610, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
tensor(0.4265, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
31 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.3906, device='cuda:0', dtype=torch.float16) tensor(0.6064, device='cuda:0', dtype=torch.float16)
tensor(1.6289, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.0932, device='cuda:0', dtype=torch.float16)
tensor(2.6211, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(2.1055, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(0.0618, device='cuda:0')
old_score: tensor(0.0884, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0732, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.806907176971436
Validation after dual ascent:
out_inf: tensor(20.3906, device='cuda:0', dtype=torch.float16) tensor(0.6064, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0744, device='cuda:0', dtype=torch.float16)
tensor(1.9180, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(2.4941, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(1.9883, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
31 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(27.1250, device='cuda:0', dtype=torch.float16) tensor(0.5332, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.0447, device='cuda:0')
old_score: tensor(0.0729, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0604, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.7843062877655
Validation after dual ascent:
out_inf: tensor(27.1250, device='cuda:0', dtype=torch.float16) tensor(0.5332, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.9512, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
31 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(375., device='cuda:0', dtype=torch.float16) tensor(0.4734, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.9629, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.7935, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
layer 31 done
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.47it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  3.17it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.50it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.76it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.49it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.800001
layer 1 sparsity 0.800001
layer 2 sparsity 0.800001
layer 3 sparsity 0.800001
layer 4 sparsity 0.800001
layer 5 sparsity 0.800001
layer 6 sparsity 0.800001
layer 7 sparsity 0.800001
layer 8 sparsity 0.800001
layer 9 sparsity 0.800001
layer 10 sparsity 0.800001
layer 11 sparsity 0.800001
layer 12 sparsity 0.800001
layer 13 sparsity 0.800001
layer 14 sparsity 0.800001
layer 15 sparsity 0.800001
layer 16 sparsity 0.800001
layer 17 sparsity 0.800001
layer 18 sparsity 0.800001
layer 19 sparsity 0.800001
layer 20 sparsity 0.800001
layer 21 sparsity 0.800001
layer 22 sparsity 0.800001
layer 23 sparsity 0.800001
layer 24 sparsity 0.800001
layer 25 sparsity 0.800001
layer 26 sparsity 0.800001
layer 27 sparsity 0.800001
layer 28 sparsity 0.800001
layer 29 sparsity 0.800001
layer 30 sparsity 0.800001
layer 31 sparsity 0.800001
sparsity sanity check 0.8000
******************************
evaluating on wikitext2
nsamples 35
sample 0
wikitext perplexity 137.60482788085938
sparsegpt_dual_3	0.8000	137.6048	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.8, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='sparsegpt_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
dataset loading complete
pruning layer 0 name self_attn.q_proj
Validation after prune:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.8218, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.k_proj
Validation after prune:
out_inf: tensor(10.5859, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.v_proj
Validation after prune:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0962, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1089, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1089, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.0991, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0198, device='cuda:0')
tensor(0.0402, device='cuda:0')
old_score: tensor(0.0067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0040, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.193007230758667
Validation after dual ascent:
out_inf: tensor(0.5063, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.0623, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0565, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0671, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.0524, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0518, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0661, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0642, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0458, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0284, device='cuda:0')
old_score: tensor(0.0009, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0005, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.846898078918457
Validation after dual ascent:
out_inf: tensor(0.2223, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0627, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0724, device='cuda:0', dtype=torch.float16) tensor(0.0006, device='cuda:0', dtype=torch.float16)
tensor(0.0544, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0547, device='cuda:0', dtype=torch.float16) tensor(0.0006, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(1.7402, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(1.7070, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(1.6348, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(1.6152, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0036, device='cuda:0')
tensor(0.0278, device='cuda:0')
old_score: tensor(0.0352, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0267, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.750387191772461
Validation after dual ascent:
out_inf: tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(1.7129, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(1.6660, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(1.6172, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.up_proj
Validation after prune:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
tensor(0.8076, device='cuda:0', dtype=torch.float16) tensor(0.0319, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0036, device='cuda:0')
tensor(0.0255, device='cuda:0')
old_score: tensor(0.0312, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0241, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.754462003707886
Validation after dual ascent:
out_inf: tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0620, device='cuda:0', dtype=torch.float16)
tensor(0.7686, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.8779, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.0237, device='cuda:0', dtype=torch.float16)
tensor(0.7412, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0764, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0831, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0771, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0704, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0917, device='cuda:0')
old_score: tensor(0.0030, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0024, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.42045974731445
Validation after dual ascent:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0421, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0453, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0430, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0479, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.1094, device='cuda:0', dtype=torch.float16) tensor(1.0322, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.7891, device='cuda:0', dtype=torch.float16) tensor(0.0419, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.k_proj
Validation after prune:
out_inf: tensor(11.4219, device='cuda:0', dtype=torch.float16) tensor(1.5303, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.4307, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.2061, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.2109, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.2852, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.1973, device='cuda:0', dtype=torch.float16) tensor(0.0172, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0126, device='cuda:0')
tensor(0.0514, device='cuda:0')
old_score: tensor(0.0170, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0127, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9505617618560791
Validation after dual ascent:
out_inf: tensor(1.4307, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.3428, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.3096, device='cuda:0', dtype=torch.float16) tensor(0.0136, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.4385, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.6089, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.2996, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.4526, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.5122, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.0368, device='cuda:0')
old_score: tensor(0.0020, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0014, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.889006853103638
Validation after dual ascent:
out_inf: tensor(0.6089, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.0923, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0529, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.1326, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0684, device='cuda:0', dtype=torch.float16) tensor(0.0014, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.gate_proj
Validation after prune:
out_inf: tensor(13.4844, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(1.6562, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0187, device='cuda:0')
tensor(0.0631, device='cuda:0')
old_score: tensor(0.0463, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0360, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.773854494094849
Validation after dual ascent:
out_inf: tensor(13.4844, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.5879, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(3.5156, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0151, device='cuda:0')
tensor(0.0560, device='cuda:0')
old_score: tensor(0.0405, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0324, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.764545917510986
Validation after dual ascent:
out_inf: tensor(2.5879, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(1.9375, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.down_proj
Validation after prune:
out_inf: tensor(144.6250, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.0657, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.0964, device='cuda:0')
old_score: tensor(0.0035, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0030, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.99214434623718
Validation after dual ascent:
out_inf: tensor(144.6250, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.2344, device='cuda:0', dtype=torch.float16) tensor(0.8618, device='cuda:0', dtype=torch.float16)
tensor(1.6328, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
tensor(1.6758, device='cuda:0', dtype=torch.float16) tensor(0.1422, device='cuda:0', dtype=torch.float16)
tensor(1.7539, device='cuda:0', dtype=torch.float16) tensor(0.1442, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.1448, device='cuda:0', dtype=torch.float16)
tensor(0.1066, device='cuda:0')
old_score: tensor(0.1443, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0918, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.89058232307434
Validation after dual ascent:
out_inf: tensor(14.2344, device='cuda:0', dtype=torch.float16) tensor(0.8618, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(1.2207, device='cuda:0', dtype=torch.float16) tensor(0.0962, device='cuda:0', dtype=torch.float16)
tensor(1.1855, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.5859, device='cuda:0', dtype=torch.float16) tensor(1.4053, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.2280, device='cuda:0', dtype=torch.float16)
tensor(2.3359, device='cuda:0', dtype=torch.float16) tensor(0.2227, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.2253, device='cuda:0', dtype=torch.float16)
tensor(2.4766, device='cuda:0', dtype=torch.float16) tensor(0.2275, device='cuda:0', dtype=torch.float16)
tensor(0.0935, device='cuda:0')
old_score: tensor(0.2258, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1383, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.972031354904175
Validation after dual ascent:
out_inf: tensor(15.5859, device='cuda:0', dtype=torch.float16) tensor(1.4053, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
tensor(1.7275, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
tensor(1.6855, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1102, device='cuda:0', dtype=torch.float16)
tensor(0.4124, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.4539, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
tensor(0.3936, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0058, device='cuda:0')
tensor(0.0648, device='cuda:0')
old_score: tensor(0.0468, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0360, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9812009334564209
Validation after dual ascent:
out_inf: tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1102, device='cuda:0', dtype=torch.float16)
tensor(0.3357, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.3420, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(0.3687, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.4253, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1375, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.1026, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0959, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.1316, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.0295, device='cuda:0')
old_score: tensor(0.0026, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0019, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.912429571151733
Validation after dual ascent:
out_inf: tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.0955, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0712, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0779, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0745, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.9238, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(4.1328, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(3.9688, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(3.2969, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(4., device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0170, device='cuda:0')
tensor(0.1452, device='cuda:0')
old_score: tensor(0.0589, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0455, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.765443563461304
Validation after dual ascent:
out_inf: tensor(2.9238, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.8643, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0143, device='cuda:0')
tensor(0.1274, device='cuda:0')
old_score: tensor(0.0501, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0398, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.770571708679199
Validation after dual ascent:
out_inf: tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(0.5420, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.5479, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.6338, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.5439, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.3037, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.0925, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.1000, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.1305, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.1123, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.0943, device='cuda:0')
old_score: tensor(0.0050, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0043, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 165.3695125579834
Validation after dual ascent:
out_inf: tensor(0.3037, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.0646, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.0663, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.0670, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.0693, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.0469, device='cuda:0', dtype=torch.float16) tensor(0.8315, device='cuda:0', dtype=torch.float16)
tensor(2.9766, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(3.1719, device='cuda:0', dtype=torch.float16) tensor(0.1641, device='cuda:0', dtype=torch.float16)
tensor(2.3594, device='cuda:0', dtype=torch.float16) tensor(0.1683, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0186, device='cuda:0')
tensor(0.1744, device='cuda:0')
old_score: tensor(0.1683, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1113, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1951279640197754
Validation after dual ascent:
out_inf: tensor(13.0469, device='cuda:0', dtype=torch.float16) tensor(0.8315, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(1.6914, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(1.3389, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.0469, device='cuda:0', dtype=torch.float16) tensor(1.3311, device='cuda:0', dtype=torch.float16)
tensor(2.7500, device='cuda:0', dtype=torch.float16) tensor(0.2700, device='cuda:0', dtype=torch.float16)
tensor(2.9141, device='cuda:0', dtype=torch.float16) tensor(0.2644, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.2673, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0106, device='cuda:0')
tensor(0.1223, device='cuda:0')
old_score: tensor(0.2644, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1687, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9796938896179199
Validation after dual ascent:
out_inf: tensor(20.0469, device='cuda:0', dtype=torch.float16) tensor(1.3311, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.1614, device='cuda:0', dtype=torch.float16)
tensor(2.4805, device='cuda:0', dtype=torch.float16) tensor(0.1769, device='cuda:0', dtype=torch.float16)
tensor(2.3320, device='cuda:0', dtype=torch.float16) tensor(0.1726, device='cuda:0', dtype=torch.float16)
tensor(2.1270, device='cuda:0', dtype=torch.float16) tensor(0.1638, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.4492, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.7041, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.7100, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0052, device='cuda:0')
tensor(0.1322, device='cuda:0')
old_score: tensor(0.0667, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0499, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7936992645263672
Validation after dual ascent:
out_inf: tensor(2.4492, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
tensor(0.5498, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
tensor(0.5962, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(0.4614, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9995, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1501, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
tensor(0.1714, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.2378, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.1313, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0337, device='cuda:0')
old_score: tensor(0.0040, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0027, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.880598306655884
Validation after dual ascent:
out_inf: tensor(0.9995, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1068, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.0876, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.1123, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0964, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.6621, device='cuda:0', dtype=torch.float16) tensor(0.1566, device='cuda:0', dtype=torch.float16)
tensor(2.2324, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(2.1016, device='cuda:0', dtype=torch.float16) tensor(0.0835, device='cuda:0', dtype=torch.float16)
tensor(2.3789, device='cuda:0', dtype=torch.float16) tensor(0.0761, device='cuda:0', dtype=torch.float16)
tensor(2.2695, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0053, device='cuda:0')
tensor(0.0399, device='cuda:0')
old_score: tensor(0.0775, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0564, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.222729444503784
Validation after dual ascent:
out_inf: tensor(3.6621, device='cuda:0', dtype=torch.float16) tensor(0.1566, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.1582, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.8164, device='cuda:0', dtype=torch.float16) tensor(0.1032, device='cuda:0', dtype=torch.float16)
tensor(1.3223, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.2167, device='cuda:0')
old_score: tensor(0.0599, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0451, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.774482727050781
Validation after dual ascent:
out_inf: tensor(3.8164, device='cuda:0', dtype=torch.float16) tensor(0.1032, device='cuda:0', dtype=torch.float16)
tensor(0.6660, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.8369, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.6528, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.1055, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2188, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1165, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1116, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0137, device='cuda:0')
tensor(0.0303, device='cuda:0')
old_score: tensor(0.0076, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0064, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 149.2508852481842
Validation after dual ascent:
out_inf: tensor(0.6528, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.0609, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.1014, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.0807, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0766, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.1953, device='cuda:0', dtype=torch.float16) tensor(0.8237, device='cuda:0', dtype=torch.float16)
tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(2.4941, device='cuda:0', dtype=torch.float16) tensor(0.1588, device='cuda:0', dtype=torch.float16)
tensor(2.2422, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1547, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0197, device='cuda:0')
tensor(0.0360, device='cuda:0')
old_score: tensor(0.1552, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0944, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.399349927902222
Validation after dual ascent:
out_inf: tensor(12.1953, device='cuda:0', dtype=torch.float16) tensor(0.8237, device='cuda:0', dtype=torch.float16)
tensor(1.1816, device='cuda:0', dtype=torch.float16) tensor(0.0905, device='cuda:0', dtype=torch.float16)
tensor(1.2129, device='cuda:0', dtype=torch.float16) tensor(0.0993, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.6406, device='cuda:0', dtype=torch.float16) tensor(1.4219, device='cuda:0', dtype=torch.float16)
tensor(3.3047, device='cuda:0', dtype=torch.float16) tensor(0.2566, device='cuda:0', dtype=torch.float16)
tensor(3.4688, device='cuda:0', dtype=torch.float16) tensor(0.2600, device='cuda:0', dtype=torch.float16)
tensor(3.2891, device='cuda:0', dtype=torch.float16) tensor(0.2482, device='cuda:0', dtype=torch.float16)
tensor(3.3750, device='cuda:0', dtype=torch.float16) tensor(0.2532, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0130, device='cuda:0')
tensor(0.0962, device='cuda:0')
old_score: tensor(0.2544, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1450, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9758427143096924
Validation after dual ascent:
out_inf: tensor(21.6406, device='cuda:0', dtype=torch.float16) tensor(1.4219, device='cuda:0', dtype=torch.float16)
tensor(1.5459, device='cuda:0', dtype=torch.float16) tensor(0.1389, device='cuda:0', dtype=torch.float16)
tensor(1.8477, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
tensor(1.5791, device='cuda:0', dtype=torch.float16) tensor(0.1477, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.9482, device='cuda:0', dtype=torch.float16) tensor(0.1445, device='cuda:0', dtype=torch.float16)
tensor(0.8159, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.7241, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.6709, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0051, device='cuda:0')
tensor(0.1107, device='cuda:0')
old_score: tensor(0.0670, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0463, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7894160747528076
Validation after dual ascent:
out_inf: tensor(1.9482, device='cuda:0', dtype=torch.float16) tensor(0.1445, device='cuda:0', dtype=torch.float16)
tensor(0.3936, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.4534, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.4282, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.2627, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.3552, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.1565, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.2397, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.0314, device='cuda:0')
old_score: tensor(0.0065, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0042, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.872441530227661
Validation after dual ascent:
out_inf: tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.1353, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.1226, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.1531, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.1421, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.4688, device='cuda:0', dtype=torch.float16) tensor(0.2231, device='cuda:0', dtype=torch.float16)
tensor(3.4180, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(3.2617, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(2.4219, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
tensor(2.7676, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0115, device='cuda:0')
tensor(0.0605, device='cuda:0')
old_score: tensor(0.0936, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0623, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.230810403823853
Validation after dual ascent:
out_inf: tensor(5.4688, device='cuda:0', dtype=torch.float16) tensor(0.2231, device='cuda:0', dtype=torch.float16)
tensor(0.8267, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(0.9912, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.9731, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.3691, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(1.0693, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(1.1699, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0064, device='cuda:0')
tensor(0.0437, device='cuda:0')
old_score: tensor(0.0667, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0462, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.23512864112854
Validation after dual ascent:
out_inf: tensor(3.3691, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.6655, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(0.6494, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.8760, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.1548, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.2000, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1973, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0193, device='cuda:0')
tensor(0.0493, device='cuda:0')
old_score: tensor(0.0101, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 117.03384184837341
Validation after dual ascent:
out_inf: tensor(0.8760, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.1465, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.1437, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1294, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1257, device='cuda:0', dtype=torch.float16) tensor(0.0076, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.4922, device='cuda:0', dtype=torch.float16) tensor(0.8125, device='cuda:0', dtype=torch.float16)
tensor(2.4453, device='cuda:0', dtype=torch.float16) tensor(0.1846, device='cuda:0', dtype=torch.float16)
tensor(2.4688, device='cuda:0', dtype=torch.float16) tensor(0.1844, device='cuda:0', dtype=torch.float16)
tensor(2.6016, device='cuda:0', dtype=torch.float16) tensor(0.1837, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.1842, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0148, device='cuda:0')
tensor(0.1171, device='cuda:0')
old_score: tensor(0.1842, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1039, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.664803981781006
Validation after dual ascent:
out_inf: tensor(15.4922, device='cuda:0', dtype=torch.float16) tensor(0.8125, device='cuda:0', dtype=torch.float16)
tensor(1.2861, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(1.4160, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.2344, device='cuda:0', dtype=torch.float16) tensor(1.4443, device='cuda:0', dtype=torch.float16)
tensor(3.3906, device='cuda:0', dtype=torch.float16) tensor(0.2935, device='cuda:0', dtype=torch.float16)
tensor(4.3047, device='cuda:0', dtype=torch.float16) tensor(0.2935, device='cuda:0', dtype=torch.float16)
tensor(3.9766, device='cuda:0', dtype=torch.float16) tensor(0.2966, device='cuda:0', dtype=torch.float16)
tensor(3.8281, device='cuda:0', dtype=torch.float16) tensor(0.2935, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0184, device='cuda:0')
tensor(0.1765, device='cuda:0')
old_score: tensor(0.2944, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1597, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.973020076751709
Validation after dual ascent:
out_inf: tensor(19.2344, device='cuda:0', dtype=torch.float16) tensor(1.4443, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.1606, device='cuda:0', dtype=torch.float16)
tensor(1.7627, device='cuda:0', dtype=torch.float16) tensor(0.1670, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(1.6270, device='cuda:0', dtype=torch.float16) tensor(0.1586, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3359, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0677, device='cuda:0', dtype=torch.float16)
tensor(0.7764, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0050, device='cuda:0')
tensor(0.1280, device='cuda:0')
old_score: tensor(0.0667, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0430, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7867698669433594
Validation after dual ascent:
out_inf: tensor(2.3359, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
tensor(0.3765, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.3533, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.3828, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.3828, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.3716, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1733, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2192, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0189, device='cuda:0')
tensor(0.0337, device='cuda:0')
old_score: tensor(0.0095, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0056, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.140625953674316
Validation after dual ascent:
out_inf: tensor(1.3828, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.2168, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.1548, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.1392, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.1455, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.3926, device='cuda:0', dtype=torch.float16) tensor(0.2974, device='cuda:0', dtype=torch.float16)
tensor(2.1758, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(2.0586, device='cuda:0', dtype=torch.float16) tensor(0.1015, device='cuda:0', dtype=torch.float16)
tensor(0.0902, device='cuda:0')
old_score: tensor(0.1033, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0627, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.50957655906677
Validation after dual ascent:
out_inf: tensor(3.3926, device='cuda:0', dtype=torch.float16) tensor(0.2974, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(1.2129, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(0.9971, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.8770, device='cuda:0', dtype=torch.float16) tensor(0.1296, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(1.0752, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0727, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(0.0590, device='cuda:0')
old_score: tensor(0.0718, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0466, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.554465532302856
Validation after dual ascent:
out_inf: tensor(3.8770, device='cuda:0', dtype=torch.float16) tensor(0.1296, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.6392, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.5869, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.8765, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(0.2136, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.1812, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1802, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.2051, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0146, device='cuda:0')
tensor(0.0359, device='cuda:0')
old_score: tensor(0.0124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0084, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 149.08875012397766
Validation after dual ascent:
out_inf: tensor(0.8765, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(0.1195, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1294, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1152, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.1504, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.7109, device='cuda:0', dtype=torch.float16) tensor(0.7578, device='cuda:0', dtype=torch.float16)
tensor(3.9766, device='cuda:0', dtype=torch.float16) tensor(0.2040, device='cuda:0', dtype=torch.float16)
tensor(3.6328, device='cuda:0', dtype=torch.float16) tensor(0.2007, device='cuda:0', dtype=torch.float16)
tensor(2.8984, device='cuda:0', dtype=torch.float16) tensor(0.1948, device='cuda:0', dtype=torch.float16)
tensor(3.6016, device='cuda:0', dtype=torch.float16) tensor(0.1987, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0157, device='cuda:0')
tensor(0.0556, device='cuda:0')
old_score: tensor(0.1996, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1100, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.671519041061401
Validation after dual ascent:
out_inf: tensor(15.7109, device='cuda:0', dtype=torch.float16) tensor(0.7578, device='cuda:0', dtype=torch.float16)
tensor(2.3125, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
tensor(1.4121, device='cuda:0', dtype=torch.float16) tensor(0.1131, device='cuda:0', dtype=torch.float16)
tensor(1.3955, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
tensor(1.9512, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.5156, device='cuda:0', dtype=torch.float16) tensor(1.4658, device='cuda:0', dtype=torch.float16)
tensor(3.9609, device='cuda:0', dtype=torch.float16) tensor(0.3345, device='cuda:0', dtype=torch.float16)
tensor(3.6484, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(3.6406, device='cuda:0', dtype=torch.float16) tensor(0.3203, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0185, device='cuda:0')
tensor(0.0537, device='cuda:0')
old_score: tensor(0.3267, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1676, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1668031215667725
Validation after dual ascent:
out_inf: tensor(17.5156, device='cuda:0', dtype=torch.float16) tensor(1.4658, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1707, device='cuda:0', dtype=torch.float16)
tensor(1.6904, device='cuda:0', dtype=torch.float16) tensor(0.1726, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1604, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.2324, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
tensor(0.6787, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0055, device='cuda:0')
tensor(0.1233, device='cuda:0')
old_score: tensor(0.0745, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0477, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7907028198242188
Validation after dual ascent:
out_inf: tensor(2.2324, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(0.4131, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.3916, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.8174, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.2871, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.2549, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.2285, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.2134, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0188, device='cuda:0')
tensor(0.0286, device='cuda:0')
old_score: tensor(0.0113, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0065, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.301635026931763
Validation after dual ascent:
out_inf: tensor(1.8174, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.1729, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.1318, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.1826, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.1953, device='cuda:0', dtype=torch.float16) tensor(0.3125, device='cuda:0', dtype=torch.float16)
tensor(2.5332, device='cuda:0', dtype=torch.float16) tensor(0.1057, device='cuda:0', dtype=torch.float16)
tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.1015, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(2.1328, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0166, device='cuda:0')
tensor(0.1511, device='cuda:0')
old_score: tensor(0.1031, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0651, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.225637197494507
Validation after dual ascent:
out_inf: tensor(6.1953, device='cuda:0', dtype=torch.float16) tensor(0.3125, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(1.0889, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(1.4395, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9648, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(1.3828, device='cuda:0', dtype=torch.float16) tensor(0.0758, device='cuda:0', dtype=torch.float16)
tensor(1.3340, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(1.0654, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0070, device='cuda:0')
tensor(0.1026, device='cuda:0')
old_score: tensor(0.0743, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0488, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.229308605194092
Validation after dual ascent:
out_inf: tensor(4.9648, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
tensor(0.4658, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.2441, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.2189, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.2556, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.3037, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0183, device='cuda:0')
tensor(0.0434, device='cuda:0')
old_score: tensor(0.0126, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0087, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 116.96429967880249
Validation after dual ascent:
out_inf: tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.1482, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1614, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1268, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1431, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.6562, device='cuda:0', dtype=torch.float16) tensor(0.7446, device='cuda:0', dtype=torch.float16)
tensor(3.9531, device='cuda:0', dtype=torch.float16) tensor(0.2097, device='cuda:0', dtype=torch.float16)
tensor(3.2109, device='cuda:0', dtype=torch.float16) tensor(0.2017, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.1973, device='cuda:0', dtype=torch.float16)
tensor(3.7109, device='cuda:0', dtype=torch.float16) tensor(0.2054, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0144, device='cuda:0')
tensor(0.0556, device='cuda:0')
old_score: tensor(0.2035, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1073, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.651269197463989
Validation after dual ascent:
out_inf: tensor(16.6562, device='cuda:0', dtype=torch.float16) tensor(0.7446, device='cuda:0', dtype=torch.float16)
tensor(1.4248, device='cuda:0', dtype=torch.float16) tensor(0.1109, device='cuda:0', dtype=torch.float16)
tensor(1.4502, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(1.3721, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.2891, device='cuda:0', dtype=torch.float16) tensor(1.4795, device='cuda:0', dtype=torch.float16)
tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.3669, device='cuda:0', dtype=torch.float16)
tensor(4.3906, device='cuda:0', dtype=torch.float16) tensor(0.3618, device='cuda:0', dtype=torch.float16)
tensor(4., device='cuda:0', dtype=torch.float16) tensor(0.3545, device='cuda:0', dtype=torch.float16)
tensor(3.9922, device='cuda:0', dtype=torch.float16) tensor(0.3606, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0181, device='cuda:0')
tensor(0.0603, device='cuda:0')
old_score: tensor(0.3608, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1733, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1624011993408203
Validation after dual ascent:
out_inf: tensor(15.2891, device='cuda:0', dtype=torch.float16) tensor(1.4795, device='cuda:0', dtype=torch.float16)
tensor(1.9346, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(1.7607, device='cuda:0', dtype=torch.float16) tensor(0.1714, device='cuda:0', dtype=torch.float16)
tensor(1.6973, device='cuda:0', dtype=torch.float16) tensor(0.1660, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1769, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.4102, device='cuda:0', dtype=torch.float16) tensor(0.1692, device='cuda:0', dtype=torch.float16)
tensor(0.7764, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(0.7251, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(0.7041, device='cuda:0', dtype=torch.float16) tensor(0.0772, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0794, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0056, device='cuda:0')
tensor(0.1226, device='cuda:0')
old_score: tensor(0.0792, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0486, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7880852222442627
Validation after dual ascent:
out_inf: tensor(2.4102, device='cuda:0', dtype=torch.float16) tensor(0.1692, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.4048, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.3997, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4761, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.3379, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.2871, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.2402, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.2686, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.0158, device='cuda:0')
old_score: tensor(0.0131, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0073, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.790220975875854
Validation after dual ascent:
out_inf: tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.1812, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1680, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.1387, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.1611, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.9375, device='cuda:0', dtype=torch.float16) tensor(0.3169, device='cuda:0', dtype=torch.float16)
tensor(1.8574, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
tensor(1.7695, device='cuda:0', dtype=torch.float16) tensor(0.0977, device='cuda:0', dtype=torch.float16)
tensor(1.5020, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0168, device='cuda:0')
tensor(0.0663, device='cuda:0')
old_score: tensor(0.0994, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0632, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.209440231323242
Validation after dual ascent:
out_inf: tensor(3.9375, device='cuda:0', dtype=torch.float16) tensor(0.3169, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.9326, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.9873, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.8320, device='cuda:0', dtype=torch.float16) tensor(0.1464, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(1.9570, device='cuda:0', dtype=torch.float16) tensor(0.0738, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.0738, device='cuda:0', dtype=torch.float16)
tensor(1.0605, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0070, device='cuda:0')
tensor(0.0504, device='cuda:0')
old_score: tensor(0.0745, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0491, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.209396362304688
Validation after dual ascent:
out_inf: tensor(7.8320, device='cuda:0', dtype=torch.float16) tensor(0.1464, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.6826, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.6279, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.8384, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.3188, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0110, device='cuda:0')
tensor(0.0210, device='cuda:0')
old_score: tensor(0.0132, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0090, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 149.08996772766113
Validation after dual ascent:
out_inf: tensor(0.8384, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.1543, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1558, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1777, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1523, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.8125, device='cuda:0', dtype=torch.float16) tensor(0.7324, device='cuda:0', dtype=torch.float16)
tensor(3.8516, device='cuda:0', dtype=torch.float16) tensor(0.2084, device='cuda:0', dtype=torch.float16)
tensor(4.6328, device='cuda:0', dtype=torch.float16) tensor(0.1978, device='cuda:0', dtype=torch.float16)
tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.1917, device='cuda:0', dtype=torch.float16)
tensor(4.3984, device='cuda:0', dtype=torch.float16) tensor(0.2030, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0136, device='cuda:0')
tensor(0.1015, device='cuda:0')
old_score: tensor(0.2002, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1136, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.6647117137908936
Validation after dual ascent:
out_inf: tensor(13.8125, device='cuda:0', dtype=torch.float16) tensor(0.7324, device='cuda:0', dtype=torch.float16)
tensor(1.6982, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
tensor(1.8018, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(1.7285, device='cuda:0', dtype=torch.float16) tensor(0.1161, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.2812, device='cuda:0', dtype=torch.float16) tensor(1.5957, device='cuda:0', dtype=torch.float16)
tensor(4.2812, device='cuda:0', dtype=torch.float16) tensor(0.3645, device='cuda:0', dtype=torch.float16)
tensor(4.1406, device='cuda:0', dtype=torch.float16) tensor(0.3428, device='cuda:0', dtype=torch.float16)
tensor(3.9688, device='cuda:0', dtype=torch.float16) tensor(0.3381, device='cuda:0', dtype=torch.float16)
tensor(4.0781, device='cuda:0', dtype=torch.float16) tensor(0.3582, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0184, device='cuda:0')
tensor(0.0955, device='cuda:0')
old_score: tensor(0.3508, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1785, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1622741222381592
Validation after dual ascent:
out_inf: tensor(16.2812, device='cuda:0', dtype=torch.float16) tensor(1.5957, device='cuda:0', dtype=torch.float16)
tensor(1.8760, device='cuda:0', dtype=torch.float16) tensor(0.1874, device='cuda:0', dtype=torch.float16)
tensor(1.8945, device='cuda:0', dtype=torch.float16) tensor(0.1749, device='cuda:0', dtype=torch.float16)
tensor(1.8223, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1825, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(0.8306, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.8408, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(0.8228, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(0.7104, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0062, device='cuda:0')
tensor(0.1561, device='cuda:0')
old_score: tensor(0.0828, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0523, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7880280017852783
Validation after dual ascent:
out_inf: tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.4829, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.4990, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.3555, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.3564, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.2129, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.2412, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.2676, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.0207, device='cuda:0')
old_score: tensor(0.0130, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.82451319694519
Validation after dual ascent:
out_inf: tensor(2.3555, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.1621, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.1445, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.1475, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.3926, device='cuda:0', dtype=torch.float16) tensor(0.3025, device='cuda:0', dtype=torch.float16)
tensor(2.3145, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
tensor(2.2051, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.0959, device='cuda:0', dtype=torch.float16)
tensor(1.8320, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0195, device='cuda:0')
tensor(0.0509, device='cuda:0')
old_score: tensor(0.0983, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0635, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 42.19293665885925
Validation after dual ascent:
out_inf: tensor(3.3926, device='cuda:0', dtype=torch.float16) tensor(0.3025, device='cuda:0', dtype=torch.float16)
tensor(0.9502, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.9829, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(0.9146, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.8940, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.6992, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
tensor(1.6055, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.0749, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(1.2666, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0132, device='cuda:0')
tensor(0.0729, device='cuda:0')
old_score: tensor(0.0743, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0492, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.243855476379395
Validation after dual ascent:
out_inf: tensor(6.6992, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.5796, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
tensor(0.3662, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.3379, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.4961, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0158, device='cuda:0')
tensor(0.0368, device='cuda:0')
old_score: tensor(0.0126, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 149.18353247642517
Validation after dual ascent:
out_inf: tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.1616, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1709, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1846, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.1665, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.4609, device='cuda:0', dtype=torch.float16) tensor(0.7598, device='cuda:0', dtype=torch.float16)
tensor(4.7500, device='cuda:0', dtype=torch.float16) tensor(0.2207, device='cuda:0', dtype=torch.float16)
tensor(5.0391, device='cuda:0', dtype=torch.float16) tensor(0.2136, device='cuda:0', dtype=torch.float16)
tensor(4.3086, device='cuda:0', dtype=torch.float16) tensor(0.2039, device='cuda:0', dtype=torch.float16)
tensor(4.6406, device='cuda:0', dtype=torch.float16) tensor(0.2162, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0139, device='cuda:0')
tensor(0.1048, device='cuda:0')
old_score: tensor(0.2136, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1155, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.669763088226318
Validation after dual ascent:
out_inf: tensor(15.4609, device='cuda:0', dtype=torch.float16) tensor(0.7598, device='cuda:0', dtype=torch.float16)
tensor(1.9248, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.8809, device='cuda:0', dtype=torch.float16) tensor(0.1128, device='cuda:0', dtype=torch.float16)
tensor(1.7861, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(1.7871, device='cuda:0', dtype=torch.float16) tensor(0.1188, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.k_proj
Validation after prune:
out_inf: tensor(14.2188, device='cuda:0', dtype=torch.float16) tensor(1.5059, device='cuda:0', dtype=torch.float16)
tensor(3.7598, device='cuda:0', dtype=torch.float16) tensor(0.3594, device='cuda:0', dtype=torch.float16)
tensor(3.3906, device='cuda:0', dtype=torch.float16) tensor(0.3452, device='cuda:0', dtype=torch.float16)
tensor(3.2812, device='cuda:0', dtype=torch.float16) tensor(0.3308, device='cuda:0', dtype=torch.float16)
tensor(3.6172, device='cuda:0', dtype=torch.float16) tensor(0.3550, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0179, device='cuda:0')
tensor(0.1008, device='cuda:0')
old_score: tensor(0.3477, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1809, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1634626388549805
Validation after dual ascent:
out_inf: tensor(14.2188, device='cuda:0', dtype=torch.float16) tensor(1.5059, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1902, device='cuda:0', dtype=torch.float16)
tensor(1.8760, device='cuda:0', dtype=torch.float16) tensor(0.1764, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.1704, device='cuda:0', dtype=torch.float16)
tensor(2.0410, device='cuda:0', dtype=torch.float16) tensor(0.1866, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3672, device='cuda:0', dtype=torch.float16) tensor(0.1901, device='cuda:0', dtype=torch.float16)
tensor(1.0850, device='cuda:0', dtype=torch.float16) tensor(0.0982, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0075, device='cuda:0')
tensor(0.1859, device='cuda:0')
old_score: tensor(0.0970, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0608, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.788109302520752
Validation after dual ascent:
out_inf: tensor(2.3672, device='cuda:0', dtype=torch.float16) tensor(0.1901, device='cuda:0', dtype=torch.float16)
tensor(0.7993, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(0.7920, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.7168, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.8643, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.7090, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.4004, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.4736, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
tensor(0.0211, device='cuda:0')
old_score: tensor(0.0173, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0093, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.861560821533203
Validation after dual ascent:
out_inf: tensor(2.7090, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.2715, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.2090, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.3203, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.2773, device='cuda:0', dtype=torch.float16) tensor(0.3318, device='cuda:0', dtype=torch.float16)
tensor(2.0215, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(1.7930, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(2.1602, device='cuda:0', dtype=torch.float16) tensor(0.0973, device='cuda:0', dtype=torch.float16)
tensor(1.9785, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0185, device='cuda:0')
tensor(0.0195, device='cuda:0')
old_score: tensor(0.1014, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0623, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.693760633468628
Validation after dual ascent:
out_inf: tensor(4.2773, device='cuda:0', dtype=torch.float16) tensor(0.3318, device='cuda:0', dtype=torch.float16)
tensor(0.9893, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(1.0713, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.5781, device='cuda:0', dtype=torch.float16) tensor(0.1503, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(1.1670, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(1.3926, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
tensor(1.1006, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0085, device='cuda:0')
tensor(0.0440, device='cuda:0')
old_score: tensor(0.0761, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0483, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.240205764770508
Validation after dual ascent:
out_inf: tensor(3.5781, device='cuda:0', dtype=torch.float16) tensor(0.1503, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.5420, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0029, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.4619, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3838, device='cuda:0', dtype=torch.float16) tensor(0.0124, device='cuda:0', dtype=torch.float16)
tensor(0.4404, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.0571, device='cuda:0')
old_score: tensor(0.0132, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0085, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.94574642181396
Validation after dual ascent:
out_inf: tensor(1.0029, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.1819, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1602, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1807, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1960, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(0.7632, device='cuda:0', dtype=torch.float16)
tensor(4.4453, device='cuda:0', dtype=torch.float16) tensor(0.2303, device='cuda:0', dtype=torch.float16)
tensor(3.8125, device='cuda:0', dtype=torch.float16) tensor(0.2214, device='cuda:0', dtype=torch.float16)
tensor(3.3594, device='cuda:0', dtype=torch.float16) tensor(0.2103, device='cuda:0', dtype=torch.float16)
tensor(4.6875, device='cuda:0', dtype=torch.float16) tensor(0.2271, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0153, device='cuda:0')
tensor(0.1633, device='cuda:0')
old_score: tensor(0.2223, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1208, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.668926954269409
Validation after dual ascent:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(0.7632, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.9375, device='cuda:0', dtype=torch.float16) tensor(0.1192, device='cuda:0', dtype=torch.float16)
tensor(1.5977, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(2.1113, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.k_proj
Validation after prune:
out_inf: tensor(14.9531, device='cuda:0', dtype=torch.float16) tensor(1.5547, device='cuda:0', dtype=torch.float16)
tensor(5.0078, device='cuda:0', dtype=torch.float16) tensor(0.3889, device='cuda:0', dtype=torch.float16)
tensor(3.8828, device='cuda:0', dtype=torch.float16) tensor(0.3730, device='cuda:0', dtype=torch.float16)
tensor(3.5703, device='cuda:0', dtype=torch.float16) tensor(0.3552, device='cuda:0', dtype=torch.float16)
tensor(4.2969, device='cuda:0', dtype=torch.float16) tensor(0.3816, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0194, device='cuda:0')
tensor(0.1512, device='cuda:0')
old_score: tensor(0.3748, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1890, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1645467281341553
Validation after dual ascent:
out_inf: tensor(14.9531, device='cuda:0', dtype=torch.float16) tensor(1.5547, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1986, device='cuda:0', dtype=torch.float16)
tensor(1.9775, device='cuda:0', dtype=torch.float16) tensor(0.1863, device='cuda:0', dtype=torch.float16)
tensor(1.8193, device='cuda:0', dtype=torch.float16) tensor(0.1774, device='cuda:0', dtype=torch.float16)
tensor(1.8682, device='cuda:0', dtype=torch.float16) tensor(0.1940, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.1367, device='cuda:0', dtype=torch.float16) tensor(0.1849, device='cuda:0', dtype=torch.float16)
tensor(0.9004, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(0.9717, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(0.8838, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
tensor(0.9224, device='cuda:0', dtype=torch.float16) tensor(0.0905, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0069, device='cuda:0')
tensor(0.1868, device='cuda:0')
old_score: tensor(0.0892, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0553, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7898566722869873
Validation after dual ascent:
out_inf: tensor(2.1367, device='cuda:0', dtype=torch.float16) tensor(0.1849, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.6890, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.5771, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.9961, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.4541, device='cuda:0', dtype=torch.float16) tensor(0.0185, device='cuda:0', dtype=torch.float16)
tensor(0.4229, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.3730, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.0196, device='cuda:0')
old_score: tensor(0.0174, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0094, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.862690925598145
Validation after dual ascent:
out_inf: tensor(2.9961, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.2256, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.2373, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.8223, device='cuda:0', dtype=torch.float16) tensor(0.3245, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(1.7402, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(1.5879, device='cuda:0', dtype=torch.float16) tensor(0.1022, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0194, device='cuda:0')
tensor(0.0203, device='cuda:0')
old_score: tensor(0.1016, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0620, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.703746557235718
Validation after dual ascent:
out_inf: tensor(3.8223, device='cuda:0', dtype=torch.float16) tensor(0.3245, device='cuda:0', dtype=torch.float16)
tensor(0.9536, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.0617, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.up_proj
Validation after prune:
out_inf: tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.1558, device='cuda:0', dtype=torch.float16)
tensor(1.5898, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.0785, device='cuda:0', dtype=torch.float16)
tensor(1.1582, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0093, device='cuda:0')
tensor(0.0463, device='cuda:0')
old_score: tensor(0.0787, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0500, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.249340295791626
Validation after dual ascent:
out_inf: tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.1558, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.6611, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0928, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.4424, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.3828, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.4541, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.0582, device='cuda:0')
old_score: tensor(0.0138, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.9471151828766
Validation after dual ascent:
out_inf: tensor(1.0928, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1387, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1484, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1396, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.0781, device='cuda:0', dtype=torch.float16) tensor(0.7261, device='cuda:0', dtype=torch.float16)
tensor(3.8281, device='cuda:0', dtype=torch.float16) tensor(0.2257, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.2131, device='cuda:0', dtype=torch.float16)
tensor(3.1367, device='cuda:0', dtype=torch.float16) tensor(0.2035, device='cuda:0', dtype=torch.float16)
tensor(3.1797, device='cuda:0', dtype=torch.float16) tensor(0.2198, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0154, device='cuda:0')
tensor(0.1370, device='cuda:0')
old_score: tensor(0.2156, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1182, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.651776313781738
Validation after dual ascent:
out_inf: tensor(12.0781, device='cuda:0', dtype=torch.float16) tensor(0.7261, device='cuda:0', dtype=torch.float16)
tensor(1.8711, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.3574, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.4375, device='cuda:0', dtype=torch.float16) tensor(1.5264, device='cuda:0', dtype=torch.float16)
tensor(4.5703, device='cuda:0', dtype=torch.float16) tensor(0.4048, device='cuda:0', dtype=torch.float16)
tensor(4.0703, device='cuda:0', dtype=torch.float16) tensor(0.3809, device='cuda:0', dtype=torch.float16)
tensor(3.8906, device='cuda:0', dtype=torch.float16) tensor(0.3674, device='cuda:0', dtype=torch.float16)
tensor(4.4688, device='cuda:0', dtype=torch.float16) tensor(0.3909, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0197, device='cuda:0')
tensor(0.1363, device='cuda:0')
old_score: tensor(0.3860, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1931, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1617028713226318
Validation after dual ascent:
out_inf: tensor(16.4375, device='cuda:0', dtype=torch.float16) tensor(1.5264, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.2048, device='cuda:0', dtype=torch.float16)
tensor(1.9648, device='cuda:0', dtype=torch.float16) tensor(0.1902, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(1.9023, device='cuda:0', dtype=torch.float16) tensor(0.1975, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.1484, device='cuda:0', dtype=torch.float16) tensor(0.2081, device='cuda:0', dtype=torch.float16)
tensor(0.8643, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(1.0020, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0968, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0066, device='cuda:0')
tensor(0.1712, device='cuda:0')
old_score: tensor(0.0948, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0575, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7867748737335205
Validation after dual ascent:
out_inf: tensor(3.1484, device='cuda:0', dtype=torch.float16) tensor(0.2081, device='cuda:0', dtype=torch.float16)
tensor(0.5303, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.4810, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.6914, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.6064, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.4326, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.0180, device='cuda:0')
old_score: tensor(0.0186, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0090, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.777308940887451
Validation after dual ascent:
out_inf: tensor(2.6914, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1982, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1953, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.2793, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.3286, device='cuda:0', dtype=torch.float16)
tensor(2.5352, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(2.3320, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(3.4062, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0188, device='cuda:0')
tensor(0.0211, device='cuda:0')
old_score: tensor(0.1041, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0627, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.661802053451538
Validation after dual ascent:
out_inf: tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.3286, device='cuda:0', dtype=torch.float16)
tensor(1.4473, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(1.4961, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0639, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.5996, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0543, device='cuda:0')
old_score: tensor(0.0822, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0518, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.211638689041138
Validation after dual ascent:
out_inf: tensor(3.5996, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
tensor(0.6650, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.9751, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.4980, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.5732, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0197, device='cuda:0')
tensor(0.0456, device='cuda:0')
old_score: tensor(0.0148, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0095, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 148.7844443321228
Validation after dual ascent:
out_inf: tensor(0.9751, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
tensor(0.2434, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1858, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.2061, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.2883, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.7969, device='cuda:0', dtype=torch.float16) tensor(0.7368, device='cuda:0', dtype=torch.float16)
tensor(4.1172, device='cuda:0', dtype=torch.float16) tensor(0.2213, device='cuda:0', dtype=torch.float16)
tensor(3.6211, device='cuda:0', dtype=torch.float16) tensor(0.2032, device='cuda:0', dtype=torch.float16)
tensor(3.5078, device='cuda:0', dtype=torch.float16) tensor(0.1958, device='cuda:0', dtype=torch.float16)
tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.2117, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0182, device='cuda:0')
tensor(0.0716, device='cuda:0')
old_score: tensor(0.2080, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.65132474899292
Validation after dual ascent:
out_inf: tensor(14.7969, device='cuda:0', dtype=torch.float16) tensor(0.7368, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.1072, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.7969, device='cuda:0', dtype=torch.float16) tensor(1.3770, device='cuda:0', dtype=torch.float16)
tensor(5.1172, device='cuda:0', dtype=torch.float16) tensor(0.3811, device='cuda:0', dtype=torch.float16)
tensor(4.6016, device='cuda:0', dtype=torch.float16) tensor(0.3479, device='cuda:0', dtype=torch.float16)
tensor(4.4141, device='cuda:0', dtype=torch.float16) tensor(0.3347, device='cuda:0', dtype=torch.float16)
tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.3606, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0130, device='cuda:0')
tensor(0.0515, device='cuda:0')
old_score: tensor(0.3560, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1752, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3487098217010498
Validation after dual ascent:
out_inf: tensor(18.7969, device='cuda:0', dtype=torch.float16) tensor(1.3770, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.1903, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1694, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.1614, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3340, device='cuda:0', dtype=torch.float16) tensor(0.2065, device='cuda:0', dtype=torch.float16)
tensor(0.7529, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0072, device='cuda:0')
tensor(0.1613, device='cuda:0')
old_score: tensor(0.0990, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0613, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7873425483703613
Validation after dual ascent:
out_inf: tensor(2.3340, device='cuda:0', dtype=torch.float16) tensor(0.2065, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(0.4927, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.4980, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.3076, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.2803, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0136, device='cuda:0')
tensor(0.0298, device='cuda:0')
old_score: tensor(0.0195, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.164610624313354
Validation after dual ascent:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.1824, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1504, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.1475, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1829, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.8945, device='cuda:0', dtype=torch.float16) tensor(0.3225, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1040, device='cuda:0', dtype=torch.float16)
tensor(2.2012, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.0946, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0190, device='cuda:0')
tensor(0.0209, device='cuda:0')
old_score: tensor(0.0991, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0602, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.668744564056396
Validation after dual ascent:
out_inf: tensor(3.8945, device='cuda:0', dtype=torch.float16) tensor(0.3225, device='cuda:0', dtype=torch.float16)
tensor(1.2334, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(1.6191, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.9858, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1953, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(1.3857, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0098, device='cuda:0')
tensor(0.0515, device='cuda:0')
old_score: tensor(0.0804, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0516, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.207248449325562
Validation after dual ascent:
out_inf: tensor(4.1953, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(0.5576, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.5342, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.5479, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.7310, device='cuda:0', dtype=torch.float16) tensor(0.0366, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.4717, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
tensor(0.0375, device='cuda:0')
old_score: tensor(0.0153, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.69527125358582
Validation after dual ascent:
out_inf: tensor(0.7310, device='cuda:0', dtype=torch.float16) tensor(0.0366, device='cuda:0', dtype=torch.float16)
tensor(0.2183, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1816, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.2086, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.2129, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.0312, device='cuda:0', dtype=torch.float16) tensor(0.7656, device='cuda:0', dtype=torch.float16)
tensor(4.5078, device='cuda:0', dtype=torch.float16) tensor(0.2495, device='cuda:0', dtype=torch.float16)
tensor(3.8906, device='cuda:0', dtype=torch.float16) tensor(0.2336, device='cuda:0', dtype=torch.float16)
tensor(3.5781, device='cuda:0', dtype=torch.float16) tensor(0.2261, device='cuda:0', dtype=torch.float16)
tensor(3.8750, device='cuda:0', dtype=torch.float16) tensor(0.2448, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0151, device='cuda:0')
tensor(0.1948, device='cuda:0')
old_score: tensor(0.2384, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1278, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.654510498046875
Validation after dual ascent:
out_inf: tensor(14.0312, device='cuda:0', dtype=torch.float16) tensor(0.7656, device='cuda:0', dtype=torch.float16)
tensor(1.8496, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.1184, device='cuda:0', dtype=torch.float16)
tensor(1.6855, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.6094, device='cuda:0', dtype=torch.float16) tensor(1.6260, device='cuda:0', dtype=torch.float16)
tensor(4.0391, device='cuda:0', dtype=torch.float16) tensor(0.4324, device='cuda:0', dtype=torch.float16)
tensor(3.9570, device='cuda:0', dtype=torch.float16) tensor(0.4097, device='cuda:0', dtype=torch.float16)
tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.3921, device='cuda:0', dtype=torch.float16)
tensor(5.2812, device='cuda:0', dtype=torch.float16) tensor(0.4275, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0179, device='cuda:0')
tensor(0.1698, device='cuda:0')
old_score: tensor(0.4155, device='cuda:0', dtype=torch.float16) new_score: tensor(0.2057, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1637132167816162
Validation after dual ascent:
out_inf: tensor(17.6094, device='cuda:0', dtype=torch.float16) tensor(1.6260, device='cuda:0', dtype=torch.float16)
tensor(2.4336, device='cuda:0', dtype=torch.float16) tensor(0.2219, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1987, device='cuda:0', dtype=torch.float16)
tensor(1.9746, device='cuda:0', dtype=torch.float16) tensor(0.1908, device='cuda:0', dtype=torch.float16)
tensor(2.4707, device='cuda:0', dtype=torch.float16) tensor(0.2115, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.2010, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0073, device='cuda:0')
tensor(0.2046, device='cuda:0')
old_score: tensor(0.1023, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0645, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7927491664886475
Validation after dual ascent:
out_inf: tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.2010, device='cuda:0', dtype=torch.float16)
tensor(0.5576, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.5088, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.5581, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.5176, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.9414, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0196, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0148, device='cuda:0')
tensor(0.0310, device='cuda:0')
old_score: tensor(0.0216, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.059050559997559
Validation after dual ascent:
out_inf: tensor(3.9414, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.1895, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1689, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.2656, device='cuda:0', dtype=torch.float16) tensor(0.3352, device='cuda:0', dtype=torch.float16)
tensor(2.4395, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
tensor(2.2812, device='cuda:0', dtype=torch.float16) tensor(0.0951, device='cuda:0', dtype=torch.float16)
tensor(2.1914, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0194, device='cuda:0')
tensor(0.0222, device='cuda:0')
old_score: tensor(0.1021, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0621, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.650862693786621
Validation after dual ascent:
out_inf: tensor(5.2656, device='cuda:0', dtype=torch.float16) tensor(0.3352, device='cuda:0', dtype=torch.float16)
tensor(1.6533, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(1.3682, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(1.4316, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(1.3037, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.3125, device='cuda:0', dtype=torch.float16) tensor(0.1688, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
tensor(1.3789, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.0783, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0569, device='cuda:0')
old_score: tensor(0.0825, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0532, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.200141429901123
Validation after dual ascent:
out_inf: tensor(4.3125, device='cuda:0', dtype=torch.float16) tensor(0.1688, device='cuda:0', dtype=torch.float16)
tensor(0.7168, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(0.6206, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.6167, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.3921, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.4414, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.0353, device='cuda:0')
old_score: tensor(0.0160, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.17172813415527
Validation after dual ascent:
out_inf: tensor(0.6167, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.1748, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1897, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1382, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1377, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1172, device='cuda:0', dtype=torch.float16) tensor(0.7466, device='cuda:0', dtype=torch.float16)
tensor(4.1797, device='cuda:0', dtype=torch.float16) tensor(0.2372, device='cuda:0', dtype=torch.float16)
tensor(3.6406, device='cuda:0', dtype=torch.float16) tensor(0.2188, device='cuda:0', dtype=torch.float16)
tensor(3.6367, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(4.1289, device='cuda:0', dtype=torch.float16) tensor(0.2279, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0165, device='cuda:0')
tensor(0.1803, device='cuda:0')
old_score: tensor(0.2223, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1202, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.650826692581177
Validation after dual ascent:
out_inf: tensor(14.1172, device='cuda:0', dtype=torch.float16) tensor(0.7466, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1159, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.4316, device='cuda:0', dtype=torch.float16) tensor(0.1241, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.3594, device='cuda:0', dtype=torch.float16) tensor(1.5967, device='cuda:0', dtype=torch.float16)
tensor(5.7734, device='cuda:0', dtype=torch.float16) tensor(0.4089, device='cuda:0', dtype=torch.float16)
tensor(5., device='cuda:0', dtype=torch.float16) tensor(0.3748, device='cuda:0', dtype=torch.float16)
tensor(5.5000, device='cuda:0', dtype=torch.float16) tensor(0.3513, device='cuda:0', dtype=torch.float16)
tensor(5.3516, device='cuda:0', dtype=torch.float16) tensor(0.3928, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0133, device='cuda:0')
tensor(0.1219, device='cuda:0')
old_score: tensor(0.3818, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1913, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3480322360992432
Validation after dual ascent:
out_inf: tensor(21.3594, device='cuda:0', dtype=torch.float16) tensor(1.5967, device='cuda:0', dtype=torch.float16)
tensor(2.7422, device='cuda:0', dtype=torch.float16) tensor(0.2103, device='cuda:0', dtype=torch.float16)
tensor(2.1211, device='cuda:0', dtype=torch.float16) tensor(0.1841, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1731, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1979, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3730, device='cuda:0', dtype=torch.float16) tensor(0.2032, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0996, device='cuda:0', dtype=torch.float16)
tensor(0.7520, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(0.7432, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(0.8179, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0069, device='cuda:0')
tensor(0.1864, device='cuda:0')
old_score: tensor(0.0954, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0605, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7863364219665527
Validation after dual ascent:
out_inf: tensor(2.3730, device='cuda:0', dtype=torch.float16) tensor(0.2032, device='cuda:0', dtype=torch.float16)
tensor(0.6650, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.4546, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
tensor(0.5850, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.2246, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.5635, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0166, device='cuda:0')
tensor(0.0380, device='cuda:0')
old_score: tensor(0.0195, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.07373571395874
Validation after dual ascent:
out_inf: tensor(3.2246, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.2207, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1611, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.9688, device='cuda:0', dtype=torch.float16) tensor(0.3523, device='cuda:0', dtype=torch.float16)
tensor(2.1953, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
tensor(1.9131, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(2.1699, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0158, device='cuda:0')
tensor(0.0172, device='cuda:0')
old_score: tensor(0.1035, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0635, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.114808082580566
Validation after dual ascent:
out_inf: tensor(4.9688, device='cuda:0', dtype=torch.float16) tensor(0.3523, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(1.4316, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(1.5840, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(1.6035, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.1635, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
tensor(1.0732, device='cuda:0', dtype=torch.float16) tensor(0.0806, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.0783, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0821, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0098, device='cuda:0')
tensor(0.0600, device='cuda:0')
old_score: tensor(0.0817, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0530, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.227887630462646
Validation after dual ascent:
out_inf: tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.1635, device='cuda:0', dtype=torch.float16)
tensor(0.6294, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.7803, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.3965, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.3955, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.3848, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.3916, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.0473, device='cuda:0')
old_score: tensor(0.0159, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.10309028625488
Validation after dual ascent:
out_inf: tensor(0.7803, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.1689, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1521, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1538, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.6562, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.2428, device='cuda:0', dtype=torch.float16)
tensor(5.2109, device='cuda:0', dtype=torch.float16) tensor(0.2223, device='cuda:0', dtype=torch.float16)
tensor(4.6719, device='cuda:0', dtype=torch.float16) tensor(0.2107, device='cuda:0', dtype=torch.float16)
tensor(5.2500, device='cuda:0', dtype=torch.float16) tensor(0.2307, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0166, device='cuda:0')
tensor(0.1650, device='cuda:0')
old_score: tensor(0.2266, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1304, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.6537556648254395
Validation after dual ascent:
out_inf: tensor(16.6562, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.1438, device='cuda:0', dtype=torch.float16)
tensor(2.0410, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.8613, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(2.1797, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.3594, device='cuda:0', dtype=torch.float16) tensor(1.5723, device='cuda:0', dtype=torch.float16)
tensor(5.2109, device='cuda:0', dtype=torch.float16) tensor(0.3955, device='cuda:0', dtype=torch.float16)
tensor(4.8281, device='cuda:0', dtype=torch.float16) tensor(0.3533, device='cuda:0', dtype=torch.float16)
tensor(3.7812, device='cuda:0', dtype=torch.float16) tensor(0.3340, device='cuda:0', dtype=torch.float16)
tensor(4.5938, device='cuda:0', dtype=torch.float16) tensor(0.3708, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0178, device='cuda:0')
tensor(0.1362, device='cuda:0')
old_score: tensor(0.3635, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1975, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1645262241363525
Validation after dual ascent:
out_inf: tensor(19.3594, device='cuda:0', dtype=torch.float16) tensor(1.5723, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.2181, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.1895, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1786, device='cuda:0', dtype=torch.float16)
tensor(2.4531, device='cuda:0', dtype=torch.float16) tensor(0.2035, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.7715, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.1514, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(1.1455, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.0987, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0074, device='cuda:0')
tensor(0.1980, device='cuda:0')
old_score: tensor(0.0978, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0649, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7916817665100098
Validation after dual ascent:
out_inf: tensor(2.7715, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(0.7158, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(0.6548, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.6538, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.0508, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0166, device='cuda:0')
tensor(0.0389, device='cuda:0')
old_score: tensor(0.0216, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0127, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.5352783203125
Validation after dual ascent:
out_inf: tensor(4.0508, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.3008, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.2168, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.3320, device='cuda:0', dtype=torch.float16) tensor(0.3625, device='cuda:0', dtype=torch.float16)
tensor(2.8301, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(3.3613, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(3.2520, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.1095, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0151, device='cuda:0')
tensor(0.0171, device='cuda:0')
old_score: tensor(0.1099, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0679, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.10105013847351
Validation after dual ascent:
out_inf: tensor(6.3320, device='cuda:0', dtype=torch.float16) tensor(0.3625, device='cuda:0', dtype=torch.float16)
tensor(1.7676, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(2.1602, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(1.4902, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1250, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(1.6191, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(1.7539, device='cuda:0', dtype=torch.float16) tensor(0.0804, device='cuda:0', dtype=torch.float16)
tensor(1.8711, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0095, device='cuda:0')
tensor(0.0740, device='cuda:0')
old_score: tensor(0.0834, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0549, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.212197303771973
Validation after dual ascent:
out_inf: tensor(4.1250, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.6558, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(0.6235, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.7363, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.3301, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.3423, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.3418, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0152, device='cuda:0')
tensor(0.0357, device='cuda:0')
old_score: tensor(0.0164, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 148.28008270263672
Validation after dual ascent:
out_inf: tensor(0.7363, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.1709, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1934, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1680, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1742, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.4141, device='cuda:0', dtype=torch.float16) tensor(0.7412, device='cuda:0', dtype=torch.float16)
tensor(3.8320, device='cuda:0', dtype=torch.float16) tensor(0.2180, device='cuda:0', dtype=torch.float16)
tensor(3.3398, device='cuda:0', dtype=torch.float16) tensor(0.1932, device='cuda:0', dtype=torch.float16)
tensor(3.0391, device='cuda:0', dtype=torch.float16) tensor(0.1859, device='cuda:0', dtype=torch.float16)
tensor(3.4141, device='cuda:0', dtype=torch.float16) tensor(0.2031, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0172, device='cuda:0')
tensor(0.1685, device='cuda:0')
old_score: tensor(0.2001, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1164, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.645236253738403
Validation after dual ascent:
out_inf: tensor(14.4141, device='cuda:0', dtype=torch.float16) tensor(0.7412, device='cuda:0', dtype=torch.float16)
tensor(1.8242, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.4980, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.1199, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.6562, device='cuda:0', dtype=torch.float16) tensor(1.5186, device='cuda:0', dtype=torch.float16)
tensor(5.3672, device='cuda:0', dtype=torch.float16) tensor(0.3540, device='cuda:0', dtype=torch.float16)
tensor(4.9219, device='cuda:0', dtype=torch.float16) tensor(0.3108, device='cuda:0', dtype=torch.float16)
tensor(4.2188, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(5.4531, device='cuda:0', dtype=torch.float16) tensor(0.3257, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0193, device='cuda:0')
tensor(0.1374, device='cuda:0')
old_score: tensor(0.3228, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1772, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1592166423797607
Validation after dual ascent:
out_inf: tensor(20.6562, device='cuda:0', dtype=torch.float16) tensor(1.5186, device='cuda:0', dtype=torch.float16)
tensor(2.3086, device='cuda:0', dtype=torch.float16) tensor(0.1975, device='cuda:0', dtype=torch.float16)
tensor(1.7666, device='cuda:0', dtype=torch.float16) tensor(0.1686, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.1599, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1827, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.2129, device='cuda:0', dtype=torch.float16) tensor(0.1871, device='cuda:0', dtype=torch.float16)
tensor(0.7446, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(0.6978, device='cuda:0', dtype=torch.float16) tensor(0.0808, device='cuda:0', dtype=torch.float16)
tensor(0.6880, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.6616, device='cuda:0', dtype=torch.float16) tensor(0.0835, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0062, device='cuda:0')
tensor(0.1565, device='cuda:0')
old_score: tensor(0.0830, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0551, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7864024639129639
Validation after dual ascent:
out_inf: tensor(2.2129, device='cuda:0', dtype=torch.float16) tensor(0.1871, device='cuda:0', dtype=torch.float16)
tensor(0.5684, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.4578, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.4993, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.5161, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.3906, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.6143, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.5225, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.5400, device='cuda:0', dtype=torch.float16) tensor(0.0196, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0195, device='cuda:0')
tensor(0.0378, device='cuda:0')
old_score: tensor(0.0191, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.177024841308594
Validation after dual ascent:
out_inf: tensor(4.3906, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.2227, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.2051, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1943, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1885, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.0352, device='cuda:0', dtype=torch.float16) tensor(0.3516, device='cuda:0', dtype=torch.float16)
tensor(2.9922, device='cuda:0', dtype=torch.float16) tensor(0.1184, device='cuda:0', dtype=torch.float16)
tensor(2.9727, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(2.8125, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(3.1055, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0136, device='cuda:0')
tensor(0.0158, device='cuda:0')
old_score: tensor(0.1117, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0711, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.102102994918823
Validation after dual ascent:
out_inf: tensor(7.0352, device='cuda:0', dtype=torch.float16) tensor(0.3516, device='cuda:0', dtype=torch.float16)
tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0785, device='cuda:0', dtype=torch.float16)
tensor(2.1211, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(1.7930, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(1.5371, device='cuda:0', dtype=torch.float16) tensor(0.0727, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.9023, device='cuda:0', dtype=torch.float16) tensor(0.1570, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(2.0352, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(1.2998, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0084, device='cuda:0')
tensor(0.0759, device='cuda:0')
old_score: tensor(0.0820, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0553, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.214907169342041
Validation after dual ascent:
out_inf: tensor(3.9023, device='cuda:0', dtype=torch.float16) tensor(0.1570, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.4346, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0134, device='cuda:0')
tensor(0.0231, device='cuda:0')
old_score: tensor(0.0156, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 148.20885133743286
Validation after dual ascent:
out_inf: tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.1538, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1455, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1621, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1904, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.9688, device='cuda:0', dtype=torch.float16) tensor(0.7607, device='cuda:0', dtype=torch.float16)
tensor(4.2188, device='cuda:0', dtype=torch.float16) tensor(0.2231, device='cuda:0', dtype=torch.float16)
tensor(3.7812, device='cuda:0', dtype=torch.float16) tensor(0.2025, device='cuda:0', dtype=torch.float16)
tensor(3.2695, device='cuda:0', dtype=torch.float16) tensor(0.1937, device='cuda:0', dtype=torch.float16)
tensor(3.7266, device='cuda:0', dtype=torch.float16) tensor(0.2101, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0177, device='cuda:0')
tensor(0.1798, device='cuda:0')
old_score: tensor(0.2074, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1202, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.652924060821533
Validation after dual ascent:
out_inf: tensor(16.9688, device='cuda:0', dtype=torch.float16) tensor(0.7607, device='cuda:0', dtype=torch.float16)
tensor(1.8779, device='cuda:0', dtype=torch.float16) tensor(0.1334, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.7344, device='cuda:0', dtype=torch.float16) tensor(1.4951, device='cuda:0', dtype=torch.float16)
tensor(4.7109, device='cuda:0', dtype=torch.float16) tensor(0.3540, device='cuda:0', dtype=torch.float16)
tensor(4.6328, device='cuda:0', dtype=torch.float16) tensor(0.3206, device='cuda:0', dtype=torch.float16)
tensor(4.3164, device='cuda:0', dtype=torch.float16) tensor(0.3069, device='cuda:0', dtype=torch.float16)
tensor(4.3828, device='cuda:0', dtype=torch.float16) tensor(0.3342, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0177, device='cuda:0')
tensor(0.1407, device='cuda:0')
old_score: tensor(0.3289, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1818, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1619279384613037
Validation after dual ascent:
out_inf: tensor(19.7344, device='cuda:0', dtype=torch.float16) tensor(1.4951, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.2013, device='cuda:0', dtype=torch.float16)
tensor(1.8867, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(1.6924, device='cuda:0', dtype=torch.float16) tensor(0.1659, device='cuda:0', dtype=torch.float16)
tensor(2.2246, device='cuda:0', dtype=torch.float16) tensor(0.1865, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.4746, device='cuda:0', dtype=torch.float16) tensor(0.1730, device='cuda:0', dtype=torch.float16)
tensor(0.9814, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
tensor(0.9443, device='cuda:0', dtype=torch.float16) tensor(0.0901, device='cuda:0', dtype=torch.float16)
tensor(0.9287, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0072, device='cuda:0')
tensor(0.1965, device='cuda:0')
old_score: tensor(0.0930, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0635, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7902193069458008
Validation after dual ascent:
out_inf: tensor(2.4746, device='cuda:0', dtype=torch.float16) tensor(0.1730, device='cuda:0', dtype=torch.float16)
tensor(0.6450, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
tensor(0.6279, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.2031, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.0195, device='cuda:0')
old_score: tensor(0.0169, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0092, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.810190677642822
Validation after dual ascent:
out_inf: tensor(4.2031, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.2871, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.2328, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.2168, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.2402, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.1484, device='cuda:0', dtype=torch.float16) tensor(0.3584, device='cuda:0', dtype=torch.float16)
tensor(2.9805, device='cuda:0', dtype=torch.float16) tensor(0.1203, device='cuda:0', dtype=torch.float16)
tensor(3.3398, device='cuda:0', dtype=torch.float16) tensor(0.1102, device='cuda:0', dtype=torch.float16)
tensor(2.6211, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(2.4941, device='cuda:0', dtype=torch.float16) tensor(0.1110, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0136, device='cuda:0')
tensor(0.0157, device='cuda:0')
old_score: tensor(0.1124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0709, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.102522373199463
Validation after dual ascent:
out_inf: tensor(8.1484, device='cuda:0', dtype=torch.float16) tensor(0.3584, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.0791, device='cuda:0', dtype=torch.float16)
tensor(2.4922, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(2.1797, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.5156, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(1.2676, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(1.0879, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(1.4277, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0084, device='cuda:0')
tensor(0.0728, device='cuda:0')
old_score: tensor(0.0815, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0544, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.23976755142212
Validation after dual ascent:
out_inf: tensor(3.5156, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.8110, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.4541, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.4146, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.3894, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0180, device='cuda:0')
tensor(0.0366, device='cuda:0')
old_score: tensor(0.0161, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 116.8438811302185
Validation after dual ascent:
out_inf: tensor(0.8110, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.1909, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1732, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.7124, device='cuda:0', dtype=torch.float16)
tensor(3.6016, device='cuda:0', dtype=torch.float16) tensor(0.2014, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.1840, device='cuda:0', dtype=torch.float16)
tensor(3.8047, device='cuda:0', dtype=torch.float16) tensor(0.1763, device='cuda:0', dtype=torch.float16)
tensor(3.1953, device='cuda:0', dtype=torch.float16) tensor(0.1879, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0176, device='cuda:0')
tensor(0.1540, device='cuda:0')
old_score: tensor(0.1874, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1111, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.647011756896973
Validation after dual ascent:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.7124, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.1057, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1004, device='cuda:0', dtype=torch.float16)
tensor(1.6865, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.7969, device='cuda:0', dtype=torch.float16) tensor(1.4951, device='cuda:0', dtype=torch.float16)
tensor(3.9297, device='cuda:0', dtype=torch.float16) tensor(0.3306, device='cuda:0', dtype=torch.float16)
tensor(4.0703, device='cuda:0', dtype=torch.float16) tensor(0.2966, device='cuda:0', dtype=torch.float16)
tensor(3.5156, device='cuda:0', dtype=torch.float16) tensor(0.2861, device='cuda:0', dtype=torch.float16)
tensor(3.8672, device='cuda:0', dtype=torch.float16) tensor(0.3069, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0192, device='cuda:0')
tensor(0.1224, device='cuda:0')
old_score: tensor(0.3049, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1726, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.1588466167449951
Validation after dual ascent:
out_inf: tensor(19.7969, device='cuda:0', dtype=torch.float16) tensor(1.4951, device='cuda:0', dtype=torch.float16)
tensor(1.8535, device='cuda:0', dtype=torch.float16) tensor(0.1929, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1567, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1766, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.6191, device='cuda:0', dtype=torch.float16) tensor(0.1768, device='cuda:0', dtype=torch.float16)
tensor(0.7891, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
tensor(0.8091, device='cuda:0', dtype=torch.float16) tensor(0.0783, device='cuda:0', dtype=torch.float16)
tensor(0.7744, device='cuda:0', dtype=torch.float16) tensor(0.0772, device='cuda:0', dtype=torch.float16)
tensor(0.9619, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0062, device='cuda:0')
tensor(0.1531, device='cuda:0')
old_score: tensor(0.0798, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0533, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7878587245941162
Validation after dual ascent:
out_inf: tensor(2.6191, device='cuda:0', dtype=torch.float16) tensor(0.1768, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.4819, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.9434, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
tensor(0.7842, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.5889, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.0338, device='cuda:0')
old_score: tensor(0.0119, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0063, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.801101207733154
Validation after dual ascent:
out_inf: tensor(2.9434, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
tensor(0.2441, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.1973, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.2358, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.2090, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.1406, device='cuda:0', dtype=torch.float16) tensor(0.3379, device='cuda:0', dtype=torch.float16)
tensor(3.2422, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
tensor(3.2500, device='cuda:0', dtype=torch.float16) tensor(0.1102, device='cuda:0', dtype=torch.float16)
tensor(3.6914, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(3.2812, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0136, device='cuda:0')
tensor(0.0157, device='cuda:0')
old_score: tensor(0.1121, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0701, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.092745065689087
Validation after dual ascent:
out_inf: tensor(8.1406, device='cuda:0', dtype=torch.float16) tensor(0.3379, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(1.7461, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(1.7832, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.4004, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
tensor(1.1699, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0775, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0081, device='cuda:0')
tensor(0.0725, device='cuda:0')
old_score: tensor(0.0803, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0531, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.237526655197144
Validation after dual ascent:
out_inf: tensor(3.4004, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
tensor(0.7261, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.5996, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.5996, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
tensor(0.4214, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.3311, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
tensor(0.2803, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0175, device='cuda:0')
tensor(0.0314, device='cuda:0')
old_score: tensor(0.0150, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 116.82023286819458
Validation after dual ascent:
out_inf: tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.2542, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1914, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.1790, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.1472, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.1250, device='cuda:0', dtype=torch.float16) tensor(0.7451, device='cuda:0', dtype=torch.float16)
tensor(3.1641, device='cuda:0', dtype=torch.float16) tensor(0.1982, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.1846, device='cuda:0', dtype=torch.float16)
tensor(3.2930, device='cuda:0', dtype=torch.float16) tensor(0.1831, device='cuda:0', dtype=torch.float16)
tensor(3.1953, device='cuda:0', dtype=torch.float16) tensor(0.1863, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0196, device='cuda:0')
tensor(0.1423, device='cuda:0')
old_score: tensor(0.1880, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1074, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.644092798233032
Validation after dual ascent:
out_inf: tensor(13.1250, device='cuda:0', dtype=torch.float16) tensor(0.7451, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.6650, device='cuda:0', dtype=torch.float16) tensor(0.1029, device='cuda:0', dtype=torch.float16)
tensor(1.3740, device='cuda:0', dtype=torch.float16) tensor(0.0987, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1406, device='cuda:0', dtype=torch.float16) tensor(1.4805, device='cuda:0', dtype=torch.float16)
tensor(3.7422, device='cuda:0', dtype=torch.float16) tensor(0.3115, device='cuda:0', dtype=torch.float16)
tensor(3.6562, device='cuda:0', dtype=torch.float16) tensor(0.2891, device='cuda:0', dtype=torch.float16)
tensor(3.8984, device='cuda:0', dtype=torch.float16) tensor(0.2900, device='cuda:0', dtype=torch.float16)
tensor(3.4062, device='cuda:0', dtype=torch.float16) tensor(0.2927, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0133, device='cuda:0')
tensor(0.0906, device='cuda:0')
old_score: tensor(0.2959, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1615, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3436176776885986
Validation after dual ascent:
out_inf: tensor(17.1406, device='cuda:0', dtype=torch.float16) tensor(1.4805, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1788, device='cuda:0', dtype=torch.float16)
tensor(1.8105, device='cuda:0', dtype=torch.float16) tensor(0.1549, device='cuda:0', dtype=torch.float16)
tensor(1.7314, device='cuda:0', dtype=torch.float16) tensor(0.1486, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1636, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.9258, device='cuda:0', dtype=torch.float16) tensor(0.1984, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0890, device='cuda:0', dtype=torch.float16)
tensor(0.7646, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(0.8452, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(0.7876, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0068, device='cuda:0')
tensor(0.1635, device='cuda:0')
old_score: tensor(0.0862, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0557, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7834720611572266
Validation after dual ascent:
out_inf: tensor(2.9258, device='cuda:0', dtype=torch.float16) tensor(0.1984, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.5034, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.6240, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.0307, device='cuda:0')
old_score: tensor(0.0136, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0078, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.801107406616211
Validation after dual ascent:
out_inf: tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.2510, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2246, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.3394, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.2334, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.8359, device='cuda:0', dtype=torch.float16) tensor(0.3342, device='cuda:0', dtype=torch.float16)
tensor(2.7148, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
tensor(2.7188, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
tensor(2.8008, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(2.4766, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0133, device='cuda:0')
tensor(0.0157, device='cuda:0')
old_score: tensor(0.1139, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0712, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.099880695343018
Validation after dual ascent:
out_inf: tensor(6.8359, device='cuda:0', dtype=torch.float16) tensor(0.3342, device='cuda:0', dtype=torch.float16)
tensor(1.6523, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(1.8877, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(1.7129, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.5508, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
tensor(1.4277, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(1.4629, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0081, device='cuda:0')
tensor(0.0764, device='cuda:0')
old_score: tensor(0.0812, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0534, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.208842277526855
Validation after dual ascent:
out_inf: tensor(4.5508, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
tensor(0.5356, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.7100, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.6465, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.9727, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.2285, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.2517, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.2292, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
tensor(0.2012, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0161, device='cuda:0')
tensor(0.0317, device='cuda:0')
old_score: tensor(0.0149, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 108.32952356338501
Validation after dual ascent:
out_inf: tensor(1.9727, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.1555, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1583, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1732, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1826, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.5625, device='cuda:0', dtype=torch.float16) tensor(0.7231, device='cuda:0', dtype=torch.float16)
tensor(3.8359, device='cuda:0', dtype=torch.float16) tensor(0.1866, device='cuda:0', dtype=torch.float16)
tensor(4.0312, device='cuda:0', dtype=torch.float16) tensor(0.1725, device='cuda:0', dtype=torch.float16)
tensor(3.5625, device='cuda:0', dtype=torch.float16) tensor(0.1709, device='cuda:0', dtype=torch.float16)
tensor(3.7109, device='cuda:0', dtype=torch.float16) tensor(0.1763, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0197, device='cuda:0')
tensor(0.1477, device='cuda:0')
old_score: tensor(0.1766, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1025, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.64415168762207
Validation after dual ascent:
out_inf: tensor(16.5625, device='cuda:0', dtype=torch.float16) tensor(0.7231, device='cuda:0', dtype=torch.float16)
tensor(1.6172, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.0984, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.0929, device='cuda:0', dtype=torch.float16)
tensor(1.3486, device='cuda:0', dtype=torch.float16) tensor(0.1043, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.5469, device='cuda:0', dtype=torch.float16) tensor(1.5088, device='cuda:0', dtype=torch.float16)
tensor(3.3516, device='cuda:0', dtype=torch.float16) tensor(0.2881, device='cuda:0', dtype=torch.float16)
tensor(3.0859, device='cuda:0', dtype=torch.float16) tensor(0.2661, device='cuda:0', dtype=torch.float16)
tensor(3.5586, device='cuda:0', dtype=torch.float16) tensor(0.2683, device='cuda:0', dtype=torch.float16)
tensor(3.2461, device='cuda:0', dtype=torch.float16) tensor(0.2715, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0138, device='cuda:0')
tensor(0.0921, device='cuda:0')
old_score: tensor(0.2734, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1523, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3389742374420166
Validation after dual ascent:
out_inf: tensor(19.5469, device='cuda:0', dtype=torch.float16) tensor(1.5088, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.1693, device='cuda:0', dtype=torch.float16)
tensor(1.7275, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
tensor(1.4805, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(2.2520, device='cuda:0', dtype=torch.float16) tensor(0.1549, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.5254, device='cuda:0', dtype=torch.float16) tensor(0.1931, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(0.9072, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
tensor(0.8550, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0071, device='cuda:0')
tensor(0.1711, device='cuda:0')
old_score: tensor(0.0873, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7795200347900391
Validation after dual ascent:
out_inf: tensor(2.5254, device='cuda:0', dtype=torch.float16) tensor(0.1931, device='cuda:0', dtype=torch.float16)
tensor(0.5151, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.4861, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.3457, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.3145, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.4346, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.0283, device='cuda:0')
old_score: tensor(0.0150, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0087, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.805139064788818
Validation after dual ascent:
out_inf: tensor(2.3457, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.2788, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.2429, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.2021, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.2554, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.5859, device='cuda:0', dtype=torch.float16) tensor(0.3423, device='cuda:0', dtype=torch.float16)
tensor(3.1289, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(4.8711, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(3.6523, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(3.3477, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0139, device='cuda:0')
tensor(0.0167, device='cuda:0')
old_score: tensor(0.1193, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0731, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.102199077606201
Validation after dual ascent:
out_inf: tensor(8.5859, device='cuda:0', dtype=torch.float16) tensor(0.3423, device='cuda:0', dtype=torch.float16)
tensor(1.7881, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.0705, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.8496, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(1.1758, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0086, device='cuda:0')
tensor(0.0834, device='cuda:0')
old_score: tensor(0.0846, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0549, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.213314771652222
Validation after dual ascent:
out_inf: tensor(3.8496, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.6689, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.2314, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.2363, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.2866, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.2349, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0101, device='cuda:0')
tensor(0.0216, device='cuda:0')
old_score: tensor(0.0160, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0105, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 108.27910089492798
Validation after dual ascent:
out_inf: tensor(1.2314, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.1846, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1611, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1489, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1294, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.q_proj
Validation after prune:
out_inf: tensor(20.7812, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(3.9766, device='cuda:0', dtype=torch.float16) tensor(0.1790, device='cuda:0', dtype=torch.float16)
tensor(3.6953, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.1724, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0200, device='cuda:0')
tensor(0.0472, device='cuda:0')
old_score: tensor(0.1708, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0966, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.294224500656128
Validation after dual ascent:
out_inf: tensor(20.7812, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1079, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.0928, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.6094, device='cuda:0', dtype=torch.float16) tensor(1.4648, device='cuda:0', dtype=torch.float16)
tensor(3.8281, device='cuda:0', dtype=torch.float16) tensor(0.2856, device='cuda:0', dtype=torch.float16)
tensor(3.5625, device='cuda:0', dtype=torch.float16) tensor(0.2629, device='cuda:0', dtype=torch.float16)
tensor(3.6172, device='cuda:0', dtype=torch.float16) tensor(0.2617, device='cuda:0', dtype=torch.float16)
tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.2742, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0149, device='cuda:0')
tensor(0.0811, device='cuda:0')
old_score: tensor(0.2712, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1477, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3379888534545898
Validation after dual ascent:
out_inf: tensor(21.6094, device='cuda:0', dtype=torch.float16) tensor(1.4648, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.1422, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1324, device='cuda:0', dtype=torch.float16)
tensor(1.4404, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.0781, device='cuda:0', dtype=torch.float16) tensor(0.2032, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(0.8018, device='cuda:0', dtype=torch.float16) tensor(0.0857, device='cuda:0', dtype=torch.float16)
tensor(0.7939, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
tensor(0.7549, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0071, device='cuda:0')
tensor(0.1615, device='cuda:0')
old_score: tensor(0.0878, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0551, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7746682167053223
Validation after dual ascent:
out_inf: tensor(3.0781, device='cuda:0', dtype=torch.float16) tensor(0.2032, device='cuda:0', dtype=torch.float16)
tensor(0.5225, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(0.5757, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.6660, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.5264, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(0.4639, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.0320, device='cuda:0')
old_score: tensor(0.0178, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0094, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.795762777328491
Validation after dual ascent:
out_inf: tensor(1.6660, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1738, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1572, device='cuda:0', dtype=torch.float16) tensor(0.0088, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.1250, device='cuda:0', dtype=torch.float16) tensor(0.3630, device='cuda:0', dtype=torch.float16)
tensor(2.8105, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
tensor(2.9473, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(3.2266, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(2.9492, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0152, device='cuda:0')
tensor(0.0178, device='cuda:0')
old_score: tensor(0.1202, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.075872898101807
Validation after dual ascent:
out_inf: tensor(9.1250, device='cuda:0', dtype=torch.float16) tensor(0.3630, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(1.6719, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.8613, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.0883, device='cuda:0', dtype=torch.float16)
tensor(1.3027, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0091, device='cuda:0')
tensor(0.0795, device='cuda:0')
old_score: tensor(0.0842, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0544, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.211865425109863
Validation after dual ascent:
out_inf: tensor(3.8613, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(0.6846, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(0.6943, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.3037, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.2959, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.2905, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0159, device='cuda:0')
tensor(0.0308, device='cuda:0')
old_score: tensor(0.0166, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0103, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 108.13150310516357
Validation after dual ascent:
out_inf: tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.1455, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1604, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1614, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.2500, device='cuda:0', dtype=torch.float16) tensor(0.6938, device='cuda:0', dtype=torch.float16)
tensor(3.5391, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(3.9688, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(3.4062, device='cuda:0', dtype=torch.float16) tensor(0.1539, device='cuda:0', dtype=torch.float16)
tensor(3.5156, device='cuda:0', dtype=torch.float16) tensor(0.1571, device='cuda:0', dtype=torch.float16)
tensor(0.0266, device='cuda:0')
old_score: tensor(0.1577, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0905, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.843578100204468
Validation after dual ascent:
out_inf: tensor(18.2500, device='cuda:0', dtype=torch.float16) tensor(0.6938, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.5625, device='cuda:0', dtype=torch.float16) tensor(1.4756, device='cuda:0', dtype=torch.float16)
tensor(2.8125, device='cuda:0', dtype=torch.float16) tensor(0.2522, device='cuda:0', dtype=torch.float16)
tensor(2.5625, device='cuda:0', dtype=torch.float16) tensor(0.2341, device='cuda:0', dtype=torch.float16)
tensor(2.5039, device='cuda:0', dtype=torch.float16) tensor(0.2363, device='cuda:0', dtype=torch.float16)
tensor(3.3633, device='cuda:0', dtype=torch.float16) tensor(0.2410, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0156, device='cuda:0')
tensor(0.0777, device='cuda:0')
old_score: tensor(0.2410, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1362, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3327462673187256
Validation after dual ascent:
out_inf: tensor(17.5625, device='cuda:0', dtype=torch.float16) tensor(1.4756, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(1.5293, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.4727, device='cuda:0', dtype=torch.float16) tensor(0.2015, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.8701, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.0890, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0074, device='cuda:0')
tensor(0.1604, device='cuda:0')
old_score: tensor(0.0891, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0569, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7726438045501709
Validation after dual ascent:
out_inf: tensor(3.4727, device='cuda:0', dtype=torch.float16) tensor(0.2015, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.5576, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.5166, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.4624, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.4111, device='cuda:0', dtype=torch.float16) tensor(0.0163, device='cuda:0', dtype=torch.float16)
tensor(0.0349, device='cuda:0')
old_score: tensor(0.0152, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0092, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.807539463043213
Validation after dual ascent:
out_inf: tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.2712, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1738, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.2388, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.3208, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.2852, device='cuda:0', dtype=torch.float16) tensor(0.3425, device='cuda:0', dtype=torch.float16)
tensor(2.4023, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(2.9570, device='cuda:0', dtype=torch.float16) tensor(0.1151, device='cuda:0', dtype=torch.float16)
tensor(2.3770, device='cuda:0', dtype=torch.float16) tensor(0.1123, device='cuda:0', dtype=torch.float16)
tensor(2.1875, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0136, device='cuda:0')
tensor(0.0162, device='cuda:0')
old_score: tensor(0.1166, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0731, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.078477382659912
Validation after dual ascent:
out_inf: tensor(7.2852, device='cuda:0', dtype=torch.float16) tensor(0.3425, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.0803, device='cuda:0', dtype=torch.float16)
tensor(1.5957, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(1.3369, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.6445, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(1.1816, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0082, device='cuda:0')
tensor(0.0803, device='cuda:0')
old_score: tensor(0.0833, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0547, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.181077003479004
Validation after dual ascent:
out_inf: tensor(3.6445, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.6475, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.4451, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.1797, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.1917, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0158, device='cuda:0')
tensor(0.0319, device='cuda:0')
old_score: tensor(0.0153, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0098, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 108.24251008033752
Validation after dual ascent:
out_inf: tensor(0.4451, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.1282, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.1381, device='cuda:0', dtype=torch.float16) tensor(0.0095, device='cuda:0', dtype=torch.float16)
tensor(0.1472, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1279, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.q_proj
Validation after prune:
out_inf: tensor(20.5469, device='cuda:0', dtype=torch.float16) tensor(0.7173, device='cuda:0', dtype=torch.float16)
tensor(3.3281, device='cuda:0', dtype=torch.float16) tensor(0.1576, device='cuda:0', dtype=torch.float16)
tensor(2.8438, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(2.7500, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
tensor(0.0231, device='cuda:0')
old_score: tensor(0.1482, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0892, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.856126070022583
Validation after dual ascent:
out_inf: tensor(20.5469, device='cuda:0', dtype=torch.float16) tensor(0.7173, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
tensor(1.0752, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.0925, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.8125, device='cuda:0', dtype=torch.float16) tensor(1.4004, device='cuda:0', dtype=torch.float16)
tensor(2.8516, device='cuda:0', dtype=torch.float16) tensor(0.2415, device='cuda:0', dtype=torch.float16)
tensor(2.8594, device='cuda:0', dtype=torch.float16) tensor(0.2184, device='cuda:0', dtype=torch.float16)
tensor(2.8203, device='cuda:0', dtype=torch.float16) tensor(0.2142, device='cuda:0', dtype=torch.float16)
tensor(2.9922, device='cuda:0', dtype=torch.float16) tensor(0.2294, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0147, device='cuda:0')
tensor(0.0675, device='cuda:0')
old_score: tensor(0.2260, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1338, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3380153179168701
Validation after dual ascent:
out_inf: tensor(20.8125, device='cuda:0', dtype=torch.float16) tensor(1.4004, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
tensor(1.4248, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
tensor(1.3154, device='cuda:0', dtype=torch.float16) tensor(0.1188, device='cuda:0', dtype=torch.float16)
tensor(1.4365, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1931, device='cuda:0', dtype=torch.float16)
tensor(0.7783, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(1.0361, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(0.7808, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0074, device='cuda:0')
tensor(0.1598, device='cuda:0')
old_score: tensor(0.0899, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0587, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.775254487991333
Validation after dual ascent:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1931, device='cuda:0', dtype=torch.float16)
tensor(0.6157, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
tensor(0.5884, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.6123, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.5483, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0318, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.5498, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.0315, device='cuda:0')
old_score: tensor(0.0139, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0082, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.819747924804688
Validation after dual ascent:
out_inf: tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0318, device='cuda:0', dtype=torch.float16)
tensor(0.2192, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.1885, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.2041, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.9609, device='cuda:0', dtype=torch.float16) tensor(0.3381, device='cuda:0', dtype=torch.float16)
tensor(2.4883, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(3.4609, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(2.1758, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0131, device='cuda:0')
tensor(0.0155, device='cuda:0')
old_score: tensor(0.1136, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0724, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.094280481338501
Validation after dual ascent:
out_inf: tensor(7.9609, device='cuda:0', dtype=torch.float16) tensor(0.3381, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(1.6182, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.2930, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0080, device='cuda:0')
tensor(0.0771, device='cuda:0')
old_score: tensor(0.0820, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0542, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.211437463760376
Validation after dual ascent:
out_inf: tensor(3.2930, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(0.5171, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.2129, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1787, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.1708, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.2188, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0180, device='cuda:0')
tensor(0.0361, device='cuda:0')
old_score: tensor(0.0145, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0093, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 108.16695547103882
Validation after dual ascent:
out_inf: tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.1300, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1301, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1456, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1256, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.q_proj
Validation after prune:
out_inf: tensor(22.7500, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(3.3125, device='cuda:0', dtype=torch.float16) tensor(0.1547, device='cuda:0', dtype=torch.float16)
tensor(3.5000, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(3.5625, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(3.3125, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(0.0257, device='cuda:0')
old_score: tensor(0.1458, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0863, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.844405174255371
Validation after dual ascent:
out_inf: tensor(22.7500, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.3965, device='cuda:0', dtype=torch.float16)
tensor(3.1875, device='cuda:0', dtype=torch.float16) tensor(0.2238, device='cuda:0', dtype=torch.float16)
tensor(2.7266, device='cuda:0', dtype=torch.float16) tensor(0.2023, device='cuda:0', dtype=torch.float16)
tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.1980, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.2108, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0160, device='cuda:0')
tensor(0.0663, device='cuda:0')
old_score: tensor(0.2087, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1228, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3354864120483398
Validation after dual ascent:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.3965, device='cuda:0', dtype=torch.float16)
tensor(1.5322, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.2261, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.9912, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0079, device='cuda:0')
tensor(0.1669, device='cuda:0')
old_score: tensor(0.0977, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0629, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7734708786010742
Validation after dual ascent:
out_inf: tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.2261, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.5542, device='cuda:0', dtype=torch.float16) tensor(0.0650, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9282, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.5649, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.0345, device='cuda:0')
old_score: tensor(0.0161, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0097, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.812495231628418
Validation after dual ascent:
out_inf: tensor(0.9282, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.2422, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1953, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.2095, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.2808, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.4609, device='cuda:0', dtype=torch.float16) tensor(0.3479, device='cuda:0', dtype=torch.float16)
tensor(4.0312, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(3.3066, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(2.5898, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0131, device='cuda:0')
tensor(0.0157, device='cuda:0')
old_score: tensor(0.1150, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0735, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.08338212966919
Validation after dual ascent:
out_inf: tensor(8.4609, device='cuda:0', dtype=torch.float16) tensor(0.3479, device='cuda:0', dtype=torch.float16)
tensor(2.0742, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(1.8262, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(1.5596, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.4863, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(1.4395, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0083, device='cuda:0')
tensor(0.0795, device='cuda:0')
old_score: tensor(0.0830, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0550, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.187501430511475
Validation after dual ascent:
out_inf: tensor(3.4863, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.6045, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.2646, device='cuda:0', dtype=torch.float16) tensor(0.0373, device='cuda:0', dtype=torch.float16)
tensor(0.1787, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.1486, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.1754, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
tensor(0.1694, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0169, device='cuda:0')
tensor(0.0351, device='cuda:0')
old_score: tensor(0.0148, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0095, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 108.08648419380188
Validation after dual ascent:
out_inf: tensor(1.2646, device='cuda:0', dtype=torch.float16) tensor(0.0373, device='cuda:0', dtype=torch.float16)
tensor(0.1261, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1274, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1266, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.1230, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.q_proj
Validation after prune:
out_inf: tensor(23.9219, device='cuda:0', dtype=torch.float16) tensor(0.7769, device='cuda:0', dtype=torch.float16)
tensor(3.5938, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(3.7422, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.1547, device='cuda:0', dtype=torch.float16)
tensor(0.0264, device='cuda:0')
old_score: tensor(0.1501, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0879, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.851659297943115
Validation after dual ascent:
out_inf: tensor(23.9219, device='cuda:0', dtype=torch.float16) tensor(0.7769, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.0857, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.k_proj
Validation after prune:
out_inf: tensor(22.9375, device='cuda:0', dtype=torch.float16) tensor(1.3613, device='cuda:0', dtype=torch.float16)
tensor(4.3750, device='cuda:0', dtype=torch.float16) tensor(0.2379, device='cuda:0', dtype=torch.float16)
tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.2117, device='cuda:0', dtype=torch.float16)
tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.2041, device='cuda:0', dtype=torch.float16)
tensor(4.5078, device='cuda:0', dtype=torch.float16) tensor(0.2274, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0162, device='cuda:0')
tensor(0.0677, device='cuda:0')
old_score: tensor(0.2203, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1262, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3328545093536377
Validation after dual ascent:
out_inf: tensor(22.9375, device='cuda:0', dtype=torch.float16) tensor(1.3613, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.3262, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(1.3828, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.4707, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.8633, device='cuda:0', dtype=torch.float16) tensor(0.2445, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(1.2705, device='cuda:0', dtype=torch.float16) tensor(0.0982, device='cuda:0', dtype=torch.float16)
tensor(1.0586, device='cuda:0', dtype=torch.float16) tensor(0.1062, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0083, device='cuda:0')
tensor(0.1727, device='cuda:0')
old_score: tensor(0.1038, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0662, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7734856605529785
Validation after dual ascent:
out_inf: tensor(3.8633, device='cuda:0', dtype=torch.float16) tensor(0.2445, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.6685, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.4961, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
tensor(0.0345, device='cuda:0')
old_score: tensor(0.0174, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.801528930664062
Validation after dual ascent:
out_inf: tensor(1.4961, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.1953, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.2109, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1895, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.2373, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1523, device='cuda:0', dtype=torch.float16) tensor(0.3711, device='cuda:0', dtype=torch.float16)
tensor(2.5820, device='cuda:0', dtype=torch.float16) tensor(0.1250, device='cuda:0', dtype=torch.float16)
tensor(2.8477, device='cuda:0', dtype=torch.float16) tensor(0.1156, device='cuda:0', dtype=torch.float16)
tensor(2.3594, device='cuda:0', dtype=torch.float16) tensor(0.1101, device='cuda:0', dtype=torch.float16)
tensor(2.7480, device='cuda:0', dtype=torch.float16) tensor(0.1211, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0136, device='cuda:0')
tensor(0.0163, device='cuda:0')
old_score: tensor(0.1179, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0767, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.082932233810425
Validation after dual ascent:
out_inf: tensor(7.1523, device='cuda:0', dtype=torch.float16) tensor(0.3711, device='cuda:0', dtype=torch.float16)
tensor(2.0254, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(1.8633, device='cuda:0', dtype=torch.float16) tensor(0.0761, device='cuda:0', dtype=torch.float16)
tensor(1.8848, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(1.9160, device='cuda:0', dtype=torch.float16) tensor(0.0803, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.7227, device='cuda:0', dtype=torch.float16) tensor(0.1528, device='cuda:0', dtype=torch.float16)
tensor(1.1963, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(1.2510, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0087, device='cuda:0')
tensor(0.0833, device='cuda:0')
old_score: tensor(0.0856, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0576, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.209312438964844
Validation after dual ascent:
out_inf: tensor(3.7227, device='cuda:0', dtype=torch.float16) tensor(0.1528, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0617, device='cuda:0', dtype=torch.float16)
tensor(0.8164, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.0742, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.1470, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.1555, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
tensor(0.1665, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1660, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0134, device='cuda:0')
tensor(0.0280, device='cuda:0')
old_score: tensor(0.0158, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 108.2501289844513
Validation after dual ascent:
out_inf: tensor(4.0742, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.1302, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1604, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1294, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1262, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.4531, device='cuda:0', dtype=torch.float16) tensor(0.7651, device='cuda:0', dtype=torch.float16)
tensor(3.1719, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(3.2656, device='cuda:0', dtype=torch.float16) tensor(0.1444, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(3.8125, device='cuda:0', dtype=torch.float16) tensor(0.1523, device='cuda:0', dtype=torch.float16)
tensor(0.0229, device='cuda:0')
old_score: tensor(0.1486, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0887, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.851312160491943
Validation after dual ascent:
out_inf: tensor(18.4531, device='cuda:0', dtype=torch.float16) tensor(0.7651, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.0926, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.k_proj
Validation after prune:
out_inf: tensor(22.6094, device='cuda:0', dtype=torch.float16) tensor(1.5664, device='cuda:0', dtype=torch.float16)
tensor(2.7422, device='cuda:0', dtype=torch.float16) tensor(0.2400, device='cuda:0', dtype=torch.float16)
tensor(2.3906, device='cuda:0', dtype=torch.float16) tensor(0.2181, device='cuda:0', dtype=torch.float16)
tensor(2.5449, device='cuda:0', dtype=torch.float16) tensor(0.2075, device='cuda:0', dtype=torch.float16)
tensor(2.6016, device='cuda:0', dtype=torch.float16) tensor(0.2308, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0163, device='cuda:0')
tensor(0.0598, device='cuda:0')
old_score: tensor(0.2241, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1305, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3335890769958496
Validation after dual ascent:
out_inf: tensor(22.6094, device='cuda:0', dtype=torch.float16) tensor(1.5664, device='cuda:0', dtype=torch.float16)
tensor(1.6152, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(1.4443, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.8652, device='cuda:0', dtype=torch.float16) tensor(0.2133, device='cuda:0', dtype=torch.float16)
tensor(0.9624, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0973, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.1057, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0084, device='cuda:0')
tensor(0.1880, device='cuda:0')
old_score: tensor(0.1032, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0690, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7711920738220215
Validation after dual ascent:
out_inf: tensor(3.8652, device='cuda:0', dtype=torch.float16) tensor(0.2133, device='cuda:0', dtype=torch.float16)
tensor(0.6182, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0619, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.3340, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.9023, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.0335, device='cuda:0')
old_score: tensor(0.0181, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.801846981048584
Validation after dual ascent:
out_inf: tensor(1.3340, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.3281, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.2852, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.7969, device='cuda:0', dtype=torch.float16) tensor(0.4177, device='cuda:0', dtype=torch.float16)
tensor(4.1484, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
tensor(3.4199, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(3.5078, device='cuda:0', dtype=torch.float16) tensor(0.1175, device='cuda:0', dtype=torch.float16)
tensor(3.7422, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0154, device='cuda:0')
tensor(0.0189, device='cuda:0')
old_score: tensor(0.1259, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0807, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.091532468795776
Validation after dual ascent:
out_inf: tensor(8.7969, device='cuda:0', dtype=torch.float16) tensor(0.4177, device='cuda:0', dtype=torch.float16)
tensor(2.2441, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(2.0801, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.0713, device='cuda:0', dtype=torch.float16)
tensor(2.6758, device='cuda:0', dtype=torch.float16) tensor(0.0843, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1445, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.0855, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0099, device='cuda:0')
tensor(0.0955, device='cuda:0')
old_score: tensor(0.0916, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0609, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.220333099365234
Validation after dual ascent:
out_inf: tensor(4.1445, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.7520, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.8574, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.2607, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.2363, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(0.2422, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0141, device='cuda:0')
tensor(0.0199, device='cuda:0')
old_score: tensor(0.0184, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0116, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 100.12493705749512
Validation after dual ascent:
out_inf: tensor(3.8574, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.1606, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1523, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1658, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1466, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.q_proj
Validation after prune:
out_inf: tensor(23.4844, device='cuda:0', dtype=torch.float16) tensor(0.7544, device='cuda:0', dtype=torch.float16)
tensor(4.4219, device='cuda:0', dtype=torch.float16) tensor(0.1707, device='cuda:0', dtype=torch.float16)
tensor(4.5312, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(4.7500, device='cuda:0', dtype=torch.float16) tensor(0.1633, device='cuda:0', dtype=torch.float16)
tensor(0.0669, device='cuda:0')
old_score: tensor(0.1594, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0932, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.846551895141602
Validation after dual ascent:
out_inf: tensor(23.4844, device='cuda:0', dtype=torch.float16) tensor(0.7544, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(1.6406, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.0625, device='cuda:0', dtype=torch.float16) tensor(1.5293, device='cuda:0', dtype=torch.float16)
tensor(3.9609, device='cuda:0', dtype=torch.float16) tensor(0.2622, device='cuda:0', dtype=torch.float16)
tensor(3.3672, device='cuda:0', dtype=torch.float16) tensor(0.2365, device='cuda:0', dtype=torch.float16)
tensor(3.0703, device='cuda:0', dtype=torch.float16) tensor(0.2230, device='cuda:0', dtype=torch.float16)
tensor(3.6016, device='cuda:0', dtype=torch.float16) tensor(0.2478, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0198, device='cuda:0')
tensor(0.0598, device='cuda:0')
old_score: tensor(0.2424, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1370, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.378382444381714
Validation after dual ascent:
out_inf: tensor(20.0625, device='cuda:0', dtype=torch.float16) tensor(1.5293, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
tensor(1.5342, device='cuda:0', dtype=torch.float16) tensor(0.1378, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1210, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.3086, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(1.7988, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.1855, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.1293, device='cuda:0')
old_score: tensor(0.1221, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0789, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.9605107307434082
Validation after dual ascent:
out_inf: tensor(4.3086, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(0.7261, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.8833, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(0.7158, device='cuda:0', dtype=torch.float16) tensor(0.0819, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(1.1504, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.0428, device='cuda:0')
old_score: tensor(0.0216, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0127, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.801687479019165
Validation after dual ascent:
out_inf: tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.3887, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.4668, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.3672, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0132, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.3672, device='cuda:0', dtype=torch.float16) tensor(0.4734, device='cuda:0', dtype=torch.float16)
tensor(3.4590, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(3.6133, device='cuda:0', dtype=torch.float16) tensor(0.1371, device='cuda:0', dtype=torch.float16)
tensor(3.4414, device='cuda:0', dtype=torch.float16) tensor(0.1270, device='cuda:0', dtype=torch.float16)
tensor(3.3867, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0170, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.1382, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0872, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.088086605072021
Validation after dual ascent:
out_inf: tensor(8.3672, device='cuda:0', dtype=torch.float16) tensor(0.4734, device='cuda:0', dtype=torch.float16)
tensor(2.3828, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(2.1504, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
tensor(1.9551, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(2.7246, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.8281, device='cuda:0', dtype=torch.float16) tensor(0.1918, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(1.3770, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0120, device='cuda:0')
tensor(0.1179, device='cuda:0')
old_score: tensor(0.1011, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0663, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.227962493896484
Validation after dual ascent:
out_inf: tensor(4.8281, device='cuda:0', dtype=torch.float16) tensor(0.1918, device='cuda:0', dtype=torch.float16)
tensor(0.9902, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.9297, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(0.2280, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(0.2068, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(0.2590, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0182, device='cuda:0')
tensor(0.0208, device='cuda:0')
old_score: tensor(0.0220, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0137, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 76.27104043960571
Validation after dual ascent:
out_inf: tensor(5.9297, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(0.1865, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.1788, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.1763, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1890, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.q_proj
Validation after prune:
out_inf: tensor(21.6719, device='cuda:0', dtype=torch.float16) tensor(0.8008, device='cuda:0', dtype=torch.float16)
tensor(4.5859, device='cuda:0', dtype=torch.float16) tensor(0.1910, device='cuda:0', dtype=torch.float16)
tensor(3.8203, device='cuda:0', dtype=torch.float16) tensor(0.1761, device='cuda:0', dtype=torch.float16)
tensor(3.6328, device='cuda:0', dtype=torch.float16) tensor(0.1644, device='cuda:0', dtype=torch.float16)
tensor(4.3828, device='cuda:0', dtype=torch.float16) tensor(0.1857, device='cuda:0', dtype=torch.float16)
tensor(0.0244, device='cuda:0')
old_score: tensor(0.1793, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0969, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.848270416259766
Validation after dual ascent:
out_inf: tensor(21.6719, device='cuda:0', dtype=torch.float16) tensor(0.8008, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.0990, device='cuda:0', dtype=torch.float16)
tensor(1.2227, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.k_proj
Validation after prune:
out_inf: tensor(23.0781, device='cuda:0', dtype=torch.float16) tensor(1.4980, device='cuda:0', dtype=torch.float16)
tensor(4.4297, device='cuda:0', dtype=torch.float16) tensor(0.2932, device='cuda:0', dtype=torch.float16)
tensor(4.0391, device='cuda:0', dtype=torch.float16) tensor(0.2642, device='cuda:0', dtype=torch.float16)
tensor(4.0625, device='cuda:0', dtype=torch.float16) tensor(0.2451, device='cuda:0', dtype=torch.float16)
tensor(4.2188, device='cuda:0', dtype=torch.float16) tensor(0.2861, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0165, device='cuda:0')
tensor(0.0702, device='cuda:0')
old_score: tensor(0.2722, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1406, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3364112377166748
Validation after dual ascent:
out_inf: tensor(23.0781, device='cuda:0', dtype=torch.float16) tensor(1.4980, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1488, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1428, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.2622, device='cuda:0', dtype=torch.float16)
tensor(1.2930, device='cuda:0', dtype=torch.float16) tensor(0.1396, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(1.3369, device='cuda:0', dtype=torch.float16) tensor(0.1350, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0104, device='cuda:0')
tensor(0.2572, device='cuda:0')
old_score: tensor(0.1318, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0847, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7746405601501465
Validation after dual ascent:
out_inf: tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.2622, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
tensor(0.6782, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
tensor(0.7651, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.5557, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(1.8945, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(1.7324, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0182, device='cuda:0')
tensor(0.0261, device='cuda:0')
old_score: tensor(0.0255, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0149, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.817293882369995
Validation after dual ascent:
out_inf: tensor(1.5557, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
tensor(0.3867, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.3359, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.3984, device='cuda:0', dtype=torch.float16) tensor(0.5132, device='cuda:0', dtype=torch.float16)
tensor(3.5820, device='cuda:0', dtype=torch.float16) tensor(0.1566, device='cuda:0', dtype=torch.float16)
tensor(4.2109, device='cuda:0', dtype=torch.float16) tensor(0.1453, device='cuda:0', dtype=torch.float16)
tensor(3.4062, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
tensor(3.8086, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0197, device='cuda:0')
tensor(0.0260, device='cuda:0')
old_score: tensor(0.1472, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0884, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.071485996246338
Validation after dual ascent:
out_inf: tensor(8.3984, device='cuda:0', dtype=torch.float16) tensor(0.5132, device='cuda:0', dtype=torch.float16)
tensor(2.7852, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(2.7070, device='cuda:0', dtype=torch.float16) tensor(0.0905, device='cuda:0', dtype=torch.float16)
tensor(2.1309, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(2.6133, device='cuda:0', dtype=torch.float16) tensor(0.0920, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.2148, device='cuda:0', dtype=torch.float16) tensor(0.2191, device='cuda:0', dtype=torch.float16)
tensor(2.1309, device='cuda:0', dtype=torch.float16) tensor(0.1161, device='cuda:0', dtype=torch.float16)
tensor(1.8535, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(2.1797, device='cuda:0', dtype=torch.float16) tensor(0.1004, device='cuda:0', dtype=torch.float16)
tensor(1.9395, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0157, device='cuda:0')
tensor(0.1286, device='cuda:0')
old_score: tensor(0.1093, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0692, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.224786281585693
Validation after dual ascent:
out_inf: tensor(5.2148, device='cuda:0', dtype=torch.float16) tensor(0.2191, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.0730, device='cuda:0', dtype=torch.float16)
tensor(0.9268, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(1.0098, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0279, device='cuda:0', dtype=torch.float16)
tensor(0.3379, device='cuda:0', dtype=torch.float16) tensor(0.0252, device='cuda:0', dtype=torch.float16)
tensor(0.2869, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.3398, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0167, device='cuda:0')
tensor(0.0245, device='cuda:0')
old_score: tensor(0.0260, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0158, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 68.16663360595703
Validation after dual ascent:
out_inf: tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(0.2423, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.2216, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.2120, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.2040, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.6875, device='cuda:0', dtype=torch.float16) tensor(0.7495, device='cuda:0', dtype=torch.float16)
tensor(4.1836, device='cuda:0', dtype=torch.float16) tensor(0.2209, device='cuda:0', dtype=torch.float16)
tensor(4.2070, device='cuda:0', dtype=torch.float16) tensor(0.2029, device='cuda:0', dtype=torch.float16)
tensor(4.1641, device='cuda:0', dtype=torch.float16) tensor(0.1891, device='cuda:0', dtype=torch.float16)
tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.2112, device='cuda:0', dtype=torch.float16)
tensor(0.0292, device='cuda:0')
old_score: tensor(0.2061, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1001, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.861539602279663
Validation after dual ascent:
out_inf: tensor(13.6875, device='cuda:0', dtype=torch.float16) tensor(0.7495, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.1059, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.k_proj
Validation after prune:
out_inf: tensor(36.1250, device='cuda:0', dtype=torch.float16) tensor(1.4238, device='cuda:0', dtype=torch.float16)
tensor(13.5469, device='cuda:0', dtype=torch.float16) tensor(0.3486, device='cuda:0', dtype=torch.float16)
tensor(12.6875, device='cuda:0', dtype=torch.float16) tensor(0.3157, device='cuda:0', dtype=torch.float16)
tensor(12.8750, device='cuda:0', dtype=torch.float16) tensor(0.2883, device='cuda:0', dtype=torch.float16)
tensor(12.7656, device='cuda:0', dtype=torch.float16) tensor(0.3362, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0150, device='cuda:0')
tensor(0.0548, device='cuda:0')
old_score: tensor(0.3220, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1516, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.8291330337524414
Validation after dual ascent:
out_inf: tensor(36.1250, device='cuda:0', dtype=torch.float16) tensor(1.4238, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.1609, device='cuda:0', dtype=torch.float16)
tensor(2.9219, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
tensor(2.7344, device='cuda:0', dtype=torch.float16) tensor(0.1334, device='cuda:0', dtype=torch.float16)
tensor(2.9375, device='cuda:0', dtype=torch.float16) tensor(0.1570, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.1484, device='cuda:0', dtype=torch.float16) tensor(0.3044, device='cuda:0', dtype=torch.float16)
tensor(1.8086, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.1501, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1399, device='cuda:0', dtype=torch.float16)
tensor(1.7051, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0106, device='cuda:0')
tensor(0.0982, device='cuda:0')
old_score: tensor(0.1493, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0918, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.5264153480529785
Validation after dual ascent:
out_inf: tensor(6.1484, device='cuda:0', dtype=torch.float16) tensor(0.3044, device='cuda:0', dtype=torch.float16)
tensor(0.8164, device='cuda:0', dtype=torch.float16) tensor(0.0960, device='cuda:0', dtype=torch.float16)
tensor(0.8613, device='cuda:0', dtype=torch.float16) tensor(0.0949, device='cuda:0', dtype=torch.float16)
tensor(1.0586, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(0.8457, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.7471, device='cuda:0', dtype=torch.float16) tensor(0.0748, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0136, device='cuda:0')
tensor(0.0254, device='cuda:0')
old_score: tensor(0.0248, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0128, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.111122608184814
Validation after dual ascent:
out_inf: tensor(1.7471, device='cuda:0', dtype=torch.float16) tensor(0.0748, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.3320, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.gate_proj
Validation after prune:
out_inf: tensor(14.1641, device='cuda:0', dtype=torch.float16) tensor(0.5107, device='cuda:0', dtype=torch.float16)
tensor(3.6426, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
tensor(3.7656, device='cuda:0', dtype=torch.float16) tensor(0.1538, device='cuda:0', dtype=torch.float16)
tensor(3.5430, device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(3.5488, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0182, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.1565, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0883, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.56813621520996
Validation after dual ascent:
out_inf: tensor(14.1641, device='cuda:0', dtype=torch.float16) tensor(0.5107, device='cuda:0', dtype=torch.float16)
tensor(2.6367, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(2.4043, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(2.2812, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(2.4648, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.up_proj
Validation after prune:
out_inf: tensor(10.1406, device='cuda:0', dtype=torch.float16) tensor(0.2573, device='cuda:0', dtype=torch.float16)
tensor(4.3984, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(4.3281, device='cuda:0', dtype=torch.float16) tensor(0.1189, device='cuda:0', dtype=torch.float16)
tensor(3.9297, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(3.9492, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0171, device='cuda:0')
tensor(0.0400, device='cuda:0')
old_score: tensor(0.1205, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0714, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.712528705596924
Validation after dual ascent:
out_inf: tensor(10.1406, device='cuda:0', dtype=torch.float16) tensor(0.2573, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(1.2031, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.down_proj
Validation after prune:
out_inf: tensor(8.8828, device='cuda:0', dtype=torch.float16) tensor(0.1066, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.3835, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
tensor(0.0266, device='cuda:0')
old_score: tensor(0.0303, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0187, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.06950879096985
Validation after dual ascent:
out_inf: tensor(8.8828, device='cuda:0', dtype=torch.float16) tensor(0.1066, device='cuda:0', dtype=torch.float16)
tensor(0.3057, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.2969, device='cuda:0', dtype=torch.float16) tensor(0.0194, device='cuda:0', dtype=torch.float16)
tensor(0.3086, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.4062, device='cuda:0', dtype=torch.float16) tensor(0.8257, device='cuda:0', dtype=torch.float16)
tensor(5.0312, device='cuda:0', dtype=torch.float16) tensor(0.2064, device='cuda:0', dtype=torch.float16)
tensor(5.4609, device='cuda:0', dtype=torch.float16) tensor(0.1932, device='cuda:0', dtype=torch.float16)
tensor(4.6562, device='cuda:0', dtype=torch.float16) tensor(0.1827, device='cuda:0', dtype=torch.float16)
tensor(5.2734, device='cuda:0', dtype=torch.float16) tensor(0.1992, device='cuda:0', dtype=torch.float16)
tensor(0.0255, device='cuda:0')
old_score: tensor(0.1954, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0914, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.836341142654419
Validation after dual ascent:
out_inf: tensor(16.4062, device='cuda:0', dtype=torch.float16) tensor(0.8257, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.0968, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.0806, device='cuda:0', dtype=torch.float16)
tensor(1.6328, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.1719, device='cuda:0', dtype=torch.float16) tensor(1.5986, device='cuda:0', dtype=torch.float16)
tensor(4.7734, device='cuda:0', dtype=torch.float16) tensor(0.3042, device='cuda:0', dtype=torch.float16)
tensor(4.6094, device='cuda:0', dtype=torch.float16) tensor(0.2776, device='cuda:0', dtype=torch.float16)
tensor(5.0312, device='cuda:0', dtype=torch.float16) tensor(0.2593, device='cuda:0', dtype=torch.float16)
tensor(4.7891, device='cuda:0', dtype=torch.float16) tensor(0.2942, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0168, device='cuda:0')
tensor(0.0654, device='cuda:0')
old_score: tensor(0.2839, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1266, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.3341302871704102
Validation after dual ascent:
out_inf: tensor(21.1719, device='cuda:0', dtype=torch.float16) tensor(1.5986, device='cuda:0', dtype=torch.float16)
tensor(1.4814, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.8477, device='cuda:0', dtype=torch.float16) tensor(0.3340, device='cuda:0', dtype=torch.float16)
tensor(1.5527, device='cuda:0', dtype=torch.float16) tensor(0.1781, device='cuda:0', dtype=torch.float16)
tensor(1.7285, device='cuda:0', dtype=torch.float16) tensor(0.1757, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(1.8945, device='cuda:0', dtype=torch.float16) tensor(0.1741, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0138, device='cuda:0')
tensor(0.3482, device='cuda:0')
old_score: tensor(0.1733, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1077, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7733104228973389
Validation after dual ascent:
out_inf: tensor(5.8477, device='cuda:0', dtype=torch.float16) tensor(0.3340, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
tensor(0.9629, device='cuda:0', dtype=torch.float16) tensor(0.1124, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(1.1436, device='cuda:0', dtype=torch.float16) tensor(0.1098, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.8145, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(3.0703, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0108, device='cuda:0')
tensor(0.0137, device='cuda:0')
old_score: tensor(0.0519, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0296, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.915126323699951
Validation after dual ascent:
out_inf: tensor(3.8145, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.gate_proj
Validation after prune:
out_inf: tensor(17.4219, device='cuda:0', dtype=torch.float16) tensor(0.5698, device='cuda:0', dtype=torch.float16)
tensor(4.7148, device='cuda:0', dtype=torch.float16) tensor(0.1897, device='cuda:0', dtype=torch.float16)
tensor(4.6055, device='cuda:0', dtype=torch.float16) tensor(0.1808, device='cuda:0', dtype=torch.float16)
tensor(3.8867, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(4.0742, device='cuda:0', dtype=torch.float16) tensor(0.1826, device='cuda:0', dtype=torch.float16)
tensor(0.0220, device='cuda:0')
old_score: tensor(0.1805, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0968, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.442530393600464
Validation after dual ascent:
out_inf: tensor(17.4219, device='cuda:0', dtype=torch.float16) tensor(0.5698, device='cuda:0', dtype=torch.float16)
tensor(2.6797, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(2.8438, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(2.7422, device='cuda:0', dtype=torch.float16) tensor(0.0866, device='cuda:0', dtype=torch.float16)
tensor(3.3203, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.up_proj
Validation after prune:
out_inf: tensor(10.7812, device='cuda:0', dtype=torch.float16) tensor(0.3501, device='cuda:0', dtype=torch.float16)
tensor(4.4609, device='cuda:0', dtype=torch.float16) tensor(0.1503, device='cuda:0', dtype=torch.float16)
tensor(4.5156, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(4.5039, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(4.5547, device='cuda:0', dtype=torch.float16) tensor(0.1448, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0169, device='cuda:0')
tensor(0.0265, device='cuda:0')
old_score: tensor(0.1434, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0778, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.131999015808105
Validation after dual ascent:
out_inf: tensor(10.7812, device='cuda:0', dtype=torch.float16) tensor(0.3501, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.0794, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.down_proj
Validation after prune:
out_inf: tensor(12.3828, device='cuda:0', dtype=torch.float16) tensor(0.1937, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.0433, device='cuda:0')
old_score: tensor(0.0433, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0255, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 163.9220838546753
Validation after dual ascent:
out_inf: tensor(12.3828, device='cuda:0', dtype=torch.float16) tensor(0.1937, device='cuda:0', dtype=torch.float16)
tensor(0.4438, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.4221, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.4324, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.4736, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.1562, device='cuda:0', dtype=torch.float16) tensor(0.9224, device='cuda:0', dtype=torch.float16)
tensor(10.2656, device='cuda:0', dtype=torch.float16) tensor(0.3132, device='cuda:0', dtype=torch.float16)
tensor(9.9375, device='cuda:0', dtype=torch.float16) tensor(0.2957, device='cuda:0', dtype=torch.float16)
tensor(9.2969, device='cuda:0', dtype=torch.float16) tensor(0.2808, device='cuda:0', dtype=torch.float16)
tensor(9.6094, device='cuda:0', dtype=torch.float16) tensor(0.2986, device='cuda:0', dtype=torch.float16)
tensor(0.0434, device='cuda:0')
old_score: tensor(0.2971, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0912, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.830543518066406
Validation after dual ascent:
out_inf: tensor(17.1562, device='cuda:0', dtype=torch.float16) tensor(0.9224, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(2.7578, device='cuda:0', dtype=torch.float16) tensor(0.0951, device='cuda:0', dtype=torch.float16)
tensor(3.0352, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(2.6895, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4531, device='cuda:0', dtype=torch.float16) tensor(1.4629, device='cuda:0', dtype=torch.float16)
tensor(11.1641, device='cuda:0', dtype=torch.float16) tensor(0.4502, device='cuda:0', dtype=torch.float16)
tensor(10.4297, device='cuda:0', dtype=torch.float16) tensor(0.4248, device='cuda:0', dtype=torch.float16)
tensor(11.2578, device='cuda:0', dtype=torch.float16) tensor(0.4028, device='cuda:0', dtype=torch.float16)
tensor(10.8438, device='cuda:0', dtype=torch.float16) tensor(0.4329, device='cuda:0', dtype=torch.float16)
tensor(0.0220, device='cuda:0')
old_score: tensor(0.4275, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1292, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9357922077178955
Validation after dual ascent:
out_inf: tensor(19.4531, device='cuda:0', dtype=torch.float16) tensor(1.4629, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1143, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.8359, device='cuda:0', dtype=torch.float16) tensor(0.4055, device='cuda:0', dtype=torch.float16)
tensor(3.9453, device='cuda:0', dtype=torch.float16) tensor(0.1915, device='cuda:0', dtype=torch.float16)
tensor(3.5430, device='cuda:0', dtype=torch.float16) tensor(0.1836, device='cuda:0', dtype=torch.float16)
tensor(3.5000, device='cuda:0', dtype=torch.float16) tensor(0.1750, device='cuda:0', dtype=torch.float16)
tensor(3.7422, device='cuda:0', dtype=torch.float16) tensor(0.1860, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.2285, device='cuda:0')
old_score: tensor(0.1840, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0867, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 0.7775676250457764
Validation after dual ascent:
out_inf: tensor(6.8359, device='cuda:0', dtype=torch.float16) tensor(0.4055, device='cuda:0', dtype=torch.float16)
tensor(0.9482, device='cuda:0', dtype=torch.float16) tensor(0.0901, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(1.0244, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(0.9814, device='cuda:0', dtype=torch.float16) tensor(0.0882, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.4492, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(1.8984, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.9453, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0151, device='cuda:0')
tensor(0.0960, device='cuda:0')
old_score: tensor(0.0630, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0330, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.436265468597412
Validation after dual ascent:
out_inf: tensor(5.4492, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.6182, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.gate_proj
Validation after prune:
out_inf: tensor(19.2031, device='cuda:0', dtype=torch.float16) tensor(0.6118, device='cuda:0', dtype=torch.float16)
tensor(17.8438, device='cuda:0', dtype=torch.float16) tensor(0.2487, device='cuda:0', dtype=torch.float16)
tensor(9.1719, device='cuda:0', dtype=torch.float16) tensor(0.2385, device='cuda:0', dtype=torch.float16)
tensor(8.6719, device='cuda:0', dtype=torch.float16) tensor(0.2275, device='cuda:0', dtype=torch.float16)
tensor(8.3438, device='cuda:0', dtype=torch.float16) tensor(0.2349, device='cuda:0', dtype=torch.float16)
tensor(0.0638, device='cuda:0')
old_score: tensor(0.2374, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0883, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.47383499145508
Validation after dual ascent:
out_inf: tensor(19.2031, device='cuda:0', dtype=torch.float16) tensor(0.6118, device='cuda:0', dtype=torch.float16)
tensor(15.1562, device='cuda:0', dtype=torch.float16) tensor(0.0910, device='cuda:0', dtype=torch.float16)
tensor(6.4062, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(6.2305, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(7.3750, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.up_proj
Validation after prune:
out_inf: tensor(11.5312, device='cuda:0', dtype=torch.float16) tensor(0.5332, device='cuda:0', dtype=torch.float16)
tensor(19.3594, device='cuda:0', dtype=torch.float16) tensor(0.2047, device='cuda:0', dtype=torch.float16)
tensor(7.6758, device='cuda:0', dtype=torch.float16) tensor(0.1952, device='cuda:0', dtype=torch.float16)
tensor(8.1172, device='cuda:0', dtype=torch.float16) tensor(0.1893, device='cuda:0', dtype=torch.float16)
tensor(7.2812, device='cuda:0', dtype=torch.float16) tensor(0.1936, device='cuda:0', dtype=torch.float16)
tensor(0.0427, device='cuda:0')
old_score: tensor(0.1958, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0715, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 49.419554710388184
Validation after dual ascent:
out_inf: tensor(11.5312, device='cuda:0', dtype=torch.float16) tensor(0.5332, device='cuda:0', dtype=torch.float16)
tensor(9.2344, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(7.6289, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(12.0312, device='cuda:0', dtype=torch.float16) tensor(0.0647, device='cuda:0', dtype=torch.float16)
tensor(6.3477, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.down_proj
Validation after prune:
out_inf: tensor(61.1875, device='cuda:0', dtype=torch.float16) tensor(0.5054, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(2.5859, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(2.5586, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(2.3438, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(0.1567, device='cuda:0')
old_score: tensor(0.0687, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0338, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 164.2973394393921
Validation after dual ascent:
out_inf: tensor(61.1875, device='cuda:0', dtype=torch.float16) tensor(0.5054, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.0348, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.8799, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.70it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  4.79it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.32it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.75it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.32it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.799842
layer 1 sparsity 0.799842
layer 2 sparsity 0.799842
layer 3 sparsity 0.799842
layer 4 sparsity 0.799842
layer 5 sparsity 0.799842
layer 6 sparsity 0.799842
layer 7 sparsity 0.799842
layer 8 sparsity 0.799842
layer 9 sparsity 0.799842
layer 10 sparsity 0.799842
layer 11 sparsity 0.799842
layer 12 sparsity 0.799842
layer 13 sparsity 0.799842
layer 14 sparsity 0.799842
layer 15 sparsity 0.799842
layer 16 sparsity 0.799842
layer 17 sparsity 0.799842
layer 18 sparsity 0.799842
layer 19 sparsity 0.799842
layer 20 sparsity 0.799842
layer 21 sparsity 0.799842
layer 22 sparsity 0.799842
layer 23 sparsity 0.799842
layer 24 sparsity 0.799842
layer 25 sparsity 0.799842
layer 26 sparsity 0.799842
layer 27 sparsity 0.799842
layer 28 sparsity 0.799842
layer 29 sparsity 0.799842
layer 30 sparsity 0.799842
layer 31 sparsity 0.799842
sparsity sanity check 0.7998
******************************
evaluating on wikitext2
nsamples 35
sample 0
wikitext perplexity 117.3979263305664
wanda_dual_3	0.7998	117.3979	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-3-8b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.8, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='wanda_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
