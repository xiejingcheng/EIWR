nohup: ignoring input
2025-04-23 23:20:27.393198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-23 23:20:27.595603: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-23 23:20:27.601839: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-23 23:20:27.601868: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-23 23:20:32.939587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-23 23:20:32.941623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-23 23:20:32.944401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.77it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.22it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.14it/s]
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
model.embed_tokens.weight torch.Size([32000, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([32000, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:00<03:24,  1.24it/s]  1%|          | 2/256 [00:01<03:15,  1.30it/s]  2%|▏         | 4/256 [00:01<01:38,  2.55it/s]  2%|▏         | 5/256 [00:02<01:51,  2.26it/s]  2%|▏         | 6/256 [00:02<01:25,  2.91it/s]  3%|▎         | 7/256 [00:03<01:58,  2.10it/s]  3%|▎         | 8/256 [00:03<01:31,  2.70it/s]  4%|▎         | 9/256 [00:03<01:11,  3.44it/s]  4%|▍         | 11/256 [00:03<00:48,  5.10it/s]  5%|▍         | 12/256 [00:03<00:44,  5.46it/s]  5%|▌         | 13/256 [00:04<01:32,  2.63it/s]  5%|▌         | 14/256 [00:05<01:29,  2.71it/s]  6%|▌         | 15/256 [00:05<01:15,  3.19it/s]  6%|▋         | 16/256 [00:05<01:05,  3.66it/s]  7%|▋         | 18/256 [00:06<01:08,  3.48it/s]  8%|▊         | 20/256 [00:06<00:51,  4.60it/s]  8%|▊         | 21/256 [00:06<00:45,  5.20it/s]  9%|▊         | 22/256 [00:06<00:48,  4.81it/s]  9%|▉         | 24/256 [00:07<00:43,  5.36it/s] 10%|▉         | 25/256 [00:07<00:41,  5.52it/s] 10%|█         | 26/256 [00:07<00:54,  4.22it/s] 11%|█         | 28/256 [00:07<00:45,  4.97it/s] 11%|█▏        | 29/256 [00:08<00:46,  4.85it/s] 12%|█▏        | 31/256 [00:08<00:39,  5.73it/s] 12%|█▎        | 32/256 [00:08<00:46,  4.78it/s] 13%|█▎        | 33/256 [00:09<00:57,  3.85it/s] 13%|█▎        | 34/256 [00:09<01:01,  3.58it/s] 14%|█▎        | 35/256 [00:09<01:09,  3.20it/s] 14%|█▍        | 36/256 [00:10<01:21,  2.71it/s] 14%|█▍        | 37/256 [00:10<01:15,  2.91it/s] 15%|█▍        | 38/256 [00:10<01:09,  3.12it/s] 16%|█▌        | 40/256 [00:11<01:03,  3.39it/s] 16%|█▋        | 42/256 [00:11<00:44,  4.81it/s] 17%|█▋        | 43/256 [00:11<00:39,  5.41it/s] 17%|█▋        | 44/256 [00:11<00:38,  5.46it/s] 18%|█▊        | 45/256 [00:11<00:34,  6.17it/s] 18%|█▊        | 46/256 [00:12<00:32,  6.40it/s] 18%|█▊        | 47/256 [00:12<00:34,  6.11it/s] 19%|█▉        | 48/256 [00:12<00:37,  5.48it/s] 19%|█▉        | 49/256 [00:12<00:34,  6.03it/s] 20%|█▉        | 50/256 [00:13<00:52,  3.94it/s] 21%|██        | 53/256 [00:13<00:50,  4.05it/s] 21%|██        | 54/256 [00:14<00:48,  4.15it/s] 21%|██▏       | 55/256 [00:14<00:42,  4.78it/s] 22%|██▏       | 56/256 [00:14<00:48,  4.09it/s] 22%|██▏       | 57/256 [00:14<00:44,  4.43it/s] 23%|██▎       | 58/256 [00:14<00:49,  3.97it/s] 23%|██▎       | 59/256 [00:15<00:43,  4.52it/s] 23%|██▎       | 60/256 [00:15<00:46,  4.18it/s] 24%|██▍       | 61/256 [00:15<00:54,  3.55it/s] 24%|██▍       | 62/256 [00:16<01:01,  3.15it/s] 25%|██▍       | 63/256 [00:16<00:53,  3.63it/s] 25%|██▌       | 64/256 [00:16<00:43,  4.41it/s] 25%|██▌       | 65/256 [00:17<01:10,  2.71it/s] 26%|██▌       | 67/256 [00:17<00:45,  4.18it/s] 27%|██▋       | 68/256 [00:17<00:43,  4.29it/s] 27%|██▋       | 69/256 [00:17<00:44,  4.24it/s] 28%|██▊       | 71/256 [00:18<00:33,  5.45it/s] 29%|██▊       | 73/256 [00:18<00:27,  6.74it/s] 29%|██▉       | 74/256 [00:18<00:27,  6.66it/s] 29%|██▉       | 75/256 [00:18<00:32,  5.59it/s] 30%|██▉       | 76/256 [00:19<00:46,  3.84it/s] 30%|███       | 78/256 [00:19<00:31,  5.58it/s] 31%|███       | 79/256 [00:19<00:40,  4.40it/s] 31%|███▏      | 80/256 [00:20<00:51,  3.42it/s] 32%|███▏      | 81/256 [00:20<00:55,  3.13it/s] 32%|███▏      | 82/256 [00:20<00:46,  3.78it/s] 32%|███▏      | 83/256 [00:21<00:55,  3.10it/s] 33%|███▎      | 84/256 [00:21<00:52,  3.25it/s] 33%|███▎      | 85/256 [00:21<00:50,  3.41it/s] 34%|███▎      | 86/256 [00:21<00:47,  3.61it/s] 34%|███▍      | 87/256 [00:22<01:05,  2.60it/s] 34%|███▍      | 88/256 [00:23<01:07,  2.49it/s] 35%|███▍      | 89/256 [00:23<01:01,  2.73it/s] 35%|███▌      | 90/256 [00:23<01:01,  2.70it/s] 36%|███▌      | 91/256 [00:24<00:59,  2.79it/s] 36%|███▌      | 92/256 [00:24<00:49,  3.31it/s] 36%|███▋      | 93/256 [00:24<00:43,  3.78it/s] 37%|███▋      | 94/256 [00:24<00:51,  3.15it/s] 37%|███▋      | 95/256 [00:25<01:06,  2.42it/s] 38%|███▊      | 96/256 [00:25<00:53,  3.02it/s] 38%|███▊      | 97/256 [00:26<00:57,  2.78it/s] 38%|███▊      | 98/256 [00:26<00:47,  3.33it/s] 39%|███▊      | 99/256 [00:26<00:45,  3.43it/s] 39%|███▉      | 100/256 [00:26<00:43,  3.58it/s] 39%|███▉      | 101/256 [00:27<01:16,  2.03it/s] 40%|███▉      | 102/256 [00:27<01:06,  2.32it/s] 41%|████      | 104/256 [00:28<00:42,  3.55it/s] 41%|████▏     | 106/256 [00:28<00:34,  4.31it/s] 42%|████▏     | 107/256 [00:28<00:34,  4.27it/s] 42%|████▏     | 108/256 [00:29<00:49,  3.01it/s] 43%|████▎     | 111/256 [00:29<00:30,  4.70it/s] 44%|████▍     | 112/256 [00:29<00:32,  4.46it/s] 44%|████▍     | 113/256 [00:30<00:32,  4.45it/s] 45%|████▍     | 114/256 [00:30<00:29,  4.86it/s] 45%|████▍     | 115/256 [00:30<00:27,  5.10it/s] 45%|████▌     | 116/256 [00:30<00:39,  3.58it/s] 46%|████▌     | 117/256 [00:31<00:32,  4.27it/s] 46%|████▌     | 118/256 [00:31<00:30,  4.55it/s] 47%|████▋     | 120/256 [00:31<00:21,  6.41it/s] 47%|████▋     | 121/256 [00:31<00:19,  6.77it/s] 48%|████▊     | 122/256 [00:32<00:37,  3.57it/s] 48%|████▊     | 123/256 [00:32<00:40,  3.27it/s] 48%|████▊     | 124/256 [00:33<00:53,  2.48it/s] 49%|████▉     | 125/256 [00:34<01:24,  1.56it/s] 49%|████▉     | 126/256 [00:34<01:11,  1.83it/s] 50%|████▉     | 127/256 [00:35<01:15,  1.70it/s] 50%|█████     | 129/256 [00:35<00:45,  2.76it/s] 51%|█████     | 130/256 [00:35<00:41,  3.00it/s] 51%|█████     | 131/256 [00:36<00:39,  3.20it/s] 52%|█████▏    | 132/256 [00:36<00:37,  3.33it/s] 52%|█████▏    | 133/256 [00:37<00:46,  2.63it/s] 52%|█████▏    | 134/256 [00:37<00:46,  2.65it/s] 53%|█████▎    | 135/256 [00:37<00:37,  3.27it/s] 53%|█████▎    | 136/256 [00:37<00:37,  3.22it/s] 54%|█████▎    | 137/256 [00:38<00:30,  3.84it/s] 54%|█████▍    | 138/256 [00:38<00:27,  4.36it/s] 54%|█████▍    | 139/256 [00:38<00:24,  4.76it/s] 55%|█████▍    | 140/256 [00:38<00:22,  5.15it/s] 55%|█████▌    | 142/256 [00:38<00:17,  6.66it/s] 56%|█████▌    | 143/256 [00:38<00:16,  6.86it/s] 57%|█████▋    | 145/256 [00:39<00:35,  3.15it/s] 57%|█████▋    | 146/256 [00:40<00:39,  2.81it/s] 57%|█████▋    | 147/256 [00:40<00:35,  3.03it/s] 58%|█████▊    | 148/256 [00:41<00:36,  2.93it/s] 59%|█████▊    | 150/256 [00:41<00:29,  3.61it/s] 59%|█████▉    | 151/256 [00:41<00:25,  4.18it/s] 59%|█████▉    | 152/256 [00:41<00:28,  3.67it/s] 60%|█████▉    | 153/256 [00:42<00:25,  4.07it/s] 60%|██████    | 154/256 [00:42<00:29,  3.50it/s] 61%|██████    | 155/256 [00:42<00:26,  3.85it/s] 61%|██████    | 156/256 [00:42<00:21,  4.55it/s] 61%|██████▏   | 157/256 [00:43<00:28,  3.52it/s] 62%|██████▏   | 158/256 [00:43<00:24,  4.03it/s] 62%|██████▏   | 159/256 [00:44<00:42,  2.26it/s] 62%|██████▎   | 160/256 [00:44<00:33,  2.91it/s] 63%|██████▎   | 162/256 [00:45<00:36,  2.55it/s] 64%|██████▎   | 163/256 [00:45<00:32,  2.85it/s] 64%|██████▍   | 164/256 [00:45<00:27,  3.40it/s] 65%|██████▍   | 166/256 [00:46<00:23,  3.90it/s] 65%|██████▌   | 167/256 [00:46<00:25,  3.48it/s] 66%|██████▌   | 168/256 [00:46<00:28,  3.04it/s] 66%|██████▌   | 169/256 [00:47<00:32,  2.70it/s] 66%|██████▋   | 170/256 [00:47<00:31,  2.71it/s] 67%|██████▋   | 172/256 [00:48<00:22,  3.78it/s] 68%|██████▊   | 173/256 [00:48<00:21,  3.91it/s] 68%|██████▊   | 174/256 [00:48<00:28,  2.85it/s] 68%|██████▊   | 175/256 [00:49<00:41,  1.94it/s] 69%|██████▉   | 176/256 [00:50<00:36,  2.21it/s] 69%|██████▉   | 177/256 [00:50<00:29,  2.66it/s] 70%|██████▉   | 179/256 [00:50<00:19,  3.86it/s] 70%|███████   | 180/256 [00:51<00:37,  2.04it/s] 71%|███████   | 181/256 [00:51<00:29,  2.52it/s] 71%|███████   | 182/256 [00:52<00:38,  1.92it/s] 72%|███████▏  | 184/256 [00:53<00:35,  2.02it/s] 73%|███████▎  | 186/256 [00:53<00:24,  2.87it/s] 73%|███████▎  | 187/256 [00:54<00:27,  2.48it/s] 73%|███████▎  | 188/256 [00:54<00:23,  2.83it/s] 74%|███████▍  | 189/256 [00:55<00:24,  2.79it/s] 74%|███████▍  | 190/256 [00:55<00:21,  3.01it/s] 75%|███████▍  | 191/256 [00:55<00:19,  3.32it/s] 75%|███████▌  | 192/256 [00:56<00:23,  2.77it/s] 75%|███████▌  | 193/256 [00:56<00:21,  2.92it/s] 77%|███████▋  | 196/256 [00:56<00:13,  4.39it/s] 77%|███████▋  | 197/256 [00:57<00:15,  3.79it/s] 78%|███████▊  | 199/256 [00:57<00:11,  4.84it/s] 79%|███████▊  | 201/256 [00:57<00:10,  5.42it/s] 79%|███████▉  | 202/256 [00:58<00:12,  4.40it/s] 79%|███████▉  | 203/256 [00:58<00:10,  4.99it/s] 80%|███████▉  | 204/256 [00:58<00:09,  5.66it/s] 80%|████████  | 205/256 [00:58<00:08,  6.26it/s] 81%|████████  | 207/256 [00:58<00:06,  7.55it/s] 81%|████████▏ | 208/256 [00:58<00:07,  6.38it/s] 82%|████████▏ | 210/256 [00:58<00:05,  8.54it/s] 83%|████████▎ | 212/256 [00:59<00:05,  8.28it/s] 83%|████████▎ | 213/256 [00:59<00:05,  7.40it/s] 84%|████████▎ | 214/256 [00:59<00:07,  5.63it/s] 84%|████████▍ | 215/256 [01:00<00:09,  4.48it/s] 84%|████████▍ | 216/256 [01:00<00:09,  4.40it/s] 85%|████████▌ | 218/256 [01:00<00:07,  5.24it/s] 86%|████████▌ | 219/256 [01:01<00:14,  2.49it/s] 86%|████████▌ | 220/256 [01:01<00:12,  2.91it/s] 86%|████████▋ | 221/256 [01:02<00:12,  2.86it/s] 87%|████████▋ | 222/256 [01:02<00:12,  2.83it/s] 87%|████████▋ | 223/256 [01:02<00:12,  2.70it/s] 88%|████████▊ | 224/256 [01:04<00:25,  1.25it/s] 88%|████████▊ | 225/256 [01:05<00:24,  1.27it/s] 88%|████████▊ | 226/256 [01:05<00:18,  1.65it/s] 89%|████████▊ | 227/256 [01:06<00:14,  1.96it/s] 89%|████████▉ | 228/256 [01:06<00:13,  2.09it/s] 89%|████████▉ | 229/256 [01:07<00:20,  1.33it/s] 90%|████████▉ | 230/256 [01:07<00:14,  1.77it/s] 90%|█████████ | 231/256 [01:08<00:13,  1.85it/s] 91%|█████████ | 232/256 [01:08<00:11,  2.12it/s] 91%|█████████ | 233/256 [01:08<00:08,  2.59it/s] 92%|█████████▏| 235/256 [01:09<00:05,  3.60it/s] 92%|█████████▏| 236/256 [01:09<00:05,  3.50it/s] 93%|█████████▎| 237/256 [01:09<00:04,  3.89it/s] 93%|█████████▎| 238/256 [01:09<00:04,  4.47it/s] 93%|█████████▎| 239/256 [01:10<00:03,  4.33it/s] 94%|█████████▍| 241/256 [01:10<00:02,  5.59it/s] 95%|█████████▍| 242/256 [01:11<00:04,  2.81it/s] 95%|█████████▌| 244/256 [01:11<00:02,  4.30it/s] 96%|█████████▌| 245/256 [01:11<00:02,  4.25it/s] 96%|█████████▌| 246/256 [01:11<00:02,  4.72it/s] 97%|█████████▋| 248/256 [01:11<00:01,  6.40it/s] 97%|█████████▋| 249/256 [01:12<00:01,  3.89it/s] 98%|█████████▊| 251/256 [01:12<00:00,  5.42it/s] 98%|█████████▊| 252/256 [01:13<00:01,  3.41it/s] 99%|█████████▉| 253/256 [01:13<00:01,  2.86it/s]100%|█████████▉| 255/256 [01:14<00:00,  2.98it/s]100%|██████████| 256/256 [01:14<00:00,  3.05it/s]100%|██████████| 256/256 [01:14<00:00,  3.42it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
pruning layer 0 name self_attn.q_proj
Validation after prune:
out_inf: tensor(7.8555, device='cuda:0', dtype=torch.float16) tensor(0.6099, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.k_proj
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0703, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.v_proj
Validation after prune:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0388, device='cuda:0')
old_score: tensor(0.0018, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.852855205535889
Validation after dual ascent:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0230, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0309, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0248, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0245, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0055, device='cuda:0', dtype=torch.float16) tensor(8.7202e-05, device='cuda:0', dtype=torch.float16)
tensor(0.0033, device='cuda:0', dtype=torch.float16) tensor(0.0001, device='cuda:0', dtype=torch.float16)
tensor(0.0053, device='cuda:0', dtype=torch.float16) tensor(0.0001, device='cuda:0', dtype=torch.float16)
tensor(0.0068, device='cuda:0', dtype=torch.float16) tensor(9.0718e-05, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.4131, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0164, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.0107, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0060, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.442747116088867
Validation after dual ascent:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.2842, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.2859, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.up_proj
Validation after prune:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1738, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1665, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0158, device='cuda:0')
tensor(0.0181, device='cuda:0')
old_score: tensor(0.0105, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0059, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.521525621414185
Validation after dual ascent:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1079, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.1211, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.1284, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.1123, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0476, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0431, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0389, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0459, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0726, device='cuda:0')
old_score: tensor(0.0013, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0009, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.78464555740356
Validation after dual ascent:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0203, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0225, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0222, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0444, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.q_proj
Validation after prune:
out_inf: tensor(9.2500, device='cuda:0', dtype=torch.float16) tensor(0.7812, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
tensor(0.9629, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.k_proj
Validation after prune:
out_inf: tensor(7.7383, device='cuda:0', dtype=torch.float16) tensor(0.7896, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.2666, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2744, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.2695, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0193, device='cuda:0')
tensor(0.0290, device='cuda:0')
old_score: tensor(0.0067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0037, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.242616891860962
Validation after dual ascent:
out_inf: tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.1572, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.1689, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.1631, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.5386, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.0273, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
tensor(0.0150, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0241, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0216, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.gate_proj
Validation after prune:
out_inf: tensor(43.6562, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(3.7188, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(3.4688, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(3.8750, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0160, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.0229, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0140, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.83124327659607
Validation after dual ascent:
out_inf: tensor(43.6562, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.up_proj
Validation after prune:
out_inf: tensor(37.7188, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(2.4688, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0130, device='cuda:0')
tensor(0.0198, device='cuda:0')
old_score: tensor(0.0209, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.856199264526367
Validation after dual ascent:
out_inf: tensor(37.7188, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.down_proj
Validation after prune:
out_inf: tensor(2674., device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0908, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0878, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(2.0303, device='cuda:0')
old_score: tensor(0.0037, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0135, device='cuda:0', dtype=torch.float16)
Not converged!
Dual ascent finished!
Time: 98.74338936805725
Validation after dual ascent:
out_inf: tensor(2674., device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0908, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0878, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12., device='cuda:0', dtype=torch.float16) tensor(0.9028, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.k_proj
Validation after prune:
out_inf: tensor(13.4219, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0680, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.9785, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.3418, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.4590, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.0207, device='cuda:0')
old_score: tensor(0.0332, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0216, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4496214389801025
Validation after dual ascent:
out_inf: tensor(2.9785, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
tensor(0.2539, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.2668, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.2549, device='cuda:0', dtype=torch.float16) tensor(0.0214, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9341, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.2323, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0934, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.1364, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0425, device='cuda:0')
old_score: tensor(0.0022, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0017, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.942537069320679
Validation after dual ascent:
out_inf: tensor(0.9341, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1069, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.1520, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.1103, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0942, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.2324, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0166, device='cuda:0')
tensor(0.0158, device='cuda:0')
old_score: tensor(0.0334, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.977049589157104
Validation after dual ascent:
out_inf: tensor(2.2324, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(0.3552, device='cuda:0', dtype=torch.float16) tensor(0.0237, device='cuda:0', dtype=torch.float16)
tensor(0.4268, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.3782, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
tensor(0.4211, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.3125, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.2666, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.3730, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0166, device='cuda:0')
tensor(0.0247, device='cuda:0')
old_score: tensor(0.0306, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0222, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110334634780884
Validation after dual ascent:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.2312, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.2405, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.2421, device='cuda:0', dtype=torch.float16) tensor(0.0237, device='cuda:0', dtype=torch.float16)
tensor(0.2595, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.0884, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.1057, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1099, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1192, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0774, device='cuda:0')
old_score: tensor(0.0054, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0046, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 99.07238173484802
Validation after dual ascent:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.0664, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0763, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.0721, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0824, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(0.8271, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0')
old_score: tensor(0.1021, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0714, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.956305980682373
Validation after dual ascent:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(0.8271, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(1.1748, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(1.1846, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.1034, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0150, device='cuda:0')
tensor(0.0522, device='cuda:0')
old_score: tensor(0.1058, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0734, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.79109787940979
Validation after dual ascent:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(1.0557, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.7051, device='cuda:0', dtype=torch.float16) tensor(0.1945, device='cuda:0', dtype=torch.float16)
tensor(0.4468, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.4751, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.4448, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0176, device='cuda:0')
tensor(0.0302, device='cuda:0')
old_score: tensor(0.0546, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0404, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.465723991394043
Validation after dual ascent:
out_inf: tensor(2.7051, device='cuda:0', dtype=torch.float16) tensor(0.1945, device='cuda:0', dtype=torch.float16)
tensor(0.4058, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.4714, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.5620, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.4412, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.1746, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.1528, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.1484, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0376, device='cuda:0')
old_score: tensor(0.0031, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0025, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.974648714065552
Validation after dual ascent:
out_inf: tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.1494, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0933, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1138, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.1045, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.0820, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0067, device='cuda:0')
tensor(0.0184, device='cuda:0')
old_score: tensor(0.0430, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0334, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.117404937744141
Validation after dual ascent:
out_inf: tensor(5.0820, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(0.6006, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0188, device='cuda:0')
tensor(0.1437, device='cuda:0')
old_score: tensor(0.0396, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0309, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.188746690750122
Validation after dual ascent:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
tensor(0.3037, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.3445, device='cuda:0', dtype=torch.float16) tensor(0.0290, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.3101, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5771, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.1238, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1736, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1309, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1255, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0199, device='cuda:0')
tensor(0.0524, device='cuda:0')
old_score: tensor(0.0079, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0069, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 70.26182007789612
Validation after dual ascent:
out_inf: tensor(1.5771, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.0862, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1395, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1021, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0961, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.1797, device='cuda:0', dtype=torch.float16) tensor(0.8057, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.1396, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1032, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0187, device='cuda:0')
tensor(0.0536, device='cuda:0')
old_score: tensor(0.1036, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0760, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2081897258758545
Validation after dual ascent:
out_inf: tensor(13.1797, device='cuda:0', dtype=torch.float16) tensor(0.8057, device='cuda:0', dtype=torch.float16)
tensor(0.9580, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.9263, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(1.0420, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(1.0215, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.0254, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0183, device='cuda:0')
tensor(0.0405, device='cuda:0')
old_score: tensor(0.1060, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0768, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.836452960968018
Validation after dual ascent:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.0254, device='cuda:0', dtype=torch.float16)
tensor(1.1357, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.0137, device='cuda:0', dtype=torch.float16) tensor(0.0819, device='cuda:0', dtype=torch.float16)
tensor(1.0479, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.4746, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(0.6006, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.0301, device='cuda:0')
old_score: tensor(0.0569, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0433, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4664151668548584
Validation after dual ascent:
out_inf: tensor(3.4746, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(0.4116, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.4128, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.4465, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.3203, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.2217, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.2158, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0269, device='cuda:0')
old_score: tensor(0.0061, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0047, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.964456558227539
Validation after dual ascent:
out_inf: tensor(3.3203, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
tensor(0.1348, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.7617, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0172, device='cuda:0')
tensor(0.2353, device='cuda:0')
old_score: tensor(0.0524, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0416, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.184902667999268
Validation after dual ascent:
out_inf: tensor(4.7617, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.6255, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.6040, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.1191, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0144, device='cuda:0')
tensor(0.2109, device='cuda:0')
old_score: tensor(0.0468, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0374, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.188089370727539
Validation after dual ascent:
out_inf: tensor(3.1191, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(0.3699, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.3481, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.down_proj
Validation after prune:
out_inf: tensor(9.3359, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.2061, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.2295, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1914, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.2275, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0108, device='cuda:0')
tensor(0.0148, device='cuda:0')
old_score: tensor(0.0117, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 46.09372806549072
Validation after dual ascent:
out_inf: tensor(9.3359, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.1584, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1378, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1326, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1582, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.5234, device='cuda:0', dtype=torch.float16) tensor(0.8149, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.1092, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
tensor(0.0869, device='cuda:0')
old_score: tensor(0.1113, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0845, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.960939645767212
Validation after dual ascent:
out_inf: tensor(14.5234, device='cuda:0', dtype=torch.float16) tensor(0.8149, device='cuda:0', dtype=torch.float16)
tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.9746, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4062, device='cuda:0', dtype=torch.float16) tensor(1.0625, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1196, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0152, device='cuda:0')
tensor(0.0609, device='cuda:0')
old_score: tensor(0.1166, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0867, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.789873361587524
Validation after dual ascent:
out_inf: tensor(19.4062, device='cuda:0', dtype=torch.float16) tensor(1.0625, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(1.0840, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3711, device='cuda:0', dtype=torch.float16) tensor(0.2059, device='cuda:0', dtype=torch.float16)
tensor(0.4468, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.4741, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.5073, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0168, device='cuda:0')
tensor(0.0345, device='cuda:0')
old_score: tensor(0.0608, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0483, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4708027839660645
Validation after dual ascent:
out_inf: tensor(2.3711, device='cuda:0', dtype=torch.float16) tensor(0.2059, device='cuda:0', dtype=torch.float16)
tensor(0.4045, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.3359, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.2310, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.2197, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.2383, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2214, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0319, device='cuda:0')
old_score: tensor(0.0067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.976927518844604
Validation after dual ascent:
out_inf: tensor(4.3359, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.2034, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.1482, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.1888, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.2021, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.7988, device='cuda:0', dtype=torch.float16) tensor(0.2249, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0131, device='cuda:0')
tensor(0.0272, device='cuda:0')
old_score: tensor(0.0593, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0466, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.119384050369263
Validation after dual ascent:
out_inf: tensor(3.7988, device='cuda:0', dtype=torch.float16) tensor(0.2249, device='cuda:0', dtype=torch.float16)
tensor(0.6846, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.6943, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.5728, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4258, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0069, device='cuda:0')
tensor(0.0242, device='cuda:0')
old_score: tensor(0.0526, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.122817754745483
Validation after dual ascent:
out_inf: tensor(4.4258, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(0.3767, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5576, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.2134, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.3267, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.2078, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0167, device='cuda:0')
tensor(0.0127, device='cuda:0')
old_score: tensor(0.0144, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0128, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 31.63829755783081
Validation after dual ascent:
out_inf: tensor(1.5576, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.1804, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.2446, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1323, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.5547, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(2.0586, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.7773, device='cuda:0', dtype=torch.float16) tensor(0.1350, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0154, device='cuda:0')
tensor(0.0523, device='cuda:0')
old_score: tensor(0.1345, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1001, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.210299253463745
Validation after dual ascent:
out_inf: tensor(13.5547, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(1.4307, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
tensor(1.4199, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.6875, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.7520, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0176, device='cuda:0')
tensor(0.0565, device='cuda:0')
old_score: tensor(0.1379, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.212895631790161
Validation after dual ascent:
out_inf: tensor(16.6875, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(1.4678, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(1.5254, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.5488, device='cuda:0', dtype=torch.float16) tensor(0.2539, device='cuda:0', dtype=torch.float16)
tensor(0.5815, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.5864, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(0.6177, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.5796, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.0594, device='cuda:0')
old_score: tensor(0.0724, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.472820281982422
Validation after dual ascent:
out_inf: tensor(3.5488, device='cuda:0', dtype=torch.float16) tensor(0.2539, device='cuda:0', dtype=torch.float16)
tensor(0.4717, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5122, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.5913, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.7383, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.3271, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.2988, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0118, device='cuda:0')
tensor(0.0213, device='cuda:0')
old_score: tensor(0.0112, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0083, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.296136856079102
Validation after dual ascent:
out_inf: tensor(4.7383, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.2739, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2568, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.5664, device='cuda:0', dtype=torch.float16) tensor(0.2866, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
tensor(0.8887, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0034, device='cuda:0')
tensor(0.0291, device='cuda:0')
old_score: tensor(0.0659, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115855693817139
Validation after dual ascent:
out_inf: tensor(4.5664, device='cuda:0', dtype=torch.float16) tensor(0.2866, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.9453, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0020, device='cuda:0')
tensor(0.0252, device='cuda:0')
old_score: tensor(0.0569, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0449, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.118627548217773
Validation after dual ascent:
out_inf: tensor(2.9453, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.2637, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
tensor(0.3193, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.2354, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0081, device='cuda:0')
tensor(0.0137, device='cuda:0')
old_score: tensor(0.0176, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0153, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.94735813140869
Validation after dual ascent:
out_inf: tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.1968, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.2188, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1499, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.2454, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1371, device='cuda:0', dtype=torch.float16)
tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(2.0625, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0471, device='cuda:0')
old_score: tensor(0.1401, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1041, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2110812664031982
Validation after dual ascent:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.4121, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.9858, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1436, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1406, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0405, device='cuda:0')
old_score: tensor(0.1415, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1043, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.213479995727539
Validation after dual ascent:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.9858, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.3691, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8242, device='cuda:0', dtype=torch.float16) tensor(0.2639, device='cuda:0', dtype=torch.float16)
tensor(0.6079, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0114, device='cuda:0')
tensor(0.0677, device='cuda:0')
old_score: tensor(0.0765, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0599, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4721362590789795
Validation after dual ascent:
out_inf: tensor(4.8242, device='cuda:0', dtype=torch.float16) tensor(0.2639, device='cuda:0', dtype=torch.float16)
tensor(0.5405, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.5571, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(0.5249, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.9082, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3516, device='cuda:0', dtype=torch.float16) tensor(0.0163, device='cuda:0', dtype=torch.float16)
tensor(0.4502, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0177, device='cuda:0')
tensor(0.0276, device='cuda:0')
old_score: tensor(0.0144, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.34908390045166
Validation after dual ascent:
out_inf: tensor(3.9082, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.2529, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.3721, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.3286, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.0713, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0326, device='cuda:0')
old_score: tensor(0.0703, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0539, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.116764068603516
Validation after dual ascent:
out_inf: tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.3286, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.9473, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.8765, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0781, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0022, device='cuda:0')
tensor(0.0285, device='cuda:0')
old_score: tensor(0.0608, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0475, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.12134051322937
Validation after dual ascent:
out_inf: tensor(4.0781, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.3982, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.4980, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.5742, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.3818, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(0.3721, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.3320, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0075, device='cuda:0')
tensor(0.0157, device='cuda:0')
old_score: tensor(0.0206, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0175, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.12742829322815
Validation after dual ascent:
out_inf: tensor(2.5742, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.2693, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.2556, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.2434, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.2822, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(2.1719, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(2.1367, device='cuda:0', dtype=torch.float16) tensor(0.1367, device='cuda:0', dtype=torch.float16)
tensor(0.1500, device='cuda:0')
old_score: tensor(0.1379, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.950187683105469
Validation after dual ascent:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1029, device='cuda:0', dtype=torch.float16)
tensor(1.4795, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(1.4443, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(1.0127, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(1.5449, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
tensor(0.1496, device='cuda:0')
old_score: tensor(0.1395, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1039, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.985426664352417
Validation after dual ascent:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(1.0127, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(1.2490, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0766, device='cuda:0', dtype=torch.float16)
tensor(0.6304, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.5752, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(0.0670, device='cuda:0')
old_score: tensor(0.0782, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0608, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.962560176849365
Validation after dual ascent:
out_inf: tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
tensor(0.5278, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.5396, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.4180, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0187, device='cuda:0')
tensor(0.0217, device='cuda:0')
old_score: tensor(0.0168, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.89716911315918
Validation after dual ascent:
out_inf: tensor(4.4180, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.2305, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3018, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.2876, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.7227, device='cuda:0', dtype=torch.float16) tensor(0.3235, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(1.2012, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0038, device='cuda:0')
tensor(0.0355, device='cuda:0')
old_score: tensor(0.0709, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0553, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.128740549087524
Validation after dual ascent:
out_inf: tensor(5.7227, device='cuda:0', dtype=torch.float16) tensor(0.3235, device='cuda:0', dtype=torch.float16)
tensor(0.7544, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.7803, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.5352, device='cuda:0', dtype=torch.float16) tensor(0.2090, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0025, device='cuda:0')
tensor(0.0324, device='cuda:0')
old_score: tensor(0.0638, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.140190124511719
Validation after dual ascent:
out_inf: tensor(7.5352, device='cuda:0', dtype=torch.float16) tensor(0.2090, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.6543, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.3892, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.4526, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0177, device='cuda:0')
tensor(0.0236, device='cuda:0')
old_score: tensor(0.0225, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0193, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.32552170753479
Validation after dual ascent:
out_inf: tensor(2.6543, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.3135, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.2471, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.7920, device='cuda:0', dtype=torch.float16)
tensor(1.5918, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.7910, device='cuda:0', dtype=torch.float16) tensor(0.1460, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(0.2079, device='cuda:0')
old_score: tensor(0.1440, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.969998836517334
Validation after dual ascent:
out_inf: tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.7920, device='cuda:0', dtype=torch.float16)
tensor(1.2979, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1079, device='cuda:0', dtype=torch.float16)
tensor(1.1865, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4219, device='cuda:0', dtype=torch.float16) tensor(1.0342, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1431, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.1494, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.1517, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1459, device='cuda:0', dtype=torch.float16)
tensor(0.2171, device='cuda:0')
old_score: tensor(0.1476, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1116, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.004978895187378
Validation after dual ascent:
out_inf: tensor(19.4219, device='cuda:0', dtype=torch.float16) tensor(1.0342, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.2812, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.6904, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.0829, device='cuda:0')
old_score: tensor(0.0818, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0647, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.980709552764893
Validation after dual ascent:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.2812, device='cuda:0', dtype=torch.float16)
tensor(0.5459, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.5825, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
tensor(0.5825, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.8320, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0196, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0196, device='cuda:0')
tensor(0.0400, device='cuda:0')
old_score: tensor(0.0185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0141, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.683923006057739
Validation after dual ascent:
out_inf: tensor(3.8320, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3926, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.2793, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.3389, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.4766, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(1.4326, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0403, device='cuda:0')
old_score: tensor(0.0728, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0578, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.137495279312134
Validation after dual ascent:
out_inf: tensor(6.4766, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
tensor(0.8916, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.2213, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0029, device='cuda:0')
tensor(0.0380, device='cuda:0')
old_score: tensor(0.0668, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0536, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1370344161987305
Validation after dual ascent:
out_inf: tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.2213, device='cuda:0', dtype=torch.float16)
tensor(0.4961, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4736, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.3740, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.3564, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.3320, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0044, device='cuda:0')
tensor(0.0208, device='cuda:0')
old_score: tensor(0.0244, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0214, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.35900330543518
Validation after dual ascent:
out_inf: tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.2676, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.3462, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(0.2350, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.9844, device='cuda:0', dtype=torch.float16) tensor(0.7798, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.1495, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(0.1227, device='cuda:0')
old_score: tensor(0.1455, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.973779678344727
Validation after dual ascent:
out_inf: tensor(13.9844, device='cuda:0', dtype=torch.float16) tensor(0.7798, device='cuda:0', dtype=torch.float16)
tensor(1.3135, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(1.0469, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1534, device='cuda:0', dtype=torch.float16)
tensor(1.7461, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
tensor(0.1277, device='cuda:0')
old_score: tensor(0.1498, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1151, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.011037349700928
Validation after dual ascent:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(1.0469, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.4307, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1183, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.1875, device='cuda:0', dtype=torch.float16) tensor(0.2869, device='cuda:0', dtype=torch.float16)
tensor(0.6401, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.6724, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0192, device='cuda:0')
tensor(0.0843, device='cuda:0')
old_score: tensor(0.0826, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0663, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2138376235961914
Validation after dual ascent:
out_inf: tensor(7.1875, device='cuda:0', dtype=torch.float16) tensor(0.2869, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.6538, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.0039, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(0.4404, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0076, device='cuda:0')
tensor(0.0309, device='cuda:0')
old_score: tensor(0.0238, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0175, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7358202934265137
Validation after dual ascent:
out_inf: tensor(5.0039, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.3311, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.4023, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.3599, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.7812, device='cuda:0', dtype=torch.float16) tensor(0.3398, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.2129, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(1.3311, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0040, device='cuda:0')
tensor(0.0430, device='cuda:0')
old_score: tensor(0.0741, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0592, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1332972049713135
Validation after dual ascent:
out_inf: tensor(6.7812, device='cuda:0', dtype=torch.float16) tensor(0.3398, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.9248, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.1045, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.6621, device='cuda:0', dtype=torch.float16) tensor(0.2379, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.5591, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0031, device='cuda:0')
tensor(0.0408, device='cuda:0')
old_score: tensor(0.0692, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0558, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.131296873092651
Validation after dual ascent:
out_inf: tensor(3.6621, device='cuda:0', dtype=torch.float16) tensor(0.2379, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.0586, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.4858, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0044, device='cuda:0')
tensor(0.0240, device='cuda:0')
old_score: tensor(0.0269, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0234, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.337368726730347
Validation after dual ascent:
out_inf: tensor(3.0586, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.3364, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.2451, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.2964, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
tensor(0.3691, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(0.7793, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
tensor(2.4961, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
tensor(0.1669, device='cuda:0')
old_score: tensor(0.1511, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1180, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.976272583007812
Validation after dual ascent:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(0.7793, device='cuda:0', dtype=torch.float16)
tensor(1.7305, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(1.9082, device='cuda:0', dtype=torch.float16) tensor(0.1159, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
tensor(1.9121, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.9297, device='cuda:0', dtype=torch.float16) tensor(1.0166, device='cuda:0', dtype=torch.float16)
tensor(1.7930, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.9033, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
tensor(1.8027, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(0.1729, device='cuda:0')
old_score: tensor(0.1520, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1174, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.022193908691406
Validation after dual ascent:
out_inf: tensor(15.9297, device='cuda:0', dtype=torch.float16) tensor(1.0166, device='cuda:0', dtype=torch.float16)
tensor(1.5068, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(1.3818, device='cuda:0', dtype=torch.float16) tensor(0.1167, device='cuda:0', dtype=torch.float16)
tensor(1.5605, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.3438, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.7490, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(0.7778, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(0.7534, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0174, device='cuda:0')
tensor(0.0799, device='cuda:0')
old_score: tensor(0.0961, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0775, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.792660474777222
Validation after dual ascent:
out_inf: tensor(8.3438, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.6514, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.6450, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(0.5757, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0063, device='cuda:0')
tensor(0.0361, device='cuda:0')
old_score: tensor(0.0269, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0192, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7410695552825928
Validation after dual ascent:
out_inf: tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.4297, device='cuda:0', dtype=torch.float16) tensor(0.3511, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(1.5801, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(1.5723, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0044, device='cuda:0')
tensor(0.0475, device='cuda:0')
old_score: tensor(0.0771, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0616, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.140612363815308
Validation after dual ascent:
out_inf: tensor(6.4297, device='cuda:0', dtype=torch.float16) tensor(0.3511, device='cuda:0', dtype=torch.float16)
tensor(1.1768, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(1.1123, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.9717, device='cuda:0', dtype=torch.float16) tensor(0.0615, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.8691, device='cuda:0', dtype=torch.float16) tensor(0.2423, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.6045, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.6084, device='cuda:0', dtype=torch.float16) tensor(0.0727, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0034, device='cuda:0')
tensor(0.0455, device='cuda:0')
old_score: tensor(0.0726, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0587, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.140873670578003
Validation after dual ascent:
out_inf: tensor(3.8691, device='cuda:0', dtype=torch.float16) tensor(0.2423, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.4917, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.2148, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.4634, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.4956, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0022, device='cuda:0')
tensor(0.0265, device='cuda:0')
old_score: tensor(0.0286, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.344026803970337
Validation after dual ascent:
out_inf: tensor(3.2148, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.3101, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.4094, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.4375, device='cuda:0', dtype=torch.float16) tensor(0.7842, device='cuda:0', dtype=torch.float16)
tensor(2.1055, device='cuda:0', dtype=torch.float16) tensor(0.1538, device='cuda:0', dtype=torch.float16)
tensor(2.0273, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.1617, device='cuda:0', dtype=torch.float16)
tensor(1.8086, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.2244, device='cuda:0')
old_score: tensor(0.1570, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4773733615875244
Validation after dual ascent:
out_inf: tensor(17.4375, device='cuda:0', dtype=torch.float16) tensor(0.7842, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1225, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.6562, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
tensor(1.7090, device='cuda:0', dtype=torch.float16) tensor(0.1626, device='cuda:0', dtype=torch.float16)
tensor(2.2461, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.1606, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0171, device='cuda:0')
tensor(0.2298, device='cuda:0')
old_score: tensor(0.1624, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1265, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4795126914978027
Validation after dual ascent:
out_inf: tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1241, device='cuda:0', dtype=torch.float16)
tensor(1.3926, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(1.3730, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.2266, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(0.7466, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(0.7783, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0084, device='cuda:0')
tensor(0.1414, device='cuda:0')
old_score: tensor(0.0950, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4728384017944336
Validation after dual ascent:
out_inf: tensor(6.2266, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(0.6255, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(0.6343, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.1680, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0262, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0063, device='cuda:0')
tensor(0.0139, device='cuda:0')
old_score: tensor(0.0282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0203, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.945566415786743
Validation after dual ascent:
out_inf: tensor(5.1680, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.4116, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.8086, device='cuda:0', dtype=torch.float16) tensor(0.3567, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.0791, device='cuda:0', dtype=torch.float16)
tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0045, device='cuda:0')
tensor(0.0528, device='cuda:0')
old_score: tensor(0.0795, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0636, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.128627300262451
Validation after dual ascent:
out_inf: tensor(6.8086, device='cuda:0', dtype=torch.float16) tensor(0.3567, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9727, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0037, device='cuda:0')
tensor(0.0517, device='cuda:0')
old_score: tensor(0.0760, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0615, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.129853010177612
Validation after dual ascent:
out_inf: tensor(4.9727, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.4995, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.4951, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
tensor(0.5088, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
tensor(0.5186, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0020, device='cuda:0')
tensor(0.0310, device='cuda:0')
old_score: tensor(0.0305, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0266, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.314873218536377
Validation after dual ascent:
out_inf: tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.2781, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.3276, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.5859, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1561, device='cuda:0', dtype=torch.float16)
tensor(2.1211, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1632, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0161, device='cuda:0')
tensor(0.2444, device='cuda:0')
old_score: tensor(0.1593, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1259, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4840996265411377
Validation after dual ascent:
out_inf: tensor(13.5859, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
tensor(1.4854, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(1.6074, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9990, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1611, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.2466, device='cuda:0')
old_score: tensor(0.1622, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1272, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4842779636383057
Validation after dual ascent:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9990, device='cuda:0', dtype=torch.float16)
tensor(1.3721, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
tensor(1.5352, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.5342, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.1797, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.1020, device='cuda:0', dtype=torch.float16)
tensor(0.7905, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0088, device='cuda:0')
tensor(0.1586, device='cuda:0')
old_score: tensor(0.1002, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0818, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.479159355163574
Validation after dual ascent:
out_inf: tensor(5.1797, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.6597, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(0.6724, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0173, device='cuda:0')
tensor(0.0305, device='cuda:0')
old_score: tensor(0.0295, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0212, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9436888694763184
Validation after dual ascent:
out_inf: tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.4619, device='cuda:0', dtype=torch.float16) tensor(0.0214, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.0078, device='cuda:0', dtype=torch.float16) tensor(0.3726, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(1.3789, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.0586, device='cuda:0')
old_score: tensor(0.0822, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0652, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.128201484680176
Validation after dual ascent:
out_inf: tensor(7.0078, device='cuda:0', dtype=torch.float16) tensor(0.3726, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.7461, device='cuda:0', dtype=torch.float16) tensor(0.2693, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(0.7363, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.0584, device='cuda:0')
old_score: tensor(0.0797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0640, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.136981964111328
Validation after dual ascent:
out_inf: tensor(4.7461, device='cuda:0', dtype=torch.float16) tensor(0.2693, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.1172, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.6187, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.5869, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0024, device='cuda:0')
tensor(0.0387, device='cuda:0')
old_score: tensor(0.0342, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0297, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.317332029342651
Validation after dual ascent:
out_inf: tensor(5.1172, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.3804, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.6953, device='cuda:0', dtype=torch.float16) tensor(0.7998, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(1.9258, device='cuda:0', dtype=torch.float16) tensor(0.1633, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1692, device='cuda:0', dtype=torch.float16)
tensor(2.2402, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0076, device='cuda:0')
tensor(0.0607, device='cuda:0')
old_score: tensor(0.1641, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1277, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2133638858795166
Validation after dual ascent:
out_inf: tensor(13.6953, device='cuda:0', dtype=torch.float16) tensor(0.7998, device='cuda:0', dtype=torch.float16)
tensor(1.7246, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(1.4824, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
tensor(1.4971, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4375, device='cuda:0', dtype=torch.float16) tensor(1.0713, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
tensor(1.7559, device='cuda:0', dtype=torch.float16) tensor(0.1681, device='cuda:0', dtype=torch.float16)
tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.1730, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.1669, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0093, device='cuda:0')
tensor(0.0557, device='cuda:0')
old_score: tensor(0.1682, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1290, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2080326080322266
Validation after dual ascent:
out_inf: tensor(19.4375, device='cuda:0', dtype=torch.float16) tensor(1.0713, device='cuda:0', dtype=torch.float16)
tensor(1.4189, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1343, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.3240, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0996, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(0.8037, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0130, device='cuda:0')
tensor(0.1722, device='cuda:0')
old_score: tensor(0.1010, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0816, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4645209312438965
Validation after dual ascent:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.3240, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.7231, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0851, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.2852, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0088, device='cuda:0')
tensor(0.0547, device='cuda:0')
old_score: tensor(0.0328, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7282471656799316
Validation after dual ascent:
out_inf: tensor(7.2852, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(0.3711, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.3926, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.3721, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1914, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(1.6309, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.0685, device='cuda:0')
old_score: tensor(0.0857, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0687, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.094701290130615
Validation after dual ascent:
out_inf: tensor(7.1914, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(1.2012, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(1.0752, device='cuda:0', dtype=torch.float16) tensor(0.0686, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4336, device='cuda:0', dtype=torch.float16) tensor(0.2827, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0048, device='cuda:0')
tensor(0.0680, device='cuda:0')
old_score: tensor(0.0832, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0674, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.098865032196045
Validation after dual ascent:
out_inf: tensor(4.4336, device='cuda:0', dtype=torch.float16) tensor(0.2827, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.6099, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.8926, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.5664, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0028, device='cuda:0')
tensor(0.0457, device='cuda:0')
old_score: tensor(0.0368, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0322, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.247689247131348
Validation after dual ascent:
out_inf: tensor(2.8926, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.3438, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.4373, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.2188, device='cuda:0', dtype=torch.float16) tensor(0.7871, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1538, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1562, device='cuda:0', dtype=torch.float16)
tensor(1.8945, device='cuda:0', dtype=torch.float16) tensor(0.1611, device='cuda:0', dtype=torch.float16)
tensor(1.8350, device='cuda:0', dtype=torch.float16) tensor(0.1576, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0145, device='cuda:0')
tensor(0.2424, device='cuda:0')
old_score: tensor(0.1572, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4755139350891113
Validation after dual ascent:
out_inf: tensor(15.2188, device='cuda:0', dtype=torch.float16) tensor(0.7871, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.2744, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6797, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1641, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1681, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.2491, device='cuda:0')
old_score: tensor(0.1646, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1274, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4789600372314453
Validation after dual ascent:
out_inf: tensor(15.6797, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.3506, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.3359, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.1029, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0089, device='cuda:0')
tensor(0.1645, device='cuda:0')
old_score: tensor(0.1023, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0833, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4671080112457275
Validation after dual ascent:
out_inf: tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.3359, device='cuda:0', dtype=torch.float16)
tensor(0.6509, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.6382, device='cuda:0', dtype=torch.float16) tensor(0.0806, device='cuda:0', dtype=torch.float16)
tensor(0.6313, device='cuda:0', dtype=torch.float16) tensor(0.0827, device='cuda:0', dtype=torch.float16)
tensor(0.6392, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.4336, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.5386, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0043, device='cuda:0')
tensor(0.0583, device='cuda:0')
old_score: tensor(0.0331, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0242, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7268130779266357
Validation after dual ascent:
out_inf: tensor(5.4336, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
tensor(0.4229, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
tensor(0.3848, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.1641, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(1.7070, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0902, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.0768, device='cuda:0')
old_score: tensor(0.0895, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0707, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.091335773468018
Validation after dual ascent:
out_inf: tensor(9.1641, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(1.0361, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(1.0723, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9805, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(0.8076, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.8867, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.0765, device='cuda:0')
old_score: tensor(0.0868, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0696, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.092468023300171
Validation after dual ascent:
out_inf: tensor(4.9805, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.5312, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.5752, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0035, device='cuda:0')
tensor(0.0562, device='cuda:0')
old_score: tensor(0.0405, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0352, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.23746109008789
Validation after dual ascent:
out_inf: tensor(6.5312, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
tensor(0.4224, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.3394, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.3513, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.4390, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2812, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.1582, device='cuda:0', dtype=torch.float16)
tensor(2.3828, device='cuda:0', dtype=torch.float16) tensor(0.1586, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.1638, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1603, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0157, device='cuda:0')
tensor(0.2654, device='cuda:0')
old_score: tensor(0.1603, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4759325981140137
Validation after dual ascent:
out_inf: tensor(17.2812, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(1.8564, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.6758, device='cuda:0', dtype=torch.float16) tensor(0.1195, device='cuda:0', dtype=torch.float16)
tensor(1.5020, device='cuda:0', dtype=torch.float16) tensor(0.1231, device='cuda:0', dtype=torch.float16)
tensor(1.6494, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.6094, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(2.0586, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1698, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.2708, device='cuda:0')
old_score: tensor(0.1661, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1266, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4807662963867188
Validation after dual ascent:
out_inf: tensor(16.6094, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(1.4570, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.3857, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5., device='cuda:0', dtype=torch.float16) tensor(0.3425, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0099, device='cuda:0')
tensor(0.1862, device='cuda:0')
old_score: tensor(0.1093, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0879, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.471296787261963
Validation after dual ascent:
out_inf: tensor(5., device='cuda:0', dtype=torch.float16) tensor(0.3425, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(0.7642, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(0.6860, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.6016, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(0.8013, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0056, device='cuda:0')
tensor(0.0790, device='cuda:0')
old_score: tensor(0.0395, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0287, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7276599407196045
Validation after dual ascent:
out_inf: tensor(5.6016, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(0.6538, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.1172, device='cuda:0', dtype=torch.float16) tensor(0.4260, device='cuda:0', dtype=torch.float16)
tensor(1.4746, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.4580, device='cuda:0', dtype=torch.float16) tensor(0.0992, device='cuda:0', dtype=torch.float16)
tensor(1.4785, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0074, device='cuda:0')
tensor(0.0953, device='cuda:0')
old_score: tensor(0.0973, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0746, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.09748649597168
Validation after dual ascent:
out_inf: tensor(8.1172, device='cuda:0', dtype=torch.float16) tensor(0.4260, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(1.3799, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.4258, device='cuda:0', dtype=torch.float16) tensor(0.3174, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0067, device='cuda:0')
tensor(0.0934, device='cuda:0')
old_score: tensor(0.0934, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.094005584716797
Validation after dual ascent:
out_inf: tensor(5.4258, device='cuda:0', dtype=torch.float16) tensor(0.3174, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.0469, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(0.4897, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.5146, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0047, device='cuda:0')
tensor(0.0745, device='cuda:0')
old_score: tensor(0.0460, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0397, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.222951889038086
Validation after dual ascent:
out_inf: tensor(6.0469, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.4463, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.8750, device='cuda:0', dtype=torch.float16) tensor(0.7983, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1636, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1630, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1686, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1652, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0100, device='cuda:0')
tensor(0.0637, device='cuda:0')
old_score: tensor(0.1650, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.212430715560913
Validation after dual ascent:
out_inf: tensor(16.8750, device='cuda:0', dtype=torch.float16) tensor(0.7983, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.4014, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
tensor(1.2236, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.3125, device='cuda:0', dtype=torch.float16) tensor(1.0176, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.1682, device='cuda:0', dtype=torch.float16)
tensor(2.3438, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0117, device='cuda:0')
tensor(0.0631, device='cuda:0')
old_score: tensor(0.1697, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1259, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.213818311691284
Validation after dual ascent:
out_inf: tensor(17.3125, device='cuda:0', dtype=torch.float16) tensor(1.0176, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.3528, device='cuda:0', dtype=torch.float16)
tensor(0.8247, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.1110, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0183, device='cuda:0')
tensor(0.1985, device='cuda:0')
old_score: tensor(0.1121, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0878, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4687557220458984
Validation after dual ascent:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.3528, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
tensor(0.7437, device='cuda:0', dtype=torch.float16) tensor(0.0832, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(0.7466, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.0195, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.5073, device='cuda:0', dtype=torch.float16) tensor(0.0310, device='cuda:0', dtype=torch.float16)
tensor(0.7080, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.7290, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0106, device='cuda:0')
tensor(0.0558, device='cuda:0')
old_score: tensor(0.0318, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0234, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7244572639465332
Validation after dual ascent:
out_inf: tensor(6.0195, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.8164, device='cuda:0', dtype=torch.float16) tensor(0.4419, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0085, device='cuda:0')
tensor(0.1163, device='cuda:0')
old_score: tensor(0.1031, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0794, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.087616205215454
Validation after dual ascent:
out_inf: tensor(7.8164, device='cuda:0', dtype=torch.float16) tensor(0.4419, device='cuda:0', dtype=torch.float16)
tensor(1.1973, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.3176, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(0.8115, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0077, device='cuda:0')
tensor(0.1116, device='cuda:0')
old_score: tensor(0.0973, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0763, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0927207469940186
Validation after dual ascent:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.3176, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.6079, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.6118, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.9492, device='cuda:0', dtype=torch.float16) tensor(0.1515, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.5400, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.4673, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.6167, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0049, device='cuda:0')
tensor(0.0788, device='cuda:0')
old_score: tensor(0.0465, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0403, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.23478078842163
Validation after dual ascent:
out_inf: tensor(4.9492, device='cuda:0', dtype=torch.float16) tensor(0.1515, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.4148, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.4048, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.5303, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.9766, device='cuda:0', dtype=torch.float16) tensor(0.8169, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1682, device='cuda:0', dtype=torch.float16)
tensor(1.8984, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1699, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0121, device='cuda:0')
tensor(0.0768, device='cuda:0')
old_score: tensor(0.1694, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1279, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.210235595703125
Validation after dual ascent:
out_inf: tensor(13.9766, device='cuda:0', dtype=torch.float16) tensor(0.8169, device='cuda:0', dtype=torch.float16)
tensor(1.2246, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(1.2227, device='cuda:0', dtype=torch.float16) tensor(0.1199, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.5723, device='cuda:0', dtype=torch.float16) tensor(0.1365, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.6250, device='cuda:0', dtype=torch.float16) tensor(0.9839, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(2.2422, device='cuda:0', dtype=torch.float16) tensor(0.1711, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0776, device='cuda:0')
old_score: tensor(0.1742, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1296, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2060015201568604
Validation after dual ascent:
out_inf: tensor(17.6250, device='cuda:0', dtype=torch.float16) tensor(0.9839, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
tensor(1.2803, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.4014, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.3716, device='cuda:0', dtype=torch.float16)
tensor(0.8779, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(0.9487, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(0.9160, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0065, device='cuda:0')
tensor(0.0696, device='cuda:0')
old_score: tensor(0.1224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0966, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.194859027862549
Validation after dual ascent:
out_inf: tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.3716, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0973, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(0.7607, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(0.8740, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.3164, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.9346, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0140, device='cuda:0')
tensor(0.0259, device='cuda:0')
old_score: tensor(0.0305, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0220, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.917959451675415
Validation after dual ascent:
out_inf: tensor(4.3164, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.7520, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.9688, device='cuda:0', dtype=torch.float16) tensor(0.4546, device='cuda:0', dtype=torch.float16)
tensor(1.7285, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1112, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0102, device='cuda:0')
tensor(0.1435, device='cuda:0')
old_score: tensor(0.1091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0831, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.095390319824219
Validation after dual ascent:
out_inf: tensor(8.9688, device='cuda:0', dtype=torch.float16) tensor(0.4546, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.1367, device='cuda:0', dtype=torch.float16) tensor(0.3230, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.1015, device='cuda:0', dtype=torch.float16)
tensor(0.8418, device='cuda:0', dtype=torch.float16) tensor(0.0995, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.1034, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0093, device='cuda:0')
tensor(0.1358, device='cuda:0')
old_score: tensor(0.1016, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0790, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.09466290473938
Validation after dual ascent:
out_inf: tensor(6.1367, device='cuda:0', dtype=torch.float16) tensor(0.3230, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.6226, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(0.7485, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.8633, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.5127, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0059, device='cuda:0')
tensor(0.0919, device='cuda:0')
old_score: tensor(0.0492, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0429, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.230783462524414
Validation after dual ascent:
out_inf: tensor(5.8633, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(0.4561, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.4448, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.0938, device='cuda:0', dtype=torch.float16) tensor(0.7803, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(1.6602, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1688, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.3225, device='cuda:0')
old_score: tensor(0.1646, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4763236045837402
Validation after dual ascent:
out_inf: tensor(13.0938, device='cuda:0', dtype=torch.float16) tensor(0.7803, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1244, device='cuda:0', dtype=torch.float16)
tensor(1.4043, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(1.3105, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.5781, device='cuda:0', dtype=torch.float16) tensor(1.0088, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(2.3672, device='cuda:0', dtype=torch.float16) tensor(0.1733, device='cuda:0', dtype=torch.float16)
tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0191, device='cuda:0')
tensor(0.3278, device='cuda:0')
old_score: tensor(0.1685, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1246, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.477604866027832
Validation after dual ascent:
out_inf: tensor(19.5781, device='cuda:0', dtype=torch.float16) tensor(1.0088, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.2822, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.3457, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1335, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.1758, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(0.9390, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0129, device='cuda:0')
tensor(0.2467, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0956, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4714176654815674
Validation after dual ascent:
out_inf: tensor(4.1758, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(0.9136, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.7817, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(0.7905, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(0.9897, device='cuda:0', dtype=torch.float16) tensor(0.1024, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.9961, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0088, device='cuda:0')
tensor(0.0547, device='cuda:0')
old_score: tensor(0.0312, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0233, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7240853309631348
Validation after dual ascent:
out_inf: tensor(5.9961, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.8740, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.0938, device='cuda:0', dtype=torch.float16) tensor(0.4470, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1103, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.6143, device='cuda:0', dtype=torch.float16) tensor(0.1126, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0113, device='cuda:0')
tensor(0.1634, device='cuda:0')
old_score: tensor(0.1124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0859, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.089127540588379
Validation after dual ascent:
out_inf: tensor(8.0938, device='cuda:0', dtype=torch.float16) tensor(0.4470, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(1.1064, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.8828, device='cuda:0', dtype=torch.float16) tensor(0.3315, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.1051, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0103, device='cuda:0')
tensor(0.1537, device='cuda:0')
old_score: tensor(0.1046, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0813, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.093572616577148
Validation after dual ascent:
out_inf: tensor(7.8828, device='cuda:0', dtype=torch.float16) tensor(0.3315, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.6602, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(0.5928, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.5737, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0063, device='cuda:0')
tensor(0.0990, device='cuda:0')
old_score: tensor(0.0510, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0444, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.205871343612671
Validation after dual ascent:
out_inf: tensor(5.6602, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.3931, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.4609, device='cuda:0', dtype=torch.float16) tensor(0.8032, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.1709, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1661, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0080, device='cuda:0')
tensor(0.0639, device='cuda:0')
old_score: tensor(0.1666, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.211033582687378
Validation after dual ascent:
out_inf: tensor(15.4609, device='cuda:0', dtype=torch.float16) tensor(0.8032, device='cuda:0', dtype=torch.float16)
tensor(1.2949, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1233, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.5625, device='cuda:0', dtype=torch.float16) tensor(1.0146, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1697, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1744, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0616, device='cuda:0')
old_score: tensor(0.1705, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1252, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.216092348098755
Validation after dual ascent:
out_inf: tensor(17.5625, device='cuda:0', dtype=torch.float16) tensor(1.0146, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.1332, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.3740, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(0.9326, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(0.9756, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2548, device='cuda:0')
old_score: tensor(0.1252, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0973, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4769628047943115
Validation after dual ascent:
out_inf: tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.3740, device='cuda:0', dtype=torch.float16)
tensor(0.8882, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(0.8574, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.7031, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(0.7891, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0052, device='cuda:0')
tensor(0.0745, device='cuda:0')
old_score: tensor(0.0390, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0284, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.738438367843628
Validation after dual ascent:
out_inf: tensor(11.7031, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
tensor(0.7075, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.0312, device='cuda:0', dtype=torch.float16) tensor(0.4629, device='cuda:0', dtype=torch.float16)
tensor(1.9727, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1137, device='cuda:0', dtype=torch.float16)
tensor(1.6338, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.1161, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0123, device='cuda:0')
tensor(0.1765, device='cuda:0')
old_score: tensor(0.1162, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0869, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.120438575744629
Validation after dual ascent:
out_inf: tensor(11.0312, device='cuda:0', dtype=torch.float16) tensor(0.4629, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0923, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.3406, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0111, device='cuda:0')
tensor(0.1647, device='cuda:0')
old_score: tensor(0.1071, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0815, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.126660346984863
Validation after dual ascent:
out_inf: tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.3406, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0827, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.7612, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.down_proj
Validation after prune:
out_inf: tensor(7.1250, device='cuda:0', dtype=torch.float16) tensor(0.1860, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0073, device='cuda:0')
tensor(0.1132, device='cuda:0')
old_score: tensor(0.0536, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0464, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.224197387695312
Validation after dual ascent:
out_inf: tensor(7.1250, device='cuda:0', dtype=torch.float16) tensor(0.1860, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(0.7832, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.1670, device='cuda:0', dtype=torch.float16)
tensor(1.6855, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(1.7617, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0065, device='cuda:0')
tensor(0.0659, device='cuda:0')
old_score: tensor(0.1678, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2071776390075684
Validation after dual ascent:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(0.7832, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(1.3770, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
tensor(1.4717, device='cuda:0', dtype=torch.float16) tensor(0.1310, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9722, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1659, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1748, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0080, device='cuda:0')
tensor(0.0642, device='cuda:0')
old_score: tensor(0.1692, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2106993198394775
Validation after dual ascent:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9722, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.3916, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.4922, device='cuda:0', dtype=torch.float16) tensor(0.3914, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0150, device='cuda:0')
tensor(0.2955, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1029, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4734506607055664
Validation after dual ascent:
out_inf: tensor(5.4922, device='cuda:0', dtype=torch.float16) tensor(0.3914, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(0.9111, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(0.9189, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.0303, device='cuda:0', dtype=torch.float16) tensor(0.1091, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.o_proj
Validation after prune:
out_inf: tensor(9.7578, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.7002, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.7012, device='cuda:0', dtype=torch.float16) tensor(0.0310, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0096, device='cuda:0')
tensor(0.0650, device='cuda:0')
old_score: tensor(0.0332, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0249, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.731583595275879
Validation after dual ascent:
out_inf: tensor(9.7578, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.7295, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.6704, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.4297, device='cuda:0', dtype=torch.float16) tensor(0.4578, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(1.7334, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.4736, device='cuda:0', dtype=torch.float16) tensor(0.1184, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0134, device='cuda:0')
tensor(0.1970, device='cuda:0')
old_score: tensor(0.1185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0896, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1213274002075195
Validation after dual ascent:
out_inf: tensor(9.4297, device='cuda:0', dtype=torch.float16) tensor(0.4578, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(1.7480, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.0907, device='cuda:0', dtype=torch.float16)
tensor(1.6904, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.8906, device='cuda:0', dtype=torch.float16) tensor(0.3374, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(0.9414, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.1819, device='cuda:0')
old_score: tensor(0.1085, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0833, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1223413944244385
Validation after dual ascent:
out_inf: tensor(6.8906, device='cuda:0', dtype=torch.float16) tensor(0.3374, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.7358, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.8037, device='cuda:0', dtype=torch.float16) tensor(0.0843, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.3633, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0070, device='cuda:0')
tensor(0.1100, device='cuda:0')
old_score: tensor(0.0522, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0457, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.261034965515137
Validation after dual ascent:
out_inf: tensor(4.3633, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.4836, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.6475, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.5312, device='cuda:0', dtype=torch.float16) tensor(0.8374, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1698, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1724, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0115, device='cuda:0')
tensor(0.0814, device='cuda:0')
old_score: tensor(0.1738, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1284, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.20793080329895
Validation after dual ascent:
out_inf: tensor(18.5312, device='cuda:0', dtype=torch.float16) tensor(0.8374, device='cuda:0', dtype=torch.float16)
tensor(1.3115, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.0156, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1750, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1719, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.1831, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.1753, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0134, device='cuda:0')
tensor(0.0832, device='cuda:0')
old_score: tensor(0.1764, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1292, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.212486505508423
Validation after dual ascent:
out_inf: tensor(20.0156, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(1.2900, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.4219, device='cuda:0', dtype=torch.float16) tensor(0.4133, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
tensor(1.1826, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0062, device='cuda:0')
tensor(0.0771, device='cuda:0')
old_score: tensor(0.1361, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1045, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2072951793670654
Validation after dual ascent:
out_inf: tensor(7.4219, device='cuda:0', dtype=torch.float16) tensor(0.4133, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(0.8872, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.9312, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(0.9756, device='cuda:0', dtype=torch.float16) tensor(0.1103, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.7500, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0071, device='cuda:0')
tensor(0.0109, device='cuda:0')
old_score: tensor(0.0323, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4687206745147705
Validation after dual ascent:
out_inf: tensor(11.7500, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.7500, device='cuda:0', dtype=torch.float16) tensor(0.4585, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1209, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1180, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1239, device='cuda:0', dtype=torch.float16)
tensor(1.9824, device='cuda:0', dtype=torch.float16) tensor(0.1206, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0139, device='cuda:0')
tensor(0.2056, device='cuda:0')
old_score: tensor(0.1208, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0903, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.120696544647217
Validation after dual ascent:
out_inf: tensor(10.7500, device='cuda:0', dtype=torch.float16) tensor(0.4585, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0832, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(1.3311, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.2891, device='cuda:0', dtype=torch.float16) tensor(0.3438, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0125, device='cuda:0')
tensor(0.1884, device='cuda:0')
old_score: tensor(0.1099, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0835, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.126899003982544
Validation after dual ascent:
out_inf: tensor(6.2891, device='cuda:0', dtype=torch.float16) tensor(0.3438, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(0.7476, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.1942, device='cuda:0', dtype=torch.float16)
tensor(0.6069, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0079, device='cuda:0')
tensor(0.1232, device='cuda:0')
old_score: tensor(0.0548, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0477, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.278101682662964
Validation after dual ascent:
out_inf: tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.1942, device='cuda:0', dtype=torch.float16)
tensor(0.6128, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.5737, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.4888, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.6084, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1777, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(1.9766, device='cuda:0', dtype=torch.float16) tensor(0.1835, device='cuda:0', dtype=torch.float16)
tensor(1.9180, device='cuda:0', dtype=torch.float16) tensor(0.1758, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0074, device='cuda:0')
tensor(0.0787, device='cuda:0')
old_score: tensor(0.1776, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1321, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2098729610443115
Validation after dual ascent:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.4434, device='cuda:0', dtype=torch.float16) tensor(0.1334, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.3428, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.5410, device='cuda:0', dtype=torch.float16) tensor(0.1378, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.8438, device='cuda:0', dtype=torch.float16) tensor(0.9473, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1794, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1855, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1780, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0783, device='cuda:0')
old_score: tensor(0.1797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1326, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.211369276046753
Validation after dual ascent:
out_inf: tensor(18.8438, device='cuda:0', dtype=torch.float16) tensor(0.9473, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
tensor(1.6689, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.7148, device='cuda:0', dtype=torch.float16) tensor(0.4414, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(1.3799, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.1650, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.3587, device='cuda:0')
old_score: tensor(0.1475, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.473519802093506
Validation after dual ascent:
out_inf: tensor(5.7148, device='cuda:0', dtype=torch.float16) tensor(0.4414, device='cuda:0', dtype=torch.float16)
tensor(1.0674, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(0.9663, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.o_proj
Validation after prune:
out_inf: tensor(17.4688, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.8989, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0183, device='cuda:0')
tensor(0.0639, device='cuda:0')
old_score: tensor(0.0309, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0233, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7323858737945557
Validation after dual ascent:
out_inf: tensor(17.4688, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.4976, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.2344, device='cuda:0', dtype=torch.float16) tensor(0.4558, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1228, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1199, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0148, device='cuda:0')
tensor(0.2238, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0923, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.119619369506836
Validation after dual ascent:
out_inf: tensor(10.2344, device='cuda:0', dtype=torch.float16) tensor(0.4558, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(1.2432, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.4570, device='cuda:0', dtype=torch.float16) tensor(0.0960, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.1172, device='cuda:0', dtype=torch.float16) tensor(0.3433, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0134, device='cuda:0')
tensor(0.2061, device='cuda:0')
old_score: tensor(0.1122, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0856, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.122714042663574
Validation after dual ascent:
out_inf: tensor(7.1172, device='cuda:0', dtype=torch.float16) tensor(0.3433, device='cuda:0', dtype=torch.float16)
tensor(0.8159, device='cuda:0', dtype=torch.float16) tensor(0.0866, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(0.7954, device='cuda:0', dtype=torch.float16) tensor(0.0882, device='cuda:0', dtype=torch.float16)
tensor(0.8472, device='cuda:0', dtype=torch.float16) tensor(0.0890, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.8379, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(0.6709, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.5811, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.5981, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0081, device='cuda:0')
tensor(0.1269, device='cuda:0')
old_score: tensor(0.0546, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0481, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.283907651901245
Validation after dual ascent:
out_inf: tensor(3.8379, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.5166, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.5708, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.8984, device='cuda:0', dtype=torch.float16) tensor(0.7778, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1675, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1742, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0079, device='cuda:0')
tensor(0.0746, device='cuda:0')
old_score: tensor(0.1678, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1248, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.210767984390259
Validation after dual ascent:
out_inf: tensor(15.8984, device='cuda:0', dtype=torch.float16) tensor(0.7778, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.4346, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1250, device='cuda:0', dtype=torch.float16) tensor(0.9795, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1686, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1748, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0105, device='cuda:0')
tensor(0.0750, device='cuda:0')
old_score: tensor(0.1686, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1245, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2129342555999756
Validation after dual ascent:
out_inf: tensor(17.1250, device='cuda:0', dtype=torch.float16) tensor(0.9795, device='cuda:0', dtype=torch.float16)
tensor(1.4355, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.5488, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.4551, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.6055, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.3555, device='cuda:0', dtype=torch.float16) tensor(0.4246, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
tensor(1.2607, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
tensor(1.1045, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.3359, device='cuda:0')
old_score: tensor(0.1436, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4743010997772217
Validation after dual ascent:
out_inf: tensor(6.3555, device='cuda:0', dtype=torch.float16) tensor(0.4246, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(1.0068, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(1.1631, device='cuda:0', dtype=torch.float16) tensor(0.1142, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.o_proj
Validation after prune:
out_inf: tensor(14.0234, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0124, device='cuda:0')
tensor(0.0293, device='cuda:0')
old_score: tensor(0.0339, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0252, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.675294876098633
Validation after dual ascent:
out_inf: tensor(14.0234, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(0.6958, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.7422, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.1225, device='cuda:0', dtype=torch.float16)
tensor(1.7070, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.2388, device='cuda:0')
old_score: tensor(0.1250, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0941, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.122363328933716
Validation after dual ascent:
out_inf: tensor(11.7422, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(1.1748, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.4102, device='cuda:0', dtype=torch.float16) tensor(0.3496, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1153, device='cuda:0', dtype=torch.float16)
tensor(0.9502, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.2203, device='cuda:0')
old_score: tensor(0.1146, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0875, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.123349666595459
Validation after dual ascent:
out_inf: tensor(7.4102, device='cuda:0', dtype=torch.float16) tensor(0.3496, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.8979, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.8438, device='cuda:0', dtype=torch.float16) tensor(0.1978, device='cuda:0', dtype=torch.float16)
tensor(0.6553, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.7222, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0085, device='cuda:0')
tensor(0.1348, device='cuda:0')
old_score: tensor(0.0560, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0495, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.26305890083313
Validation after dual ascent:
out_inf: tensor(4.8438, device='cuda:0', dtype=torch.float16) tensor(0.1978, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.6157, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.5967, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.q_proj
Validation after prune:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(1.8770, device='cuda:0', dtype=torch.float16) tensor(0.1819, device='cuda:0', dtype=torch.float16)
tensor(1.6963, device='cuda:0', dtype=torch.float16) tensor(0.1776, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1885, device='cuda:0', dtype=torch.float16)
tensor(1.7617, device='cuda:0', dtype=torch.float16) tensor(0.1796, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0073, device='cuda:0')
tensor(0.0905, device='cuda:0')
old_score: tensor(0.1819, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1357, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.213099241256714
Validation after dual ascent:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
tensor(1.4180, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.1406, device='cuda:0', dtype=torch.float16)
tensor(1.6572, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(0.9268, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.1835, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1785, device='cuda:0', dtype=torch.float16)
tensor(2.2422, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1798, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0086, device='cuda:0')
tensor(0.0902, device='cuda:0')
old_score: tensor(0.1830, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1360, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2146847248077393
Validation after dual ascent:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(0.9268, device='cuda:0', dtype=torch.float16)
tensor(1.4053, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(1.5957, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(1.5029, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.3984, device='cuda:0', dtype=torch.float16) tensor(0.4639, device='cuda:0', dtype=torch.float16)
tensor(1.4297, device='cuda:0', dtype=torch.float16) tensor(0.1595, device='cuda:0', dtype=torch.float16)
tensor(1.1904, device='cuda:0', dtype=torch.float16) tensor(0.1566, device='cuda:0', dtype=torch.float16)
tensor(1.2871, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(1.2803, device='cuda:0', dtype=torch.float16) tensor(0.1570, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0190, device='cuda:0')
tensor(0.4185, device='cuda:0')
old_score: tensor(0.1594, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1223, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4752604961395264
Validation after dual ascent:
out_inf: tensor(5.3984, device='cuda:0', dtype=torch.float16) tensor(0.4639, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(1.1182, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.2373, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.7881, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0134, device='cuda:0')
tensor(0.0227, device='cuda:0')
old_score: tensor(0.0282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0199, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.871504545211792
Validation after dual ascent:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(0.5674, device='cuda:0', dtype=torch.float16) tensor(0.0163, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.7500, device='cuda:0', dtype=torch.float16) tensor(0.4858, device='cuda:0', dtype=torch.float16)
tensor(1.7793, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0175, device='cuda:0')
tensor(0.2749, device='cuda:0')
old_score: tensor(0.1295, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0974, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.122372627258301
Validation after dual ascent:
out_inf: tensor(9.7500, device='cuda:0', dtype=torch.float16) tensor(0.4858, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(1.2236, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(1.2168, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.up_proj
Validation after prune:
out_inf: tensor(8.6016, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1178, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.2539, device='cuda:0')
old_score: tensor(0.1189, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0908, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.128443241119385
Validation after dual ascent:
out_inf: tensor(8.6016, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
tensor(0.8813, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0940, device='cuda:0', dtype=torch.float16)
tensor(0.8896, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.2089, device='cuda:0', dtype=torch.float16)
tensor(0.7314, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.6870, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.7197, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0096, device='cuda:0')
tensor(0.1501, device='cuda:0')
old_score: tensor(0.0582, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0515, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.207082033157349
Validation after dual ascent:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.2089, device='cuda:0', dtype=torch.float16)
tensor(0.6729, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.6323, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.5571, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.6948, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.2812, device='cuda:0', dtype=torch.float16) tensor(0.8257, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1849, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1761, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0074, device='cuda:0')
tensor(0.0859, device='cuda:0')
old_score: tensor(0.1797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1323, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2098426818847656
Validation after dual ascent:
out_inf: tensor(14.2812, device='cuda:0', dtype=torch.float16) tensor(0.8257, device='cuda:0', dtype=torch.float16)
tensor(1.4795, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.5088, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.1562, device='cuda:0', dtype=torch.float16) tensor(1.0078, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1816, device='cuda:0', dtype=torch.float16)
tensor(2.1289, device='cuda:0', dtype=torch.float16) tensor(0.1812, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.1886, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1782, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0856, device='cuda:0')
old_score: tensor(0.1824, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1328, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2125191688537598
Validation after dual ascent:
out_inf: tensor(18.1562, device='cuda:0', dtype=torch.float16) tensor(1.0078, device='cuda:0', dtype=torch.float16)
tensor(1.4727, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
tensor(1.4229, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
tensor(1.5293, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4661, device='cuda:0', dtype=torch.float16)
tensor(1.3721, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.1594, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1641, device='cuda:0', dtype=torch.float16)
tensor(1.4785, device='cuda:0', dtype=torch.float16) tensor(0.1575, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.4085, device='cuda:0')
old_score: tensor(0.1602, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1227, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4730100631713867
Validation after dual ascent:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4661, device='cuda:0', dtype=torch.float16)
tensor(1.2871, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.1299, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.o_proj
Validation after prune:
out_inf: tensor(21.7344, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0194, device='cuda:0')
tensor(0.0387, device='cuda:0')
old_score: tensor(0.0349, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0258, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.275705814361572
Validation after dual ascent:
out_inf: tensor(21.7344, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(0.8994, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.0234, device='cuda:0', dtype=torch.float16) tensor(0.5088, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1312, device='cuda:0', dtype=torch.float16)
tensor(1.8008, device='cuda:0', dtype=torch.float16) tensor(0.1360, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0185, device='cuda:0')
tensor(0.2934, device='cuda:0')
old_score: tensor(0.1328, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0990, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.124722480773926
Validation after dual ascent:
out_inf: tensor(9.0234, device='cuda:0', dtype=torch.float16) tensor(0.5088, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(1.2275, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.up_proj
Validation after prune:
out_inf: tensor(8.2578, device='cuda:0', dtype=torch.float16) tensor(0.3833, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2711, device='cuda:0')
old_score: tensor(0.1223, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0925, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.12812352180481
Validation after dual ascent:
out_inf: tensor(8.2578, device='cuda:0', dtype=torch.float16) tensor(0.3833, device='cuda:0', dtype=torch.float16)
tensor(0.9126, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(1.0127, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(0.9028, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(0.9780, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.3398, device='cuda:0', dtype=torch.float16) tensor(0.2195, device='cuda:0', dtype=torch.float16)
tensor(0.6338, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.6465, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.7466, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0110, device='cuda:0')
tensor(0.1693, device='cuda:0')
old_score: tensor(0.0611, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0537, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.193763494491577
Validation after dual ascent:
out_inf: tensor(5.3398, device='cuda:0', dtype=torch.float16) tensor(0.2195, device='cuda:0', dtype=torch.float16)
tensor(0.6279, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.6323, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.7373, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1953, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(2.5547, device='cuda:0', dtype=torch.float16) tensor(0.1918, device='cuda:0', dtype=torch.float16)
tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
tensor(2.5000, device='cuda:0', dtype=torch.float16) tensor(0.1976, device='cuda:0', dtype=torch.float16)
tensor(2.4922, device='cuda:0', dtype=torch.float16) tensor(0.1871, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0843, device='cuda:0')
old_score: tensor(0.1910, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1383, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.209346055984497
Validation after dual ascent:
out_inf: tensor(15.1953, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
tensor(1.5098, device='cuda:0', dtype=torch.float16) tensor(0.1420, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.5000, device='cuda:0', dtype=torch.float16) tensor(0.9604, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.1964, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1925, device='cuda:0', dtype=torch.float16)
tensor(3.2734, device='cuda:0', dtype=torch.float16) tensor(0.2041, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.1923, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0112, device='cuda:0')
tensor(0.0860, device='cuda:0')
old_score: tensor(0.1963, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1396, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2142159938812256
Validation after dual ascent:
out_inf: tensor(18.5000, device='cuda:0', dtype=torch.float16) tensor(0.9604, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(1.5566, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.v_proj
Validation after prune:
out_inf: tensor(10.0469, device='cuda:0', dtype=torch.float16) tensor(0.4722, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1609, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1663, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1587, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0048, device='cuda:0')
tensor(0.0789, device='cuda:0')
old_score: tensor(0.1614, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1228, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2063751220703125
Validation after dual ascent:
out_inf: tensor(10.0469, device='cuda:0', dtype=torch.float16) tensor(0.4722, device='cuda:0', dtype=torch.float16)
tensor(1.2529, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.5195, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(1.0752, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0073, device='cuda:0')
tensor(0.0132, device='cuda:0')
old_score: tensor(0.0227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0172, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2020444869995117
Validation after dual ascent:
out_inf: tensor(5.5195, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(1.0850, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.8438, device='cuda:0', dtype=torch.float16) tensor(0.5366, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.9727, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(1.8320, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0051, device='cuda:0')
tensor(0.0370, device='cuda:0')
old_score: tensor(0.1375, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.058556318283081
Validation after dual ascent:
out_inf: tensor(10.8438, device='cuda:0', dtype=torch.float16) tensor(0.5366, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.1797, device='cuda:0', dtype=torch.float16) tensor(0.4080, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1265, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0184, device='cuda:0')
tensor(0.3036, device='cuda:0')
old_score: tensor(0.1274, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0951, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.130352735519409
Validation after dual ascent:
out_inf: tensor(7.1797, device='cuda:0', dtype=torch.float16) tensor(0.4080, device='cuda:0', dtype=torch.float16)
tensor(1.0713, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0977, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.2427, device='cuda:0', dtype=torch.float16)
tensor(0.7046, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(0.6470, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.8325, device='cuda:0', dtype=torch.float16) tensor(0.0675, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0130, device='cuda:0')
tensor(0.1984, device='cuda:0')
old_score: tensor(0.0653, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0569, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.137487649917603
Validation after dual ascent:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.2427, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.7861, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.7017, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.3828, device='cuda:0', dtype=torch.float16) tensor(0.8398, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.1931, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1914, device='cuda:0', dtype=torch.float16)
tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1987, device='cuda:0', dtype=torch.float16)
tensor(2.8438, device='cuda:0', dtype=torch.float16) tensor(0.1887, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0159, device='cuda:0')
tensor(0.0725, device='cuda:0')
old_score: tensor(0.1929, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1372, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.79045581817627
Validation after dual ascent:
out_inf: tensor(14.3828, device='cuda:0', dtype=torch.float16) tensor(0.8398, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.5361, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.8594, device='cuda:0', dtype=torch.float16) tensor(0.9941, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.1978, device='cuda:0', dtype=torch.float16)
tensor(3.2422, device='cuda:0', dtype=torch.float16) tensor(0.1957, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0169, device='cuda:0')
tensor(0.0771, device='cuda:0')
old_score: tensor(0.1981, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1385, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.811341524124146
Validation after dual ascent:
out_inf: tensor(20.8594, device='cuda:0', dtype=torch.float16) tensor(0.9941, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.1133, device='cuda:0', dtype=torch.float16) tensor(0.5107, device='cuda:0', dtype=torch.float16)
tensor(1.5029, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1716, device='cuda:0', dtype=torch.float16)
tensor(1.4502, device='cuda:0', dtype=torch.float16) tensor(0.1763, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0188, device='cuda:0')
tensor(0.1177, device='cuda:0')
old_score: tensor(0.1719, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1298, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2177212238311768
Validation after dual ascent:
out_inf: tensor(7.1133, device='cuda:0', dtype=torch.float16) tensor(0.5107, device='cuda:0', dtype=torch.float16)
tensor(1.5137, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.1206, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.o_proj
Validation after prune:
out_inf: tensor(9.1250, device='cuda:0', dtype=torch.float16) tensor(0.1389, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0093, device='cuda:0')
tensor(0.0234, device='cuda:0')
old_score: tensor(0.0343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0222, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.559874296188354
Validation after dual ascent:
out_inf: tensor(9.1250, device='cuda:0', dtype=torch.float16) tensor(0.1389, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.7969, device='cuda:0', dtype=torch.float16) tensor(0.5630, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0054, device='cuda:0')
tensor(0.0447, device='cuda:0')
old_score: tensor(0.1417, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.074936628341675
Validation after dual ascent:
out_inf: tensor(11.7969, device='cuda:0', dtype=torch.float16) tensor(0.5630, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1048, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1063, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.up_proj
Validation after prune:
out_inf: tensor(12.3828, device='cuda:0', dtype=torch.float16) tensor(0.4485, device='cuda:0', dtype=torch.float16)
tensor(2.0820, device='cuda:0', dtype=torch.float16) tensor(0.1335, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(2.4180, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1321, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0043, device='cuda:0')
tensor(0.0422, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0988, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.070505142211914
Validation after dual ascent:
out_inf: tensor(12.3828, device='cuda:0', dtype=torch.float16) tensor(0.4485, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0913, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.down_proj
Validation after prune:
out_inf: tensor(8.6094, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(0.8608, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.7354, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0170, device='cuda:0')
tensor(0.2569, device='cuda:0')
old_score: tensor(0.0734, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0634, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.115864038467407
Validation after dual ascent:
out_inf: tensor(8.6094, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.7676, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0639, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.9531, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1808, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.1824, device='cuda:0', dtype=torch.float16)
tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1902, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.1786, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0073, device='cuda:0')
tensor(0.0381, device='cuda:0')
old_score: tensor(0.1831, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1283, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.419684410095215
Validation after dual ascent:
out_inf: tensor(12.9531, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
tensor(1.6279, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.2188, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(2.9453, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
tensor(2.4453, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.1836, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0187, device='cuda:0')
tensor(0.0783, device='cuda:0')
old_score: tensor(0.1885, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1292, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2156362533569336
Validation after dual ascent:
out_inf: tensor(20.2188, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.5049, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.4844, device='cuda:0', dtype=torch.float16)
tensor(1.4658, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1740, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1652, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0194, device='cuda:0')
tensor(0.4090, device='cuda:0')
old_score: tensor(0.1686, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1261, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.476609706878662
Validation after dual ascent:
out_inf: tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.4844, device='cuda:0', dtype=torch.float16)
tensor(1.5410, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(1.2744, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.o_proj
Validation after prune:
out_inf: tensor(17.3281, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0311, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.0118, device='cuda:0')
old_score: tensor(0.0376, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0263, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4690909385681152
Validation after dual ascent:
out_inf: tensor(17.3281, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(0.7593, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.gate_proj
Validation after prune:
out_inf: tensor(12.1875, device='cuda:0', dtype=torch.float16) tensor(0.5771, device='cuda:0', dtype=torch.float16)
tensor(2.7891, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(2.8203, device='cuda:0', dtype=torch.float16) tensor(0.1476, device='cuda:0', dtype=torch.float16)
tensor(3.2617, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0060, device='cuda:0')
tensor(0.0479, device='cuda:0')
old_score: tensor(0.1442, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1047, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.066036462783813
Validation after dual ascent:
out_inf: tensor(12.1875, device='cuda:0', dtype=torch.float16) tensor(0.5771, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(2.4258, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.up_proj
Validation after prune:
out_inf: tensor(9.5000, device='cuda:0', dtype=torch.float16) tensor(0.4985, device='cuda:0', dtype=torch.float16)
tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0055, device='cuda:0')
tensor(0.0457, device='cuda:0')
old_score: tensor(0.1396, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.070371389389038
Validation after dual ascent:
out_inf: tensor(9.5000, device='cuda:0', dtype=torch.float16) tensor(0.4985, device='cuda:0', dtype=torch.float16)
tensor(3.2109, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(2.6074, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(3.1680, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.down_proj
Validation after prune:
out_inf: tensor(22.2812, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(0.9556, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(1.0127, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(0.8721, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.9697, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0029, device='cuda:0')
tensor(0.0312, device='cuda:0')
old_score: tensor(0.0811, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0688, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.883069038391113
Validation after dual ascent:
out_inf: tensor(22.2812, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(0.9722, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.9546, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.8271, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.8467, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.8438, device='cuda:0', dtype=torch.float16)
tensor(2.6211, device='cuda:0', dtype=torch.float16) tensor(0.1946, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.1948, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.2004, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.1921, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0131, device='cuda:0')
tensor(0.0596, device='cuda:0')
old_score: tensor(0.1956, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1333, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.785561084747314
Validation after dual ascent:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.8438, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1343, device='cuda:0', dtype=torch.float16)
tensor(1.6689, device='cuda:0', dtype=torch.float16) tensor(0.1239, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.5938, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(3.2344, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(2.6797, device='cuda:0', dtype=torch.float16) tensor(0.2007, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.2080, device='cuda:0', dtype=torch.float16)
tensor(3.0859, device='cuda:0', dtype=torch.float16) tensor(0.1992, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0131, device='cuda:0')
tensor(0.0592, device='cuda:0')
old_score: tensor(0.2025, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1353, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.80991530418396
Validation after dual ascent:
out_inf: tensor(18.5938, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(1.6787, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
tensor(1.4971, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.v_proj
Validation after prune:
out_inf: tensor(9.5625, device='cuda:0', dtype=torch.float16) tensor(0.5439, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1787, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.1810, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.1854, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1779, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0152, device='cuda:0')
tensor(0.1022, device='cuda:0')
old_score: tensor(0.1808, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1322, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2178258895874023
Validation after dual ascent:
out_inf: tensor(9.5625, device='cuda:0', dtype=torch.float16) tensor(0.5439, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1228, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.o_proj
Validation after prune:
out_inf: tensor(19.3438, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0085, device='cuda:0')
tensor(0.0162, device='cuda:0')
old_score: tensor(0.0284, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0201, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2070391178131104
Validation after dual ascent:
out_inf: tensor(19.3438, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(0.9033, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(1.1758, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.gate_proj
Validation after prune:
out_inf: tensor(33.5625, device='cuda:0', dtype=torch.float16) tensor(0.6353, device='cuda:0', dtype=torch.float16)
tensor(17.1875, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(13.4219, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
tensor(14.4375, device='cuda:0', dtype=torch.float16) tensor(0.1541, device='cuda:0', dtype=torch.float16)
tensor(13.5625, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0086, device='cuda:0')
tensor(0.0471, device='cuda:0')
old_score: tensor(0.1508, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1049, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.084192514419556
Validation after dual ascent:
out_inf: tensor(33.5625, device='cuda:0', dtype=torch.float16) tensor(0.6353, device='cuda:0', dtype=torch.float16)
tensor(9.1094, device='cuda:0', dtype=torch.float16) tensor(0.1059, device='cuda:0', dtype=torch.float16)
tensor(7.6562, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(7.4062, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(7.5938, device='cuda:0', dtype=torch.float16) tensor(0.1072, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.up_proj
Validation after prune:
out_inf: tensor(34.0938, device='cuda:0', dtype=torch.float16) tensor(0.5845, device='cuda:0', dtype=torch.float16)
tensor(16.4375, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(14.7031, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(17.6875, device='cuda:0', dtype=torch.float16) tensor(0.1501, device='cuda:0', dtype=torch.float16)
tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0084, device='cuda:0')
tensor(0.0448, device='cuda:0')
old_score: tensor(0.1467, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.087677478790283
Validation after dual ascent:
out_inf: tensor(34.0938, device='cuda:0', dtype=torch.float16) tensor(0.5845, device='cuda:0', dtype=torch.float16)
tensor(7.7188, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(9.0625, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(9.3438, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(10.8906, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.down_proj
Validation after prune:
out_inf: tensor(1407., device='cuda:0', dtype=torch.float16) tensor(0.5200, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0893, device='cuda:0', dtype=torch.float16)
tensor(1.0928, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(1.2744, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0133, device='cuda:0')
tensor(0.0527, device='cuda:0')
old_score: tensor(0.0906, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0743, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.812885522842407
Validation after dual ascent:
out_inf: tensor(1407., device='cuda:0', dtype=torch.float16) tensor(0.5200, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.4922, device='cuda:0', dtype=torch.float16) tensor(0.8408, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.1775, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.1798, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.1849, device='cuda:0', dtype=torch.float16)
tensor(3.1094, device='cuda:0', dtype=torch.float16) tensor(0.1781, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2382, device='cuda:0')
old_score: tensor(0.1802, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1091, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.475679397583008
Validation after dual ascent:
out_inf: tensor(13.4922, device='cuda:0', dtype=torch.float16) tensor(0.8408, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1012, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.1106, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.k_proj
Validation after prune:
out_inf: tensor(24.2812, device='cuda:0', dtype=torch.float16) tensor(1.0664, device='cuda:0', dtype=torch.float16)
tensor(3.3438, device='cuda:0', dtype=torch.float16) tensor(0.1912, device='cuda:0', dtype=torch.float16)
tensor(3.2656, device='cuda:0', dtype=torch.float16) tensor(0.1915, device='cuda:0', dtype=torch.float16)
tensor(3.3906, device='cuda:0', dtype=torch.float16) tensor(0.1981, device='cuda:0', dtype=torch.float16)
tensor(3.6328, device='cuda:0', dtype=torch.float16) tensor(0.1923, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.2487, device='cuda:0')
old_score: tensor(0.1934, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1122, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4768524169921875
Validation after dual ascent:
out_inf: tensor(24.2812, device='cuda:0', dtype=torch.float16) tensor(1.0664, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.6953, device='cuda:0', dtype=torch.float16) tensor(0.4180, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
tensor(1.1768, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(1.2842, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0124, device='cuda:0')
tensor(0.2069, device='cuda:0')
old_score: tensor(0.1387, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0968, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4731173515319824
Validation after dual ascent:
out_inf: tensor(6.6953, device='cuda:0', dtype=torch.float16) tensor(0.4180, device='cuda:0', dtype=torch.float16)
tensor(0.9619, device='cuda:0', dtype=torch.float16) tensor(0.0977, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
tensor(1.0205, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.o_proj
Validation after prune:
out_inf: tensor(129.6250, device='cuda:0', dtype=torch.float16) tensor(0.2457, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0419, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0110, device='cuda:0')
tensor(0.1127, device='cuda:0')
old_score: tensor(0.0441, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0277, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7324819564819336
Validation after dual ascent:
out_inf: tensor(129.6250, device='cuda:0', dtype=torch.float16) tensor(0.2457, device='cuda:0', dtype=torch.float16)
tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0280, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0286, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.gate_proj
Validation after prune:
out_inf: tensor(29.9375, device='cuda:0', dtype=torch.float16) tensor(0.6763, device='cuda:0', dtype=torch.float16)
tensor(6.0781, device='cuda:0', dtype=torch.float16) tensor(0.1550, device='cuda:0', dtype=torch.float16)
tensor(5.7578, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.1580, device='cuda:0', dtype=torch.float16)
tensor(5.9688, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0199, device='cuda:0')
tensor(0.2271, device='cuda:0')
old_score: tensor(0.1567, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0953, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1379687786102295
Validation after dual ascent:
out_inf: tensor(29.9375, device='cuda:0', dtype=torch.float16) tensor(0.6763, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(2.1602, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.up_proj
Validation after prune:
out_inf: tensor(33.4375, device='cuda:0', dtype=torch.float16) tensor(0.6929, device='cuda:0', dtype=torch.float16)
tensor(9.4531, device='cuda:0', dtype=torch.float16) tensor(0.1505, device='cuda:0', dtype=torch.float16)
tensor(8.0312, device='cuda:0', dtype=torch.float16) tensor(0.1526, device='cuda:0', dtype=torch.float16)
tensor(7.6562, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(7.8750, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.2132, device='cuda:0')
old_score: tensor(0.1516, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0904, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.143447160720825
Validation after dual ascent:
out_inf: tensor(33.4375, device='cuda:0', dtype=torch.float16) tensor(0.6929, device='cuda:0', dtype=torch.float16)
tensor(2.9375, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(2.5117, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
tensor(2.8398, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.down_proj
Validation after prune:
out_inf: tensor(198.5000, device='cuda:0', dtype=torch.float16) tensor(1.5518, device='cuda:0', dtype=torch.float16)
tensor(2.7852, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(3.1250, device='cuda:0', dtype=torch.float16) tensor(0.1055, device='cuda:0', dtype=torch.float16)
tensor(3.4375, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.01it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.03it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.84it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25': 0, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.599870
layer 1 sparsity 0.599870
layer 2 sparsity 0.599870
layer 3 sparsity 0.599870
layer 4 sparsity 0.599870
layer 5 sparsity 0.599870
layer 6 sparsity 0.599870
layer 7 sparsity 0.599870
layer 8 sparsity 0.599870
layer 9 sparsity 0.599870
layer 10 sparsity 0.599870
layer 11 sparsity 0.599870
layer 12 sparsity 0.599870
layer 13 sparsity 0.599870
layer 14 sparsity 0.599870
layer 15 sparsity 0.599870
layer 16 sparsity 0.599870
layer 17 sparsity 0.599870
layer 18 sparsity 0.599870
layer 19 sparsity 0.599870
layer 20 sparsity 0.599870
layer 21 sparsity 0.599870
layer 22 sparsity 0.599870
layer 23 sparsity 0.599870
layer 24 sparsity 0.599870
layer 25 sparsity 0.599870
layer 26 sparsity 0.599870
layer 27 sparsity 0.599870
layer 28 sparsity 0.599870
layer 29 sparsity 0.599870
layer 30 sparsity 0.599870
layer 31 sparsity 0.599870
sparsity sanity check 0.5999
******************************
evaluating on wikitext2
nsamples 83
sample 0
sample 50
wikitext perplexity 9.791441917419434
wanda_dual_3	0.5999	9.7914	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.6, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='wanda_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
2025-04-24 00:37:44.274638: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 00:37:44.464777: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 00:37:44.470150: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 00:37:44.470179: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 00:37:48.036500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 00:37:48.037059: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 00:37:48.039345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.81it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.24it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.16it/s]
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
model.embed_tokens.weight torch.Size([32000, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([32000, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:00<03:22,  1.26it/s]  1%|          | 2/256 [00:01<03:06,  1.36it/s]  2%|▏         | 4/256 [00:01<01:26,  2.93it/s]  2%|▏         | 5/256 [00:02<01:30,  2.78it/s]  2%|▏         | 6/256 [00:02<01:11,  3.49it/s]  3%|▎         | 7/256 [00:02<01:47,  2.31it/s]  3%|▎         | 8/256 [00:03<01:24,  2.95it/s]  4%|▎         | 9/256 [00:03<01:06,  3.71it/s]  4%|▍         | 11/256 [00:03<00:45,  5.34it/s]  5%|▍         | 12/256 [00:03<00:42,  5.77it/s]  5%|▌         | 13/256 [00:04<01:29,  2.71it/s]  5%|▌         | 14/256 [00:04<01:27,  2.78it/s]  6%|▌         | 15/256 [00:04<01:14,  3.26it/s]  6%|▋         | 16/256 [00:05<01:04,  3.72it/s]  7%|▋         | 18/256 [00:05<01:07,  3.53it/s]  8%|▊         | 20/256 [00:05<00:50,  4.66it/s]  8%|▊         | 21/256 [00:06<00:45,  5.21it/s]  9%|▊         | 22/256 [00:06<00:48,  4.79it/s]  9%|▉         | 24/256 [00:06<00:42,  5.51it/s] 10%|▉         | 25/256 [00:06<00:39,  5.78it/s] 10%|█         | 26/256 [00:07<00:53,  4.31it/s] 11%|█         | 28/256 [00:07<00:44,  5.15it/s] 11%|█▏        | 29/256 [00:07<00:45,  4.99it/s] 12%|█▏        | 31/256 [00:07<00:38,  5.91it/s] 12%|█▎        | 32/256 [00:08<00:45,  4.89it/s] 13%|█▎        | 33/256 [00:08<00:56,  3.92it/s] 13%|█▎        | 34/256 [00:08<01:01,  3.62it/s] 14%|█▎        | 35/256 [00:09<01:09,  3.18it/s] 14%|█▍        | 36/256 [00:09<01:20,  2.72it/s] 14%|█▍        | 37/256 [00:10<01:14,  2.93it/s] 15%|█▍        | 38/256 [00:10<01:08,  3.17it/s] 16%|█▌        | 40/256 [00:10<01:02,  3.43it/s] 16%|█▋        | 42/256 [00:11<00:43,  4.88it/s] 17%|█▋        | 43/256 [00:11<00:38,  5.47it/s] 17%|█▋        | 44/256 [00:11<00:38,  5.54it/s] 18%|█▊        | 46/256 [00:11<00:32,  6.43it/s] 18%|█▊        | 47/256 [00:11<00:33,  6.25it/s] 19%|█▉        | 48/256 [00:12<00:37,  5.54it/s] 19%|█▉        | 49/256 [00:12<00:34,  6.03it/s] 20%|█▉        | 50/256 [00:12<00:49,  4.20it/s] 21%|██        | 53/256 [00:13<00:48,  4.19it/s] 21%|██        | 54/256 [00:13<00:47,  4.28it/s] 21%|██▏       | 55/256 [00:13<00:40,  4.90it/s] 22%|██▏       | 56/256 [00:13<00:47,  4.17it/s] 22%|██▏       | 57/256 [00:14<00:44,  4.52it/s] 23%|██▎       | 58/256 [00:14<00:48,  4.07it/s] 23%|██▎       | 59/256 [00:14<00:42,  4.63it/s] 23%|██▎       | 60/256 [00:14<00:45,  4.30it/s] 24%|██▍       | 61/256 [00:15<00:54,  3.55it/s] 24%|██▍       | 62/256 [00:15<00:59,  3.25it/s] 25%|██▍       | 63/256 [00:15<00:51,  3.73it/s] 25%|██▌       | 64/256 [00:15<00:43,  4.43it/s] 25%|██▌       | 65/256 [00:16<01:08,  2.78it/s] 26%|██▌       | 67/256 [00:16<00:43,  4.30it/s] 27%|██▋       | 68/256 [00:17<00:42,  4.38it/s] 27%|██▋       | 69/256 [00:17<00:43,  4.29it/s] 28%|██▊       | 71/256 [00:17<00:33,  5.53it/s] 29%|██▊       | 73/256 [00:17<00:26,  6.80it/s] 29%|██▉       | 74/256 [00:17<00:26,  6.86it/s] 29%|██▉       | 75/256 [00:18<00:32,  5.57it/s] 30%|██▉       | 76/256 [00:18<00:45,  3.95it/s] 30%|███       | 78/256 [00:18<00:31,  5.70it/s] 31%|███       | 79/256 [00:19<00:39,  4.52it/s] 31%|███▏      | 80/256 [00:19<00:49,  3.56it/s] 32%|███▏      | 81/256 [00:19<00:54,  3.22it/s] 32%|███▏      | 82/256 [00:20<00:44,  3.88it/s] 32%|███▏      | 83/256 [00:20<00:57,  3.02it/s] 33%|███▎      | 84/256 [00:20<00:53,  3.19it/s] 33%|███▎      | 85/256 [00:21<00:49,  3.44it/s] 34%|███▎      | 86/256 [00:21<00:45,  3.71it/s] 34%|███▍      | 87/256 [00:21<01:02,  2.70it/s] 34%|███▍      | 88/256 [00:22<01:04,  2.61it/s] 35%|███▍      | 89/256 [00:22<00:58,  2.84it/s] 35%|███▌      | 90/256 [00:22<00:59,  2.80it/s] 36%|███▌      | 91/256 [00:23<00:57,  2.88it/s] 36%|███▌      | 92/256 [00:23<00:48,  3.41it/s] 36%|███▋      | 93/256 [00:23<00:41,  3.88it/s] 37%|███▋      | 94/256 [00:24<00:50,  3.21it/s] 37%|███▋      | 95/256 [00:24<01:04,  2.48it/s] 38%|███▊      | 96/256 [00:24<00:51,  3.08it/s] 38%|███▊      | 97/256 [00:25<00:55,  2.85it/s] 38%|███▊      | 98/256 [00:25<00:46,  3.41it/s] 39%|███▊      | 99/256 [00:25<00:44,  3.52it/s] 39%|███▉      | 100/256 [00:25<00:42,  3.68it/s] 39%|███▉      | 101/256 [00:26<01:14,  2.09it/s] 40%|███▉      | 102/256 [00:27<01:04,  2.40it/s] 41%|████      | 104/256 [00:27<00:41,  3.69it/s] 41%|████▏     | 106/256 [00:27<00:33,  4.47it/s] 42%|████▏     | 107/256 [00:27<00:33,  4.43it/s] 42%|████▏     | 108/256 [00:28<00:48,  3.07it/s] 43%|████▎     | 111/256 [00:28<00:30,  4.79it/s] 44%|████▍     | 112/256 [00:29<00:31,  4.56it/s] 44%|████▍     | 113/256 [00:29<00:31,  4.55it/s] 45%|████▍     | 114/256 [00:29<00:28,  4.96it/s] 45%|████▍     | 115/256 [00:29<00:27,  5.19it/s] 45%|████▌     | 116/256 [00:30<00:38,  3.64it/s] 46%|████▌     | 117/256 [00:30<00:31,  4.37it/s] 46%|████▌     | 118/256 [00:30<00:29,  4.63it/s] 47%|████▋     | 120/256 [00:30<00:20,  6.50it/s] 47%|████▋     | 121/256 [00:30<00:19,  6.88it/s] 48%|████▊     | 122/256 [00:31<00:37,  3.61it/s] 48%|████▊     | 123/256 [00:31<00:40,  3.29it/s] 48%|████▊     | 124/256 [00:32<00:52,  2.53it/s] 49%|████▉     | 125/256 [00:33<01:23,  1.57it/s] 49%|████▉     | 126/256 [00:33<01:09,  1.86it/s] 50%|████▉     | 127/256 [00:34<01:15,  1.71it/s] 50%|█████     | 129/256 [00:34<00:45,  2.79it/s] 51%|█████     | 130/256 [00:34<00:41,  3.04it/s] 51%|█████     | 131/256 [00:35<00:38,  3.23it/s] 52%|█████▏    | 132/256 [00:35<00:36,  3.35it/s] 52%|█████▏    | 133/256 [00:36<00:45,  2.70it/s] 52%|█████▏    | 134/256 [00:36<00:45,  2.66it/s] 53%|█████▎    | 135/256 [00:36<00:36,  3.29it/s] 53%|█████▎    | 136/256 [00:36<00:36,  3.25it/s] 54%|█████▎    | 137/256 [00:37<00:30,  3.85it/s] 54%|█████▍    | 138/256 [00:37<00:27,  4.36it/s] 54%|█████▍    | 139/256 [00:37<00:24,  4.77it/s] 55%|█████▍    | 140/256 [00:37<00:22,  5.16it/s] 55%|█████▌    | 142/256 [00:37<00:16,  6.71it/s] 56%|█████▌    | 143/256 [00:37<00:16,  6.89it/s] 57%|█████▋    | 145/256 [00:38<00:34,  3.19it/s] 57%|█████▋    | 146/256 [00:39<00:38,  2.83it/s] 57%|█████▋    | 147/256 [00:39<00:35,  3.05it/s] 58%|█████▊    | 148/256 [00:40<00:37,  2.88it/s] 59%|█████▊    | 150/256 [00:40<00:29,  3.54it/s] 59%|█████▉    | 151/256 [00:40<00:25,  4.11it/s] 59%|█████▉    | 152/256 [00:40<00:28,  3.65it/s] 60%|█████▉    | 153/256 [00:41<00:25,  4.05it/s] 60%|██████    | 154/256 [00:41<00:29,  3.49it/s] 61%|██████    | 155/256 [00:41<00:26,  3.87it/s] 61%|██████    | 156/256 [00:41<00:21,  4.59it/s] 61%|██████▏   | 157/256 [00:42<00:27,  3.58it/s] 62%|██████▏   | 158/256 [00:42<00:24,  4.08it/s] 62%|██████▏   | 159/256 [00:43<00:42,  2.29it/s] 62%|██████▎   | 160/256 [00:43<00:32,  2.94it/s] 63%|██████▎   | 162/256 [00:44<00:36,  2.58it/s] 64%|██████▎   | 163/256 [00:44<00:32,  2.89it/s] 64%|██████▍   | 164/256 [00:44<00:26,  3.45it/s] 65%|██████▍   | 166/256 [00:45<00:22,  4.00it/s] 65%|██████▌   | 167/256 [00:45<00:25,  3.52it/s] 66%|██████▌   | 168/256 [00:45<00:28,  3.10it/s] 66%|██████▌   | 169/256 [00:46<00:32,  2.72it/s] 66%|██████▋   | 170/256 [00:46<00:31,  2.74it/s] 67%|██████▋   | 172/256 [00:46<00:22,  3.82it/s] 68%|██████▊   | 173/256 [00:47<00:21,  3.94it/s] 68%|██████▊   | 174/256 [00:47<00:28,  2.87it/s] 68%|██████▊   | 175/256 [00:48<00:41,  1.96it/s] 69%|██████▉   | 176/256 [00:49<00:36,  2.21it/s] 69%|██████▉   | 177/256 [00:49<00:29,  2.66it/s] 70%|██████▉   | 179/256 [00:49<00:19,  3.85it/s] 70%|███████   | 180/256 [00:50<00:37,  2.01it/s] 71%|███████   | 181/256 [00:50<00:29,  2.51it/s] 71%|███████   | 182/256 [00:51<00:38,  1.91it/s] 72%|███████▏  | 184/256 [00:52<00:35,  2.00it/s] 73%|███████▎  | 186/256 [00:52<00:24,  2.89it/s] 73%|███████▎  | 187/256 [00:53<00:27,  2.48it/s] 73%|███████▎  | 188/256 [00:53<00:24,  2.81it/s] 74%|███████▍  | 189/256 [00:54<00:23,  2.84it/s] 74%|███████▍  | 190/256 [00:54<00:21,  3.02it/s] 75%|███████▍  | 191/256 [00:54<00:19,  3.34it/s] 75%|███████▌  | 192/256 [00:55<00:22,  2.81it/s] 75%|███████▌  | 193/256 [00:55<00:21,  2.94it/s] 77%|███████▋  | 196/256 [00:55<00:13,  4.46it/s] 77%|███████▋  | 197/256 [00:56<00:15,  3.85it/s] 78%|███████▊  | 199/256 [00:56<00:11,  4.89it/s] 79%|███████▊  | 201/256 [00:56<00:09,  5.54it/s] 79%|███████▉  | 202/256 [00:57<00:12,  4.43it/s] 79%|███████▉  | 203/256 [00:57<00:10,  5.04it/s] 80%|███████▉  | 204/256 [00:57<00:09,  5.68it/s] 80%|████████  | 205/256 [00:57<00:08,  6.32it/s] 81%|████████  | 207/256 [00:57<00:06,  7.93it/s] 81%|████████▏ | 208/256 [00:57<00:07,  6.80it/s] 82%|████████▏ | 210/256 [00:57<00:05,  8.95it/s] 83%|████████▎ | 212/256 [00:58<00:05,  8.32it/s] 83%|████████▎ | 213/256 [00:58<00:05,  7.38it/s] 84%|████████▎ | 214/256 [00:58<00:07,  5.62it/s] 84%|████████▍ | 215/256 [00:58<00:09,  4.50it/s] 84%|████████▍ | 216/256 [00:59<00:09,  4.41it/s] 85%|████████▌ | 218/256 [00:59<00:07,  5.27it/s] 86%|████████▌ | 219/256 [01:00<00:14,  2.50it/s] 86%|████████▌ | 220/256 [01:00<00:12,  2.95it/s] 86%|████████▋ | 221/256 [01:01<00:12,  2.85it/s] 87%|████████▋ | 222/256 [01:01<00:12,  2.83it/s] 87%|████████▋ | 223/256 [01:01<00:12,  2.73it/s] 88%|████████▊ | 224/256 [01:03<00:24,  1.31it/s] 88%|████████▊ | 225/256 [01:04<00:22,  1.35it/s] 88%|████████▊ | 226/256 [01:04<00:17,  1.75it/s] 89%|████████▊ | 227/256 [01:04<00:13,  2.11it/s] 89%|████████▉ | 228/256 [01:05<00:12,  2.26it/s] 89%|████████▉ | 229/256 [01:06<00:18,  1.44it/s] 90%|████████▉ | 230/256 [01:06<00:13,  1.90it/s] 90%|█████████ | 231/256 [01:06<00:12,  1.95it/s] 91%|█████████ | 232/256 [01:07<00:10,  2.22it/s] 91%|█████████ | 233/256 [01:07<00:08,  2.70it/s] 92%|█████████▏| 235/256 [01:07<00:05,  3.76it/s] 92%|█████████▏| 236/256 [01:08<00:05,  3.64it/s] 93%|█████████▎| 237/256 [01:08<00:04,  4.02it/s] 93%|█████████▎| 238/256 [01:08<00:03,  4.69it/s] 93%|█████████▎| 239/256 [01:08<00:03,  4.63it/s] 94%|█████████▍| 241/256 [01:08<00:02,  5.87it/s] 95%|█████████▍| 242/256 [01:09<00:04,  2.85it/s] 95%|█████████▌| 244/256 [01:09<00:02,  4.33it/s] 96%|█████████▌| 245/256 [01:10<00:02,  4.24it/s] 96%|█████████▌| 246/256 [01:10<00:02,  4.66it/s] 97%|█████████▋| 248/256 [01:10<00:01,  6.36it/s] 97%|█████████▋| 249/256 [01:10<00:01,  3.89it/s] 98%|█████████▊| 251/256 [01:11<00:00,  5.45it/s] 98%|█████████▊| 252/256 [01:11<00:01,  3.53it/s] 99%|█████████▉| 253/256 [01:12<00:01,  2.93it/s]100%|█████████▉| 255/256 [01:12<00:00,  3.04it/s]100%|██████████| 256/256 [01:13<00:00,  3.12it/s]100%|██████████| 256/256 [01:13<00:00,  3.50it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
pruning layer 0 name self_attn.q_proj
Validation after prune:
out_inf: tensor(7.8555, device='cuda:0', dtype=torch.float16) tensor(0.6099, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.k_proj
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0703, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.v_proj
Validation after prune:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0388, device='cuda:0')
old_score: tensor(0.0018, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.79934287071228
Validation after dual ascent:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0230, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0309, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0248, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0245, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0055, device='cuda:0', dtype=torch.float16) tensor(8.7202e-05, device='cuda:0', dtype=torch.float16)
tensor(0.0033, device='cuda:0', dtype=torch.float16) tensor(0.0001, device='cuda:0', dtype=torch.float16)
tensor(0.0053, device='cuda:0', dtype=torch.float16) tensor(0.0001, device='cuda:0', dtype=torch.float16)
tensor(0.0068, device='cuda:0', dtype=torch.float16) tensor(9.0718e-05, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.4131, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0164, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.0107, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0060, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.447323322296143
Validation after dual ascent:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.2842, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.2859, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.up_proj
Validation after prune:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1738, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1665, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0158, device='cuda:0')
tensor(0.0181, device='cuda:0')
old_score: tensor(0.0105, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0059, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.48267936706543
Validation after dual ascent:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1079, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.1211, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.1284, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.1123, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0476, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0431, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0389, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0459, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0726, device='cuda:0')
old_score: tensor(0.0013, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0009, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.250417470932
Validation after dual ascent:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0203, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0225, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0222, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0444, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.q_proj
Validation after prune:
out_inf: tensor(9.2500, device='cuda:0', dtype=torch.float16) tensor(0.7812, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
tensor(0.9629, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.k_proj
Validation after prune:
out_inf: tensor(7.7383, device='cuda:0', dtype=torch.float16) tensor(0.7896, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.2666, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2744, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.2695, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0193, device='cuda:0')
tensor(0.0290, device='cuda:0')
old_score: tensor(0.0067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0037, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.223603963851929
Validation after dual ascent:
out_inf: tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.1572, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.1689, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.1631, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.5386, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.0273, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
tensor(0.0150, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0241, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0216, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.gate_proj
Validation after prune:
out_inf: tensor(43.6562, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(3.7188, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(3.4688, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(3.8750, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0160, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.0229, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0140, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.777703285217285
Validation after dual ascent:
out_inf: tensor(43.6562, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.up_proj
Validation after prune:
out_inf: tensor(37.7188, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(2.4688, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0130, device='cuda:0')
tensor(0.0198, device='cuda:0')
old_score: tensor(0.0209, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.772908687591553
Validation after dual ascent:
out_inf: tensor(37.7188, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.down_proj
Validation after prune:
out_inf: tensor(2674., device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0908, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0878, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(2.0303, device='cuda:0')
old_score: tensor(0.0037, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0135, device='cuda:0', dtype=torch.float16)
Not converged!
Dual ascent finished!
Time: 98.14751267433167
Validation after dual ascent:
out_inf: tensor(2674., device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0908, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0878, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12., device='cuda:0', dtype=torch.float16) tensor(0.9028, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.k_proj
Validation after prune:
out_inf: tensor(13.4219, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0680, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.9785, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.3418, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.4590, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.0207, device='cuda:0')
old_score: tensor(0.0332, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0216, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.447927713394165
Validation after dual ascent:
out_inf: tensor(2.9785, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
tensor(0.2539, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.2668, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.2549, device='cuda:0', dtype=torch.float16) tensor(0.0214, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9341, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.2323, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0934, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.1364, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0425, device='cuda:0')
old_score: tensor(0.0022, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0017, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.938723802566528
Validation after dual ascent:
out_inf: tensor(0.9341, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1069, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.1520, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.1103, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0942, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.2324, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0166, device='cuda:0')
tensor(0.0158, device='cuda:0')
old_score: tensor(0.0334, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.970378637313843
Validation after dual ascent:
out_inf: tensor(2.2324, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(0.3552, device='cuda:0', dtype=torch.float16) tensor(0.0237, device='cuda:0', dtype=torch.float16)
tensor(0.4268, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.3782, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
tensor(0.4211, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.3125, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.2666, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.3730, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0166, device='cuda:0')
tensor(0.0247, device='cuda:0')
old_score: tensor(0.0306, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0222, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115081548690796
Validation after dual ascent:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.2312, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.2405, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.2421, device='cuda:0', dtype=torch.float16) tensor(0.0237, device='cuda:0', dtype=torch.float16)
tensor(0.2595, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.0884, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.1057, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1099, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1192, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0774, device='cuda:0')
old_score: tensor(0.0054, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0046, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 99.11949896812439
Validation after dual ascent:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.0664, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0763, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.0721, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0824, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(0.8271, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0')
old_score: tensor(0.1021, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0714, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.966545820236206
Validation after dual ascent:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(0.8271, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(1.1748, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(1.1846, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.1034, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0150, device='cuda:0')
tensor(0.0522, device='cuda:0')
old_score: tensor(0.1058, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0734, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.79701852798462
Validation after dual ascent:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(1.0557, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.7051, device='cuda:0', dtype=torch.float16) tensor(0.1945, device='cuda:0', dtype=torch.float16)
tensor(0.4468, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.4751, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.4448, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0176, device='cuda:0')
tensor(0.0302, device='cuda:0')
old_score: tensor(0.0546, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0404, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470710515975952
Validation after dual ascent:
out_inf: tensor(2.7051, device='cuda:0', dtype=torch.float16) tensor(0.1945, device='cuda:0', dtype=torch.float16)
tensor(0.4058, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.4714, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.5620, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.4412, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.1746, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.1528, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.1484, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0376, device='cuda:0')
old_score: tensor(0.0031, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0025, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.989231586456299
Validation after dual ascent:
out_inf: tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.1494, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0933, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1138, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.1045, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.0820, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0067, device='cuda:0')
tensor(0.0184, device='cuda:0')
old_score: tensor(0.0430, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0334, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.12730598449707
Validation after dual ascent:
out_inf: tensor(5.0820, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(0.6006, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0188, device='cuda:0')
tensor(0.1437, device='cuda:0')
old_score: tensor(0.0396, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0309, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.192681312561035
Validation after dual ascent:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
tensor(0.3037, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.3445, device='cuda:0', dtype=torch.float16) tensor(0.0290, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.3101, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5771, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.1238, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1736, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1309, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1255, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0199, device='cuda:0')
tensor(0.0524, device='cuda:0')
old_score: tensor(0.0079, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0069, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 70.31862545013428
Validation after dual ascent:
out_inf: tensor(1.5771, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.0862, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1395, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1021, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0961, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.1797, device='cuda:0', dtype=torch.float16) tensor(0.8057, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.1396, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1032, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0187, device='cuda:0')
tensor(0.0536, device='cuda:0')
old_score: tensor(0.1036, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0760, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1989097595214844
Validation after dual ascent:
out_inf: tensor(13.1797, device='cuda:0', dtype=torch.float16) tensor(0.8057, device='cuda:0', dtype=torch.float16)
tensor(0.9580, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.9263, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(1.0420, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(1.0215, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.0254, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0183, device='cuda:0')
tensor(0.0405, device='cuda:0')
old_score: tensor(0.1060, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0768, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.83234190940857
Validation after dual ascent:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.0254, device='cuda:0', dtype=torch.float16)
tensor(1.1357, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.0137, device='cuda:0', dtype=torch.float16) tensor(0.0819, device='cuda:0', dtype=torch.float16)
tensor(1.0479, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.4746, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(0.6006, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.0301, device='cuda:0')
old_score: tensor(0.0569, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0433, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4682257175445557
Validation after dual ascent:
out_inf: tensor(3.4746, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(0.4116, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.4128, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.4465, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.3203, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.2217, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.2158, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0269, device='cuda:0')
old_score: tensor(0.0061, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0047, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.968658685684204
Validation after dual ascent:
out_inf: tensor(3.3203, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
tensor(0.1348, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.7617, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0172, device='cuda:0')
tensor(0.2353, device='cuda:0')
old_score: tensor(0.0524, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0416, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.186804294586182
Validation after dual ascent:
out_inf: tensor(4.7617, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.6255, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.6040, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.1191, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0144, device='cuda:0')
tensor(0.2109, device='cuda:0')
old_score: tensor(0.0468, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0374, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.196000099182129
Validation after dual ascent:
out_inf: tensor(3.1191, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(0.3699, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.3481, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.down_proj
Validation after prune:
out_inf: tensor(9.3359, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.2061, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.2295, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1914, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.2275, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0108, device='cuda:0')
tensor(0.0148, device='cuda:0')
old_score: tensor(0.0117, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 46.14243459701538
Validation after dual ascent:
out_inf: tensor(9.3359, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.1584, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1378, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1326, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1582, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.5234, device='cuda:0', dtype=torch.float16) tensor(0.8149, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.1092, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
tensor(0.0869, device='cuda:0')
old_score: tensor(0.1113, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0845, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.962782144546509
Validation after dual ascent:
out_inf: tensor(14.5234, device='cuda:0', dtype=torch.float16) tensor(0.8149, device='cuda:0', dtype=torch.float16)
tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.9746, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4062, device='cuda:0', dtype=torch.float16) tensor(1.0625, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1196, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0152, device='cuda:0')
tensor(0.0609, device='cuda:0')
old_score: tensor(0.1166, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0867, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.799194097518921
Validation after dual ascent:
out_inf: tensor(19.4062, device='cuda:0', dtype=torch.float16) tensor(1.0625, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(1.0840, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3711, device='cuda:0', dtype=torch.float16) tensor(0.2059, device='cuda:0', dtype=torch.float16)
tensor(0.4468, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.4741, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.5073, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0168, device='cuda:0')
tensor(0.0345, device='cuda:0')
old_score: tensor(0.0608, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0483, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.474705457687378
Validation after dual ascent:
out_inf: tensor(2.3711, device='cuda:0', dtype=torch.float16) tensor(0.2059, device='cuda:0', dtype=torch.float16)
tensor(0.4045, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.3359, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.2310, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.2197, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.2383, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2214, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0319, device='cuda:0')
old_score: tensor(0.0067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.986371278762817
Validation after dual ascent:
out_inf: tensor(4.3359, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.2034, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.1482, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.1888, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.2021, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.7988, device='cuda:0', dtype=torch.float16) tensor(0.2249, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0131, device='cuda:0')
tensor(0.0272, device='cuda:0')
old_score: tensor(0.0593, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0466, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.126974105834961
Validation after dual ascent:
out_inf: tensor(3.7988, device='cuda:0', dtype=torch.float16) tensor(0.2249, device='cuda:0', dtype=torch.float16)
tensor(0.6846, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.6943, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.5728, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4258, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0069, device='cuda:0')
tensor(0.0242, device='cuda:0')
old_score: tensor(0.0526, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.131100177764893
Validation after dual ascent:
out_inf: tensor(4.4258, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(0.3767, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5576, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.2134, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.3267, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.2078, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0167, device='cuda:0')
tensor(0.0127, device='cuda:0')
old_score: tensor(0.0144, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0128, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 31.681525945663452
Validation after dual ascent:
out_inf: tensor(1.5576, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.1804, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.2446, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1323, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.5547, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(2.0586, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.7773, device='cuda:0', dtype=torch.float16) tensor(0.1350, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0154, device='cuda:0')
tensor(0.0523, device='cuda:0')
old_score: tensor(0.1345, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1001, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.213273286819458
Validation after dual ascent:
out_inf: tensor(13.5547, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(1.4307, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
tensor(1.4199, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.6875, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.7520, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0176, device='cuda:0')
tensor(0.0565, device='cuda:0')
old_score: tensor(0.1379, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2184343338012695
Validation after dual ascent:
out_inf: tensor(16.6875, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(1.4678, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(1.5254, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.5488, device='cuda:0', dtype=torch.float16) tensor(0.2539, device='cuda:0', dtype=torch.float16)
tensor(0.5815, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.5864, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(0.6177, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.5796, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.0594, device='cuda:0')
old_score: tensor(0.0724, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.47823166847229
Validation after dual ascent:
out_inf: tensor(3.5488, device='cuda:0', dtype=torch.float16) tensor(0.2539, device='cuda:0', dtype=torch.float16)
tensor(0.4717, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5122, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.5913, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.7383, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.3271, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.2988, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0118, device='cuda:0')
tensor(0.0213, device='cuda:0')
old_score: tensor(0.0112, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0083, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.311212062835693
Validation after dual ascent:
out_inf: tensor(4.7383, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.2739, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2568, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.5664, device='cuda:0', dtype=torch.float16) tensor(0.2866, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
tensor(0.8887, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0034, device='cuda:0')
tensor(0.0291, device='cuda:0')
old_score: tensor(0.0659, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1254167556762695
Validation after dual ascent:
out_inf: tensor(4.5664, device='cuda:0', dtype=torch.float16) tensor(0.2866, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.9453, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0020, device='cuda:0')
tensor(0.0252, device='cuda:0')
old_score: tensor(0.0569, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0449, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.13472580909729
Validation after dual ascent:
out_inf: tensor(2.9453, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.2637, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
tensor(0.3193, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.2354, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0081, device='cuda:0')
tensor(0.0137, device='cuda:0')
old_score: tensor(0.0176, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0153, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 22.011722803115845
Validation after dual ascent:
out_inf: tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.1968, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.2188, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1499, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.2454, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1371, device='cuda:0', dtype=torch.float16)
tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(2.0625, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0471, device='cuda:0')
old_score: tensor(0.1401, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1041, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2159366607666016
Validation after dual ascent:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.4121, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.9858, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1436, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1406, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0405, device='cuda:0')
old_score: tensor(0.1415, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1043, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2171812057495117
Validation after dual ascent:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.9858, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.3691, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8242, device='cuda:0', dtype=torch.float16) tensor(0.2639, device='cuda:0', dtype=torch.float16)
tensor(0.6079, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0114, device='cuda:0')
tensor(0.0677, device='cuda:0')
old_score: tensor(0.0765, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0599, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4741296768188477
Validation after dual ascent:
out_inf: tensor(4.8242, device='cuda:0', dtype=torch.float16) tensor(0.2639, device='cuda:0', dtype=torch.float16)
tensor(0.5405, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.5571, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(0.5249, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.9082, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3516, device='cuda:0', dtype=torch.float16) tensor(0.0163, device='cuda:0', dtype=torch.float16)
tensor(0.4502, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0177, device='cuda:0')
tensor(0.0276, device='cuda:0')
old_score: tensor(0.0144, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.360501289367676
Validation after dual ascent:
out_inf: tensor(3.9082, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.2529, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.3721, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.3286, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.0713, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0326, device='cuda:0')
old_score: tensor(0.0703, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0539, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.124880313873291
Validation after dual ascent:
out_inf: tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.3286, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.9473, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.8765, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0781, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0022, device='cuda:0')
tensor(0.0285, device='cuda:0')
old_score: tensor(0.0608, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0475, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.132008075714111
Validation after dual ascent:
out_inf: tensor(4.0781, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.3982, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.4980, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.5742, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.3818, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(0.3721, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.3320, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0075, device='cuda:0')
tensor(0.0157, device='cuda:0')
old_score: tensor(0.0206, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0175, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.14862036705017
Validation after dual ascent:
out_inf: tensor(2.5742, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.2693, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.2556, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.2434, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.2822, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(2.1719, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(2.1367, device='cuda:0', dtype=torch.float16) tensor(0.1367, device='cuda:0', dtype=torch.float16)
tensor(0.1500, device='cuda:0')
old_score: tensor(0.1379, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.956400871276855
Validation after dual ascent:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1029, device='cuda:0', dtype=torch.float16)
tensor(1.4795, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(1.4443, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(1.0127, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(1.5449, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
tensor(0.1496, device='cuda:0')
old_score: tensor(0.1395, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1039, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.989866495132446
Validation after dual ascent:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(1.0127, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(1.2490, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0766, device='cuda:0', dtype=torch.float16)
tensor(0.6304, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.5752, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(0.0670, device='cuda:0')
old_score: tensor(0.0782, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0608, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.956763744354248
Validation after dual ascent:
out_inf: tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
tensor(0.5278, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.5396, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.4180, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0187, device='cuda:0')
tensor(0.0217, device='cuda:0')
old_score: tensor(0.0168, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.896829128265381
Validation after dual ascent:
out_inf: tensor(4.4180, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.2305, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3018, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.2876, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.7227, device='cuda:0', dtype=torch.float16) tensor(0.3235, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(1.2012, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0038, device='cuda:0')
tensor(0.0355, device='cuda:0')
old_score: tensor(0.0709, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0553, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.132889986038208
Validation after dual ascent:
out_inf: tensor(5.7227, device='cuda:0', dtype=torch.float16) tensor(0.3235, device='cuda:0', dtype=torch.float16)
tensor(0.7544, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.7803, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.5352, device='cuda:0', dtype=torch.float16) tensor(0.2090, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0025, device='cuda:0')
tensor(0.0324, device='cuda:0')
old_score: tensor(0.0638, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.131969690322876
Validation after dual ascent:
out_inf: tensor(7.5352, device='cuda:0', dtype=torch.float16) tensor(0.2090, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.6543, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.3892, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.4526, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0177, device='cuda:0')
tensor(0.0236, device='cuda:0')
old_score: tensor(0.0225, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0193, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.315219640731812
Validation after dual ascent:
out_inf: tensor(2.6543, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.3135, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.2471, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.7920, device='cuda:0', dtype=torch.float16)
tensor(1.5918, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.7910, device='cuda:0', dtype=torch.float16) tensor(0.1460, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(0.2079, device='cuda:0')
old_score: tensor(0.1440, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.948143243789673
Validation after dual ascent:
out_inf: tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.7920, device='cuda:0', dtype=torch.float16)
tensor(1.2979, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1079, device='cuda:0', dtype=torch.float16)
tensor(1.1865, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4219, device='cuda:0', dtype=torch.float16) tensor(1.0342, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1431, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.1494, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.1517, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1459, device='cuda:0', dtype=torch.float16)
tensor(0.2171, device='cuda:0')
old_score: tensor(0.1476, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1116, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.991996765136719
Validation after dual ascent:
out_inf: tensor(19.4219, device='cuda:0', dtype=torch.float16) tensor(1.0342, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.2812, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.6904, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.0829, device='cuda:0')
old_score: tensor(0.0818, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0647, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.958354473114014
Validation after dual ascent:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.2812, device='cuda:0', dtype=torch.float16)
tensor(0.5459, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.5825, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
tensor(0.5825, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.8320, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0196, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0196, device='cuda:0')
tensor(0.0400, device='cuda:0')
old_score: tensor(0.0185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0141, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.6830079555511475
Validation after dual ascent:
out_inf: tensor(3.8320, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3926, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.2793, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.3389, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.4766, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(1.4326, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0403, device='cuda:0')
old_score: tensor(0.0728, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0578, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.130746841430664
Validation after dual ascent:
out_inf: tensor(6.4766, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
tensor(0.8916, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.2213, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0029, device='cuda:0')
tensor(0.0380, device='cuda:0')
old_score: tensor(0.0668, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0536, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.13324236869812
Validation after dual ascent:
out_inf: tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.2213, device='cuda:0', dtype=torch.float16)
tensor(0.4961, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4736, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.3740, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.3564, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.3320, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0044, device='cuda:0')
tensor(0.0208, device='cuda:0')
old_score: tensor(0.0244, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0214, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.333394765853882
Validation after dual ascent:
out_inf: tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.2676, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.3462, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(0.2350, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.9844, device='cuda:0', dtype=torch.float16) tensor(0.7798, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.1495, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(0.1227, device='cuda:0')
old_score: tensor(0.1455, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.940801858901978
Validation after dual ascent:
out_inf: tensor(13.9844, device='cuda:0', dtype=torch.float16) tensor(0.7798, device='cuda:0', dtype=torch.float16)
tensor(1.3135, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(1.0469, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1534, device='cuda:0', dtype=torch.float16)
tensor(1.7461, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
tensor(0.1277, device='cuda:0')
old_score: tensor(0.1498, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1151, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.984903335571289
Validation after dual ascent:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(1.0469, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.4307, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1183, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.1875, device='cuda:0', dtype=torch.float16) tensor(0.2869, device='cuda:0', dtype=torch.float16)
tensor(0.6401, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.6724, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0192, device='cuda:0')
tensor(0.0843, device='cuda:0')
old_score: tensor(0.0826, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0663, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2097506523132324
Validation after dual ascent:
out_inf: tensor(7.1875, device='cuda:0', dtype=torch.float16) tensor(0.2869, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.6538, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.0039, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(0.4404, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0076, device='cuda:0')
tensor(0.0309, device='cuda:0')
old_score: tensor(0.0238, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0175, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7328569889068604
Validation after dual ascent:
out_inf: tensor(5.0039, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.3311, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.4023, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.3599, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.7812, device='cuda:0', dtype=torch.float16) tensor(0.3398, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.2129, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(1.3311, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0040, device='cuda:0')
tensor(0.0430, device='cuda:0')
old_score: tensor(0.0741, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0592, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.119677543640137
Validation after dual ascent:
out_inf: tensor(6.7812, device='cuda:0', dtype=torch.float16) tensor(0.3398, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.9248, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.1045, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.6621, device='cuda:0', dtype=torch.float16) tensor(0.2379, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.5591, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0031, device='cuda:0')
tensor(0.0408, device='cuda:0')
old_score: tensor(0.0692, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0558, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.126777410507202
Validation after dual ascent:
out_inf: tensor(3.6621, device='cuda:0', dtype=torch.float16) tensor(0.2379, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.0586, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.4858, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0044, device='cuda:0')
tensor(0.0240, device='cuda:0')
old_score: tensor(0.0269, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0234, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.310951471328735
Validation after dual ascent:
out_inf: tensor(3.0586, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.3364, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.2451, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.2964, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
tensor(0.3691, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(0.7793, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
tensor(2.4961, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
tensor(0.1669, device='cuda:0')
old_score: tensor(0.1511, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1180, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.94214916229248
Validation after dual ascent:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(0.7793, device='cuda:0', dtype=torch.float16)
tensor(1.7305, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(1.9082, device='cuda:0', dtype=torch.float16) tensor(0.1159, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
tensor(1.9121, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.9297, device='cuda:0', dtype=torch.float16) tensor(1.0166, device='cuda:0', dtype=torch.float16)
tensor(1.7930, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.9033, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
tensor(1.8027, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(0.1729, device='cuda:0')
old_score: tensor(0.1520, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1174, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.981701850891113
Validation after dual ascent:
out_inf: tensor(15.9297, device='cuda:0', dtype=torch.float16) tensor(1.0166, device='cuda:0', dtype=torch.float16)
tensor(1.5068, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(1.3818, device='cuda:0', dtype=torch.float16) tensor(0.1167, device='cuda:0', dtype=torch.float16)
tensor(1.5605, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.3438, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.7490, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(0.7778, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(0.7534, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0174, device='cuda:0')
tensor(0.0799, device='cuda:0')
old_score: tensor(0.0961, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0775, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.758437871932983
Validation after dual ascent:
out_inf: tensor(8.3438, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.6514, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.6450, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(0.5757, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0063, device='cuda:0')
tensor(0.0361, device='cuda:0')
old_score: tensor(0.0269, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0192, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7396798133850098
Validation after dual ascent:
out_inf: tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.4297, device='cuda:0', dtype=torch.float16) tensor(0.3511, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(1.5801, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(1.5723, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0044, device='cuda:0')
tensor(0.0475, device='cuda:0')
old_score: tensor(0.0771, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0616, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.127136707305908
Validation after dual ascent:
out_inf: tensor(6.4297, device='cuda:0', dtype=torch.float16) tensor(0.3511, device='cuda:0', dtype=torch.float16)
tensor(1.1768, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(1.1123, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.9717, device='cuda:0', dtype=torch.float16) tensor(0.0615, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.8691, device='cuda:0', dtype=torch.float16) tensor(0.2423, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.6045, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.6084, device='cuda:0', dtype=torch.float16) tensor(0.0727, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0034, device='cuda:0')
tensor(0.0455, device='cuda:0')
old_score: tensor(0.0726, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0587, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.128876447677612
Validation after dual ascent:
out_inf: tensor(3.8691, device='cuda:0', dtype=torch.float16) tensor(0.2423, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.4917, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.2148, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.4634, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.4956, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0022, device='cuda:0')
tensor(0.0265, device='cuda:0')
old_score: tensor(0.0286, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.316159725189209
Validation after dual ascent:
out_inf: tensor(3.2148, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.3101, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.4094, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.4375, device='cuda:0', dtype=torch.float16) tensor(0.7842, device='cuda:0', dtype=torch.float16)
tensor(2.1055, device='cuda:0', dtype=torch.float16) tensor(0.1538, device='cuda:0', dtype=torch.float16)
tensor(2.0273, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.1617, device='cuda:0', dtype=torch.float16)
tensor(1.8086, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.2244, device='cuda:0')
old_score: tensor(0.1570, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4702165126800537
Validation after dual ascent:
out_inf: tensor(17.4375, device='cuda:0', dtype=torch.float16) tensor(0.7842, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1225, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.6562, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
tensor(1.7090, device='cuda:0', dtype=torch.float16) tensor(0.1626, device='cuda:0', dtype=torch.float16)
tensor(2.2461, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.1606, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0171, device='cuda:0')
tensor(0.2298, device='cuda:0')
old_score: tensor(0.1624, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1265, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4741549491882324
Validation after dual ascent:
out_inf: tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1241, device='cuda:0', dtype=torch.float16)
tensor(1.3926, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(1.3730, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.2266, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(0.7466, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(0.7783, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0084, device='cuda:0')
tensor(0.1414, device='cuda:0')
old_score: tensor(0.0950, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.469388008117676
Validation after dual ascent:
out_inf: tensor(6.2266, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(0.6255, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(0.6343, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.1680, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0262, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0063, device='cuda:0')
tensor(0.0139, device='cuda:0')
old_score: tensor(0.0282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0203, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.931680202484131
Validation after dual ascent:
out_inf: tensor(5.1680, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.4116, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.8086, device='cuda:0', dtype=torch.float16) tensor(0.3567, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.0791, device='cuda:0', dtype=torch.float16)
tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0045, device='cuda:0')
tensor(0.0528, device='cuda:0')
old_score: tensor(0.0795, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0636, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.109863758087158
Validation after dual ascent:
out_inf: tensor(6.8086, device='cuda:0', dtype=torch.float16) tensor(0.3567, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9727, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0037, device='cuda:0')
tensor(0.0517, device='cuda:0')
old_score: tensor(0.0760, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0615, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1118738651275635
Validation after dual ascent:
out_inf: tensor(4.9727, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.4995, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.4951, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
tensor(0.5088, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
tensor(0.5186, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0020, device='cuda:0')
tensor(0.0310, device='cuda:0')
old_score: tensor(0.0305, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0266, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.2803213596344
Validation after dual ascent:
out_inf: tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.2781, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.3276, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.5859, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1561, device='cuda:0', dtype=torch.float16)
tensor(2.1211, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1632, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0161, device='cuda:0')
tensor(0.2444, device='cuda:0')
old_score: tensor(0.1593, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1259, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.475371837615967
Validation after dual ascent:
out_inf: tensor(13.5859, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
tensor(1.4854, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(1.6074, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9990, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1611, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.2466, device='cuda:0')
old_score: tensor(0.1622, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1272, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4783761501312256
Validation after dual ascent:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9990, device='cuda:0', dtype=torch.float16)
tensor(1.3721, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
tensor(1.5352, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.5342, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.1797, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.1020, device='cuda:0', dtype=torch.float16)
tensor(0.7905, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0088, device='cuda:0')
tensor(0.1586, device='cuda:0')
old_score: tensor(0.1002, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0818, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.473416805267334
Validation after dual ascent:
out_inf: tensor(5.1797, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.6597, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(0.6724, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0173, device='cuda:0')
tensor(0.0305, device='cuda:0')
old_score: tensor(0.0295, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0212, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.930945634841919
Validation after dual ascent:
out_inf: tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.4619, device='cuda:0', dtype=torch.float16) tensor(0.0214, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.0078, device='cuda:0', dtype=torch.float16) tensor(0.3726, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(1.3789, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.0586, device='cuda:0')
old_score: tensor(0.0822, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0652, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.113787889480591
Validation after dual ascent:
out_inf: tensor(7.0078, device='cuda:0', dtype=torch.float16) tensor(0.3726, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.7461, device='cuda:0', dtype=torch.float16) tensor(0.2693, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(0.7363, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.0584, device='cuda:0')
old_score: tensor(0.0797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0640, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115798234939575
Validation after dual ascent:
out_inf: tensor(4.7461, device='cuda:0', dtype=torch.float16) tensor(0.2693, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.1172, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.6187, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.5869, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0024, device='cuda:0')
tensor(0.0387, device='cuda:0')
old_score: tensor(0.0342, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0297, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.289790391921997
Validation after dual ascent:
out_inf: tensor(5.1172, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.3804, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.6953, device='cuda:0', dtype=torch.float16) tensor(0.7998, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(1.9258, device='cuda:0', dtype=torch.float16) tensor(0.1633, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1692, device='cuda:0', dtype=torch.float16)
tensor(2.2402, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0076, device='cuda:0')
tensor(0.0607, device='cuda:0')
old_score: tensor(0.1641, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1277, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.210801362991333
Validation after dual ascent:
out_inf: tensor(13.6953, device='cuda:0', dtype=torch.float16) tensor(0.7998, device='cuda:0', dtype=torch.float16)
tensor(1.7246, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(1.4824, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
tensor(1.4971, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4375, device='cuda:0', dtype=torch.float16) tensor(1.0713, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
tensor(1.7559, device='cuda:0', dtype=torch.float16) tensor(0.1681, device='cuda:0', dtype=torch.float16)
tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.1730, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.1669, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0093, device='cuda:0')
tensor(0.0557, device='cuda:0')
old_score: tensor(0.1682, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1290, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.212862968444824
Validation after dual ascent:
out_inf: tensor(19.4375, device='cuda:0', dtype=torch.float16) tensor(1.0713, device='cuda:0', dtype=torch.float16)
tensor(1.4189, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1343, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.3240, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0996, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(0.8037, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0130, device='cuda:0')
tensor(0.1722, device='cuda:0')
old_score: tensor(0.1010, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0816, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.473545789718628
Validation after dual ascent:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.3240, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.7231, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0851, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.2852, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0088, device='cuda:0')
tensor(0.0547, device='cuda:0')
old_score: tensor(0.0328, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7325105667114258
Validation after dual ascent:
out_inf: tensor(7.2852, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(0.3711, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.3926, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.3721, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1914, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(1.6309, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.0685, device='cuda:0')
old_score: tensor(0.0857, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0687, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1140501499176025
Validation after dual ascent:
out_inf: tensor(7.1914, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(1.2012, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(1.0752, device='cuda:0', dtype=torch.float16) tensor(0.0686, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4336, device='cuda:0', dtype=torch.float16) tensor(0.2827, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0048, device='cuda:0')
tensor(0.0680, device='cuda:0')
old_score: tensor(0.0832, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0674, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115141868591309
Validation after dual ascent:
out_inf: tensor(4.4336, device='cuda:0', dtype=torch.float16) tensor(0.2827, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.6099, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.8926, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.5664, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0028, device='cuda:0')
tensor(0.0457, device='cuda:0')
old_score: tensor(0.0368, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0322, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.285127639770508
Validation after dual ascent:
out_inf: tensor(2.8926, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.3438, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.4373, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.2188, device='cuda:0', dtype=torch.float16) tensor(0.7871, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1538, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1562, device='cuda:0', dtype=torch.float16)
tensor(1.8945, device='cuda:0', dtype=torch.float16) tensor(0.1611, device='cuda:0', dtype=torch.float16)
tensor(1.8350, device='cuda:0', dtype=torch.float16) tensor(0.1576, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0145, device='cuda:0')
tensor(0.2424, device='cuda:0')
old_score: tensor(0.1572, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.472295045852661
Validation after dual ascent:
out_inf: tensor(15.2188, device='cuda:0', dtype=torch.float16) tensor(0.7871, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.2744, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6797, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1641, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1681, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.2491, device='cuda:0')
old_score: tensor(0.1646, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1274, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4768810272216797
Validation after dual ascent:
out_inf: tensor(15.6797, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.3506, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.3359, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.1029, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0089, device='cuda:0')
tensor(0.1645, device='cuda:0')
old_score: tensor(0.1023, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0833, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4726667404174805
Validation after dual ascent:
out_inf: tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.3359, device='cuda:0', dtype=torch.float16)
tensor(0.6509, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.6382, device='cuda:0', dtype=torch.float16) tensor(0.0806, device='cuda:0', dtype=torch.float16)
tensor(0.6313, device='cuda:0', dtype=torch.float16) tensor(0.0827, device='cuda:0', dtype=torch.float16)
tensor(0.6392, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.4336, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.5386, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0043, device='cuda:0')
tensor(0.0583, device='cuda:0')
old_score: tensor(0.0331, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0242, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7337450981140137
Validation after dual ascent:
out_inf: tensor(5.4336, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
tensor(0.4229, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
tensor(0.3848, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.1641, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(1.7070, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0902, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.0768, device='cuda:0')
old_score: tensor(0.0895, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0707, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.118020296096802
Validation after dual ascent:
out_inf: tensor(9.1641, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(1.0361, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(1.0723, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9805, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(0.8076, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.8867, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.0765, device='cuda:0')
old_score: tensor(0.0868, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0696, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.118088483810425
Validation after dual ascent:
out_inf: tensor(4.9805, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.5312, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.5752, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0035, device='cuda:0')
tensor(0.0562, device='cuda:0')
old_score: tensor(0.0405, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0352, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.280435562133789
Validation after dual ascent:
out_inf: tensor(6.5312, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
tensor(0.4224, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.3394, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.3513, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.4390, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2812, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.1582, device='cuda:0', dtype=torch.float16)
tensor(2.3828, device='cuda:0', dtype=torch.float16) tensor(0.1586, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.1638, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1603, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0157, device='cuda:0')
tensor(0.2654, device='cuda:0')
old_score: tensor(0.1603, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4734156131744385
Validation after dual ascent:
out_inf: tensor(17.2812, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(1.8564, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.6758, device='cuda:0', dtype=torch.float16) tensor(0.1195, device='cuda:0', dtype=torch.float16)
tensor(1.5020, device='cuda:0', dtype=torch.float16) tensor(0.1231, device='cuda:0', dtype=torch.float16)
tensor(1.6494, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.6094, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(2.0586, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1698, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.2708, device='cuda:0')
old_score: tensor(0.1661, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1266, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.47570538520813
Validation after dual ascent:
out_inf: tensor(16.6094, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(1.4570, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.3857, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5., device='cuda:0', dtype=torch.float16) tensor(0.3425, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0099, device='cuda:0')
tensor(0.1862, device='cuda:0')
old_score: tensor(0.1093, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0879, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4696104526519775
Validation after dual ascent:
out_inf: tensor(5., device='cuda:0', dtype=torch.float16) tensor(0.3425, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(0.7642, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(0.6860, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.6016, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(0.8013, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0056, device='cuda:0')
tensor(0.0790, device='cuda:0')
old_score: tensor(0.0395, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0287, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7332642078399658
Validation after dual ascent:
out_inf: tensor(5.6016, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(0.6538, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.1172, device='cuda:0', dtype=torch.float16) tensor(0.4260, device='cuda:0', dtype=torch.float16)
tensor(1.4746, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.4580, device='cuda:0', dtype=torch.float16) tensor(0.0992, device='cuda:0', dtype=torch.float16)
tensor(1.4785, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0074, device='cuda:0')
tensor(0.0953, device='cuda:0')
old_score: tensor(0.0973, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0746, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.118507146835327
Validation after dual ascent:
out_inf: tensor(8.1172, device='cuda:0', dtype=torch.float16) tensor(0.4260, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(1.3799, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.4258, device='cuda:0', dtype=torch.float16) tensor(0.3174, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0067, device='cuda:0')
tensor(0.0934, device='cuda:0')
old_score: tensor(0.0934, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.116914749145508
Validation after dual ascent:
out_inf: tensor(5.4258, device='cuda:0', dtype=torch.float16) tensor(0.3174, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.0469, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(0.4897, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.5146, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0047, device='cuda:0')
tensor(0.0745, device='cuda:0')
old_score: tensor(0.0460, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0397, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.27733302116394
Validation after dual ascent:
out_inf: tensor(6.0469, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.4463, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.8750, device='cuda:0', dtype=torch.float16) tensor(0.7983, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1636, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1630, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1686, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1652, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0100, device='cuda:0')
tensor(0.0637, device='cuda:0')
old_score: tensor(0.1650, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.208202838897705
Validation after dual ascent:
out_inf: tensor(16.8750, device='cuda:0', dtype=torch.float16) tensor(0.7983, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.4014, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
tensor(1.2236, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.3125, device='cuda:0', dtype=torch.float16) tensor(1.0176, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.1682, device='cuda:0', dtype=torch.float16)
tensor(2.3438, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0117, device='cuda:0')
tensor(0.0631, device='cuda:0')
old_score: tensor(0.1697, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1259, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2097578048706055
Validation after dual ascent:
out_inf: tensor(17.3125, device='cuda:0', dtype=torch.float16) tensor(1.0176, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.3528, device='cuda:0', dtype=torch.float16)
tensor(0.8247, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.1110, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0183, device='cuda:0')
tensor(0.1985, device='cuda:0')
old_score: tensor(0.1121, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0878, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.471750020980835
Validation after dual ascent:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.3528, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
tensor(0.7437, device='cuda:0', dtype=torch.float16) tensor(0.0832, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(0.7466, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.0195, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.5073, device='cuda:0', dtype=torch.float16) tensor(0.0310, device='cuda:0', dtype=torch.float16)
tensor(0.7080, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.7290, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0106, device='cuda:0')
tensor(0.0558, device='cuda:0')
old_score: tensor(0.0318, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0234, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.730647087097168
Validation after dual ascent:
out_inf: tensor(6.0195, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.8164, device='cuda:0', dtype=torch.float16) tensor(0.4419, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0085, device='cuda:0')
tensor(0.1163, device='cuda:0')
old_score: tensor(0.1031, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0794, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.11924934387207
Validation after dual ascent:
out_inf: tensor(7.8164, device='cuda:0', dtype=torch.float16) tensor(0.4419, device='cuda:0', dtype=torch.float16)
tensor(1.1973, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.3176, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(0.8115, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0077, device='cuda:0')
tensor(0.1116, device='cuda:0')
old_score: tensor(0.0973, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0763, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115185022354126
Validation after dual ascent:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.3176, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.6079, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.6118, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.9492, device='cuda:0', dtype=torch.float16) tensor(0.1515, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.5400, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.4673, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.6167, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0049, device='cuda:0')
tensor(0.0788, device='cuda:0')
old_score: tensor(0.0465, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0403, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.282246589660645
Validation after dual ascent:
out_inf: tensor(4.9492, device='cuda:0', dtype=torch.float16) tensor(0.1515, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.4148, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.4048, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.5303, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.9766, device='cuda:0', dtype=torch.float16) tensor(0.8169, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1682, device='cuda:0', dtype=torch.float16)
tensor(1.8984, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1699, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0121, device='cuda:0')
tensor(0.0768, device='cuda:0')
old_score: tensor(0.1694, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1279, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.210991144180298
Validation after dual ascent:
out_inf: tensor(13.9766, device='cuda:0', dtype=torch.float16) tensor(0.8169, device='cuda:0', dtype=torch.float16)
tensor(1.2246, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(1.2227, device='cuda:0', dtype=torch.float16) tensor(0.1199, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.5723, device='cuda:0', dtype=torch.float16) tensor(0.1365, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.6250, device='cuda:0', dtype=torch.float16) tensor(0.9839, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(2.2422, device='cuda:0', dtype=torch.float16) tensor(0.1711, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0776, device='cuda:0')
old_score: tensor(0.1742, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1296, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.211860179901123
Validation after dual ascent:
out_inf: tensor(17.6250, device='cuda:0', dtype=torch.float16) tensor(0.9839, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
tensor(1.2803, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.4014, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.3716, device='cuda:0', dtype=torch.float16)
tensor(0.8779, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(0.9487, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(0.9160, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0065, device='cuda:0')
tensor(0.0696, device='cuda:0')
old_score: tensor(0.1224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0966, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.205127000808716
Validation after dual ascent:
out_inf: tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.3716, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0973, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(0.7607, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(0.8740, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.3164, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.9346, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0140, device='cuda:0')
tensor(0.0259, device='cuda:0')
old_score: tensor(0.0305, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0220, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9318478107452393
Validation after dual ascent:
out_inf: tensor(4.3164, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.7520, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.9688, device='cuda:0', dtype=torch.float16) tensor(0.4546, device='cuda:0', dtype=torch.float16)
tensor(1.7285, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1112, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0102, device='cuda:0')
tensor(0.1435, device='cuda:0')
old_score: tensor(0.1091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0831, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.116875410079956
Validation after dual ascent:
out_inf: tensor(8.9688, device='cuda:0', dtype=torch.float16) tensor(0.4546, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.1367, device='cuda:0', dtype=torch.float16) tensor(0.3230, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.1015, device='cuda:0', dtype=torch.float16)
tensor(0.8418, device='cuda:0', dtype=torch.float16) tensor(0.0995, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.1034, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0093, device='cuda:0')
tensor(0.1358, device='cuda:0')
old_score: tensor(0.1016, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0790, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.113851070404053
Validation after dual ascent:
out_inf: tensor(6.1367, device='cuda:0', dtype=torch.float16) tensor(0.3230, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.6226, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(0.7485, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.8633, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.5127, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0059, device='cuda:0')
tensor(0.0919, device='cuda:0')
old_score: tensor(0.0492, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0429, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.267594337463379
Validation after dual ascent:
out_inf: tensor(5.8633, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(0.4561, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.4448, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.0938, device='cuda:0', dtype=torch.float16) tensor(0.7803, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(1.6602, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1688, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.3225, device='cuda:0')
old_score: tensor(0.1646, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.474496841430664
Validation after dual ascent:
out_inf: tensor(13.0938, device='cuda:0', dtype=torch.float16) tensor(0.7803, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1244, device='cuda:0', dtype=torch.float16)
tensor(1.4043, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(1.3105, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.5781, device='cuda:0', dtype=torch.float16) tensor(1.0088, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(2.3672, device='cuda:0', dtype=torch.float16) tensor(0.1733, device='cuda:0', dtype=torch.float16)
tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0191, device='cuda:0')
tensor(0.3278, device='cuda:0')
old_score: tensor(0.1685, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1246, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.477370262145996
Validation after dual ascent:
out_inf: tensor(19.5781, device='cuda:0', dtype=torch.float16) tensor(1.0088, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.2822, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.3457, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1335, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.1758, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(0.9390, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0129, device='cuda:0')
tensor(0.2467, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0956, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4737026691436768
Validation after dual ascent:
out_inf: tensor(4.1758, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(0.9136, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.7817, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(0.7905, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(0.9897, device='cuda:0', dtype=torch.float16) tensor(0.1024, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.9961, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0088, device='cuda:0')
tensor(0.0547, device='cuda:0')
old_score: tensor(0.0312, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0233, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7291996479034424
Validation after dual ascent:
out_inf: tensor(5.9961, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.8740, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.0938, device='cuda:0', dtype=torch.float16) tensor(0.4470, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1103, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.6143, device='cuda:0', dtype=torch.float16) tensor(0.1126, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0113, device='cuda:0')
tensor(0.1634, device='cuda:0')
old_score: tensor(0.1124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0859, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.114161729812622
Validation after dual ascent:
out_inf: tensor(8.0938, device='cuda:0', dtype=torch.float16) tensor(0.4470, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(1.1064, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.8828, device='cuda:0', dtype=torch.float16) tensor(0.3315, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.1051, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0103, device='cuda:0')
tensor(0.1537, device='cuda:0')
old_score: tensor(0.1046, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0813, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.121255874633789
Validation after dual ascent:
out_inf: tensor(7.8828, device='cuda:0', dtype=torch.float16) tensor(0.3315, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.6602, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(0.5928, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.5737, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0063, device='cuda:0')
tensor(0.0990, device='cuda:0')
old_score: tensor(0.0510, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0444, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.253828525543213
Validation after dual ascent:
out_inf: tensor(5.6602, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.3931, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.4609, device='cuda:0', dtype=torch.float16) tensor(0.8032, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.1709, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1661, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0080, device='cuda:0')
tensor(0.0639, device='cuda:0')
old_score: tensor(0.1666, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.20984148979187
Validation after dual ascent:
out_inf: tensor(15.4609, device='cuda:0', dtype=torch.float16) tensor(0.8032, device='cuda:0', dtype=torch.float16)
tensor(1.2949, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1233, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.5625, device='cuda:0', dtype=torch.float16) tensor(1.0146, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1697, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1744, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0616, device='cuda:0')
old_score: tensor(0.1705, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1252, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2132699489593506
Validation after dual ascent:
out_inf: tensor(17.5625, device='cuda:0', dtype=torch.float16) tensor(1.0146, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.1332, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.3740, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(0.9326, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(0.9756, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2548, device='cuda:0')
old_score: tensor(0.1252, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0973, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470425605773926
Validation after dual ascent:
out_inf: tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.3740, device='cuda:0', dtype=torch.float16)
tensor(0.8882, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(0.8574, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.7031, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(0.7891, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0052, device='cuda:0')
tensor(0.0745, device='cuda:0')
old_score: tensor(0.0390, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0284, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7352542877197266
Validation after dual ascent:
out_inf: tensor(11.7031, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
tensor(0.7075, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.0312, device='cuda:0', dtype=torch.float16) tensor(0.4629, device='cuda:0', dtype=torch.float16)
tensor(1.9727, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1137, device='cuda:0', dtype=torch.float16)
tensor(1.6338, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.1161, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0123, device='cuda:0')
tensor(0.1765, device='cuda:0')
old_score: tensor(0.1162, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0869, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.11625337600708
Validation after dual ascent:
out_inf: tensor(11.0312, device='cuda:0', dtype=torch.float16) tensor(0.4629, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0923, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.3406, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0111, device='cuda:0')
tensor(0.1647, device='cuda:0')
old_score: tensor(0.1071, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0815, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.117767810821533
Validation after dual ascent:
out_inf: tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.3406, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0827, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.7612, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.down_proj
Validation after prune:
out_inf: tensor(7.1250, device='cuda:0', dtype=torch.float16) tensor(0.1860, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0073, device='cuda:0')
tensor(0.1132, device='cuda:0')
old_score: tensor(0.0536, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0464, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.215677738189697
Validation after dual ascent:
out_inf: tensor(7.1250, device='cuda:0', dtype=torch.float16) tensor(0.1860, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(0.7832, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.1670, device='cuda:0', dtype=torch.float16)
tensor(1.6855, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(1.7617, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0065, device='cuda:0')
tensor(0.0659, device='cuda:0')
old_score: tensor(0.1678, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2050082683563232
Validation after dual ascent:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(0.7832, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(1.3770, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
tensor(1.4717, device='cuda:0', dtype=torch.float16) tensor(0.1310, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9722, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1659, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1748, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0080, device='cuda:0')
tensor(0.0642, device='cuda:0')
old_score: tensor(0.1692, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.209077835083008
Validation after dual ascent:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9722, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.3916, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.4922, device='cuda:0', dtype=torch.float16) tensor(0.3914, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0150, device='cuda:0')
tensor(0.2955, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1029, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470435857772827
Validation after dual ascent:
out_inf: tensor(5.4922, device='cuda:0', dtype=torch.float16) tensor(0.3914, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(0.9111, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(0.9189, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.0303, device='cuda:0', dtype=torch.float16) tensor(0.1091, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.o_proj
Validation after prune:
out_inf: tensor(9.7578, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.7002, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.7012, device='cuda:0', dtype=torch.float16) tensor(0.0310, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0096, device='cuda:0')
tensor(0.0650, device='cuda:0')
old_score: tensor(0.0332, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0249, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7270598411560059
Validation after dual ascent:
out_inf: tensor(9.7578, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.7295, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.6704, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.4297, device='cuda:0', dtype=torch.float16) tensor(0.4578, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(1.7334, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.4736, device='cuda:0', dtype=torch.float16) tensor(0.1184, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0134, device='cuda:0')
tensor(0.1970, device='cuda:0')
old_score: tensor(0.1185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0896, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.11069393157959
Validation after dual ascent:
out_inf: tensor(9.4297, device='cuda:0', dtype=torch.float16) tensor(0.4578, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(1.7480, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.0907, device='cuda:0', dtype=torch.float16)
tensor(1.6904, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.8906, device='cuda:0', dtype=torch.float16) tensor(0.3374, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(0.9414, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.1819, device='cuda:0')
old_score: tensor(0.1085, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0833, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.112946271896362
Validation after dual ascent:
out_inf: tensor(6.8906, device='cuda:0', dtype=torch.float16) tensor(0.3374, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.7358, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.8037, device='cuda:0', dtype=torch.float16) tensor(0.0843, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.3633, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0070, device='cuda:0')
tensor(0.1100, device='cuda:0')
old_score: tensor(0.0522, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0457, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.244794607162476
Validation after dual ascent:
out_inf: tensor(4.3633, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.4836, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.6475, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.5312, device='cuda:0', dtype=torch.float16) tensor(0.8374, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1698, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1724, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0115, device='cuda:0')
tensor(0.0814, device='cuda:0')
old_score: tensor(0.1738, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1284, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2032575607299805
Validation after dual ascent:
out_inf: tensor(18.5312, device='cuda:0', dtype=torch.float16) tensor(0.8374, device='cuda:0', dtype=torch.float16)
tensor(1.3115, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.0156, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1750, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1719, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.1831, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.1753, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0134, device='cuda:0')
tensor(0.0832, device='cuda:0')
old_score: tensor(0.1764, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1292, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.209237813949585
Validation after dual ascent:
out_inf: tensor(20.0156, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(1.2900, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.4219, device='cuda:0', dtype=torch.float16) tensor(0.4133, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
tensor(1.1826, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0062, device='cuda:0')
tensor(0.0771, device='cuda:0')
old_score: tensor(0.1361, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1045, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2032508850097656
Validation after dual ascent:
out_inf: tensor(7.4219, device='cuda:0', dtype=torch.float16) tensor(0.4133, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(0.8872, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.9312, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(0.9756, device='cuda:0', dtype=torch.float16) tensor(0.1103, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.7500, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0071, device='cuda:0')
tensor(0.0109, device='cuda:0')
old_score: tensor(0.0323, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.465583562850952
Validation after dual ascent:
out_inf: tensor(11.7500, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.7500, device='cuda:0', dtype=torch.float16) tensor(0.4585, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1209, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1180, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1239, device='cuda:0', dtype=torch.float16)
tensor(1.9824, device='cuda:0', dtype=torch.float16) tensor(0.1206, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0139, device='cuda:0')
tensor(0.2056, device='cuda:0')
old_score: tensor(0.1208, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0903, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.111895322799683
Validation after dual ascent:
out_inf: tensor(10.7500, device='cuda:0', dtype=torch.float16) tensor(0.4585, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0832, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(1.3311, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.2891, device='cuda:0', dtype=torch.float16) tensor(0.3438, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0125, device='cuda:0')
tensor(0.1884, device='cuda:0')
old_score: tensor(0.1099, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0835, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.113560676574707
Validation after dual ascent:
out_inf: tensor(6.2891, device='cuda:0', dtype=torch.float16) tensor(0.3438, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(0.7476, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.1942, device='cuda:0', dtype=torch.float16)
tensor(0.6069, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0079, device='cuda:0')
tensor(0.1232, device='cuda:0')
old_score: tensor(0.0548, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0477, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.257230043411255
Validation after dual ascent:
out_inf: tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.1942, device='cuda:0', dtype=torch.float16)
tensor(0.6128, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.5737, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.4888, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.6084, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1777, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(1.9766, device='cuda:0', dtype=torch.float16) tensor(0.1835, device='cuda:0', dtype=torch.float16)
tensor(1.9180, device='cuda:0', dtype=torch.float16) tensor(0.1758, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0074, device='cuda:0')
tensor(0.0787, device='cuda:0')
old_score: tensor(0.1776, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1321, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.206528663635254
Validation after dual ascent:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.4434, device='cuda:0', dtype=torch.float16) tensor(0.1334, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.3428, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.5410, device='cuda:0', dtype=torch.float16) tensor(0.1378, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.8438, device='cuda:0', dtype=torch.float16) tensor(0.9473, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1794, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1855, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1780, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0783, device='cuda:0')
old_score: tensor(0.1797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1326, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2104427814483643
Validation after dual ascent:
out_inf: tensor(18.8438, device='cuda:0', dtype=torch.float16) tensor(0.9473, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
tensor(1.6689, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.7148, device='cuda:0', dtype=torch.float16) tensor(0.4414, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(1.3799, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.1650, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.3587, device='cuda:0')
old_score: tensor(0.1475, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4732251167297363
Validation after dual ascent:
out_inf: tensor(5.7148, device='cuda:0', dtype=torch.float16) tensor(0.4414, device='cuda:0', dtype=torch.float16)
tensor(1.0674, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(0.9663, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.o_proj
Validation after prune:
out_inf: tensor(17.4688, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.8989, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0183, device='cuda:0')
tensor(0.0639, device='cuda:0')
old_score: tensor(0.0309, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0233, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7299413681030273
Validation after dual ascent:
out_inf: tensor(17.4688, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.4976, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.2344, device='cuda:0', dtype=torch.float16) tensor(0.4558, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1228, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1199, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0148, device='cuda:0')
tensor(0.2238, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0923, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.109499931335449
Validation after dual ascent:
out_inf: tensor(10.2344, device='cuda:0', dtype=torch.float16) tensor(0.4558, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(1.2432, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.4570, device='cuda:0', dtype=torch.float16) tensor(0.0960, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.1172, device='cuda:0', dtype=torch.float16) tensor(0.3433, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0134, device='cuda:0')
tensor(0.2061, device='cuda:0')
old_score: tensor(0.1122, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0856, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115655422210693
Validation after dual ascent:
out_inf: tensor(7.1172, device='cuda:0', dtype=torch.float16) tensor(0.3433, device='cuda:0', dtype=torch.float16)
tensor(0.8159, device='cuda:0', dtype=torch.float16) tensor(0.0866, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(0.7954, device='cuda:0', dtype=torch.float16) tensor(0.0882, device='cuda:0', dtype=torch.float16)
tensor(0.8472, device='cuda:0', dtype=torch.float16) tensor(0.0890, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.8379, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(0.6709, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.5811, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.5981, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0081, device='cuda:0')
tensor(0.1269, device='cuda:0')
old_score: tensor(0.0546, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0481, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.279893398284912
Validation after dual ascent:
out_inf: tensor(3.8379, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.5166, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.5708, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.8984, device='cuda:0', dtype=torch.float16) tensor(0.7778, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1675, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1742, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0079, device='cuda:0')
tensor(0.0746, device='cuda:0')
old_score: tensor(0.1678, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1248, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.205883502960205
Validation after dual ascent:
out_inf: tensor(15.8984, device='cuda:0', dtype=torch.float16) tensor(0.7778, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.4346, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1250, device='cuda:0', dtype=torch.float16) tensor(0.9795, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1686, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1748, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0105, device='cuda:0')
tensor(0.0750, device='cuda:0')
old_score: tensor(0.1686, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1245, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.207859992980957
Validation after dual ascent:
out_inf: tensor(17.1250, device='cuda:0', dtype=torch.float16) tensor(0.9795, device='cuda:0', dtype=torch.float16)
tensor(1.4355, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.5488, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.4551, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.6055, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.3555, device='cuda:0', dtype=torch.float16) tensor(0.4246, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
tensor(1.2607, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
tensor(1.1045, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.3359, device='cuda:0')
old_score: tensor(0.1436, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.46921706199646
Validation after dual ascent:
out_inf: tensor(6.3555, device='cuda:0', dtype=torch.float16) tensor(0.4246, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(1.0068, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(1.1631, device='cuda:0', dtype=torch.float16) tensor(0.1142, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.o_proj
Validation after prune:
out_inf: tensor(14.0234, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0124, device='cuda:0')
tensor(0.0293, device='cuda:0')
old_score: tensor(0.0339, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0252, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.667715549468994
Validation after dual ascent:
out_inf: tensor(14.0234, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(0.6958, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.7422, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.1225, device='cuda:0', dtype=torch.float16)
tensor(1.7070, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.2388, device='cuda:0')
old_score: tensor(0.1250, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0941, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115964412689209
Validation after dual ascent:
out_inf: tensor(11.7422, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(1.1748, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.4102, device='cuda:0', dtype=torch.float16) tensor(0.3496, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1153, device='cuda:0', dtype=torch.float16)
tensor(0.9502, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.2203, device='cuda:0')
old_score: tensor(0.1146, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0875, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.116190671920776
Validation after dual ascent:
out_inf: tensor(7.4102, device='cuda:0', dtype=torch.float16) tensor(0.3496, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.8979, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.8438, device='cuda:0', dtype=torch.float16) tensor(0.1978, device='cuda:0', dtype=torch.float16)
tensor(0.6553, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.7222, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0085, device='cuda:0')
tensor(0.1348, device='cuda:0')
old_score: tensor(0.0560, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0495, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.237287282943726
Validation after dual ascent:
out_inf: tensor(4.8438, device='cuda:0', dtype=torch.float16) tensor(0.1978, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.6157, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.5967, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.q_proj
Validation after prune:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(1.8770, device='cuda:0', dtype=torch.float16) tensor(0.1819, device='cuda:0', dtype=torch.float16)
tensor(1.6963, device='cuda:0', dtype=torch.float16) tensor(0.1776, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1885, device='cuda:0', dtype=torch.float16)
tensor(1.7617, device='cuda:0', dtype=torch.float16) tensor(0.1796, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0073, device='cuda:0')
tensor(0.0905, device='cuda:0')
old_score: tensor(0.1819, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1357, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2091574668884277
Validation after dual ascent:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
tensor(1.4180, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.1406, device='cuda:0', dtype=torch.float16)
tensor(1.6572, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(0.9268, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.1835, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1785, device='cuda:0', dtype=torch.float16)
tensor(2.2422, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1798, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0086, device='cuda:0')
tensor(0.0902, device='cuda:0')
old_score: tensor(0.1830, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1360, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.21357798576355
Validation after dual ascent:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(0.9268, device='cuda:0', dtype=torch.float16)
tensor(1.4053, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(1.5957, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(1.5029, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.3984, device='cuda:0', dtype=torch.float16) tensor(0.4639, device='cuda:0', dtype=torch.float16)
tensor(1.4297, device='cuda:0', dtype=torch.float16) tensor(0.1595, device='cuda:0', dtype=torch.float16)
tensor(1.1904, device='cuda:0', dtype=torch.float16) tensor(0.1566, device='cuda:0', dtype=torch.float16)
tensor(1.2871, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(1.2803, device='cuda:0', dtype=torch.float16) tensor(0.1570, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0190, device='cuda:0')
tensor(0.4185, device='cuda:0')
old_score: tensor(0.1594, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1223, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4750521183013916
Validation after dual ascent:
out_inf: tensor(5.3984, device='cuda:0', dtype=torch.float16) tensor(0.4639, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(1.1182, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.2373, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.7881, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0134, device='cuda:0')
tensor(0.0227, device='cuda:0')
old_score: tensor(0.0282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0199, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.865762233734131
Validation after dual ascent:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(0.5674, device='cuda:0', dtype=torch.float16) tensor(0.0163, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.7500, device='cuda:0', dtype=torch.float16) tensor(0.4858, device='cuda:0', dtype=torch.float16)
tensor(1.7793, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0175, device='cuda:0')
tensor(0.2749, device='cuda:0')
old_score: tensor(0.1295, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0974, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1189000606536865
Validation after dual ascent:
out_inf: tensor(9.7500, device='cuda:0', dtype=torch.float16) tensor(0.4858, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(1.2236, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(1.2168, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.up_proj
Validation after prune:
out_inf: tensor(8.6016, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1178, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.2539, device='cuda:0')
old_score: tensor(0.1189, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0908, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.135939598083496
Validation after dual ascent:
out_inf: tensor(8.6016, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
tensor(0.8813, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0940, device='cuda:0', dtype=torch.float16)
tensor(0.8896, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.2089, device='cuda:0', dtype=torch.float16)
tensor(0.7314, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.6870, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.7197, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0096, device='cuda:0')
tensor(0.1501, device='cuda:0')
old_score: tensor(0.0582, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0515, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.19966983795166
Validation after dual ascent:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.2089, device='cuda:0', dtype=torch.float16)
tensor(0.6729, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.6323, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.5571, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.6948, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.2812, device='cuda:0', dtype=torch.float16) tensor(0.8257, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1849, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1761, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0074, device='cuda:0')
tensor(0.0859, device='cuda:0')
old_score: tensor(0.1797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1323, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.208662509918213
Validation after dual ascent:
out_inf: tensor(14.2812, device='cuda:0', dtype=torch.float16) tensor(0.8257, device='cuda:0', dtype=torch.float16)
tensor(1.4795, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.5088, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.1562, device='cuda:0', dtype=torch.float16) tensor(1.0078, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1816, device='cuda:0', dtype=torch.float16)
tensor(2.1289, device='cuda:0', dtype=torch.float16) tensor(0.1812, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.1886, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1782, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0856, device='cuda:0')
old_score: tensor(0.1824, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1328, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.211822509765625
Validation after dual ascent:
out_inf: tensor(18.1562, device='cuda:0', dtype=torch.float16) tensor(1.0078, device='cuda:0', dtype=torch.float16)
tensor(1.4727, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
tensor(1.4229, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
tensor(1.5293, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4661, device='cuda:0', dtype=torch.float16)
tensor(1.3721, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.1594, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1641, device='cuda:0', dtype=torch.float16)
tensor(1.4785, device='cuda:0', dtype=torch.float16) tensor(0.1575, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.4085, device='cuda:0')
old_score: tensor(0.1602, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1227, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.472679615020752
Validation after dual ascent:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4661, device='cuda:0', dtype=torch.float16)
tensor(1.2871, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.1299, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.o_proj
Validation after prune:
out_inf: tensor(21.7344, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0194, device='cuda:0')
tensor(0.0387, device='cuda:0')
old_score: tensor(0.0349, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0258, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.26819634437561
Validation after dual ascent:
out_inf: tensor(21.7344, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(0.8994, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.0234, device='cuda:0', dtype=torch.float16) tensor(0.5088, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1312, device='cuda:0', dtype=torch.float16)
tensor(1.8008, device='cuda:0', dtype=torch.float16) tensor(0.1360, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0185, device='cuda:0')
tensor(0.2934, device='cuda:0')
old_score: tensor(0.1328, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0990, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.126916885375977
Validation after dual ascent:
out_inf: tensor(9.0234, device='cuda:0', dtype=torch.float16) tensor(0.5088, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(1.2275, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.up_proj
Validation after prune:
out_inf: tensor(8.2578, device='cuda:0', dtype=torch.float16) tensor(0.3833, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2711, device='cuda:0')
old_score: tensor(0.1223, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0925, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.130785703659058
Validation after dual ascent:
out_inf: tensor(8.2578, device='cuda:0', dtype=torch.float16) tensor(0.3833, device='cuda:0', dtype=torch.float16)
tensor(0.9126, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(1.0127, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(0.9028, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(0.9780, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.3398, device='cuda:0', dtype=torch.float16) tensor(0.2195, device='cuda:0', dtype=torch.float16)
tensor(0.6338, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.6465, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.7466, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0110, device='cuda:0')
tensor(0.1693, device='cuda:0')
old_score: tensor(0.0611, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0537, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.197854042053223
Validation after dual ascent:
out_inf: tensor(5.3398, device='cuda:0', dtype=torch.float16) tensor(0.2195, device='cuda:0', dtype=torch.float16)
tensor(0.6279, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.6323, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.7373, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1953, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(2.5547, device='cuda:0', dtype=torch.float16) tensor(0.1918, device='cuda:0', dtype=torch.float16)
tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
tensor(2.5000, device='cuda:0', dtype=torch.float16) tensor(0.1976, device='cuda:0', dtype=torch.float16)
tensor(2.4922, device='cuda:0', dtype=torch.float16) tensor(0.1871, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0843, device='cuda:0')
old_score: tensor(0.1910, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1383, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2079193592071533
Validation after dual ascent:
out_inf: tensor(15.1953, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
tensor(1.5098, device='cuda:0', dtype=torch.float16) tensor(0.1420, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.5000, device='cuda:0', dtype=torch.float16) tensor(0.9604, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.1964, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1925, device='cuda:0', dtype=torch.float16)
tensor(3.2734, device='cuda:0', dtype=torch.float16) tensor(0.2041, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.1923, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0112, device='cuda:0')
tensor(0.0860, device='cuda:0')
old_score: tensor(0.1963, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1396, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.211113214492798
Validation after dual ascent:
out_inf: tensor(18.5000, device='cuda:0', dtype=torch.float16) tensor(0.9604, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(1.5566, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.v_proj
Validation after prune:
out_inf: tensor(10.0469, device='cuda:0', dtype=torch.float16) tensor(0.4722, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1609, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1663, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1587, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0048, device='cuda:0')
tensor(0.0789, device='cuda:0')
old_score: tensor(0.1614, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1228, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2072975635528564
Validation after dual ascent:
out_inf: tensor(10.0469, device='cuda:0', dtype=torch.float16) tensor(0.4722, device='cuda:0', dtype=torch.float16)
tensor(1.2529, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.5195, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(1.0752, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0073, device='cuda:0')
tensor(0.0132, device='cuda:0')
old_score: tensor(0.0227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0172, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.200731039047241
Validation after dual ascent:
out_inf: tensor(5.5195, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(1.0850, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.8438, device='cuda:0', dtype=torch.float16) tensor(0.5366, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.9727, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(1.8320, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0051, device='cuda:0')
tensor(0.0370, device='cuda:0')
old_score: tensor(0.1375, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.058115243911743
Validation after dual ascent:
out_inf: tensor(10.8438, device='cuda:0', dtype=torch.float16) tensor(0.5366, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.1797, device='cuda:0', dtype=torch.float16) tensor(0.4080, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1265, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0184, device='cuda:0')
tensor(0.3036, device='cuda:0')
old_score: tensor(0.1274, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0951, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.128166437149048
Validation after dual ascent:
out_inf: tensor(7.1797, device='cuda:0', dtype=torch.float16) tensor(0.4080, device='cuda:0', dtype=torch.float16)
tensor(1.0713, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0977, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.2427, device='cuda:0', dtype=torch.float16)
tensor(0.7046, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(0.6470, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.8325, device='cuda:0', dtype=torch.float16) tensor(0.0675, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0130, device='cuda:0')
tensor(0.1984, device='cuda:0')
old_score: tensor(0.0653, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0569, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.133936405181885
Validation after dual ascent:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.2427, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.7861, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.7017, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.3828, device='cuda:0', dtype=torch.float16) tensor(0.8398, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.1931, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1914, device='cuda:0', dtype=torch.float16)
tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1987, device='cuda:0', dtype=torch.float16)
tensor(2.8438, device='cuda:0', dtype=torch.float16) tensor(0.1887, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0159, device='cuda:0')
tensor(0.0725, device='cuda:0')
old_score: tensor(0.1929, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1372, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.778838634490967
Validation after dual ascent:
out_inf: tensor(14.3828, device='cuda:0', dtype=torch.float16) tensor(0.8398, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.5361, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.8594, device='cuda:0', dtype=torch.float16) tensor(0.9941, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.1978, device='cuda:0', dtype=torch.float16)
tensor(3.2422, device='cuda:0', dtype=torch.float16) tensor(0.1957, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0169, device='cuda:0')
tensor(0.0771, device='cuda:0')
old_score: tensor(0.1981, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1385, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.80337405204773
Validation after dual ascent:
out_inf: tensor(20.8594, device='cuda:0', dtype=torch.float16) tensor(0.9941, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.1133, device='cuda:0', dtype=torch.float16) tensor(0.5107, device='cuda:0', dtype=torch.float16)
tensor(1.5029, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1716, device='cuda:0', dtype=torch.float16)
tensor(1.4502, device='cuda:0', dtype=torch.float16) tensor(0.1763, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0188, device='cuda:0')
tensor(0.1177, device='cuda:0')
old_score: tensor(0.1719, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1298, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.217801332473755
Validation after dual ascent:
out_inf: tensor(7.1133, device='cuda:0', dtype=torch.float16) tensor(0.5107, device='cuda:0', dtype=torch.float16)
tensor(1.5137, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.1206, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.o_proj
Validation after prune:
out_inf: tensor(9.1250, device='cuda:0', dtype=torch.float16) tensor(0.1389, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0093, device='cuda:0')
tensor(0.0234, device='cuda:0')
old_score: tensor(0.0343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0222, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.550702333450317
Validation after dual ascent:
out_inf: tensor(9.1250, device='cuda:0', dtype=torch.float16) tensor(0.1389, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.7969, device='cuda:0', dtype=torch.float16) tensor(0.5630, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0054, device='cuda:0')
tensor(0.0447, device='cuda:0')
old_score: tensor(0.1417, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.073003768920898
Validation after dual ascent:
out_inf: tensor(11.7969, device='cuda:0', dtype=torch.float16) tensor(0.5630, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1048, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1063, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.up_proj
Validation after prune:
out_inf: tensor(12.3828, device='cuda:0', dtype=torch.float16) tensor(0.4485, device='cuda:0', dtype=torch.float16)
tensor(2.0820, device='cuda:0', dtype=torch.float16) tensor(0.1335, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(2.4180, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1321, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0043, device='cuda:0')
tensor(0.0422, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0988, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.0810227394104
Validation after dual ascent:
out_inf: tensor(12.3828, device='cuda:0', dtype=torch.float16) tensor(0.4485, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0913, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.down_proj
Validation after prune:
out_inf: tensor(8.6094, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(0.8608, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.7354, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0170, device='cuda:0')
tensor(0.2569, device='cuda:0')
old_score: tensor(0.0734, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0634, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.113593101501465
Validation after dual ascent:
out_inf: tensor(8.6094, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.7676, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0639, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.9531, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1808, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.1824, device='cuda:0', dtype=torch.float16)
tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1902, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.1786, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0073, device='cuda:0')
tensor(0.0381, device='cuda:0')
old_score: tensor(0.1831, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1283, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.418415784835815
Validation after dual ascent:
out_inf: tensor(12.9531, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
tensor(1.6279, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.2188, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(2.9453, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
tensor(2.4453, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.1836, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0187, device='cuda:0')
tensor(0.0783, device='cuda:0')
old_score: tensor(0.1885, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1292, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2127864360809326
Validation after dual ascent:
out_inf: tensor(20.2188, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.5049, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.4844, device='cuda:0', dtype=torch.float16)
tensor(1.4658, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1740, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1652, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0194, device='cuda:0')
tensor(0.4090, device='cuda:0')
old_score: tensor(0.1686, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1261, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4748549461364746
Validation after dual ascent:
out_inf: tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.4844, device='cuda:0', dtype=torch.float16)
tensor(1.5410, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(1.2744, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.o_proj
Validation after prune:
out_inf: tensor(17.3281, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0311, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.0118, device='cuda:0')
old_score: tensor(0.0376, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0263, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4698736667633057
Validation after dual ascent:
out_inf: tensor(17.3281, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(0.7593, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.gate_proj
Validation after prune:
out_inf: tensor(12.1875, device='cuda:0', dtype=torch.float16) tensor(0.5771, device='cuda:0', dtype=torch.float16)
tensor(2.7891, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(2.8203, device='cuda:0', dtype=torch.float16) tensor(0.1476, device='cuda:0', dtype=torch.float16)
tensor(3.2617, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0060, device='cuda:0')
tensor(0.0479, device='cuda:0')
old_score: tensor(0.1442, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1047, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.067370414733887
Validation after dual ascent:
out_inf: tensor(12.1875, device='cuda:0', dtype=torch.float16) tensor(0.5771, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(2.4258, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.up_proj
Validation after prune:
out_inf: tensor(9.5000, device='cuda:0', dtype=torch.float16) tensor(0.4985, device='cuda:0', dtype=torch.float16)
tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0055, device='cuda:0')
tensor(0.0457, device='cuda:0')
old_score: tensor(0.1396, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.069949626922607
Validation after dual ascent:
out_inf: tensor(9.5000, device='cuda:0', dtype=torch.float16) tensor(0.4985, device='cuda:0', dtype=torch.float16)
tensor(3.2109, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(2.6074, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(3.1680, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.down_proj
Validation after prune:
out_inf: tensor(22.2812, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(0.9556, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(1.0127, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(0.8721, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.9697, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0029, device='cuda:0')
tensor(0.0312, device='cuda:0')
old_score: tensor(0.0811, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0688, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.86729121208191
Validation after dual ascent:
out_inf: tensor(22.2812, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(0.9722, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.9546, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.8271, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.8467, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.8438, device='cuda:0', dtype=torch.float16)
tensor(2.6211, device='cuda:0', dtype=torch.float16) tensor(0.1946, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.1948, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.2004, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.1921, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0131, device='cuda:0')
tensor(0.0596, device='cuda:0')
old_score: tensor(0.1956, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1333, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.774660348892212
Validation after dual ascent:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.8438, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1343, device='cuda:0', dtype=torch.float16)
tensor(1.6689, device='cuda:0', dtype=torch.float16) tensor(0.1239, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.5938, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(3.2344, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(2.6797, device='cuda:0', dtype=torch.float16) tensor(0.2007, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.2080, device='cuda:0', dtype=torch.float16)
tensor(3.0859, device='cuda:0', dtype=torch.float16) tensor(0.1992, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0131, device='cuda:0')
tensor(0.0592, device='cuda:0')
old_score: tensor(0.2025, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1353, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.794492959976196
Validation after dual ascent:
out_inf: tensor(18.5938, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(1.6787, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
tensor(1.4971, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.v_proj
Validation after prune:
out_inf: tensor(9.5625, device='cuda:0', dtype=torch.float16) tensor(0.5439, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1787, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.1810, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.1854, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1779, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0152, device='cuda:0')
tensor(0.1022, device='cuda:0')
old_score: tensor(0.1808, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1322, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.214103937149048
Validation after dual ascent:
out_inf: tensor(9.5625, device='cuda:0', dtype=torch.float16) tensor(0.5439, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1228, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.o_proj
Validation after prune:
out_inf: tensor(19.3438, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0085, device='cuda:0')
tensor(0.0162, device='cuda:0')
old_score: tensor(0.0284, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0201, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.204361915588379
Validation after dual ascent:
out_inf: tensor(19.3438, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(0.9033, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(1.1758, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.gate_proj
Validation after prune:
out_inf: tensor(33.5625, device='cuda:0', dtype=torch.float16) tensor(0.6353, device='cuda:0', dtype=torch.float16)
tensor(17.1875, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(13.4219, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
tensor(14.4375, device='cuda:0', dtype=torch.float16) tensor(0.1541, device='cuda:0', dtype=torch.float16)
tensor(13.5625, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0086, device='cuda:0')
tensor(0.0471, device='cuda:0')
old_score: tensor(0.1508, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1049, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.078585624694824
Validation after dual ascent:
out_inf: tensor(33.5625, device='cuda:0', dtype=torch.float16) tensor(0.6353, device='cuda:0', dtype=torch.float16)
tensor(9.1094, device='cuda:0', dtype=torch.float16) tensor(0.1059, device='cuda:0', dtype=torch.float16)
tensor(7.6562, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(7.4062, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(7.5938, device='cuda:0', dtype=torch.float16) tensor(0.1072, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.up_proj
Validation after prune:
out_inf: tensor(34.0938, device='cuda:0', dtype=torch.float16) tensor(0.5845, device='cuda:0', dtype=torch.float16)
tensor(16.4375, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(14.7031, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(17.6875, device='cuda:0', dtype=torch.float16) tensor(0.1501, device='cuda:0', dtype=torch.float16)
tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0084, device='cuda:0')
tensor(0.0448, device='cuda:0')
old_score: tensor(0.1467, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.088147640228271
Validation after dual ascent:
out_inf: tensor(34.0938, device='cuda:0', dtype=torch.float16) tensor(0.5845, device='cuda:0', dtype=torch.float16)
tensor(7.7188, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(9.0625, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(9.3438, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(10.8906, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.down_proj
Validation after prune:
out_inf: tensor(1407., device='cuda:0', dtype=torch.float16) tensor(0.5200, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0893, device='cuda:0', dtype=torch.float16)
tensor(1.0928, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(1.2744, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0133, device='cuda:0')
tensor(0.0527, device='cuda:0')
old_score: tensor(0.0906, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0743, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.79339861869812
Validation after dual ascent:
out_inf: tensor(1407., device='cuda:0', dtype=torch.float16) tensor(0.5200, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.4922, device='cuda:0', dtype=torch.float16) tensor(0.8408, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.1775, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.1798, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.1849, device='cuda:0', dtype=torch.float16)
tensor(3.1094, device='cuda:0', dtype=torch.float16) tensor(0.1781, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2382, device='cuda:0')
old_score: tensor(0.1802, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1091, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.472757577896118
Validation after dual ascent:
out_inf: tensor(13.4922, device='cuda:0', dtype=torch.float16) tensor(0.8408, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1012, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.1106, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.k_proj
Validation after prune:
out_inf: tensor(24.2812, device='cuda:0', dtype=torch.float16) tensor(1.0664, device='cuda:0', dtype=torch.float16)
tensor(3.3438, device='cuda:0', dtype=torch.float16) tensor(0.1912, device='cuda:0', dtype=torch.float16)
tensor(3.2656, device='cuda:0', dtype=torch.float16) tensor(0.1915, device='cuda:0', dtype=torch.float16)
tensor(3.3906, device='cuda:0', dtype=torch.float16) tensor(0.1981, device='cuda:0', dtype=torch.float16)
tensor(3.6328, device='cuda:0', dtype=torch.float16) tensor(0.1923, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.2487, device='cuda:0')
old_score: tensor(0.1934, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1122, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4763052463531494
Validation after dual ascent:
out_inf: tensor(24.2812, device='cuda:0', dtype=torch.float16) tensor(1.0664, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.6953, device='cuda:0', dtype=torch.float16) tensor(0.4180, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
tensor(1.1768, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(1.2842, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0124, device='cuda:0')
tensor(0.2069, device='cuda:0')
old_score: tensor(0.1387, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0968, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.472566604614258
Validation after dual ascent:
out_inf: tensor(6.6953, device='cuda:0', dtype=torch.float16) tensor(0.4180, device='cuda:0', dtype=torch.float16)
tensor(0.9619, device='cuda:0', dtype=torch.float16) tensor(0.0977, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
tensor(1.0205, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.o_proj
Validation after prune:
out_inf: tensor(129.6250, device='cuda:0', dtype=torch.float16) tensor(0.2457, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0419, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0110, device='cuda:0')
tensor(0.1127, device='cuda:0')
old_score: tensor(0.0441, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0277, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7295281887054443
Validation after dual ascent:
out_inf: tensor(129.6250, device='cuda:0', dtype=torch.float16) tensor(0.2457, device='cuda:0', dtype=torch.float16)
tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0280, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0286, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.gate_proj
Validation after prune:
out_inf: tensor(29.9375, device='cuda:0', dtype=torch.float16) tensor(0.6763, device='cuda:0', dtype=torch.float16)
tensor(6.0781, device='cuda:0', dtype=torch.float16) tensor(0.1550, device='cuda:0', dtype=torch.float16)
tensor(5.7578, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.1580, device='cuda:0', dtype=torch.float16)
tensor(5.9688, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0199, device='cuda:0')
tensor(0.2271, device='cuda:0')
old_score: tensor(0.1567, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0953, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.141645669937134
Validation after dual ascent:
out_inf: tensor(29.9375, device='cuda:0', dtype=torch.float16) tensor(0.6763, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(2.1602, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.up_proj
Validation after prune:
out_inf: tensor(33.4375, device='cuda:0', dtype=torch.float16) tensor(0.6929, device='cuda:0', dtype=torch.float16)
tensor(9.4531, device='cuda:0', dtype=torch.float16) tensor(0.1505, device='cuda:0', dtype=torch.float16)
tensor(8.0312, device='cuda:0', dtype=torch.float16) tensor(0.1526, device='cuda:0', dtype=torch.float16)
tensor(7.6562, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(7.8750, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.2132, device='cuda:0')
old_score: tensor(0.1516, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0904, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.138890027999878
Validation after dual ascent:
out_inf: tensor(33.4375, device='cuda:0', dtype=torch.float16) tensor(0.6929, device='cuda:0', dtype=torch.float16)
tensor(2.9375, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(2.5117, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
tensor(2.8398, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.down_proj
Validation after prune:
out_inf: tensor(198.5000, device='cuda:0', dtype=torch.float16) tensor(1.5518, device='cuda:0', dtype=torch.float16)
tensor(2.7852, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(3.1250, device='cuda:0', dtype=torch.float16) tensor(0.1055, device='cuda:0', dtype=torch.float16)
tensor(3.4375, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.19it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.09it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.93it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25': 0, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.599870
layer 1 sparsity 0.599870
layer 2 sparsity 0.599870
layer 3 sparsity 0.599870
layer 4 sparsity 0.599870
layer 5 sparsity 0.599870
layer 6 sparsity 0.599870
layer 7 sparsity 0.599870
layer 8 sparsity 0.599870
layer 9 sparsity 0.599870
layer 10 sparsity 0.599870
layer 11 sparsity 0.599870
layer 12 sparsity 0.599870
layer 13 sparsity 0.599870
layer 14 sparsity 0.599870
layer 15 sparsity 0.599870
layer 16 sparsity 0.599870
layer 17 sparsity 0.599870
layer 18 sparsity 0.599870
layer 19 sparsity 0.599870
layer 20 sparsity 0.599870
layer 21 sparsity 0.599870
layer 22 sparsity 0.599870
layer 23 sparsity 0.599870
layer 24 sparsity 0.599870
layer 25 sparsity 0.599870
layer 26 sparsity 0.599870
layer 27 sparsity 0.599870
layer 28 sparsity 0.599870
layer 29 sparsity 0.599870
layer 30 sparsity 0.599870
layer 31 sparsity 0.599870
sparsity sanity check 0.5999
******************************
evaluating on wikitext2
nsamples 83
sample 0
sample 50
wikitext perplexity 9.791441917419434
wanda_dual_3	0.5999	9.7914	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf', seed=0, nsamples=256, dual_theld=0.0, n_batch=8, sparsity_ratio=0.6, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='wanda_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
2025-04-24 01:54:49.637876: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 01:54:49.839833: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 01:54:49.845123: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 01:54:49.845152: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 01:54:53.529580: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 01:54:53.530136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 01:54:53.530154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.10it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.69it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.59it/s]
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
model.embed_tokens.weight torch.Size([32000, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([32000, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:00<03:22,  1.26it/s]  1%|          | 2/256 [00:01<03:13,  1.31it/s]  2%|▏         | 4/256 [00:01<01:37,  2.58it/s]  2%|▏         | 5/256 [00:02<01:54,  2.20it/s]  2%|▏         | 6/256 [00:02<01:33,  2.68it/s]  3%|▎         | 7/256 [00:03<02:04,  2.00it/s]  3%|▎         | 8/256 [00:03<01:35,  2.61it/s]  4%|▎         | 9/256 [00:03<01:13,  3.35it/s]  4%|▍         | 11/256 [00:03<00:49,  4.99it/s]  5%|▍         | 12/256 [00:03<00:44,  5.49it/s]  5%|▌         | 13/256 [00:04<01:31,  2.66it/s]  5%|▌         | 14/256 [00:05<01:28,  2.73it/s]  6%|▌         | 15/256 [00:05<01:15,  3.21it/s]  6%|▋         | 16/256 [00:05<01:05,  3.69it/s]  7%|▋         | 18/256 [00:06<01:08,  3.47it/s]  8%|▊         | 20/256 [00:06<00:51,  4.60it/s]  8%|▊         | 21/256 [00:06<00:45,  5.20it/s]  9%|▊         | 22/256 [00:06<00:48,  4.87it/s]  9%|▉         | 24/256 [00:07<00:41,  5.55it/s] 10%|▉         | 25/256 [00:07<00:39,  5.81it/s] 10%|█         | 26/256 [00:07<00:52,  4.39it/s] 11%|█         | 28/256 [00:07<00:43,  5.22it/s] 11%|█▏        | 29/256 [00:08<00:45,  4.95it/s] 12%|█▏        | 31/256 [00:08<00:38,  5.87it/s] 12%|█▎        | 32/256 [00:08<00:45,  4.87it/s] 13%|█▎        | 33/256 [00:09<00:57,  3.89it/s] 13%|█▎        | 34/256 [00:09<01:01,  3.63it/s] 14%|█▎        | 35/256 [00:09<01:09,  3.19it/s] 14%|█▍        | 36/256 [00:10<01:19,  2.76it/s] 14%|█▍        | 37/256 [00:10<01:13,  2.96it/s] 15%|█▍        | 38/256 [00:10<01:08,  3.19it/s] 16%|█▌        | 40/256 [00:11<01:03,  3.43it/s] 16%|█▋        | 42/256 [00:11<00:44,  4.86it/s] 17%|█▋        | 43/256 [00:11<00:39,  5.36it/s] 17%|█▋        | 44/256 [00:11<00:38,  5.44it/s] 18%|█▊        | 46/256 [00:12<00:33,  6.34it/s] 18%|█▊        | 47/256 [00:12<00:34,  6.14it/s] 19%|█▉        | 48/256 [00:12<00:37,  5.58it/s] 19%|█▉        | 49/256 [00:12<00:33,  6.13it/s] 20%|█▉        | 50/256 [00:13<00:48,  4.24it/s] 21%|██        | 53/256 [00:13<00:47,  4.26it/s] 21%|██        | 54/256 [00:13<00:47,  4.27it/s] 21%|██▏       | 55/256 [00:14<00:41,  4.87it/s] 22%|██▏       | 56/256 [00:14<00:48,  4.13it/s] 22%|██▏       | 57/256 [00:14<00:44,  4.48it/s] 23%|██▎       | 58/256 [00:14<00:49,  3.98it/s] 23%|██▎       | 59/256 [00:15<00:43,  4.52it/s] 23%|██▎       | 60/256 [00:15<00:46,  4.23it/s] 24%|██▍       | 61/256 [00:15<00:54,  3.61it/s] 24%|██▍       | 62/256 [00:16<00:59,  3.27it/s] 25%|██▍       | 63/256 [00:16<00:51,  3.76it/s] 25%|██▌       | 64/256 [00:16<00:42,  4.55it/s] 25%|██▌       | 65/256 [00:17<01:09,  2.76it/s] 26%|██▌       | 67/256 [00:17<00:44,  4.23it/s] 27%|██▋       | 68/256 [00:17<00:43,  4.35it/s] 27%|██▋       | 69/256 [00:17<00:44,  4.24it/s] 28%|██▊       | 71/256 [00:17<00:34,  5.40it/s] 29%|██▊       | 73/256 [00:18<00:27,  6.71it/s] 29%|██▉       | 74/256 [00:18<00:26,  6.77it/s] 29%|██▉       | 75/256 [00:18<00:31,  5.70it/s] 30%|██▉       | 76/256 [00:19<00:46,  3.91it/s] 30%|███       | 78/256 [00:19<00:32,  5.54it/s] 31%|███       | 79/256 [00:19<00:39,  4.51it/s] 31%|███▏      | 80/256 [00:19<00:49,  3.57it/s] 32%|███▏      | 81/256 [00:20<01:03,  2.77it/s] 32%|███▏      | 82/256 [00:20<00:54,  3.22it/s] 32%|███▏      | 83/256 [00:21<01:08,  2.51it/s] 33%|███▎      | 84/256 [00:21<01:01,  2.79it/s] 33%|███▎      | 85/256 [00:21<00:54,  3.15it/s] 34%|███▎      | 86/256 [00:22<00:47,  3.55it/s] 34%|███▍      | 87/256 [00:22<01:03,  2.65it/s] 34%|███▍      | 88/256 [00:23<01:06,  2.54it/s] 35%|███▍      | 89/256 [00:23<01:00,  2.78it/s] 35%|███▌      | 90/256 [00:23<01:00,  2.75it/s] 36%|███▌      | 91/256 [00:24<00:58,  2.84it/s] 36%|███▌      | 92/256 [00:24<00:48,  3.36it/s] 36%|███▋      | 93/256 [00:24<00:42,  3.82it/s] 37%|███▋      | 94/256 [00:24<00:51,  3.16it/s] 37%|███▋      | 95/256 [00:25<01:04,  2.48it/s] 38%|███▊      | 96/256 [00:25<00:51,  3.10it/s] 38%|███▊      | 97/256 [00:26<00:56,  2.83it/s] 38%|███▊      | 98/256 [00:26<00:46,  3.37it/s] 39%|███▊      | 99/256 [00:26<00:45,  3.49it/s] 39%|███▉      | 100/256 [00:26<00:42,  3.63it/s] 39%|███▉      | 101/256 [00:27<01:15,  2.05it/s] 40%|███▉      | 102/256 [00:27<01:05,  2.35it/s] 41%|████      | 104/256 [00:28<00:41,  3.64it/s] 41%|████▏     | 106/256 [00:28<00:33,  4.41it/s] 42%|████▏     | 107/256 [00:28<00:33,  4.42it/s] 42%|████▏     | 108/256 [00:29<00:48,  3.04it/s] 43%|████▎     | 111/256 [00:29<00:30,  4.74it/s] 44%|████▍     | 112/256 [00:29<00:32,  4.45it/s] 44%|████▍     | 113/256 [00:30<00:32,  4.45it/s] 45%|████▍     | 114/256 [00:30<00:29,  4.86it/s] 45%|████▍     | 115/256 [00:30<00:27,  5.11it/s] 45%|████▌     | 116/256 [00:30<00:38,  3.63it/s] 46%|████▌     | 117/256 [00:31<00:31,  4.39it/s] 46%|████▌     | 118/256 [00:31<00:29,  4.66it/s] 47%|████▋     | 120/256 [00:31<00:20,  6.53it/s] 47%|████▋     | 121/256 [00:31<00:19,  6.89it/s] 48%|████▊     | 122/256 [00:32<00:37,  3.56it/s] 48%|████▊     | 123/256 [00:32<00:40,  3.28it/s] 48%|████▊     | 124/256 [00:33<00:52,  2.50it/s] 49%|████▉     | 125/256 [00:34<01:22,  1.59it/s] 49%|████▉     | 126/256 [00:34<01:08,  1.89it/s] 50%|████▉     | 127/256 [00:35<01:15,  1.71it/s] 50%|█████     | 129/256 [00:35<00:45,  2.79it/s] 51%|█████     | 130/256 [00:35<00:41,  3.02it/s] 51%|█████     | 131/256 [00:36<00:39,  3.19it/s] 52%|█████▏    | 132/256 [00:36<00:37,  3.32it/s] 52%|█████▏    | 133/256 [00:36<00:45,  2.72it/s] 52%|█████▏    | 134/256 [00:37<00:44,  2.73it/s] 53%|█████▎    | 135/256 [00:37<00:36,  3.36it/s] 53%|█████▎    | 136/256 [00:37<00:36,  3.33it/s] 54%|█████▎    | 137/256 [00:37<00:30,  3.92it/s] 54%|█████▍    | 138/256 [00:38<00:26,  4.41it/s] 54%|█████▍    | 139/256 [00:38<00:24,  4.73it/s] 55%|█████▍    | 140/256 [00:38<00:22,  5.13it/s] 55%|█████▌    | 142/256 [00:38<00:17,  6.67it/s] 56%|█████▌    | 143/256 [00:38<00:16,  6.84it/s] 57%|█████▋    | 145/256 [00:39<00:34,  3.20it/s] 57%|█████▋    | 146/256 [00:40<00:38,  2.86it/s] 57%|█████▋    | 147/256 [00:40<00:35,  3.09it/s] 58%|█████▊    | 148/256 [00:40<00:36,  2.98it/s] 59%|█████▊    | 150/256 [00:41<00:29,  3.64it/s] 59%|█████▉    | 151/256 [00:41<00:24,  4.21it/s] 59%|█████▉    | 152/256 [00:41<00:28,  3.69it/s] 60%|█████▉    | 153/256 [00:41<00:25,  4.07it/s] 60%|██████    | 154/256 [00:42<00:29,  3.49it/s] 61%|██████    | 155/256 [00:42<00:26,  3.86it/s] 61%|██████    | 156/256 [00:42<00:21,  4.59it/s] 61%|██████▏   | 157/256 [00:43<00:27,  3.65it/s] 62%|██████▏   | 158/256 [00:43<00:23,  4.16it/s] 62%|██████▏   | 159/256 [00:44<00:42,  2.29it/s] 62%|██████▎   | 160/256 [00:44<00:32,  2.92it/s] 63%|██████▎   | 162/256 [00:45<00:37,  2.53it/s] 64%|██████▎   | 163/256 [00:45<00:32,  2.84it/s] 64%|██████▍   | 164/256 [00:45<00:27,  3.39it/s] 65%|██████▍   | 166/256 [00:45<00:22,  3.97it/s] 65%|██████▌   | 167/256 [00:46<00:25,  3.52it/s] 66%|██████▌   | 168/256 [00:46<00:28,  3.12it/s] 66%|██████▌   | 169/256 [00:47<00:32,  2.69it/s] 66%|██████▋   | 170/256 [00:47<00:31,  2.71it/s] 67%|██████▋   | 172/256 [00:47<00:22,  3.75it/s] 68%|██████▊   | 173/256 [00:48<00:21,  3.89it/s] 68%|██████▊   | 174/256 [00:48<00:28,  2.83it/s] 68%|██████▊   | 175/256 [00:49<00:40,  1.98it/s] 69%|██████▉   | 176/256 [00:49<00:35,  2.23it/s] 69%|██████▉   | 177/256 [00:50<00:29,  2.67it/s] 70%|██████▉   | 179/256 [00:50<00:20,  3.84it/s] 70%|███████   | 180/256 [00:51<00:37,  2.02it/s] 71%|███████   | 181/256 [00:51<00:29,  2.50it/s] 71%|███████   | 182/256 [00:52<00:38,  1.95it/s] 72%|███████▏  | 184/256 [00:53<00:35,  2.03it/s] 73%|███████▎  | 186/256 [00:53<00:24,  2.92it/s] 73%|███████▎  | 187/256 [00:54<00:27,  2.48it/s] 73%|███████▎  | 188/256 [00:54<00:24,  2.83it/s] 74%|███████▍  | 189/256 [00:54<00:23,  2.89it/s] 74%|███████▍  | 190/256 [00:55<00:21,  3.11it/s] 75%|███████▍  | 191/256 [00:55<00:19,  3.42it/s] 75%|███████▌  | 192/256 [00:55<00:22,  2.89it/s] 75%|███████▌  | 193/256 [00:56<00:21,  2.89it/s] 77%|███████▋  | 196/256 [00:56<00:13,  4.37it/s] 77%|███████▋  | 197/256 [00:56<00:15,  3.76it/s] 78%|███████▊  | 199/256 [00:57<00:11,  4.80it/s] 79%|███████▊  | 201/256 [00:57<00:10,  5.42it/s] 79%|███████▉  | 202/256 [00:57<00:11,  4.53it/s] 80%|███████▉  | 204/256 [00:57<00:09,  5.77it/s] 80%|████████  | 206/256 [00:58<00:06,  7.16it/s] 81%|████████  | 207/256 [00:58<00:06,  7.50it/s] 81%|████████▏ | 208/256 [00:58<00:07,  6.55it/s] 82%|████████▏ | 210/256 [00:58<00:05,  8.69it/s] 83%|████████▎ | 212/256 [00:58<00:05,  8.41it/s] 83%|████████▎ | 213/256 [00:58<00:05,  7.41it/s] 84%|████████▎ | 214/256 [00:59<00:07,  5.62it/s] 84%|████████▍ | 215/256 [00:59<00:09,  4.46it/s] 84%|████████▍ | 216/256 [00:59<00:09,  4.36it/s] 85%|████████▌ | 218/256 [01:00<00:07,  5.17it/s] 86%|████████▌ | 219/256 [01:01<00:14,  2.55it/s] 86%|████████▌ | 220/256 [01:01<00:12,  2.99it/s] 86%|████████▋ | 221/256 [01:01<00:12,  2.91it/s] 87%|████████▋ | 222/256 [01:02<00:11,  2.88it/s] 87%|████████▋ | 223/256 [01:02<00:11,  2.76it/s] 88%|████████▊ | 224/256 [01:04<00:23,  1.34it/s] 88%|████████▊ | 225/256 [01:04<00:22,  1.38it/s] 88%|████████▊ | 226/256 [01:05<00:16,  1.77it/s] 89%|████████▊ | 227/256 [01:05<00:13,  2.12it/s] 89%|████████▉ | 228/256 [01:05<00:12,  2.25it/s] 89%|████████▉ | 229/256 [01:06<00:18,  1.45it/s] 90%|████████▉ | 230/256 [01:07<00:13,  1.92it/s] 90%|█████████ | 231/256 [01:07<00:12,  1.98it/s] 91%|█████████ | 232/256 [01:07<00:10,  2.24it/s] 91%|█████████ | 233/256 [01:08<00:08,  2.70it/s] 92%|█████████▏| 235/256 [01:08<00:05,  3.75it/s] 92%|█████████▏| 236/256 [01:08<00:05,  3.63it/s] 93%|█████████▎| 237/256 [01:08<00:04,  4.02it/s] 93%|█████████▎| 238/256 [01:08<00:03,  4.68it/s] 93%|█████████▎| 239/256 [01:09<00:03,  4.63it/s] 94%|█████████▍| 241/256 [01:09<00:02,  5.89it/s] 95%|█████████▍| 242/256 [01:10<00:04,  2.91it/s] 95%|█████████▌| 244/256 [01:10<00:02,  4.44it/s] 96%|█████████▌| 245/256 [01:10<00:02,  4.39it/s] 96%|█████████▌| 246/256 [01:10<00:02,  4.87it/s] 97%|█████████▋| 248/256 [01:10<00:01,  6.49it/s] 97%|█████████▋| 249/256 [01:11<00:01,  3.92it/s] 98%|█████████▊| 251/256 [01:11<00:00,  5.46it/s] 98%|█████████▊| 252/256 [01:12<00:01,  3.50it/s] 99%|█████████▉| 253/256 [01:12<00:01,  2.97it/s]100%|█████████▉| 255/256 [01:13<00:00,  3.10it/s]100%|██████████| 256/256 [01:13<00:00,  3.14it/s]100%|██████████| 256/256 [01:13<00:00,  3.47it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
pruning layer 0 name self_attn.q_proj
Validation after prune:
out_inf: tensor(7.8555, device='cuda:0', dtype=torch.float16) tensor(0.6099, device='cuda:0', dtype=torch.float16)
tensor(0.2070, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.2344, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.2070, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.2344, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.k_proj
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.1895, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.v_proj
Validation after prune:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1277, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0572, device='cuda:0')
old_score: tensor(0.0036, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0019, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.803145408630371
Validation after dual ascent:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0735, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0718, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0718, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0605, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0124, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
tensor(0.0074, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0158, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0130, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.8955, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.9346, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.8877, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0183, device='cuda:0')
tensor(0.0178, device='cuda:0')
old_score: tensor(0.0200, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0124, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 29.142491817474365
Validation after dual ascent:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.6465, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.7080, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.6279, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.up_proj
Validation after prune:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.4209, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.4385, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0185, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0193, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.0193, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 27.326149463653564
Validation after dual ascent:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.3076, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.3237, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.3584, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.2939, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.1113, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.1152, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0947, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.1221, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.1215, device='cuda:0')
old_score: tensor(0.0024, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0018, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.62817144393921
Validation after dual ascent:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0557, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0457, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0483, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0649, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.q_proj
Validation after prune:
out_inf: tensor(9.3984, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(1.6738, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(1.7461, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
tensor(1.7119, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.k_proj
Validation after prune:
out_inf: tensor(7.9297, device='cuda:0', dtype=torch.float16) tensor(0.8110, device='cuda:0', dtype=torch.float16)
tensor(1.6064, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(1.6338, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.6050, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.6206, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.6665, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.0195, device='cuda:0')
old_score: tensor(0.0124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0076, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.880062818527222
Validation after dual ascent:
out_inf: tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.5176, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.5288, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.5679, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.5220, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0462, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0928, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0684, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0471, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0263, device='cuda:0')
old_score: tensor(0.0017, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0012, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.912938117980957
Validation after dual ascent:
out_inf: tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0375, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0393, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0402, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0369, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.gate_proj
Validation after prune:
out_inf: tensor(42.9062, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(13.9062, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(13.2188, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(14.4531, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0189, device='cuda:0')
tensor(0.0209, device='cuda:0')
old_score: tensor(0.0420, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0284, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.76542067527771
Validation after dual ascent:
out_inf: tensor(42.9062, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
tensor(4.1875, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(4.0625, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(3.6406, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(5.1250, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.up_proj
Validation after prune:
out_inf: tensor(37.4688, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(10.0469, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(9.9219, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(9.2031, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(10.3281, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0187, device='cuda:0')
tensor(0.0291, device='cuda:0')
old_score: tensor(0.0366, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0262, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.850221872329712
Validation after dual ascent:
out_inf: tensor(37.4688, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(2.8125, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(2.7500, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.0279, device='cuda:0', dtype=torch.float16)
tensor(3.5000, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.down_proj
Validation after prune:
out_inf: tensor(2612., device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.1719, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(1.9491, device='cuda:0')
old_score: tensor(0.0065, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0086, device='cuda:0', dtype=torch.float16)
Not converged!
Dual ascent finished!
Time: 98.18776416778564
Validation after dual ascent:
out_inf: tensor(2612., device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.1719, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.4609, device='cuda:0', dtype=torch.float16) tensor(0.9609, device='cuda:0', dtype=torch.float16)
tensor(2.8867, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(2.6758, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(3.0703, device='cuda:0', dtype=torch.float16) tensor(0.1210, device='cuda:0', dtype=torch.float16)
tensor(0.0531, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0669, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.93264365196228
Validation after dual ascent:
out_inf: tensor(13.4609, device='cuda:0', dtype=torch.float16) tensor(0.9609, device='cuda:0', dtype=torch.float16)
tensor(2.0352, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.0647, device='cuda:0', dtype=torch.float16)
tensor(1.5215, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.k_proj
Validation after prune:
out_inf: tensor(14.5859, device='cuda:0', dtype=torch.float16) tensor(1.1406, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(0.0584, device='cuda:0')
old_score: tensor(0.1267, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0684, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.961416721343994
Validation after dual ascent:
out_inf: tensor(14.5859, device='cuda:0', dtype=torch.float16) tensor(1.1406, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
tensor(1.5723, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
tensor(0.8271, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(1.0303, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0043, device='cuda:0')
tensor(0.0485, device='cuda:0')
old_score: tensor(0.0546, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0378, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1795871257781982
Validation after dual ascent:
out_inf: tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
tensor(0.4553, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1783, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.1445, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1146, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.1615, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0662, device='cuda:0')
old_score: tensor(0.0026, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0020, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.96352481842041
Validation after dual ascent:
out_inf: tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1461, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.2646, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.1301, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.2208, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(1.5332, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(1.4893, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0153, device='cuda:0')
tensor(0.0241, device='cuda:0')
old_score: tensor(0.0543, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0413, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.850135087966919
Validation after dual ascent:
out_inf: tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(0.8193, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.6528, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.2715, device='cuda:0', dtype=torch.float16) tensor(0.0895, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.6963, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0197, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.0496, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0381, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.927574872970581
Validation after dual ascent:
out_inf: tensor(2.2715, device='cuda:0', dtype=torch.float16) tensor(0.0895, device='cuda:0', dtype=torch.float16)
tensor(0.5986, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.4802, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.1161, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.2080, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1481, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1266, device='cuda:0')
old_score: tensor(0.0077, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.70018601417542
Validation after dual ascent:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.0848, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.0973, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.1208, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.1018, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2656, device='cuda:0', dtype=torch.float16) tensor(0.8584, device='cuda:0', dtype=torch.float16)
tensor(3.1133, device='cuda:0', dtype=torch.float16) tensor(0.1738, device='cuda:0', dtype=torch.float16)
tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.1741, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.1855, device='cuda:0', dtype=torch.float16)
tensor(3.0508, device='cuda:0', dtype=torch.float16) tensor(0.1755, device='cuda:0', dtype=torch.float16)
tensor(0.1685, device='cuda:0')
old_score: tensor(0.1772, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1194, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.942843675613403
Validation after dual ascent:
out_inf: tensor(17.2656, device='cuda:0', dtype=torch.float16) tensor(0.8584, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.7773, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(2.2520, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.1804, device='cuda:0', dtype=torch.float16)
tensor(2.8418, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(3.2266, device='cuda:0', dtype=torch.float16) tensor(0.1906, device='cuda:0', dtype=torch.float16)
tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.1814, device='cuda:0', dtype=torch.float16)
tensor(0.1599, device='cuda:0')
old_score: tensor(0.1831, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1227, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.967605352401733
Validation after dual ascent:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(1.8018, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1180, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.1203, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1835, device='cuda:0', dtype=torch.float16)
tensor(0.9355, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0871, device='cuda:0', dtype=torch.float16)
tensor(0.8408, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0162, device='cuda:0')
tensor(0.0705, device='cuda:0')
old_score: tensor(0.0879, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0660, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.749074459075928
Validation after dual ascent:
out_inf: tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1835, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(0.6362, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(0.6704, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
tensor(0.7329, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.2493, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.2046, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.2456, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.2754, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0637, device='cuda:0')
old_score: tensor(0.0038, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0028, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.965246438980103
Validation after dual ascent:
out_inf: tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1543, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.1182, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.1428, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1362, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.4258, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(2.5859, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(3.2031, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.0335, device='cuda:0')
old_score: tensor(0.0696, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0542, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.124786138534546
Validation after dual ascent:
out_inf: tensor(4.4258, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(1.0898, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.0898, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.4941, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.0771, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(1.2119, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(1.0684, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0087, device='cuda:0')
tensor(0.0281, device='cuda:0')
old_score: tensor(0.0632, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0500, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.128521680831909
Validation after dual ascent:
out_inf: tensor(2.4941, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0492, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.2231, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1774, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.2307, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1245, device='cuda:0')
old_score: tensor(0.0116, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.64572834968567
Validation after dual ascent:
out_inf: tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.1353, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1371, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1482, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1630, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.5547, device='cuda:0', dtype=torch.float16) tensor(0.8447, device='cuda:0', dtype=torch.float16)
tensor(2.6016, device='cuda:0', dtype=torch.float16) tensor(0.1801, device='cuda:0', dtype=torch.float16)
tensor(2.4316, device='cuda:0', dtype=torch.float16) tensor(0.1813, device='cuda:0', dtype=torch.float16)
tensor(2.5332, device='cuda:0', dtype=torch.float16) tensor(0.1885, device='cuda:0', dtype=torch.float16)
tensor(2.5723, device='cuda:0', dtype=torch.float16) tensor(0.1833, device='cuda:0', dtype=torch.float16)
tensor(0.1028, device='cuda:0')
old_score: tensor(0.1833, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.954383611679077
Validation after dual ascent:
out_inf: tensor(14.5547, device='cuda:0', dtype=torch.float16) tensor(0.8447, device='cuda:0', dtype=torch.float16)
tensor(1.6025, device='cuda:0', dtype=torch.float16) tensor(0.1192, device='cuda:0', dtype=torch.float16)
tensor(1.5381, device='cuda:0', dtype=torch.float16) tensor(0.1198, device='cuda:0', dtype=torch.float16)
tensor(1.7568, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.8594, device='cuda:0', dtype=torch.float16) tensor(1.0791, device='cuda:0', dtype=torch.float16)
tensor(2.4102, device='cuda:0', dtype=torch.float16) tensor(0.1848, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1847, device='cuda:0', dtype=torch.float16)
tensor(2.5156, device='cuda:0', dtype=torch.float16) tensor(0.1919, device='cuda:0', dtype=torch.float16)
tensor(2.8086, device='cuda:0', dtype=torch.float16) tensor(0.1866, device='cuda:0', dtype=torch.float16)
tensor(0.1051, device='cuda:0')
old_score: tensor(0.1870, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.981419801712036
Validation after dual ascent:
out_inf: tensor(19.8594, device='cuda:0', dtype=torch.float16) tensor(1.0791, device='cuda:0', dtype=torch.float16)
tensor(1.7881, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(1.6416, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
tensor(1.9502, device='cuda:0', dtype=torch.float16) tensor(0.1224, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.5586, device='cuda:0', dtype=torch.float16) tensor(0.1958, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(1.2861, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(1.3027, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0184, device='cuda:0')
tensor(0.0873, device='cuda:0')
old_score: tensor(0.0940, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0685, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.193026065826416
Validation after dual ascent:
out_inf: tensor(4.5586, device='cuda:0', dtype=torch.float16) tensor(0.1958, device='cuda:0', dtype=torch.float16)
tensor(0.6060, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.6201, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.6147, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.6743, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.0039, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.4639, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.3506, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.4165, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0542, device='cuda:0')
old_score: tensor(0.0091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0067, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.966852188110352
Validation after dual ascent:
out_inf: tensor(4.0039, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.2041, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.2705, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.2368, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(2.2441, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0117, device='cuda:0')
tensor(0.0365, device='cuda:0')
old_score: tensor(0.0886, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0667, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1298887729644775
Validation after dual ascent:
out_inf: tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0647, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.1582, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(1.4570, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.0763, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0775, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0077, device='cuda:0')
tensor(0.0326, device='cuda:0')
old_score: tensor(0.0772, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0596, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.127151727676392
Validation after dual ascent:
out_inf: tensor(3.1582, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.5576, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.9658, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.down_proj
Validation after prune:
out_inf: tensor(9.1875, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.4502, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.4565, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
tensor(0.4785, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0102, device='cuda:0')
tensor(0.0250, device='cuda:0')
old_score: tensor(0.0185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0159, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 84.25983333587646
Validation after dual ascent:
out_inf: tensor(9.1875, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.2046, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.2627, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
tensor(0.2195, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.2505, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16., device='cuda:0', dtype=torch.float16) tensor(0.8628, device='cuda:0', dtype=torch.float16)
tensor(2.5977, device='cuda:0', dtype=torch.float16) tensor(0.1980, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.2034, device='cuda:0', dtype=torch.float16)
tensor(3.1055, device='cuda:0', dtype=torch.float16) tensor(0.2039, device='cuda:0', dtype=torch.float16)
tensor(2.5977, device='cuda:0', dtype=torch.float16) tensor(0.2014, device='cuda:0', dtype=torch.float16)
tensor(0.0521, device='cuda:0')
old_score: tensor(0.2017, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1289, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.961780309677124
Validation after dual ascent:
out_inf: tensor(16., device='cuda:0', dtype=torch.float16) tensor(0.8628, device='cuda:0', dtype=torch.float16)
tensor(1.4482, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.4404, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(1.6846, device='cuda:0', dtype=torch.float16) tensor(0.1326, device='cuda:0', dtype=torch.float16)
tensor(1.6152, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.6719, device='cuda:0', dtype=torch.float16) tensor(1.1162, device='cuda:0', dtype=torch.float16)
tensor(2.9766, device='cuda:0', dtype=torch.float16) tensor(0.2103, device='cuda:0', dtype=torch.float16)
tensor(2.8750, device='cuda:0', dtype=torch.float16) tensor(0.2151, device='cuda:0', dtype=torch.float16)
tensor(2.7656, device='cuda:0', dtype=torch.float16) tensor(0.2150, device='cuda:0', dtype=torch.float16)
tensor(2.9531, device='cuda:0', dtype=torch.float16) tensor(0.2128, device='cuda:0', dtype=torch.float16)
tensor(0.0563, device='cuda:0')
old_score: tensor(0.2133, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1323, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.995368719100952
Validation after dual ascent:
out_inf: tensor(18.6719, device='cuda:0', dtype=torch.float16) tensor(1.1162, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1360, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.6309, device='cuda:0', dtype=torch.float16) tensor(0.2068, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.1023, device='cuda:0', dtype=torch.float16)
tensor(0.8970, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.0098, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0088, device='cuda:0')
tensor(0.0380, device='cuda:0')
old_score: tensor(0.1014, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0719, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1947004795074463
Validation after dual ascent:
out_inf: tensor(2.6309, device='cuda:0', dtype=torch.float16) tensor(0.2068, device='cuda:0', dtype=torch.float16)
tensor(0.6675, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(0.5845, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.9902, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.4409, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.0573, device='cuda:0')
old_score: tensor(0.0121, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0083, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.953009366989136
Validation after dual ascent:
out_inf: tensor(3.9902, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.2842, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.2568, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.3354, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.2661, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.1641, device='cuda:0', dtype=torch.float16) tensor(0.2098, device='cuda:0', dtype=torch.float16)
tensor(1.8965, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(2.0098, device='cuda:0', dtype=torch.float16) tensor(0.0985, device='cuda:0', dtype=torch.float16)
tensor(1.6963, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0116, device='cuda:0')
tensor(0.0515, device='cuda:0')
old_score: tensor(0.0986, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0670, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.137116432189941
Validation after dual ascent:
out_inf: tensor(4.1641, device='cuda:0', dtype=torch.float16) tensor(0.2098, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(1.3574, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
tensor(1.6621, device='cuda:0', dtype=torch.float16) tensor(0.0855, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.0843, device='cuda:0', dtype=torch.float16)
tensor(1.3691, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0091, device='cuda:0')
tensor(0.0400, device='cuda:0')
old_score: tensor(0.0854, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0596, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.129570007324219
Validation after dual ascent:
out_inf: tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.8887, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.4417, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.3003, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0114, device='cuda:0')
tensor(0.0267, device='cuda:0')
old_score: tensor(0.0210, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0173, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 84.12252020835876
Validation after dual ascent:
out_inf: tensor(1.8887, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.2288, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.3110, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.2197, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.3018, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.8525, device='cuda:0', dtype=torch.float16)
tensor(4.4492, device='cuda:0', dtype=torch.float16) tensor(0.2456, device='cuda:0', dtype=torch.float16)
tensor(4.5547, device='cuda:0', dtype=torch.float16) tensor(0.2496, device='cuda:0', dtype=torch.float16)
tensor(4.9219, device='cuda:0', dtype=torch.float16) tensor(0.2439, device='cuda:0', dtype=torch.float16)
tensor(4.6211, device='cuda:0', dtype=torch.float16) tensor(0.2463, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0176, device='cuda:0')
tensor(0.0388, device='cuda:0')
old_score: tensor(0.2463, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1388, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.784114837646484
Validation after dual ascent:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.8525, device='cuda:0', dtype=torch.float16)
tensor(2.2227, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(2.5508, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(2.1660, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.9844, device='cuda:0', dtype=torch.float16) tensor(1.0391, device='cuda:0', dtype=torch.float16)
tensor(4.5781, device='cuda:0', dtype=torch.float16) tensor(0.2544, device='cuda:0', dtype=torch.float16)
tensor(5.1562, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.2527, device='cuda:0', dtype=torch.float16)
tensor(4.4062, device='cuda:0', dtype=torch.float16) tensor(0.2551, device='cuda:0', dtype=torch.float16)
tensor(0.0342, device='cuda:0')
old_score: tensor(0.2554, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1400, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.00609016418457
Validation after dual ascent:
out_inf: tensor(16.9844, device='cuda:0', dtype=torch.float16) tensor(1.0391, device='cuda:0', dtype=torch.float16)
tensor(2.0879, device='cuda:0', dtype=torch.float16) tensor(0.1415, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(1.9580, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(1.9619, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.2969, device='cuda:0', dtype=torch.float16) tensor(0.2566, device='cuda:0', dtype=torch.float16)
tensor(1.1943, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.1188, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0065, device='cuda:0')
tensor(0.0285, device='cuda:0')
old_score: tensor(0.1211, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0766, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.203002691268921
Validation after dual ascent:
out_inf: tensor(3.2969, device='cuda:0', dtype=torch.float16) tensor(0.2566, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6611, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.6567, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.7056, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.o_proj
Validation after prune:
out_inf: tensor(8.1797, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.8784, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.0431, device='cuda:0')
old_score: tensor(0.0198, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.936031341552734
Validation after dual ascent:
out_inf: tensor(8.1797, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.4014, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.3340, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.8906, device='cuda:0', dtype=torch.float16) tensor(0.2788, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
tensor(1.7637, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.0329, device='cuda:0')
old_score: tensor(0.1028, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0607, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.126108646392822
Validation after dual ascent:
out_inf: tensor(3.8906, device='cuda:0', dtype=torch.float16) tensor(0.2788, device='cuda:0', dtype=torch.float16)
tensor(1.0020, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.8569, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.8018, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.9258, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(1.6758, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(1.8555, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(1.4824, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
tensor(1.8613, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.0273, device='cuda:0')
old_score: tensor(0.0854, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0528, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.097163677215576
Validation after dual ascent:
out_inf: tensor(2.9258, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(0.6689, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.7002, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5869, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.5850, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.0815, device='cuda:0')
old_score: tensor(0.0217, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0148, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.30572843551636
Validation after dual ascent:
out_inf: tensor(1.5869, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.1904, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.2129, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.7656, device='cuda:0', dtype=torch.float16) tensor(0.8516, device='cuda:0', dtype=torch.float16)
tensor(4.9297, device='cuda:0', dtype=torch.float16) tensor(0.2600, device='cuda:0', dtype=torch.float16)
tensor(5.7109, device='cuda:0', dtype=torch.float16) tensor(0.2646, device='cuda:0', dtype=torch.float16)
tensor(5.3906, device='cuda:0', dtype=torch.float16) tensor(0.2659, device='cuda:0', dtype=torch.float16)
tensor(6.2500, device='cuda:0', dtype=torch.float16) tensor(0.2607, device='cuda:0', dtype=torch.float16)
tensor(0.1452, device='cuda:0')
old_score: tensor(0.2627, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1343, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.976987361907959
Validation after dual ascent:
out_inf: tensor(18.7656, device='cuda:0', dtype=torch.float16) tensor(0.8516, device='cuda:0', dtype=torch.float16)
tensor(2.3965, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
tensor(1.8779, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.4844, device='cuda:0', dtype=torch.float16) tensor(0.9966, device='cuda:0', dtype=torch.float16)
tensor(4.5391, device='cuda:0', dtype=torch.float16) tensor(0.2620, device='cuda:0', dtype=torch.float16)
tensor(5.0312, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
tensor(5.2812, device='cuda:0', dtype=torch.float16) tensor(0.2683, device='cuda:0', dtype=torch.float16)
tensor(5.4609, device='cuda:0', dtype=torch.float16) tensor(0.2627, device='cuda:0', dtype=torch.float16)
tensor(0.1446, device='cuda:0')
old_score: tensor(0.2651, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1335, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.999398469924927
Validation after dual ascent:
out_inf: tensor(16.4844, device='cuda:0', dtype=torch.float16) tensor(0.9966, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.1312, device='cuda:0', dtype=torch.float16)
tensor(1.8242, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(2.1289, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.8125, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(1.3574, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.4316, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.4707, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
tensor(1.4121, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(0.0701, device='cuda:0')
old_score: tensor(0.1271, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0745, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.97664761543274
Validation after dual ascent:
out_inf: tensor(3.8125, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0748, device='cuda:0', dtype=torch.float16)
tensor(0.6924, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.4570, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.7275, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
tensor(0.0433, device='cuda:0')
old_score: tensor(0.0222, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0126, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.897404909133911
Validation after dual ascent:
out_inf: tensor(3.4570, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.3252, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.4062, device='cuda:0', dtype=torch.float16) tensor(0.3027, device='cuda:0', dtype=torch.float16)
tensor(3.1523, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(3.1191, device='cuda:0', dtype=torch.float16) tensor(0.1153, device='cuda:0', dtype=torch.float16)
tensor(3.3516, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(3.0977, device='cuda:0', dtype=torch.float16) tensor(0.1131, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0118, device='cuda:0')
tensor(0.0425, device='cuda:0')
old_score: tensor(0.1141, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0667, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.11078953742981
Validation after dual ascent:
out_inf: tensor(5.4062, device='cuda:0', dtype=torch.float16) tensor(0.3027, device='cuda:0', dtype=torch.float16)
tensor(1.4043, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(1.0215, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0664, device='cuda:0', dtype=torch.float16) tensor(0.1809, device='cuda:0', dtype=torch.float16)
tensor(1.3262, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(1.4658, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(2.1816, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(1.3135, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0065, device='cuda:0')
tensor(0.0359, device='cuda:0')
old_score: tensor(0.0966, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0585, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1128411293029785
Validation after dual ascent:
out_inf: tensor(4.0664, device='cuda:0', dtype=torch.float16) tensor(0.1809, device='cuda:0', dtype=torch.float16)
tensor(0.7012, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0165, device='cuda:0')
tensor(0.0296, device='cuda:0')
old_score: tensor(0.0255, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 88.88862562179565
Validation after dual ascent:
out_inf: tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.3130, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.3052, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19., device='cuda:0', dtype=torch.float16) tensor(0.8062, device='cuda:0', dtype=torch.float16)
tensor(5.5312, device='cuda:0', dtype=torch.float16) tensor(0.2522, device='cuda:0', dtype=torch.float16)
tensor(5.6016, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(5.2500, device='cuda:0', dtype=torch.float16) tensor(0.2590, device='cuda:0', dtype=torch.float16)
tensor(5.4062, device='cuda:0', dtype=torch.float16) tensor(0.2505, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0170, device='cuda:0')
tensor(0.0240, device='cuda:0')
old_score: tensor(0.2544, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1392, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.147586345672607
Validation after dual ascent:
out_inf: tensor(19., device='cuda:0', dtype=torch.float16) tensor(0.8062, device='cuda:0', dtype=torch.float16)
tensor(3.0234, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(2.3066, device='cuda:0', dtype=torch.float16) tensor(0.1367, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.9062, device='cuda:0', dtype=torch.float16) tensor(1.0293, device='cuda:0', dtype=torch.float16)
tensor(3.9492, device='cuda:0', dtype=torch.float16) tensor(0.2546, device='cuda:0', dtype=torch.float16)
tensor(3.8008, device='cuda:0', dtype=torch.float16) tensor(0.2576, device='cuda:0', dtype=torch.float16)
tensor(3.9727, device='cuda:0', dtype=torch.float16) tensor(0.2568, device='cuda:0', dtype=torch.float16)
tensor(4.0391, device='cuda:0', dtype=torch.float16) tensor(0.2532, device='cuda:0', dtype=torch.float16)
tensor(0.0234, device='cuda:0')
old_score: tensor(0.2556, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1385, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.0016188621521
Validation after dual ascent:
out_inf: tensor(16.9062, device='cuda:0', dtype=torch.float16) tensor(1.0293, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1393, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(1.7393, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.2622, device='cuda:0', dtype=torch.float16)
tensor(1.0947, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.3018, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0138, device='cuda:0')
tensor(0.1252, device='cuda:0')
old_score: tensor(0.1323, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0794, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.464362382888794
Validation after dual ascent:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.2622, device='cuda:0', dtype=torch.float16)
tensor(0.8374, device='cuda:0', dtype=torch.float16) tensor(0.0785, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(0.6963, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.7461, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.8628, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.0331, device='cuda:0')
old_score: tensor(0.0263, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0153, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.9315824508667
Validation after dual ascent:
out_inf: tensor(3.7461, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.3760, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.3335, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.4302, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.4341, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.8164, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(2.5547, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(5.2891, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(2.0723, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.0503, device='cuda:0')
old_score: tensor(0.1167, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0703, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.109560966491699
Validation after dual ascent:
out_inf: tensor(7.8164, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(2.8438, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.6055, device='cuda:0', dtype=torch.float16) tensor(0.1937, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1037, device='cuda:0', dtype=torch.float16)
tensor(1.9570, device='cuda:0', dtype=torch.float16) tensor(0.1043, device='cuda:0', dtype=torch.float16)
tensor(2.6602, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0070, device='cuda:0')
tensor(0.0445, device='cuda:0')
old_score: tensor(0.1036, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0635, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.107060194015503
Validation after dual ascent:
out_inf: tensor(5.6055, device='cuda:0', dtype=torch.float16) tensor(0.1937, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.6934, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.2949, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.6558, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0167, device='cuda:0')
tensor(0.0209, device='cuda:0')
old_score: tensor(0.0277, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0206, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 79.40436816215515
Validation after dual ascent:
out_inf: tensor(2.2949, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.3359, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.2705, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
tensor(0.3203, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.2832, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.8140, device='cuda:0', dtype=torch.float16)
tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.2600, device='cuda:0', dtype=torch.float16)
tensor(3.7227, device='cuda:0', dtype=torch.float16) tensor(0.2651, device='cuda:0', dtype=torch.float16)
tensor(4.8750, device='cuda:0', dtype=torch.float16) tensor(0.2727, device='cuda:0', dtype=torch.float16)
tensor(4.0898, device='cuda:0', dtype=torch.float16) tensor(0.2576, device='cuda:0', dtype=torch.float16)
tensor(0.1390, device='cuda:0')
old_score: tensor(0.2639, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1476, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.004940032958984
Validation after dual ascent:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.8140, device='cuda:0', dtype=torch.float16)
tensor(1.8027, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(1.8477, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
tensor(2.4609, device='cuda:0', dtype=torch.float16) tensor(0.1486, device='cuda:0', dtype=torch.float16)
tensor(1.8154, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.3594, device='cuda:0', dtype=torch.float16) tensor(1.0527, device='cuda:0', dtype=torch.float16)
tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
tensor(3.0586, device='cuda:0', dtype=torch.float16) tensor(0.2720, device='cuda:0', dtype=torch.float16)
tensor(3.2559, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.2646, device='cuda:0', dtype=torch.float16)
tensor(0.1357, device='cuda:0')
old_score: tensor(0.2703, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1484, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.992091655731201
Validation after dual ascent:
out_inf: tensor(18.3594, device='cuda:0', dtype=torch.float16) tensor(1.0527, device='cuda:0', dtype=torch.float16)
tensor(1.8994, device='cuda:0', dtype=torch.float16) tensor(0.1482, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1501, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
tensor(1.8574, device='cuda:0', dtype=torch.float16) tensor(0.1460, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.8516, device='cuda:0', dtype=torch.float16) tensor(0.2710, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1381, device='cuda:0', dtype=torch.float16)
tensor(1.2832, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0105, device='cuda:0')
tensor(0.0740, device='cuda:0')
old_score: tensor(0.1389, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0844, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.7316415309906
Validation after dual ascent:
out_inf: tensor(6.8516, device='cuda:0', dtype=torch.float16) tensor(0.2710, device='cuda:0', dtype=torch.float16)
tensor(0.8232, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
tensor(0.7939, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
tensor(0.7427, device='cuda:0', dtype=torch.float16) tensor(0.0830, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.6211, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.8730, device='cuda:0', dtype=torch.float16) tensor(0.0284, device='cuda:0', dtype=torch.float16)
tensor(1.4160, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0199, device='cuda:0')
tensor(0.0436, device='cuda:0')
old_score: tensor(0.0283, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0168, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.184868574142456
Validation after dual ascent:
out_inf: tensor(4.6211, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.2500, device='cuda:0', dtype=torch.float16) tensor(0.2788, device='cuda:0', dtype=torch.float16)
tensor(3.0039, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(2.4824, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0103, device='cuda:0')
tensor(0.0546, device='cuda:0')
old_score: tensor(0.1170, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0719, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.121929168701172
Validation after dual ascent:
out_inf: tensor(8.2500, device='cuda:0', dtype=torch.float16) tensor(0.2788, device='cuda:0', dtype=torch.float16)
tensor(1.6504, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(1.4033, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(1.1816, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(1.6162, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.1875, device='cuda:0', dtype=torch.float16) tensor(0.1996, device='cuda:0', dtype=torch.float16)
tensor(2.0605, device='cuda:0', dtype=torch.float16) tensor(0.1062, device='cuda:0', dtype=torch.float16)
tensor(1.7988, device='cuda:0', dtype=torch.float16) tensor(0.1062, device='cuda:0', dtype=torch.float16)
tensor(2.3340, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(1.7441, device='cuda:0', dtype=torch.float16) tensor(0.1043, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0070, device='cuda:0')
tensor(0.0495, device='cuda:0')
old_score: tensor(0.1059, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0661, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.120162487030029
Validation after dual ascent:
out_inf: tensor(5.1875, device='cuda:0', dtype=torch.float16) tensor(0.1996, device='cuda:0', dtype=torch.float16)
tensor(0.8291, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.8008, device='cuda:0', dtype=torch.float16) tensor(0.0653, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0103, device='cuda:0')
tensor(0.0239, device='cuda:0')
old_score: tensor(0.0298, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0224, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 65.08900690078735
Validation after dual ascent:
out_inf: tensor(2.8008, device='cuda:0', dtype=torch.float16) tensor(0.0653, device='cuda:0', dtype=torch.float16)
tensor(0.3843, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.3455, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(4.2383, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
tensor(4.1953, device='cuda:0', dtype=torch.float16) tensor(0.2612, device='cuda:0', dtype=torch.float16)
tensor(5.5547, device='cuda:0', dtype=torch.float16) tensor(0.2700, device='cuda:0', dtype=torch.float16)
tensor(4.4102, device='cuda:0', dtype=torch.float16) tensor(0.2554, device='cuda:0', dtype=torch.float16)
tensor(0.0918, device='cuda:0')
old_score: tensor(0.2615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1497, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.00967001914978
Validation after dual ascent:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(2.2910, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0527, device='cuda:0', dtype=torch.float16)
tensor(3.2188, device='cuda:0', dtype=torch.float16) tensor(0.2639, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.2661, device='cuda:0', dtype=torch.float16)
tensor(3.7891, device='cuda:0', dtype=torch.float16) tensor(0.2742, device='cuda:0', dtype=torch.float16)
tensor(3.3652, device='cuda:0', dtype=torch.float16) tensor(0.2607, device='cuda:0', dtype=torch.float16)
tensor(0.0938, device='cuda:0')
old_score: tensor(0.2664, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1504, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.032275199890137
Validation after dual ascent:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0527, device='cuda:0', dtype=torch.float16)
tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.1520, device='cuda:0', dtype=torch.float16)
tensor(1.9014, device='cuda:0', dtype=torch.float16) tensor(0.1500, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.6582, device='cuda:0', dtype=torch.float16) tensor(0.1478, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.0469, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(1.8613, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.4551, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.9648, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(1.3018, device='cuda:0', dtype=torch.float16) tensor(0.1371, device='cuda:0', dtype=torch.float16)
tensor(0.0493, device='cuda:0')
old_score: tensor(0.1393, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0853, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.992664337158203
Validation after dual ascent:
out_inf: tensor(7.0469, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0860, device='cuda:0', dtype=torch.float16)
tensor(0.7920, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0174, device='cuda:0')
tensor(0.0333, device='cuda:0')
old_score: tensor(0.0362, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0204, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.287816762924194
Validation after dual ascent:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0229, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.5000, device='cuda:0', dtype=torch.float16) tensor(0.2944, device='cuda:0', dtype=torch.float16)
tensor(2.8105, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(3.0332, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(2.8633, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(3.4258, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.0545, device='cuda:0')
old_score: tensor(0.1154, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0714, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.11571192741394
Validation after dual ascent:
out_inf: tensor(6.5000, device='cuda:0', dtype=torch.float16) tensor(0.2944, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.5176, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.4844, device='cuda:0', dtype=torch.float16) tensor(0.2086, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0073, device='cuda:0')
tensor(0.0502, device='cuda:0')
old_score: tensor(0.1067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0669, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110722303390503
Validation after dual ascent:
out_inf: tensor(3.4844, device='cuda:0', dtype=torch.float16) tensor(0.2086, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1201, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.7324, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0123, device='cuda:0')
tensor(0.0280, device='cuda:0')
old_score: tensor(0.0318, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0236, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 64.85975694656372
Validation after dual ascent:
out_inf: tensor(1.1201, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(0.4053, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.3936, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.3669, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.3633, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.7969, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(6.3281, device='cuda:0', dtype=torch.float16) tensor(0.2729, device='cuda:0', dtype=torch.float16)
tensor(5.9531, device='cuda:0', dtype=torch.float16) tensor(0.2712, device='cuda:0', dtype=torch.float16)
tensor(5.8125, device='cuda:0', dtype=torch.float16) tensor(0.2852, device='cuda:0', dtype=torch.float16)
tensor(5.9414, device='cuda:0', dtype=torch.float16) tensor(0.2632, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0148, device='cuda:0')
tensor(0.0470, device='cuda:0')
old_score: tensor(0.2729, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1565, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.786895751953125
Validation after dual ascent:
out_inf: tensor(19.7969, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(2.7617, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
tensor(2.6035, device='cuda:0', dtype=torch.float16) tensor(0.1548, device='cuda:0', dtype=torch.float16)
tensor(2.7617, device='cuda:0', dtype=torch.float16) tensor(0.1616, device='cuda:0', dtype=torch.float16)
tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0430, device='cuda:0', dtype=torch.float16)
tensor(4.1875, device='cuda:0', dtype=torch.float16) tensor(0.2734, device='cuda:0', dtype=torch.float16)
tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.2715, device='cuda:0', dtype=torch.float16)
tensor(4.7109, device='cuda:0', dtype=torch.float16) tensor(0.2830, device='cuda:0', dtype=torch.float16)
tensor(3.9062, device='cuda:0', dtype=torch.float16) tensor(0.2656, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0174, device='cuda:0')
tensor(0.0481, device='cuda:0')
old_score: tensor(0.2734, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1538, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.805550336837769
Validation after dual ascent:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0430, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.1560, device='cuda:0', dtype=torch.float16)
tensor(2.0820, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.1582, device='cuda:0', dtype=torch.float16)
tensor(2.1133, device='cuda:0', dtype=torch.float16) tensor(0.1490, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.9766, device='cuda:0', dtype=torch.float16) tensor(0.3145, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1608, device='cuda:0', dtype=torch.float16)
tensor(1.3027, device='cuda:0', dtype=torch.float16) tensor(0.1586, device='cuda:0', dtype=torch.float16)
tensor(1.5713, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
tensor(1.3350, device='cuda:0', dtype=torch.float16) tensor(0.1569, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0609, device='cuda:0')
old_score: tensor(0.1595, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0994, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.204355478286743
Validation after dual ascent:
out_inf: tensor(7.9766, device='cuda:0', dtype=torch.float16) tensor(0.3145, device='cuda:0', dtype=torch.float16)
tensor(0.9175, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(0.8501, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(0.8691, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6., device='cuda:0', dtype=torch.float16) tensor(0.0901, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(1.0576, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0170, device='cuda:0')
tensor(0.0333, device='cuda:0')
old_score: tensor(0.0424, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0237, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.598015069961548
Validation after dual ascent:
out_inf: tensor(6., device='cuda:0', dtype=torch.float16) tensor(0.0901, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.5439, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.5278, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(3.4980, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(3.3691, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(3.2012, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(3.2344, device='cuda:0', dtype=torch.float16) tensor(0.1222, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0128, device='cuda:0')
tensor(0.0701, device='cuda:0')
old_score: tensor(0.1245, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0770, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.124103784561157
Validation after dual ascent:
out_inf: tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(1.6836, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(1.6270, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(1.4785, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(1.9160, device='cuda:0', dtype=torch.float16) tensor(0.0735, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.2203, device='cuda:0', dtype=torch.float16)
tensor(1.6855, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.6582, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.5449, device='cuda:0', dtype=torch.float16) tensor(0.1192, device='cuda:0', dtype=torch.float16)
tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.1131, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0088, device='cuda:0')
tensor(0.0655, device='cuda:0')
old_score: tensor(0.1154, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0729, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.132627725601196
Validation after dual ascent:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.2203, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.8545, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0029, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.8965, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0191, device='cuda:0')
tensor(0.0444, device='cuda:0')
old_score: tensor(0.0360, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0263, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.65136003494263
Validation after dual ascent:
out_inf: tensor(1.0029, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0262, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.4785, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.6562, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(4.7734, device='cuda:0', dtype=torch.float16) tensor(0.2783, device='cuda:0', dtype=torch.float16)
tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.2795, device='cuda:0', dtype=torch.float16)
tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.2961, device='cuda:0', dtype=torch.float16)
tensor(4.0820, device='cuda:0', dtype=torch.float16) tensor(0.2712, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0150, device='cuda:0')
tensor(0.0765, device='cuda:0')
old_score: tensor(0.2812, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1654, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.771503448486328
Validation after dual ascent:
out_inf: tensor(18.6562, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1652, device='cuda:0', dtype=torch.float16)
tensor(2.1133, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(2.7109, device='cuda:0', dtype=torch.float16) tensor(0.1752, device='cuda:0', dtype=torch.float16)
tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.1567, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6719, device='cuda:0', dtype=torch.float16) tensor(1.0420, device='cuda:0', dtype=torch.float16)
tensor(3.8945, device='cuda:0', dtype=torch.float16) tensor(0.2888, device='cuda:0', dtype=torch.float16)
tensor(3.5391, device='cuda:0', dtype=torch.float16) tensor(0.2910, device='cuda:0', dtype=torch.float16)
tensor(3.8125, device='cuda:0', dtype=torch.float16) tensor(0.3071, device='cuda:0', dtype=torch.float16)
tensor(3.8867, device='cuda:0', dtype=torch.float16) tensor(0.2817, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0178, device='cuda:0')
tensor(0.0804, device='cuda:0')
old_score: tensor(0.2922, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1681, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.790714740753174
Validation after dual ascent:
out_inf: tensor(15.6719, device='cuda:0', dtype=torch.float16) tensor(1.0420, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1680, device='cuda:0', dtype=torch.float16)
tensor(1.9941, device='cuda:0', dtype=torch.float16) tensor(0.1676, device='cuda:0', dtype=torch.float16)
tensor(1.9697, device='cuda:0', dtype=torch.float16) tensor(0.1776, device='cuda:0', dtype=torch.float16)
tensor(1.8506, device='cuda:0', dtype=torch.float16) tensor(0.1592, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.1602, device='cuda:0', dtype=torch.float16) tensor(0.3081, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(1.4346, device='cuda:0', dtype=torch.float16) tensor(0.1592, device='cuda:0', dtype=torch.float16)
tensor(1.4678, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1561, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0149, device='cuda:0')
tensor(0.0759, device='cuda:0')
old_score: tensor(0.1597, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1989943981170654
Validation after dual ascent:
out_inf: tensor(6.1602, device='cuda:0', dtype=torch.float16) tensor(0.3081, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.9326, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.9521, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.8320, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
tensor(1.5195, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0126, device='cuda:0')
tensor(0.0192, device='cuda:0')
old_score: tensor(0.0434, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0256, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.595936059951782
Validation after dual ascent:
out_inf: tensor(6.8320, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.3008, device='cuda:0', dtype=torch.float16) tensor(0.3052, device='cuda:0', dtype=torch.float16)
tensor(3.1211, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(3.1133, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(3.2871, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(3.2051, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0124, device='cuda:0')
tensor(0.0748, device='cuda:0')
old_score: tensor(0.1250, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0781, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.128415584564209
Validation after dual ascent:
out_inf: tensor(6.3008, device='cuda:0', dtype=torch.float16) tensor(0.3052, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(1.4941, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.7930, device='cuda:0', dtype=torch.float16) tensor(0.2217, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.1161, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0092, device='cuda:0')
tensor(0.0714, device='cuda:0')
old_score: tensor(0.1187, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0753, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.124575138092041
Validation after dual ascent:
out_inf: tensor(4.7930, device='cuda:0', dtype=torch.float16) tensor(0.2217, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.7979, device='cuda:0', dtype=torch.float16) tensor(0.0744, device='cuda:0', dtype=torch.float16)
tensor(0.7529, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.7412, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.8643, device='cuda:0', dtype=torch.float16) tensor(0.0783, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0158, device='cuda:0')
tensor(0.0327, device='cuda:0')
old_score: tensor(0.0363, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0271, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.66376972198486
Validation after dual ascent:
out_inf: tensor(1.8643, device='cuda:0', dtype=torch.float16) tensor(0.0783, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
tensor(0.3823, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.4165, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0252, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.7969, device='cuda:0', dtype=torch.float16) tensor(0.7876, device='cuda:0', dtype=torch.float16)
tensor(4.2266, device='cuda:0', dtype=torch.float16) tensor(0.2747, device='cuda:0', dtype=torch.float16)
tensor(4.0820, device='cuda:0', dtype=torch.float16) tensor(0.2781, device='cuda:0', dtype=torch.float16)
tensor(4.3984, device='cuda:0', dtype=torch.float16) tensor(0.2927, device='cuda:0', dtype=torch.float16)
tensor(4.4766, device='cuda:0', dtype=torch.float16) tensor(0.2708, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0172, device='cuda:0')
tensor(0.0504, device='cuda:0')
old_score: tensor(0.2791, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1656, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.139142990112305
Validation after dual ascent:
out_inf: tensor(13.7969, device='cuda:0', dtype=torch.float16) tensor(0.7876, device='cuda:0', dtype=torch.float16)
tensor(2.4883, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(2.3574, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(2.2148, device='cuda:0', dtype=torch.float16) tensor(0.1769, device='cuda:0', dtype=torch.float16)
tensor(1.9248, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.5781, device='cuda:0', dtype=torch.float16) tensor(0.9829, device='cuda:0', dtype=torch.float16)
tensor(3.9531, device='cuda:0', dtype=torch.float16) tensor(0.2795, device='cuda:0', dtype=torch.float16)
tensor(3.3281, device='cuda:0', dtype=torch.float16) tensor(0.2820, device='cuda:0', dtype=torch.float16)
tensor(4.0859, device='cuda:0', dtype=torch.float16) tensor(0.2986, device='cuda:0', dtype=torch.float16)
tensor(3.6328, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0198, device='cuda:0')
tensor(0.0535, device='cuda:0')
old_score: tensor(0.2839, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1658, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.144810438156128
Validation after dual ascent:
out_inf: tensor(16.5781, device='cuda:0', dtype=torch.float16) tensor(0.9829, device='cuda:0', dtype=torch.float16)
tensor(1.8350, device='cuda:0', dtype=torch.float16) tensor(0.1650, device='cuda:0', dtype=torch.float16)
tensor(1.9883, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(2.0723, device='cuda:0', dtype=torch.float16) tensor(0.1768, device='cuda:0', dtype=torch.float16)
tensor(2.3945, device='cuda:0', dtype=torch.float16) tensor(0.1562, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.7695, device='cuda:0', dtype=torch.float16) tensor(0.3059, device='cuda:0', dtype=torch.float16)
tensor(1.4180, device='cuda:0', dtype=torch.float16) tensor(0.1639, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(1.7090, device='cuda:0', dtype=torch.float16) tensor(0.1697, device='cuda:0', dtype=torch.float16)
tensor(1.5029, device='cuda:0', dtype=torch.float16) tensor(0.1616, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0079, device='cuda:0')
tensor(0.0628, device='cuda:0')
old_score: tensor(0.1648, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1048, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1934468746185303
Validation after dual ascent:
out_inf: tensor(4.7695, device='cuda:0', dtype=torch.float16) tensor(0.3059, device='cuda:0', dtype=torch.float16)
tensor(0.9390, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(0.9092, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(0.9146, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.5078, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(1.6289, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(1.4707, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.0226, device='cuda:0')
old_score: tensor(0.0447, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0257, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.898720026016235
Validation after dual ascent:
out_inf: tensor(6.5078, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
tensor(0.7168, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.4336, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(3.2695, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(2.8672, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(3.1602, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0133, device='cuda:0')
tensor(0.0839, device='cuda:0')
old_score: tensor(0.1289, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.118467330932617
Validation after dual ascent:
out_inf: tensor(7.4336, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.0802, device='cuda:0', dtype=torch.float16)
tensor(1.4707, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(1.7510, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9297, device='cuda:0', dtype=torch.float16) tensor(0.2318, device='cuda:0', dtype=torch.float16)
tensor(1.8418, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.6309, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
tensor(1.7773, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0101, device='cuda:0')
tensor(0.0811, device='cuda:0')
old_score: tensor(0.1230, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0781, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.118306398391724
Validation after dual ascent:
out_inf: tensor(4.9297, device='cuda:0', dtype=torch.float16) tensor(0.2318, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.7646, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(0.9136, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(0.9912, device='cuda:0', dtype=torch.float16) tensor(0.0744, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0199, device='cuda:0')
tensor(0.0336, device='cuda:0')
old_score: tensor(0.0403, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0298, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 40.8571195602417
Validation after dual ascent:
out_inf: tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.3857, device='cuda:0', dtype=torch.float16) tensor(0.0285, device='cuda:0', dtype=torch.float16)
tensor(0.5122, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.3425, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.7500, device='cuda:0', dtype=torch.float16) tensor(0.7847, device='cuda:0', dtype=torch.float16)
tensor(3.9453, device='cuda:0', dtype=torch.float16) tensor(0.2844, device='cuda:0', dtype=torch.float16)
tensor(4.1055, device='cuda:0', dtype=torch.float16) tensor(0.2830, device='cuda:0', dtype=torch.float16)
tensor(5.0625, device='cuda:0', dtype=torch.float16) tensor(0.3064, device='cuda:0', dtype=torch.float16)
tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.2786, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0162, device='cuda:0')
tensor(0.0357, device='cuda:0')
old_score: tensor(0.2881, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1681, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.822073221206665
Validation after dual ascent:
out_inf: tensor(13.7500, device='cuda:0', dtype=torch.float16) tensor(0.7847, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.1676, device='cuda:0', dtype=torch.float16)
tensor(1.9668, device='cuda:0', dtype=torch.float16) tensor(0.1644, device='cuda:0', dtype=torch.float16)
tensor(2.2266, device='cuda:0', dtype=torch.float16) tensor(0.1816, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1586, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.4219, device='cuda:0', dtype=torch.float16) tensor(1.0586, device='cuda:0', dtype=torch.float16)
tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.2939, device='cuda:0', dtype=torch.float16)
tensor(3.9375, device='cuda:0', dtype=torch.float16) tensor(0.2935, device='cuda:0', dtype=torch.float16)
tensor(4.1445, device='cuda:0', dtype=torch.float16) tensor(0.3145, device='cuda:0', dtype=torch.float16)
tensor(3.5703, device='cuda:0', dtype=torch.float16) tensor(0.2896, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0196, device='cuda:0')
tensor(0.0404, device='cuda:0')
old_score: tensor(0.2979, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1685, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.826740741729736
Validation after dual ascent:
out_inf: tensor(16.4219, device='cuda:0', dtype=torch.float16) tensor(1.0586, device='cuda:0', dtype=torch.float16)
tensor(1.9824, device='cuda:0', dtype=torch.float16) tensor(0.1681, device='cuda:0', dtype=torch.float16)
tensor(1.9258, device='cuda:0', dtype=torch.float16) tensor(0.1650, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1818, device='cuda:0', dtype=torch.float16)
tensor(1.7871, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.4062, device='cuda:0', dtype=torch.float16) tensor(0.3047, device='cuda:0', dtype=torch.float16)
tensor(1.5928, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(1.4893, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
tensor(1.5654, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
tensor(1.4404, device='cuda:0', dtype=torch.float16) tensor(0.1620, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0089, device='cuda:0')
tensor(0.0694, device='cuda:0')
old_score: tensor(0.1646, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1037, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.196758985519409
Validation after dual ascent:
out_inf: tensor(4.4062, device='cuda:0', dtype=torch.float16) tensor(0.3047, device='cuda:0', dtype=torch.float16)
tensor(0.8369, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(0.9097, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(0.9307, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.o_proj
Validation after prune:
out_inf: tensor(8.4375, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(1.7539, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(1.4727, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0113, device='cuda:0')
tensor(0.0148, device='cuda:0')
old_score: tensor(0.0469, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0261, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115057468414307
Validation after dual ascent:
out_inf: tensor(8.4375, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1992, device='cuda:0', dtype=torch.float16) tensor(0.3298, device='cuda:0', dtype=torch.float16)
tensor(3.3516, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
tensor(3.4219, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(3.5098, device='cuda:0', dtype=torch.float16) tensor(0.1381, device='cuda:0', dtype=torch.float16)
tensor(3.9707, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.0954, device='cuda:0')
old_score: tensor(0.1317, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0829, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.117344617843628
Validation after dual ascent:
out_inf: tensor(7.1992, device='cuda:0', dtype=torch.float16) tensor(0.3298, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
tensor(1.6465, device='cuda:0', dtype=torch.float16) tensor(0.0794, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(1.5791, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.2305, device='cuda:0', dtype=torch.float16) tensor(0.2405, device='cuda:0', dtype=torch.float16)
tensor(1.9961, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(1.9434, device='cuda:0', dtype=torch.float16) tensor(0.1224, device='cuda:0', dtype=torch.float16)
tensor(2.0898, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0111, device='cuda:0')
tensor(0.0927, device='cuda:0')
old_score: tensor(0.1260, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0811, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.118363857269287
Validation after dual ascent:
out_inf: tensor(5.2305, device='cuda:0', dtype=torch.float16) tensor(0.2405, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
tensor(0.8418, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
tensor(0.9541, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.2051, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.6846, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.7080, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0079, device='cuda:0')
tensor(0.0172, device='cuda:0')
old_score: tensor(0.0428, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0317, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 40.85346722602844
Validation after dual ascent:
out_inf: tensor(2.2051, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0319, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.3569, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.8438, device='cuda:0', dtype=torch.float16) tensor(0.7661, device='cuda:0', dtype=torch.float16)
tensor(4.5742, device='cuda:0', dtype=torch.float16) tensor(0.2603, device='cuda:0', dtype=torch.float16)
tensor(4.3945, device='cuda:0', dtype=torch.float16) tensor(0.2605, device='cuda:0', dtype=torch.float16)
tensor(4.1797, device='cuda:0', dtype=torch.float16) tensor(0.2825, device='cuda:0', dtype=torch.float16)
tensor(4.8164, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0194, device='cuda:0')
tensor(0.0307, device='cuda:0')
old_score: tensor(0.2656, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1580, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9311740398406982
Validation after dual ascent:
out_inf: tensor(15.8438, device='cuda:0', dtype=torch.float16) tensor(0.7661, device='cuda:0', dtype=torch.float16)
tensor(1.8867, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(1.6699, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
tensor(2.1113, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.k_proj
Validation after prune:
out_inf: tensor(14.8203, device='cuda:0', dtype=torch.float16) tensor(1.0117, device='cuda:0', dtype=torch.float16)
tensor(4.0703, device='cuda:0', dtype=torch.float16) tensor(0.2742, device='cuda:0', dtype=torch.float16)
tensor(4.3594, device='cuda:0', dtype=torch.float16) tensor(0.2737, device='cuda:0', dtype=torch.float16)
tensor(4.1406, device='cuda:0', dtype=torch.float16) tensor(0.2974, device='cuda:0', dtype=torch.float16)
tensor(4.2852, device='cuda:0', dtype=torch.float16) tensor(0.2739, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0157, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.2798, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1610, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.672295808792114
Validation after dual ascent:
out_inf: tensor(14.8203, device='cuda:0', dtype=torch.float16) tensor(1.0117, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1558, device='cuda:0', dtype=torch.float16)
tensor(2.0840, device='cuda:0', dtype=torch.float16) tensor(0.1770, device='cuda:0', dtype=torch.float16)
tensor(1.9492, device='cuda:0', dtype=torch.float16) tensor(0.1517, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.0391, device='cuda:0', dtype=torch.float16) tensor(0.3069, device='cuda:0', dtype=torch.float16)
tensor(1.3799, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(1.3340, device='cuda:0', dtype=torch.float16) tensor(0.1595, device='cuda:0', dtype=torch.float16)
tensor(1.3818, device='cuda:0', dtype=torch.float16) tensor(0.1704, device='cuda:0', dtype=torch.float16)
tensor(1.3730, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0183, device='cuda:0')
tensor(0.2580, device='cuda:0')
old_score: tensor(0.1628, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1035, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4593169689178467
Validation after dual ascent:
out_inf: tensor(5.0391, device='cuda:0', dtype=torch.float16) tensor(0.3069, device='cuda:0', dtype=torch.float16)
tensor(0.8560, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.8950, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(0.8252, device='cuda:0', dtype=torch.float16) tensor(0.0978, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.5781, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(1.1055, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(1.6680, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0139, device='cuda:0')
tensor(0.0281, device='cuda:0')
old_score: tensor(0.0450, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0258, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.247611284255981
Validation after dual ascent:
out_inf: tensor(7.5781, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.3560, device='cuda:0', dtype=torch.float16)
tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(3.0645, device='cuda:0', dtype=torch.float16) tensor(0.1326, device='cuda:0', dtype=torch.float16)
tensor(2.7070, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0157, device='cuda:0')
tensor(0.0994, device='cuda:0')
old_score: tensor(0.1359, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0826, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.121862411499023
Validation after dual ascent:
out_inf: tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.3560, device='cuda:0', dtype=torch.float16)
tensor(2.1758, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(1.6523, device='cuda:0', dtype=torch.float16) tensor(0.0788, device='cuda:0', dtype=torch.float16)
tensor(1.6152, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
tensor(1.6035, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4570, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(2.1465, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(2.0918, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
tensor(2.2617, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0122, device='cuda:0')
tensor(0.0969, device='cuda:0')
old_score: tensor(0.1301, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0809, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.123860836029053
Validation after dual ascent:
out_inf: tensor(4.4570, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0802, device='cuda:0', dtype=torch.float16)
tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.0772, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.6367, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0078, device='cuda:0')
tensor(0.0169, device='cuda:0')
old_score: tensor(0.0471, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0338, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 40.82283687591553
Validation after dual ascent:
out_inf: tensor(3.6367, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.4521, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1172, device='cuda:0', dtype=torch.float16) tensor(0.7568, device='cuda:0', dtype=torch.float16)
tensor(4.5312, device='cuda:0', dtype=torch.float16) tensor(0.2632, device='cuda:0', dtype=torch.float16)
tensor(5.0781, device='cuda:0', dtype=torch.float16) tensor(0.2593, device='cuda:0', dtype=torch.float16)
tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.2842, device='cuda:0', dtype=torch.float16)
tensor(3.8398, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0148, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.2656, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1541, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.668407201766968
Validation after dual ascent:
out_inf: tensor(15.1172, device='cuda:0', dtype=torch.float16) tensor(0.7568, device='cuda:0', dtype=torch.float16)
tensor(2.2637, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
tensor(2.2559, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
tensor(2.5762, device='cuda:0', dtype=torch.float16) tensor(0.1718, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1442, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.8516, device='cuda:0', dtype=torch.float16) tensor(1.0273, device='cuda:0', dtype=torch.float16)
tensor(3.7070, device='cuda:0', dtype=torch.float16) tensor(0.2764, device='cuda:0', dtype=torch.float16)
tensor(3.4531, device='cuda:0', dtype=torch.float16) tensor(0.2766, device='cuda:0', dtype=torch.float16)
tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(3.1465, device='cuda:0', dtype=torch.float16) tensor(0.2710, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0178, device='cuda:0')
tensor(0.0222, device='cuda:0')
old_score: tensor(0.2812, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1562, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.673288345336914
Validation after dual ascent:
out_inf: tensor(15.8516, device='cuda:0', dtype=torch.float16) tensor(1.0273, device='cuda:0', dtype=torch.float16)
tensor(1.9512, device='cuda:0', dtype=torch.float16) tensor(0.1549, device='cuda:0', dtype=torch.float16)
tensor(1.6934, device='cuda:0', dtype=torch.float16) tensor(0.1500, device='cuda:0', dtype=torch.float16)
tensor(2.0664, device='cuda:0', dtype=torch.float16) tensor(0.1737, device='cuda:0', dtype=torch.float16)
tensor(1.8975, device='cuda:0', dtype=torch.float16) tensor(0.1462, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.2305, device='cuda:0', dtype=torch.float16) tensor(0.3088, device='cuda:0', dtype=torch.float16)
tensor(1.6289, device='cuda:0', dtype=torch.float16) tensor(0.1691, device='cuda:0', dtype=torch.float16)
tensor(1.4980, device='cuda:0', dtype=torch.float16) tensor(0.1660, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(1.4229, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0192, device='cuda:0')
tensor(0.2641, device='cuda:0')
old_score: tensor(0.1694, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1055, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.461400032043457
Validation after dual ascent:
out_inf: tensor(5.2305, device='cuda:0', dtype=torch.float16) tensor(0.3088, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(0.9390, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.1164, device='cuda:0', dtype=torch.float16)
tensor(0.8853, device='cuda:0', dtype=torch.float16) tensor(0.0993, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.3438, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(1.5352, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0143, device='cuda:0')
tensor(0.0324, device='cuda:0')
old_score: tensor(0.0535, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0318, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.200941801071167
Validation after dual ascent:
out_inf: tensor(7.3438, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.8223, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1562, device='cuda:0', dtype=torch.float16) tensor(0.3669, device='cuda:0', dtype=torch.float16)
tensor(3.4883, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(3.5566, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(3.4570, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(3.6758, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0186, device='cuda:0')
tensor(0.1169, device='cuda:0')
old_score: tensor(0.1451, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0859, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.126838684082031
Validation after dual ascent:
out_inf: tensor(7.1562, device='cuda:0', dtype=torch.float16) tensor(0.3669, device='cuda:0', dtype=torch.float16)
tensor(2.5879, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
tensor(2.3652, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(1.6680, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.3242, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.8652, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1436, device='cuda:0', dtype=torch.float16)
tensor(2.0918, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0142, device='cuda:0')
tensor(0.1125, device='cuda:0')
old_score: tensor(0.1365, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0834, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.12516713142395
Validation after dual ascent:
out_inf: tensor(5.3242, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
tensor(1.2949, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0929, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.5938, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
tensor(0.6924, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.7061, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.7705, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0066, device='cuda:0')
tensor(0.0130, device='cuda:0')
old_score: tensor(0.0488, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0345, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 40.75376558303833
Validation after dual ascent:
out_inf: tensor(5.5938, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
tensor(0.3799, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.4282, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.5625, device='cuda:0', dtype=torch.float16) tensor(0.7573, device='cuda:0', dtype=torch.float16)
tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.2651, device='cuda:0', dtype=torch.float16)
tensor(4.3867, device='cuda:0', dtype=torch.float16) tensor(0.2612, device='cuda:0', dtype=torch.float16)
tensor(4.9219, device='cuda:0', dtype=torch.float16) tensor(0.2871, device='cuda:0', dtype=torch.float16)
tensor(3.5879, device='cuda:0', dtype=torch.float16) tensor(0.2576, device='cuda:0', dtype=torch.float16)
tensor(0.0520, device='cuda:0')
old_score: tensor(0.2678, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1433, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.981858253479004
Validation after dual ascent:
out_inf: tensor(15.5625, device='cuda:0', dtype=torch.float16) tensor(0.7573, device='cuda:0', dtype=torch.float16)
tensor(1.7119, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(1.6924, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.8809, device='cuda:0', dtype=torch.float16) tensor(0.1603, device='cuda:0', dtype=torch.float16)
tensor(1.6377, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6094, device='cuda:0', dtype=torch.float16) tensor(0.9790, device='cuda:0', dtype=torch.float16)
tensor(3.5234, device='cuda:0', dtype=torch.float16) tensor(0.2732, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.2722, device='cuda:0', dtype=torch.float16)
tensor(3.9453, device='cuda:0', dtype=torch.float16) tensor(0.2939, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.2673, device='cuda:0', dtype=torch.float16)
tensor(0.0554, device='cuda:0')
old_score: tensor(0.2766, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1447, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.006614208221436
Validation after dual ascent:
out_inf: tensor(15.6094, device='cuda:0', dtype=torch.float16) tensor(0.9790, device='cuda:0', dtype=torch.float16)
tensor(1.7539, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
tensor(2.3340, device='cuda:0', dtype=torch.float16) tensor(0.1616, device='cuda:0', dtype=torch.float16)
tensor(1.6543, device='cuda:0', dtype=torch.float16) tensor(0.1359, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.3145, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1675, device='cuda:0', dtype=torch.float16)
tensor(1.4912, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
tensor(1.4736, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(1.6514, device='cuda:0', dtype=torch.float16) tensor(0.1656, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0125, device='cuda:0')
tensor(0.0657, device='cuda:0')
old_score: tensor(0.1686, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0996, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2016119956970215
Validation after dual ascent:
out_inf: tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.3145, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(0.9463, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(1.0381, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(0.9204, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.9844, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(1.5332, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(1.9434, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(1.4395, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0159, device='cuda:0')
tensor(0.0340, device='cuda:0')
old_score: tensor(0.0493, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0265, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.506086587905884
Validation after dual ascent:
out_inf: tensor(5.9844, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.5537, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.5210, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.1875, device='cuda:0', dtype=torch.float16) tensor(0.3892, device='cuda:0', dtype=torch.float16)
tensor(3.5508, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(3.2227, device='cuda:0', dtype=torch.float16) tensor(0.1488, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.1606, device='cuda:0', dtype=torch.float16)
tensor(3.0742, device='cuda:0', dtype=torch.float16) tensor(0.1517, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0137, device='cuda:0')
tensor(0.0173, device='cuda:0')
old_score: tensor(0.1533, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0894, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.045512676239014
Validation after dual ascent:
out_inf: tensor(10.1875, device='cuda:0', dtype=torch.float16) tensor(0.3892, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.0849, device='cuda:0', dtype=torch.float16)
tensor(1.8652, device='cuda:0', dtype=torch.float16) tensor(0.0990, device='cuda:0', dtype=torch.float16)
tensor(1.7871, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.2031, device='cuda:0', dtype=torch.float16) tensor(0.2573, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
tensor(2.7695, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
tensor(2.7891, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(2.4102, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0157, device='cuda:0')
tensor(0.1374, device='cuda:0')
old_score: tensor(0.1407, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0859, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110847473144531
Validation after dual ascent:
out_inf: tensor(7.2031, device='cuda:0', dtype=torch.float16) tensor(0.2573, device='cuda:0', dtype=torch.float16)
tensor(1.5527, device='cuda:0', dtype=torch.float16) tensor(0.0851, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.9448, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.5879, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0093, device='cuda:0')
tensor(0.0131, device='cuda:0')
old_score: tensor(0.0493, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0348, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.00897002220154
Validation after dual ascent:
out_inf: tensor(3.5879, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(0.3877, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.3943, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.3843, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.4590, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.7764, device='cuda:0', dtype=torch.float16)
tensor(3.4180, device='cuda:0', dtype=torch.float16) tensor(0.2666, device='cuda:0', dtype=torch.float16)
tensor(3.6953, device='cuda:0', dtype=torch.float16) tensor(0.2622, device='cuda:0', dtype=torch.float16)
tensor(4.7891, device='cuda:0', dtype=torch.float16) tensor(0.2856, device='cuda:0', dtype=torch.float16)
tensor(3.3828, device='cuda:0', dtype=torch.float16) tensor(0.2615, device='cuda:0', dtype=torch.float16)
tensor(0.0581, device='cuda:0')
old_score: tensor(0.2690, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1472, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.987412452697754
Validation after dual ascent:
out_inf: tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.7764, device='cuda:0', dtype=torch.float16)
tensor(1.8506, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
tensor(1.7363, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(1.5957, device='cuda:0', dtype=torch.float16) tensor(0.1399, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.1719, device='cuda:0', dtype=torch.float16) tensor(0.9575, device='cuda:0', dtype=torch.float16)
tensor(3.6328, device='cuda:0', dtype=torch.float16) tensor(0.2771, device='cuda:0', dtype=torch.float16)
tensor(3.8750, device='cuda:0', dtype=torch.float16) tensor(0.2751, device='cuda:0', dtype=torch.float16)
tensor(3.6094, device='cuda:0', dtype=torch.float16) tensor(0.2969, device='cuda:0', dtype=torch.float16)
tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.2751, device='cuda:0', dtype=torch.float16)
tensor(0.0594, device='cuda:0')
old_score: tensor(0.2810, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1482, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.00905179977417
Validation after dual ascent:
out_inf: tensor(16.1719, device='cuda:0', dtype=torch.float16) tensor(0.9575, device='cuda:0', dtype=torch.float16)
tensor(1.7832, device='cuda:0', dtype=torch.float16) tensor(0.1461, device='cuda:0', dtype=torch.float16)
tensor(1.9209, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(1.9648, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.5078, device='cuda:0', dtype=torch.float16) tensor(0.3271, device='cuda:0', dtype=torch.float16)
tensor(1.7090, device='cuda:0', dtype=torch.float16) tensor(0.1780, device='cuda:0', dtype=torch.float16)
tensor(2.0273, device='cuda:0', dtype=torch.float16) tensor(0.1754, device='cuda:0', dtype=torch.float16)
tensor(1.8721, device='cuda:0', dtype=torch.float16) tensor(0.1890, device='cuda:0', dtype=torch.float16)
tensor(1.6592, device='cuda:0', dtype=torch.float16) tensor(0.1771, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0147, device='cuda:0')
tensor(0.0858, device='cuda:0')
old_score: tensor(0.1799, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1091, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1979105472564697
Validation after dual ascent:
out_inf: tensor(4.5078, device='cuda:0', dtype=torch.float16) tensor(0.3271, device='cuda:0', dtype=torch.float16)
tensor(0.9639, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.1210, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.3281, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
tensor(1.4277, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.0367, device='cuda:0', dtype=torch.float16)
tensor(0.0524, device='cuda:0')
old_score: tensor(0.0393, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0224, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.868928670883179
Validation after dual ascent:
out_inf: tensor(5.3281, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.8320, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.1953, device='cuda:0', dtype=torch.float16) tensor(0.3879, device='cuda:0', dtype=torch.float16)
tensor(4.1680, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
tensor(4.0859, device='cuda:0', dtype=torch.float16) tensor(0.1537, device='cuda:0', dtype=torch.float16)
tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0193, device='cuda:0')
old_score: tensor(0.1577, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0921, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.045702695846558
Validation after dual ascent:
out_inf: tensor(10.1953, device='cuda:0', dtype=torch.float16) tensor(0.3879, device='cuda:0', dtype=torch.float16)
tensor(1.6562, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(1.9004, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
tensor(1.8770, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.5078, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(2.1738, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(2.2285, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0175, device='cuda:0')
tensor(0.1593, device='cuda:0')
old_score: tensor(0.1436, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0874, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.113161563873291
Validation after dual ascent:
out_inf: tensor(6.5078, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0832, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.0088, device='cuda:0', dtype=torch.float16) tensor(0.0834, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.8398, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0176, device='cuda:0')
tensor(0.0372, device='cuda:0')
old_score: tensor(0.0502, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0361, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.61292290687561
Validation after dual ascent:
out_inf: tensor(4.8398, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.4370, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.0781, device='cuda:0', dtype=torch.float16) tensor(0.7432, device='cuda:0', dtype=torch.float16)
tensor(4.2305, device='cuda:0', dtype=torch.float16) tensor(0.2603, device='cuda:0', dtype=torch.float16)
tensor(4.3594, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(5.2812, device='cuda:0', dtype=torch.float16) tensor(0.2815, device='cuda:0', dtype=torch.float16)
tensor(3.4727, device='cuda:0', dtype=torch.float16) tensor(0.2537, device='cuda:0', dtype=torch.float16)
tensor(0.1408, device='cuda:0')
old_score: tensor(0.2629, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1429, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.97781491279602
Validation after dual ascent:
out_inf: tensor(13.0781, device='cuda:0', dtype=torch.float16) tensor(0.7432, device='cuda:0', dtype=torch.float16)
tensor(1.7246, device='cuda:0', dtype=torch.float16) tensor(0.1409, device='cuda:0', dtype=torch.float16)
tensor(1.5342, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.6445, device='cuda:0', dtype=torch.float16) tensor(0.1583, device='cuda:0', dtype=torch.float16)
tensor(1.5654, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.6719, device='cuda:0', dtype=torch.float16) tensor(1.0029, device='cuda:0', dtype=torch.float16)
tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.2708, device='cuda:0', dtype=torch.float16)
tensor(3.6172, device='cuda:0', dtype=torch.float16) tensor(0.2703, device='cuda:0', dtype=torch.float16)
tensor(3.9531, device='cuda:0', dtype=torch.float16) tensor(0.2900, device='cuda:0', dtype=torch.float16)
tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
tensor(0.1442, device='cuda:0')
old_score: tensor(0.2747, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1443, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.982080698013306
Validation after dual ascent:
out_inf: tensor(17.6719, device='cuda:0', dtype=torch.float16) tensor(1.0029, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.1422, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
tensor(1.4551, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.8730, device='cuda:0', dtype=torch.float16) tensor(0.3474, device='cuda:0', dtype=torch.float16)
tensor(1.5352, device='cuda:0', dtype=torch.float16) tensor(0.1829, device='cuda:0', dtype=torch.float16)
tensor(1.5918, device='cuda:0', dtype=torch.float16) tensor(0.1801, device='cuda:0', dtype=torch.float16)
tensor(1.7861, device='cuda:0', dtype=torch.float16) tensor(0.1924, device='cuda:0', dtype=torch.float16)
tensor(1.7275, device='cuda:0', dtype=torch.float16) tensor(0.1825, device='cuda:0', dtype=torch.float16)
tensor(0.1073, device='cuda:0')
old_score: tensor(0.1844, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.906103372573853
Validation after dual ascent:
out_inf: tensor(3.8730, device='cuda:0', dtype=torch.float16) tensor(0.3474, device='cuda:0', dtype=torch.float16)
tensor(1.0371, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(0.9814, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.2852, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(1.6582, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.0384, device='cuda:0')
old_score: tensor(0.0464, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0279, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.880134582519531
Validation after dual ascent:
out_inf: tensor(6.2852, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.4297, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(3.7148, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(4.2344, device='cuda:0', dtype=torch.float16) tensor(0.1578, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0120, device='cuda:0')
tensor(0.0210, device='cuda:0')
old_score: tensor(0.1604, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0961, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.046245098114014
Validation after dual ascent:
out_inf: tensor(9.4297, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.0920, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(1.8008, device='cuda:0', dtype=torch.float16) tensor(0.0920, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.6172, device='cuda:0', dtype=torch.float16) tensor(0.2598, device='cuda:0', dtype=torch.float16)
tensor(2.6016, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(2.5234, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(2.2422, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0191, device='cuda:0')
tensor(0.1822, device='cuda:0')
old_score: tensor(0.1472, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0911, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.121978282928467
Validation after dual ascent:
out_inf: tensor(7.6172, device='cuda:0', dtype=torch.float16) tensor(0.2598, device='cuda:0', dtype=torch.float16)
tensor(0.8457, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(0.9678, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.5898, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.8521, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.8350, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0101, device='cuda:0')
tensor(0.0130, device='cuda:0')
old_score: tensor(0.0505, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0372, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.633402347564697
Validation after dual ascent:
out_inf: tensor(4.5898, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
tensor(0.4016, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(0.5068, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.6250, device='cuda:0', dtype=torch.float16) tensor(0.7617, device='cuda:0', dtype=torch.float16)
tensor(3.5703, device='cuda:0', dtype=torch.float16) tensor(0.2605, device='cuda:0', dtype=torch.float16)
tensor(3.5117, device='cuda:0', dtype=torch.float16) tensor(0.2549, device='cuda:0', dtype=torch.float16)
tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.2786, device='cuda:0', dtype=torch.float16)
tensor(3.3164, device='cuda:0', dtype=torch.float16) tensor(0.2527, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0192, device='cuda:0')
tensor(0.0202, device='cuda:0')
old_score: tensor(0.2617, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1448, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.411099195480347
Validation after dual ascent:
out_inf: tensor(14.6250, device='cuda:0', dtype=torch.float16) tensor(0.7617, device='cuda:0', dtype=torch.float16)
tensor(1.6338, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.5293, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1600, device='cuda:0', dtype=torch.float16)
tensor(1.6895, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1406, device='cuda:0', dtype=torch.float16) tensor(0.9980, device='cuda:0', dtype=torch.float16)
tensor(3.4062, device='cuda:0', dtype=torch.float16) tensor(0.2690, device='cuda:0', dtype=torch.float16)
tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
tensor(3.8555, device='cuda:0', dtype=torch.float16) tensor(0.2856, device='cuda:0', dtype=torch.float16)
tensor(3.6016, device='cuda:0', dtype=torch.float16) tensor(0.2642, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0193, device='cuda:0')
tensor(0.0241, device='cuda:0')
old_score: tensor(0.2715, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1454, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.155311346054077
Validation after dual ascent:
out_inf: tensor(17.1406, device='cuda:0', dtype=torch.float16) tensor(0.9980, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(1.7051, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.6719, device='cuda:0', dtype=torch.float16) tensor(0.1604, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.3325, device='cuda:0', dtype=torch.float16)
tensor(1.6982, device='cuda:0', dtype=torch.float16) tensor(0.1815, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1792, device='cuda:0', dtype=torch.float16)
tensor(1.7754, device='cuda:0', dtype=torch.float16) tensor(0.1895, device='cuda:0', dtype=torch.float16)
tensor(2.1426, device='cuda:0', dtype=torch.float16) tensor(0.1802, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0064, device='cuda:0')
tensor(0.0668, device='cuda:0')
old_score: tensor(0.1826, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1112, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2023403644561768
Validation after dual ascent:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.3325, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
tensor(0.9438, device='cuda:0', dtype=torch.float16) tensor(0.1066, device='cuda:0', dtype=torch.float16)
tensor(1.0898, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.1063, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.o_proj
Validation after prune:
out_inf: tensor(13.3828, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(1.9336, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0177, device='cuda:0')
tensor(0.0360, device='cuda:0')
old_score: tensor(0.0615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0358, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.168912649154663
Validation after dual ascent:
out_inf: tensor(13.3828, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.7485, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.3281, device='cuda:0', dtype=torch.float16) tensor(0.3694, device='cuda:0', dtype=torch.float16)
tensor(2.9609, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(2.9023, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
tensor(3.3750, device='cuda:0', dtype=torch.float16) tensor(0.1680, device='cuda:0', dtype=torch.float16)
tensor(3.2852, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0129, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.1600, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0955, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.03289794921875
Validation after dual ascent:
out_inf: tensor(7.3281, device='cuda:0', dtype=torch.float16) tensor(0.3694, device='cuda:0', dtype=torch.float16)
tensor(1.4570, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(1.6699, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(1.9082, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.0625, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(2.6367, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
tensor(1.8574, device='cuda:0', dtype=torch.float16) tensor(0.1449, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.1689, device='cuda:0')
old_score: tensor(0.1450, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0897, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110151767730713
Validation after dual ascent:
out_inf: tensor(6.0625, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.down_proj
Validation after prune:
out_inf: tensor(7.9961, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0100, device='cuda:0')
tensor(0.0137, device='cuda:0')
old_score: tensor(0.0489, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0356, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.58671259880066
Validation after dual ascent:
out_inf: tensor(7.9961, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(0.4543, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.4292, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4751, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.9062, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.2515, device='cuda:0', dtype=torch.float16)
tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.2473, device='cuda:0', dtype=torch.float16)
tensor(4.8359, device='cuda:0', dtype=torch.float16) tensor(0.2744, device='cuda:0', dtype=torch.float16)
tensor(3.5781, device='cuda:0', dtype=torch.float16) tensor(0.2474, device='cuda:0', dtype=torch.float16)
tensor(0.2569, device='cuda:0')
old_score: tensor(0.2551, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1396, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.98603081703186
Validation after dual ascent:
out_inf: tensor(17.9062, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(1.5605, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(0.9414, device='cuda:0', dtype=torch.float16)
tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(3.7891, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(3.7422, device='cuda:0', dtype=torch.float16) tensor(0.2747, device='cuda:0', dtype=torch.float16)
tensor(4.0078, device='cuda:0', dtype=torch.float16) tensor(0.2517, device='cuda:0', dtype=torch.float16)
tensor(0.2525, device='cuda:0')
old_score: tensor(0.2581, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1399, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.93233323097229
Validation after dual ascent:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(0.9414, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1359, device='cuda:0', dtype=torch.float16)
tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.3459, device='cuda:0', dtype=torch.float16)
tensor(1.7842, device='cuda:0', dtype=torch.float16) tensor(0.1881, device='cuda:0', dtype=torch.float16)
tensor(1.9023, device='cuda:0', dtype=torch.float16) tensor(0.1866, device='cuda:0', dtype=torch.float16)
tensor(1.7979, device='cuda:0', dtype=torch.float16) tensor(0.2004, device='cuda:0', dtype=torch.float16)
tensor(2.0273, device='cuda:0', dtype=torch.float16) tensor(0.1899, device='cuda:0', dtype=torch.float16)
tensor(0.1977, device='cuda:0')
old_score: tensor(0.1913, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1152, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.919653177261353
Validation after dual ascent:
out_inf: tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.3459, device='cuda:0', dtype=torch.float16)
tensor(1.1367, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
tensor(1.0381, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.o_proj
Validation after prune:
out_inf: tensor(8.8672, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(1.6914, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.0404, device='cuda:0')
old_score: tensor(0.0533, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0309, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.88624095916748
Validation after dual ascent:
out_inf: tensor(8.8672, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.4258, device='cuda:0', dtype=torch.float16) tensor(0.3682, device='cuda:0', dtype=torch.float16)
tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
tensor(2.6680, device='cuda:0', dtype=torch.float16) tensor(0.1600, device='cuda:0', dtype=torch.float16)
tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.1614, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0131, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.1633, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0985, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.056966304779053
Validation after dual ascent:
out_inf: tensor(7.4258, device='cuda:0', dtype=torch.float16) tensor(0.3682, device='cuda:0', dtype=torch.float16)
tensor(1.3457, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.9893, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.0469, device='cuda:0', dtype=torch.float16) tensor(0.2546, device='cuda:0', dtype=torch.float16)
tensor(1.8613, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1444, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(2.0957, device='cuda:0', dtype=torch.float16) tensor(0.1462, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0192, device='cuda:0')
tensor(0.1853, device='cuda:0')
old_score: tensor(0.1475, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0918, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1213059425354
Validation after dual ascent:
out_inf: tensor(5.0469, device='cuda:0', dtype=torch.float16) tensor(0.2546, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
tensor(1.1230, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(1.1436, device='cuda:0', dtype=torch.float16) tensor(0.0874, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.0762, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.7778, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0100, device='cuda:0')
old_score: tensor(0.0478, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0352, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.64347219467163
Validation after dual ascent:
out_inf: tensor(3.0762, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4055, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.8281, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(3.9141, device='cuda:0', dtype=torch.float16) tensor(0.2600, device='cuda:0', dtype=torch.float16)
tensor(4.1836, device='cuda:0', dtype=torch.float16) tensor(0.2598, device='cuda:0', dtype=torch.float16)
tensor(4.3008, device='cuda:0', dtype=torch.float16) tensor(0.2871, device='cuda:0', dtype=torch.float16)
tensor(3.2910, device='cuda:0', dtype=torch.float16) tensor(0.2593, device='cuda:0', dtype=torch.float16)
tensor(0.2466, device='cuda:0')
old_score: tensor(0.2666, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1472, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.98960280418396
Validation after dual ascent:
out_inf: tensor(16.8281, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1420, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.6777, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.2031, device='cuda:0', dtype=torch.float16) tensor(0.9697, device='cuda:0', dtype=torch.float16)
tensor(3.7383, device='cuda:0', dtype=torch.float16) tensor(0.2627, device='cuda:0', dtype=torch.float16)
tensor(3.7656, device='cuda:0', dtype=torch.float16) tensor(0.2644, device='cuda:0', dtype=torch.float16)
tensor(3.4922, device='cuda:0', dtype=torch.float16) tensor(0.2874, device='cuda:0', dtype=torch.float16)
tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.2639, device='cuda:0', dtype=torch.float16)
tensor(0.2476, device='cuda:0')
old_score: tensor(0.2695, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1472, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.95748233795166
Validation after dual ascent:
out_inf: tensor(20.2031, device='cuda:0', dtype=torch.float16) tensor(0.9697, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(1.6562, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(1.5098, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.7773, device='cuda:0', dtype=torch.float16) tensor(0.3560, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.1890, device='cuda:0', dtype=torch.float16)
tensor(2.2266, device='cuda:0', dtype=torch.float16) tensor(0.1897, device='cuda:0', dtype=torch.float16)
tensor(1.8477, device='cuda:0', dtype=torch.float16) tensor(0.2046, device='cuda:0', dtype=torch.float16)
tensor(2.1797, device='cuda:0', dtype=torch.float16) tensor(0.1915, device='cuda:0', dtype=torch.float16)
tensor(0.1678, device='cuda:0')
old_score: tensor(0.1936, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1184, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.944904088973999
Validation after dual ascent:
out_inf: tensor(7.7773, device='cuda:0', dtype=torch.float16) tensor(0.3560, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.1148, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
tensor(1.1230, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.3438, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(1.2031, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.0596, device='cuda:0')
old_score: tensor(0.0561, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0342, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.908000707626343
Validation after dual ascent:
out_inf: tensor(11.3438, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0319, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
tensor(0.7588, device='cuda:0', dtype=torch.float16) tensor(0.0387, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.4141, device='cuda:0', dtype=torch.float16) tensor(0.3640, device='cuda:0', dtype=torch.float16)
tensor(3.9375, device='cuda:0', dtype=torch.float16) tensor(0.1616, device='cuda:0', dtype=torch.float16)
tensor(3.2305, device='cuda:0', dtype=torch.float16) tensor(0.1604, device='cuda:0', dtype=torch.float16)
tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.1731, device='cuda:0', dtype=torch.float16)
tensor(3.8516, device='cuda:0', dtype=torch.float16) tensor(0.1625, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0124, device='cuda:0')
tensor(0.0214, device='cuda:0')
old_score: tensor(0.1644, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1000, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.063186168670654
Validation after dual ascent:
out_inf: tensor(8.4141, device='cuda:0', dtype=torch.float16) tensor(0.3640, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.0959, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.6250, device='cuda:0', dtype=torch.float16) tensor(0.2588, device='cuda:0', dtype=torch.float16)
tensor(1.8555, device='cuda:0', dtype=torch.float16) tensor(0.1449, device='cuda:0', dtype=torch.float16)
tensor(1.8418, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(2.0449, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1466, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.1805, device='cuda:0')
old_score: tensor(0.1478, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0923, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.13330864906311
Validation after dual ascent:
out_inf: tensor(5.6250, device='cuda:0', dtype=torch.float16) tensor(0.2588, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.0895, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.3438, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.5142, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0146, device='cuda:0')
tensor(0.0263, device='cuda:0')
old_score: tensor(0.0481, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0358, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.850070238113403
Validation after dual ascent:
out_inf: tensor(2.3438, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(0.3953, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.4272, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.4480, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.3125, device='cuda:0', dtype=torch.float16) tensor(0.7466, device='cuda:0', dtype=torch.float16)
tensor(5.1484, device='cuda:0', dtype=torch.float16) tensor(0.2551, device='cuda:0', dtype=torch.float16)
tensor(3.3438, device='cuda:0', dtype=torch.float16) tensor(0.2515, device='cuda:0', dtype=torch.float16)
tensor(3.9414, device='cuda:0', dtype=torch.float16) tensor(0.2759, device='cuda:0', dtype=torch.float16)
tensor(3.0859, device='cuda:0', dtype=torch.float16) tensor(0.2517, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0191, device='cuda:0')
tensor(0.0507, device='cuda:0')
old_score: tensor(0.2585, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1467, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.786391735076904
Validation after dual ascent:
out_inf: tensor(19.3125, device='cuda:0', dtype=torch.float16) tensor(0.7466, device='cuda:0', dtype=torch.float16)
tensor(1.5420, device='cuda:0', dtype=torch.float16) tensor(0.1405, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(1.8584, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.5781, device='cuda:0', dtype=torch.float16) tensor(0.8926, device='cuda:0', dtype=torch.float16)
tensor(3.9219, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(3.8047, device='cuda:0', dtype=torch.float16) tensor(0.2573, device='cuda:0', dtype=torch.float16)
tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.2766, device='cuda:0', dtype=torch.float16)
tensor(4.2891, device='cuda:0', dtype=torch.float16) tensor(0.2559, device='cuda:0', dtype=torch.float16)
tensor(0.0446, device='cuda:0')
old_score: tensor(0.2615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1470, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.946896314620972
Validation after dual ascent:
out_inf: tensor(16.5781, device='cuda:0', dtype=torch.float16) tensor(0.8926, device='cuda:0', dtype=torch.float16)
tensor(1.5449, device='cuda:0', dtype=torch.float16) tensor(0.1409, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.7598, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.7500, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(1.8369, device='cuda:0', dtype=torch.float16) tensor(0.2014, device='cuda:0', dtype=torch.float16)
tensor(1.9346, device='cuda:0', dtype=torch.float16) tensor(0.2010, device='cuda:0', dtype=torch.float16)
tensor(2.0430, device='cuda:0', dtype=torch.float16) tensor(0.2151, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.2036, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0142, device='cuda:0')
tensor(0.0827, device='cuda:0')
old_score: tensor(0.2052, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1252, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.192181348800659
Validation after dual ascent:
out_inf: tensor(4.7500, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.1270, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.1855, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.1186, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.o_proj
Validation after prune:
out_inf: tensor(13.6016, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.7832, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(0.0530, device='cuda:0')
old_score: tensor(0.0408, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0248, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.87986445426941
Validation after dual ascent:
out_inf: tensor(13.6016, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(1.5596, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.7754, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.3906, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(3.5781, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(2.8535, device='cuda:0', dtype=torch.float16) tensor(0.1614, device='cuda:0', dtype=torch.float16)
tensor(3.4766, device='cuda:0', dtype=torch.float16) tensor(0.1732, device='cuda:0', dtype=torch.float16)
tensor(2.9121, device='cuda:0', dtype=torch.float16) tensor(0.1610, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0127, device='cuda:0')
tensor(0.0204, device='cuda:0')
old_score: tensor(0.1643, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0989, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.052748680114746
Validation after dual ascent:
out_inf: tensor(8.3906, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(1.9043, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(1.8066, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.3867, device='cuda:0', dtype=torch.float16) tensor(0.2556, device='cuda:0', dtype=torch.float16)
tensor(2.0625, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(2.1055, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
tensor(1.8379, device='cuda:0', dtype=torch.float16) tensor(0.1562, device='cuda:0', dtype=torch.float16)
tensor(2.0566, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.1719, device='cuda:0')
old_score: tensor(0.1482, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0919, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1188836097717285
Validation after dual ascent:
out_inf: tensor(5.3867, device='cuda:0', dtype=torch.float16) tensor(0.2556, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(0.9199, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.5547, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.6357, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.6450, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0184, device='cuda:0')
tensor(0.0311, device='cuda:0')
old_score: tensor(0.0478, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0354, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.808847904205322
Validation after dual ascent:
out_inf: tensor(4.5547, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.4397, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
tensor(0.4326, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.4790, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.4458, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.7891, device='cuda:0', dtype=torch.float16) tensor(0.7217, device='cuda:0', dtype=torch.float16)
tensor(3.8047, device='cuda:0', dtype=torch.float16) tensor(0.2434, device='cuda:0', dtype=torch.float16)
tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.2423, device='cuda:0', dtype=torch.float16)
tensor(4.8984, device='cuda:0', dtype=torch.float16) tensor(0.2690, device='cuda:0', dtype=torch.float16)
tensor(3.2227, device='cuda:0', dtype=torch.float16) tensor(0.2377, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0174, device='cuda:0')
tensor(0.0390, device='cuda:0')
old_score: tensor(0.2482, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1389, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.762171030044556
Validation after dual ascent:
out_inf: tensor(15.7891, device='cuda:0', dtype=torch.float16) tensor(0.7217, device='cuda:0', dtype=torch.float16)
tensor(1.8633, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(1.6621, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.2031, device='cuda:0', dtype=torch.float16) tensor(0.9282, device='cuda:0', dtype=torch.float16)
tensor(2.9395, device='cuda:0', dtype=torch.float16) tensor(0.2435, device='cuda:0', dtype=torch.float16)
tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.2460, device='cuda:0', dtype=torch.float16)
tensor(4.9453, device='cuda:0', dtype=torch.float16) tensor(0.2671, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.2405, device='cuda:0', dtype=torch.float16)
tensor(0.0371, device='cuda:0')
old_score: tensor(0.2493, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1384, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.973942041397095
Validation after dual ascent:
out_inf: tensor(16.2031, device='cuda:0', dtype=torch.float16) tensor(0.9282, device='cuda:0', dtype=torch.float16)
tensor(1.7305, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1353, device='cuda:0', dtype=torch.float16)
tensor(1.7676, device='cuda:0', dtype=torch.float16) tensor(0.1571, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8477, device='cuda:0', dtype=torch.float16) tensor(0.3672, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(1.9004, device='cuda:0', dtype=torch.float16) tensor(0.1951, device='cuda:0', dtype=torch.float16)
tensor(2.2441, device='cuda:0', dtype=torch.float16) tensor(0.2108, device='cuda:0', dtype=torch.float16)
tensor(2.2676, device='cuda:0', dtype=torch.float16) tensor(0.1941, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0113, device='cuda:0')
tensor(0.0726, device='cuda:0')
old_score: tensor(0.1985, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1218, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1946873664855957
Validation after dual ascent:
out_inf: tensor(4.8477, device='cuda:0', dtype=torch.float16) tensor(0.3672, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(1.1162, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.2881, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.1406, device='cuda:0', dtype=torch.float16) tensor(0.1736, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(1.1758, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.0959, device='cuda:0')
old_score: tensor(0.0610, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0355, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.914538621902466
Validation after dual ascent:
out_inf: tensor(11.1406, device='cuda:0', dtype=torch.float16) tensor(0.1736, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.1094, device='cuda:0', dtype=torch.float16) tensor(0.3689, device='cuda:0', dtype=torch.float16)
tensor(2.7539, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(3.4766, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(3.1621, device='cuda:0', dtype=torch.float16) tensor(0.1788, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.1675, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0135, device='cuda:0')
tensor(0.0228, device='cuda:0')
old_score: tensor(0.1704, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1027, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.063989639282227
Validation after dual ascent:
out_inf: tensor(8.1094, device='cuda:0', dtype=torch.float16) tensor(0.3689, device='cuda:0', dtype=torch.float16)
tensor(2.0742, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1151, device='cuda:0', dtype=torch.float16)
tensor(1.9795, device='cuda:0', dtype=torch.float16) tensor(0.0968, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.2637, device='cuda:0', dtype=torch.float16)
tensor(2.0488, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(1.7949, device='cuda:0', dtype=torch.float16) tensor(0.1520, device='cuda:0', dtype=torch.float16)
tensor(2.0762, device='cuda:0', dtype=torch.float16) tensor(0.1606, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0196, device='cuda:0')
tensor(0.1891, device='cuda:0')
old_score: tensor(0.1536, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0955, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.12687087059021
Validation after dual ascent:
out_inf: tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.2637, device='cuda:0', dtype=torch.float16)
tensor(0.8608, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(0.8647, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.1070, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0900, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(0.5376, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.5405, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0094, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.0503, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0374, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.850579500198364
Validation after dual ascent:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(0.4275, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.4282, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.q_proj
Validation after prune:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(3.6289, device='cuda:0', dtype=torch.float16) tensor(0.2546, device='cuda:0', dtype=torch.float16)
tensor(3.3086, device='cuda:0', dtype=torch.float16) tensor(0.2583, device='cuda:0', dtype=torch.float16)
tensor(4.0117, device='cuda:0', dtype=torch.float16) tensor(0.2795, device='cuda:0', dtype=torch.float16)
tensor(2.9805, device='cuda:0', dtype=torch.float16) tensor(0.2520, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0188, device='cuda:0')
tensor(0.0524, device='cuda:0')
old_score: tensor(0.2610, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1498, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.735571384429932
Validation after dual ascent:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.1477, device='cuda:0', dtype=torch.float16)
tensor(1.9902, device='cuda:0', dtype=torch.float16) tensor(0.1697, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1719, device='cuda:0', dtype=torch.float16) tensor(0.8726, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.2554, device='cuda:0', dtype=torch.float16)
tensor(3.3906, device='cuda:0', dtype=torch.float16) tensor(0.2627, device='cuda:0', dtype=torch.float16)
tensor(3.3281, device='cuda:0', dtype=torch.float16) tensor(0.2820, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.2554, device='cuda:0', dtype=torch.float16)
tensor(0.0455, device='cuda:0')
old_score: tensor(0.2637, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1500, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.946075201034546
Validation after dual ascent:
out_inf: tensor(17.1719, device='cuda:0', dtype=torch.float16) tensor(0.8726, device='cuda:0', dtype=torch.float16)
tensor(1.6699, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.7471, device='cuda:0', dtype=torch.float16) tensor(0.1478, device='cuda:0', dtype=torch.float16)
tensor(1.6670, device='cuda:0', dtype=torch.float16) tensor(0.1700, device='cuda:0', dtype=torch.float16)
tensor(1.5459, device='cuda:0', dtype=torch.float16) tensor(0.1396, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.4805, device='cuda:0', dtype=torch.float16) tensor(0.3938, device='cuda:0', dtype=torch.float16)
tensor(2.4434, device='cuda:0', dtype=torch.float16) tensor(0.2142, device='cuda:0', dtype=torch.float16)
tensor(2.2207, device='cuda:0', dtype=torch.float16) tensor(0.2173, device='cuda:0', dtype=torch.float16)
tensor(2.6289, device='cuda:0', dtype=torch.float16) tensor(0.2322, device='cuda:0', dtype=torch.float16)
tensor(2.0840, device='cuda:0', dtype=torch.float16) tensor(0.2137, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0148, device='cuda:0')
tensor(0.0870, device='cuda:0')
old_score: tensor(0.2195, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1350, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.193566083908081
Validation after dual ascent:
out_inf: tensor(5.4805, device='cuda:0', dtype=torch.float16) tensor(0.3938, device='cuda:0', dtype=torch.float16)
tensor(1.4971, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.1963, device='cuda:0', dtype=torch.float16) tensor(0.1332, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.0781, device='cuda:0', dtype=torch.float16) tensor(0.1428, device='cuda:0', dtype=torch.float16)
tensor(1.5049, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(1.3350, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(1.7520, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.0927, device='cuda:0')
old_score: tensor(0.0419, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0222, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.882189512252808
Validation after dual ascent:
out_inf: tensor(5.0781, device='cuda:0', dtype=torch.float16) tensor(0.1428, device='cuda:0', dtype=torch.float16)
tensor(1.0869, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.8164, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.6055, device='cuda:0', dtype=torch.float16) tensor(0.3923, device='cuda:0', dtype=torch.float16)
tensor(3.3164, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(3.1523, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(3.2109, device='cuda:0', dtype=torch.float16) tensor(0.1853, device='cuda:0', dtype=torch.float16)
tensor(3.2344, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0156, device='cuda:0')
tensor(0.0264, device='cuda:0')
old_score: tensor(0.1768, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1050, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.050587892532349
Validation after dual ascent:
out_inf: tensor(7.6055, device='cuda:0', dtype=torch.float16) tensor(0.3923, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
tensor(1.8066, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.9004, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.5273, device='cuda:0', dtype=torch.float16) tensor(0.2791, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1560, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1588, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1676, device='cuda:0', dtype=torch.float16)
tensor(2.7227, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0091, device='cuda:0')
tensor(0.0224, device='cuda:0')
old_score: tensor(0.1597, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0979, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.052509069442749
Validation after dual ascent:
out_inf: tensor(6.5273, device='cuda:0', dtype=torch.float16) tensor(0.2791, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1103, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.0917, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.5972, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5986, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.5815, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0083, device='cuda:0')
tensor(0.0153, device='cuda:0')
old_score: tensor(0.0547, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0400, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.710501194000244
Validation after dual ascent:
out_inf: tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(0.4773, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.4705, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.5024, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.8906, device='cuda:0', dtype=torch.float16) tensor(0.8042, device='cuda:0', dtype=torch.float16)
tensor(4.2266, device='cuda:0', dtype=torch.float16) tensor(0.2732, device='cuda:0', dtype=torch.float16)
tensor(3.5938, device='cuda:0', dtype=torch.float16) tensor(0.2793, device='cuda:0', dtype=torch.float16)
tensor(3.9141, device='cuda:0', dtype=torch.float16) tensor(0.2949, device='cuda:0', dtype=torch.float16)
tensor(3.5156, device='cuda:0', dtype=torch.float16) tensor(0.2664, device='cuda:0', dtype=torch.float16)
tensor(0.1365, device='cuda:0')
old_score: tensor(0.2786, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1534, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.932140827178955
Validation after dual ascent:
out_inf: tensor(14.8906, device='cuda:0', dtype=torch.float16) tensor(0.8042, device='cuda:0', dtype=torch.float16)
tensor(1.7617, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.1531, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.1731, device='cuda:0', dtype=torch.float16)
tensor(1.6230, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.6719, device='cuda:0', dtype=torch.float16) tensor(0.9990, device='cuda:0', dtype=torch.float16)
tensor(4.0938, device='cuda:0', dtype=torch.float16) tensor(0.2759, device='cuda:0', dtype=torch.float16)
tensor(3.3906, device='cuda:0', dtype=torch.float16) tensor(0.2847, device='cuda:0', dtype=torch.float16)
tensor(3.9297, device='cuda:0', dtype=torch.float16) tensor(0.2964, device='cuda:0', dtype=torch.float16)
tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.2727, device='cuda:0', dtype=torch.float16)
tensor(0.1463, device='cuda:0')
old_score: tensor(0.2825, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1532, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.947840929031372
Validation after dual ascent:
out_inf: tensor(17.6719, device='cuda:0', dtype=torch.float16) tensor(0.9990, device='cuda:0', dtype=torch.float16)
tensor(1.6348, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.7236, device='cuda:0', dtype=torch.float16) tensor(0.1528, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.6211, device='cuda:0', dtype=torch.float16) tensor(0.4236, device='cuda:0', dtype=torch.float16)
tensor(2.4004, device='cuda:0', dtype=torch.float16) tensor(0.2272, device='cuda:0', dtype=torch.float16)
tensor(2.1992, device='cuda:0', dtype=torch.float16) tensor(0.2341, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.2426, device='cuda:0', dtype=torch.float16)
tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.2257, device='cuda:0', dtype=torch.float16)
tensor(0.1229, device='cuda:0')
old_score: tensor(0.2324, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1414, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.958901166915894
Validation after dual ascent:
out_inf: tensor(5.6211, device='cuda:0', dtype=torch.float16) tensor(0.4236, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
tensor(1.4209, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(1.4424, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1312, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.o_proj
Validation after prune:
out_inf: tensor(20.2031, device='cuda:0', dtype=torch.float16) tensor(0.2013, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
tensor(2.4766, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.0705, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
tensor(0.0865, device='cuda:0')
old_score: tensor(0.0650, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0385, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.897813081741333
Validation after dual ascent:
out_inf: tensor(20.2031, device='cuda:0', dtype=torch.float16) tensor(0.2013, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.8872, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1367, device='cuda:0', dtype=torch.float16) tensor(0.4241, device='cuda:0', dtype=torch.float16)
tensor(3.0039, device='cuda:0', dtype=torch.float16) tensor(0.1809, device='cuda:0', dtype=torch.float16)
tensor(6.2891, device='cuda:0', dtype=torch.float16) tensor(0.1873, device='cuda:0', dtype=torch.float16)
tensor(4.0117, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(3.0840, device='cuda:0', dtype=torch.float16) tensor(0.1796, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0184, device='cuda:0')
tensor(0.0306, device='cuda:0')
old_score: tensor(0.1854, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1080, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.058831930160522
Validation after dual ascent:
out_inf: tensor(7.1367, device='cuda:0', dtype=torch.float16) tensor(0.4241, device='cuda:0', dtype=torch.float16)
tensor(2.2012, device='cuda:0', dtype=torch.float16) tensor(0.1022, device='cuda:0', dtype=torch.float16)
tensor(1.9336, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.5898, device='cuda:0', dtype=torch.float16) tensor(0.3032, device='cuda:0', dtype=torch.float16)
tensor(2.0605, device='cuda:0', dtype=torch.float16) tensor(0.1641, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.1752, device='cuda:0', dtype=torch.float16)
tensor(2.4473, device='cuda:0', dtype=torch.float16) tensor(0.1631, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0110, device='cuda:0')
tensor(0.0259, device='cuda:0')
old_score: tensor(0.1674, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1010, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.03472638130188
Validation after dual ascent:
out_inf: tensor(5.5898, device='cuda:0', dtype=torch.float16) tensor(0.3032, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(1.4639, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.8770, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(0.7041, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.7686, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.6333, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0061, device='cuda:0')
tensor(0.0114, device='cuda:0')
old_score: tensor(0.0610, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0438, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.736164331436157
Validation after dual ascent:
out_inf: tensor(2.8770, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(0.5347, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.4854, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.7700, device='cuda:0', dtype=torch.float16)
tensor(3.8672, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(4.0781, device='cuda:0', dtype=torch.float16) tensor(0.2827, device='cuda:0', dtype=torch.float16)
tensor(4.0078, device='cuda:0', dtype=torch.float16) tensor(0.2996, device='cuda:0', dtype=torch.float16)
tensor(3.8359, device='cuda:0', dtype=torch.float16) tensor(0.2744, device='cuda:0', dtype=torch.float16)
tensor(0.2226, device='cuda:0')
old_score: tensor(0.2834, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1528, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.934006929397583
Validation after dual ascent:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.7700, device='cuda:0', dtype=torch.float16)
tensor(1.4170, device='cuda:0', dtype=torch.float16) tensor(0.1449, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1516, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1731, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.5312, device='cuda:0', dtype=torch.float16) tensor(0.9033, device='cuda:0', dtype=torch.float16)
tensor(5.1797, device='cuda:0', dtype=torch.float16) tensor(0.2820, device='cuda:0', dtype=torch.float16)
tensor(4.4297, device='cuda:0', dtype=torch.float16) tensor(0.2937, device='cuda:0', dtype=torch.float16)
tensor(4.8672, device='cuda:0', dtype=torch.float16) tensor(0.3074, device='cuda:0', dtype=torch.float16)
tensor(4.2109, device='cuda:0', dtype=torch.float16) tensor(0.2812, device='cuda:0', dtype=torch.float16)
tensor(0.2253, device='cuda:0')
old_score: tensor(0.2910, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1538, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.955875396728516
Validation after dual ascent:
out_inf: tensor(16.5312, device='cuda:0', dtype=torch.float16) tensor(0.9033, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1530, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1741, device='cuda:0', dtype=torch.float16)
tensor(1.5518, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.9062, device='cuda:0', dtype=torch.float16) tensor(0.4021, device='cuda:0', dtype=torch.float16)
tensor(2.3633, device='cuda:0', dtype=torch.float16) tensor(0.2196, device='cuda:0', dtype=torch.float16)
tensor(2.6133, device='cuda:0', dtype=torch.float16) tensor(0.2268, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.2361, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.2185, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0143, device='cuda:0')
tensor(0.1961, device='cuda:0')
old_score: tensor(0.2253, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1344, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.773975372314453
Validation after dual ascent:
out_inf: tensor(6.9062, device='cuda:0', dtype=torch.float16) tensor(0.4021, device='cuda:0', dtype=torch.float16)
tensor(1.3018, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.3232, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
tensor(1.3232, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.1084, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.0290, device='cuda:0', dtype=torch.float16)
tensor(0.1049, device='cuda:0')
old_score: tensor(0.0307, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0163, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.895544290542603
Validation after dual ascent:
out_inf: tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.1084, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.5312, device='cuda:0', dtype=torch.float16) tensor(0.4543, device='cuda:0', dtype=torch.float16)
tensor(3.8711, device='cuda:0', dtype=torch.float16) tensor(0.1893, device='cuda:0', dtype=torch.float16)
tensor(3.3164, device='cuda:0', dtype=torch.float16) tensor(0.1969, device='cuda:0', dtype=torch.float16)
tensor(5.3398, device='cuda:0', dtype=torch.float16) tensor(0.2035, device='cuda:0', dtype=torch.float16)
tensor(3.7266, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0186, device='cuda:0')
tensor(0.0176, device='cuda:0')
old_score: tensor(0.1943, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1092, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.000285387039185
Validation after dual ascent:
out_inf: tensor(9.5312, device='cuda:0', dtype=torch.float16) tensor(0.4543, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(2.5605, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(2.5215, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
tensor(2.3770, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.4219, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(2.4336, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.1775, device='cuda:0', dtype=torch.float16)
tensor(2.3496, device='cuda:0', dtype=torch.float16) tensor(0.1842, device='cuda:0', dtype=torch.float16)
tensor(2.7461, device='cuda:0', dtype=torch.float16) tensor(0.1716, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0132, device='cuda:0')
tensor(0.0293, device='cuda:0')
old_score: tensor(0.1765, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1026, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.045835494995117
Validation after dual ascent:
out_inf: tensor(7.4219, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(0.8096, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0694, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0069, device='cuda:0')
tensor(0.0112, device='cuda:0')
old_score: tensor(0.0679, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0473, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.702531099319458
Validation after dual ascent:
out_inf: tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.5366, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5581, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.2656, device='cuda:0', dtype=torch.float16) tensor(0.7979, device='cuda:0', dtype=torch.float16)
tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.2878, device='cuda:0', dtype=torch.float16)
tensor(4.1797, device='cuda:0', dtype=torch.float16) tensor(0.2969, device='cuda:0', dtype=torch.float16)
tensor(4.4375, device='cuda:0', dtype=torch.float16) tensor(0.3098, device='cuda:0', dtype=torch.float16)
tensor(4.0703, device='cuda:0', dtype=torch.float16) tensor(0.2844, device='cuda:0', dtype=torch.float16)
tensor(0.1817, device='cuda:0')
old_score: tensor(0.2947, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1550, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.957725048065186
Validation after dual ascent:
out_inf: tensor(14.2656, device='cuda:0', dtype=torch.float16) tensor(0.7979, device='cuda:0', dtype=torch.float16)
tensor(1.6680, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(1.7021, device='cuda:0', dtype=torch.float16) tensor(0.1539, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(1.3887, device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.5312, device='cuda:0', dtype=torch.float16) tensor(0.9600, device='cuda:0', dtype=torch.float16)
tensor(4.7734, device='cuda:0', dtype=torch.float16) tensor(0.2947, device='cuda:0', dtype=torch.float16)
tensor(4.7031, device='cuda:0', dtype=torch.float16) tensor(0.3066, device='cuda:0', dtype=torch.float16)
tensor(5.1875, device='cuda:0', dtype=torch.float16) tensor(0.3220, device='cuda:0', dtype=torch.float16)
tensor(4.9141, device='cuda:0', dtype=torch.float16) tensor(0.2922, device='cuda:0', dtype=torch.float16)
tensor(0.1991, device='cuda:0')
old_score: tensor(0.3040, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1556, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.969526529312134
Validation after dual ascent:
out_inf: tensor(18.5312, device='cuda:0', dtype=torch.float16) tensor(0.9600, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1550, device='cuda:0', dtype=torch.float16)
tensor(2.0820, device='cuda:0', dtype=torch.float16) tensor(0.1765, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1438, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.1133, device='cuda:0', dtype=torch.float16) tensor(0.4536, device='cuda:0', dtype=torch.float16)
tensor(2.5059, device='cuda:0', dtype=torch.float16) tensor(0.2427, device='cuda:0', dtype=torch.float16)
tensor(2.4727, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.2598, device='cuda:0', dtype=torch.float16)
tensor(2.4961, device='cuda:0', dtype=torch.float16) tensor(0.2424, device='cuda:0', dtype=torch.float16)
tensor(0.1476, device='cuda:0')
old_score: tensor(0.2495, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1448, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.981218576431274
Validation after dual ascent:
out_inf: tensor(7.1133, device='cuda:0', dtype=torch.float16) tensor(0.4536, device='cuda:0', dtype=torch.float16)
tensor(1.4668, device='cuda:0', dtype=torch.float16) tensor(0.1371, device='cuda:0', dtype=torch.float16)
tensor(1.4629, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(1.5889, device='cuda:0', dtype=torch.float16) tensor(0.1638, device='cuda:0', dtype=torch.float16)
tensor(1.4287, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.o_proj
Validation after prune:
out_inf: tensor(9.9141, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(2.5293, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(2.7480, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(2.4121, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.1160, device='cuda:0')
old_score: tensor(0.0460, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0230, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.88881540298462
Validation after dual ascent:
out_inf: tensor(9.9141, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(2.0352, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.1250, device='cuda:0', dtype=torch.float16) tensor(0.4688, device='cuda:0', dtype=torch.float16)
tensor(4.1836, device='cuda:0', dtype=torch.float16) tensor(0.1995, device='cuda:0', dtype=torch.float16)
tensor(5.3086, device='cuda:0', dtype=torch.float16) tensor(0.2084, device='cuda:0', dtype=torch.float16)
tensor(5.0391, device='cuda:0', dtype=torch.float16) tensor(0.2137, device='cuda:0', dtype=torch.float16)
tensor(4.7852, device='cuda:0', dtype=torch.float16) tensor(0.1976, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0197, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.2048, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1131, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.971017122268677
Validation after dual ascent:
out_inf: tensor(10.1250, device='cuda:0', dtype=torch.float16) tensor(0.4688, device='cuda:0', dtype=torch.float16)
tensor(2.2148, device='cuda:0', dtype=torch.float16) tensor(0.1072, device='cuda:0', dtype=torch.float16)
tensor(2.4629, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(2.5293, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.2148, device='cuda:0', dtype=torch.float16) tensor(0.3687, device='cuda:0', dtype=torch.float16)
tensor(3.4961, device='cuda:0', dtype=torch.float16) tensor(0.1865, device='cuda:0', dtype=torch.float16)
tensor(2.9023, device='cuda:0', dtype=torch.float16) tensor(0.1946, device='cuda:0', dtype=torch.float16)
tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.2000, device='cuda:0', dtype=torch.float16)
tensor(2.8008, device='cuda:0', dtype=torch.float16) tensor(0.1859, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0167, device='cuda:0')
tensor(0.0406, device='cuda:0')
old_score: tensor(0.1918, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1080, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.038386583328247
Validation after dual ascent:
out_inf: tensor(7.2148, device='cuda:0', dtype=torch.float16) tensor(0.3687, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.7988, device='cuda:0', dtype=torch.float16) tensor(0.1888, device='cuda:0', dtype=torch.float16)
tensor(0.8916, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(0.8530, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.9712, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0160, device='cuda:0')
tensor(0.1254, device='cuda:0')
old_score: tensor(0.0795, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0556, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.940825462341309
Validation after dual ascent:
out_inf: tensor(3.7988, device='cuda:0', dtype=torch.float16) tensor(0.1888, device='cuda:0', dtype=torch.float16)
tensor(0.9004, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.7676, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.7485, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.9922, device='cuda:0', dtype=torch.float16) tensor(0.7969, device='cuda:0', dtype=torch.float16)
tensor(4.6328, device='cuda:0', dtype=torch.float16) tensor(0.2832, device='cuda:0', dtype=torch.float16)
tensor(3.9961, device='cuda:0', dtype=torch.float16) tensor(0.2961, device='cuda:0', dtype=torch.float16)
tensor(4.4219, device='cuda:0', dtype=torch.float16) tensor(0.3113, device='cuda:0', dtype=torch.float16)
tensor(3.8594, device='cuda:0', dtype=torch.float16) tensor(0.2786, device='cuda:0', dtype=torch.float16)
tensor(0.0241, device='cuda:0')
old_score: tensor(0.2922, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1471, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.95255732536316
Validation after dual ascent:
out_inf: tensor(12.9922, device='cuda:0', dtype=torch.float16) tensor(0.7969, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(1.5527, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.4219, device='cuda:0', dtype=torch.float16) tensor(1.0166, device='cuda:0', dtype=torch.float16)
tensor(4.9922, device='cuda:0', dtype=torch.float16) tensor(0.2920, device='cuda:0', dtype=torch.float16)
tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.3064, device='cuda:0', dtype=torch.float16)
tensor(5.0312, device='cuda:0', dtype=torch.float16) tensor(0.3218, device='cuda:0', dtype=torch.float16)
tensor(4.4297, device='cuda:0', dtype=torch.float16) tensor(0.2866, device='cuda:0', dtype=torch.float16)
tensor(0.0264, device='cuda:0')
old_score: tensor(0.3018, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1483, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.973290205001831
Validation after dual ascent:
out_inf: tensor(18.4219, device='cuda:0', dtype=torch.float16) tensor(1.0166, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1476, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.2500, device='cuda:0', dtype=torch.float16) tensor(0.4434, device='cuda:0', dtype=torch.float16)
tensor(3.0312, device='cuda:0', dtype=torch.float16) tensor(0.2429, device='cuda:0', dtype=torch.float16)
tensor(2.3867, device='cuda:0', dtype=torch.float16) tensor(0.2522, device='cuda:0', dtype=torch.float16)
tensor(2.9902, device='cuda:0', dtype=torch.float16) tensor(0.2620, device='cuda:0', dtype=torch.float16)
tensor(2.7695, device='cuda:0', dtype=torch.float16) tensor(0.2413, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0108, device='cuda:0')
tensor(0.0825, device='cuda:0')
old_score: tensor(0.2495, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1436, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2012391090393066
Validation after dual ascent:
out_inf: tensor(6.2500, device='cuda:0', dtype=torch.float16) tensor(0.4434, device='cuda:0', dtype=torch.float16)
tensor(1.3369, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(1.3213, device='cuda:0', dtype=torch.float16) tensor(0.1324, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.o_proj
Validation after prune:
out_inf: tensor(18.1250, device='cuda:0', dtype=torch.float16) tensor(0.2019, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(4.9297, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.1092, device='cuda:0')
old_score: tensor(0.0633, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0342, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.866303443908691
Validation after dual ascent:
out_inf: tensor(18.1250, device='cuda:0', dtype=torch.float16) tensor(0.2019, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.8750, device='cuda:0', dtype=torch.float16) tensor(0.4880, device='cuda:0', dtype=torch.float16)
tensor(4.5312, device='cuda:0', dtype=torch.float16) tensor(0.2063, device='cuda:0', dtype=torch.float16)
tensor(4.0391, device='cuda:0', dtype=torch.float16) tensor(0.2162, device='cuda:0', dtype=torch.float16)
tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.2195, device='cuda:0', dtype=torch.float16)
tensor(3.9102, device='cuda:0', dtype=torch.float16) tensor(0.2048, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0156, device='cuda:0')
tensor(0.0161, device='cuda:0')
old_score: tensor(0.2117, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1151, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.910452604293823
Validation after dual ascent:
out_inf: tensor(10.8750, device='cuda:0', dtype=torch.float16) tensor(0.4880, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1086, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(2.6367, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
tensor(2.3262, device='cuda:0', dtype=torch.float16) tensor(0.1076, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.up_proj
Validation after prune:
out_inf: tensor(8.9141, device='cuda:0', dtype=torch.float16) tensor(0.4167, device='cuda:0', dtype=torch.float16)
tensor(5.8203, device='cuda:0', dtype=torch.float16) tensor(0.1976, device='cuda:0', dtype=torch.float16)
tensor(6.6406, device='cuda:0', dtype=torch.float16) tensor(0.2065, device='cuda:0', dtype=torch.float16)
tensor(5.9531, device='cuda:0', dtype=torch.float16) tensor(0.2126, device='cuda:0', dtype=torch.float16)
tensor(5.6680, device='cuda:0', dtype=torch.float16) tensor(0.1965, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0192, device='cuda:0')
tensor(0.0187, device='cuda:0')
old_score: tensor(0.2034, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.974159002304077
Validation after dual ascent:
out_inf: tensor(8.9141, device='cuda:0', dtype=torch.float16) tensor(0.4167, device='cuda:0', dtype=torch.float16)
tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(3.1250, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(4.3516, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(3.3086, device='cuda:0', dtype=torch.float16) tensor(0.1034, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.down_proj
Validation after prune:
out_inf: tensor(19.1250, device='cuda:0', dtype=torch.float16) tensor(0.2389, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0084, device='cuda:0')
tensor(0.0184, device='cuda:0')
old_score: tensor(0.0923, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0630, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.724817991256714
Validation after dual ascent:
out_inf: tensor(19.1250, device='cuda:0', dtype=torch.float16) tensor(0.2389, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.8994, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
tensor(0.8604, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.8213, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.3906, device='cuda:0', dtype=torch.float16) tensor(0.8213, device='cuda:0', dtype=torch.float16)
tensor(4.7070, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.3118, device='cuda:0', dtype=torch.float16)
tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(4.6406, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(0.2649, device='cuda:0')
old_score: tensor(0.3086, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1505, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.980144023895264
Validation after dual ascent:
out_inf: tensor(14.3906, device='cuda:0', dtype=torch.float16) tensor(0.8213, device='cuda:0', dtype=torch.float16)
tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1500, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(1.4463, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1094, device='cuda:0', dtype=torch.float16) tensor(0.9673, device='cuda:0', dtype=torch.float16)
tensor(5.7656, device='cuda:0', dtype=torch.float16) tensor(0.3123, device='cuda:0', dtype=torch.float16)
tensor(5.0938, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(5.5781, device='cuda:0', dtype=torch.float16) tensor(0.3413, device='cuda:0', dtype=torch.float16)
tensor(4.9844, device='cuda:0', dtype=torch.float16) tensor(0.3142, device='cuda:0', dtype=torch.float16)
tensor(0.2867, device='cuda:0')
old_score: tensor(0.3240, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1531, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.93773627281189
Validation after dual ascent:
out_inf: tensor(17.1094, device='cuda:0', dtype=torch.float16) tensor(0.9673, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1442, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
tensor(1.9375, device='cuda:0', dtype=torch.float16) tensor(0.1732, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.7500, device='cuda:0', dtype=torch.float16) tensor(0.4841, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.2590, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.2708, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.2778, device='cuda:0', dtype=torch.float16)
tensor(2.0918, device='cuda:0', dtype=torch.float16) tensor(0.2593, device='cuda:0', dtype=torch.float16)
tensor(0.2451, device='cuda:0')
old_score: tensor(0.2666, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1479, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.94280481338501
Validation after dual ascent:
out_inf: tensor(8.7500, device='cuda:0', dtype=torch.float16) tensor(0.4841, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1396, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1477, device='cuda:0', dtype=torch.float16)
tensor(1.4385, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
tensor(1.3457, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.o_proj
Validation after prune:
out_inf: tensor(20.3750, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.1305, device='cuda:0')
old_score: tensor(0.0450, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0224, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.870961666107178
Validation after dual ascent:
out_inf: tensor(20.3750, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.0279, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.gate_proj
Validation after prune:
out_inf: tensor(35.9688, device='cuda:0', dtype=torch.float16) tensor(0.5342, device='cuda:0', dtype=torch.float16)
tensor(27.5938, device='cuda:0', dtype=torch.float16) tensor(0.2219, device='cuda:0', dtype=torch.float16)
tensor(27.5625, device='cuda:0', dtype=torch.float16) tensor(0.2313, device='cuda:0', dtype=torch.float16)
tensor(26.6250, device='cuda:0', dtype=torch.float16) tensor(0.2380, device='cuda:0', dtype=torch.float16)
tensor(26.7812, device='cuda:0', dtype=torch.float16) tensor(0.2220, device='cuda:0', dtype=torch.float16)
tensor(0.0257, device='cuda:0')
old_score: tensor(0.2284, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1156, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 39.005593061447144
Validation after dual ascent:
out_inf: tensor(35.9688, device='cuda:0', dtype=torch.float16) tensor(0.5342, device='cuda:0', dtype=torch.float16)
tensor(7.6875, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(10.2812, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(10.1406, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(7.8125, device='cuda:0', dtype=torch.float16) tensor(0.1076, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.up_proj
Validation after prune:
out_inf: tensor(36.6562, device='cuda:0', dtype=torch.float16) tensor(0.5015, device='cuda:0', dtype=torch.float16)
tensor(25.4688, device='cuda:0', dtype=torch.float16) tensor(0.2153, device='cuda:0', dtype=torch.float16)
tensor(25.2344, device='cuda:0', dtype=torch.float16) tensor(0.2256, device='cuda:0', dtype=torch.float16)
tensor(25.6250, device='cuda:0', dtype=torch.float16) tensor(0.2340, device='cuda:0', dtype=torch.float16)
tensor(21.0469, device='cuda:0', dtype=torch.float16) tensor(0.2150, device='cuda:0', dtype=torch.float16)
tensor(0.0251, device='cuda:0')
old_score: tensor(0.2224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1107, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 39.02441716194153
Validation after dual ascent:
out_inf: tensor(36.6562, device='cuda:0', dtype=torch.float16) tensor(0.5015, device='cuda:0', dtype=torch.float16)
tensor(8.7188, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(10.2500, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(10.1406, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(8.2812, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.down_proj
Validation after prune:
out_inf: tensor(1588., device='cuda:0', dtype=torch.float16) tensor(0.4314, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(0.0243, device='cuda:0')
old_score: tensor(0.1119, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0721, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.37728953361511
Validation after dual ascent:
out_inf: tensor(1588., device='cuda:0', dtype=torch.float16) tensor(0.4314, device='cuda:0', dtype=torch.float16)
tensor(0.9751, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(1.0518, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.1484, device='cuda:0', dtype=torch.float16) tensor(0.8633, device='cuda:0', dtype=torch.float16)
tensor(5.3164, device='cuda:0', dtype=torch.float16) tensor(0.2981, device='cuda:0', dtype=torch.float16)
tensor(6.0039, device='cuda:0', dtype=torch.float16) tensor(0.3101, device='cuda:0', dtype=torch.float16)
tensor(5.8164, device='cuda:0', dtype=torch.float16) tensor(0.3296, device='cuda:0', dtype=torch.float16)
tensor(4.8828, device='cuda:0', dtype=torch.float16) tensor(0.3003, device='cuda:0', dtype=torch.float16)
tensor(0.0271, device='cuda:0')
old_score: tensor(0.3096, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1262, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.961625576019287
Validation after dual ascent:
out_inf: tensor(13.1484, device='cuda:0', dtype=torch.float16) tensor(0.8633, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1189, device='cuda:0', dtype=torch.float16)
tensor(3.5703, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1159, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.7812, device='cuda:0', dtype=torch.float16) tensor(1.0889, device='cuda:0', dtype=torch.float16)
tensor(6.5469, device='cuda:0', dtype=torch.float16) tensor(0.3242, device='cuda:0', dtype=torch.float16)
tensor(6.9922, device='cuda:0', dtype=torch.float16) tensor(0.3359, device='cuda:0', dtype=torch.float16)
tensor(7.1875, device='cuda:0', dtype=torch.float16) tensor(0.3540, device='cuda:0', dtype=torch.float16)
tensor(5.7969, device='cuda:0', dtype=torch.float16) tensor(0.3271, device='cuda:0', dtype=torch.float16)
tensor(0.0346, device='cuda:0')
old_score: tensor(0.3352, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1299, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.979625225067139
Validation after dual ascent:
out_inf: tensor(18.7812, device='cuda:0', dtype=torch.float16) tensor(1.0889, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
tensor(2.4219, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.9570, device='cuda:0', dtype=torch.float16) tensor(0.3879, device='cuda:0', dtype=torch.float16)
tensor(2.6445, device='cuda:0', dtype=torch.float16) tensor(0.2104, device='cuda:0', dtype=torch.float16)
tensor(4.2344, device='cuda:0', dtype=torch.float16) tensor(0.2178, device='cuda:0', dtype=torch.float16)
tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.2227, device='cuda:0', dtype=torch.float16)
tensor(2.5117, device='cuda:0', dtype=torch.float16) tensor(0.2107, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0100, device='cuda:0')
tensor(0.0315, device='cuda:0')
old_score: tensor(0.2153, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1115, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.199190139770508
Validation after dual ascent:
out_inf: tensor(7.9570, device='cuda:0', dtype=torch.float16) tensor(0.3879, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(2.7812, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.o_proj
Validation after prune:
out_inf: tensor(258.7500, device='cuda:0', dtype=torch.float16) tensor(0.3191, device='cuda:0', dtype=torch.float16)
tensor(4.5156, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(10.9375, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(10.0938, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(3.6406, device='cuda:0', dtype=torch.float16) tensor(0.1295, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.0380, device='cuda:0')
old_score: tensor(0.1350, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0584, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4516940116882324
Validation after dual ascent:
out_inf: tensor(258.7500, device='cuda:0', dtype=torch.float16) tensor(0.3191, device='cuda:0', dtype=torch.float16)
tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0563, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.gate_proj
Validation after prune:
out_inf: tensor(30.0781, device='cuda:0', dtype=torch.float16) tensor(0.6016, device='cuda:0', dtype=torch.float16)
tensor(12.6406, device='cuda:0', dtype=torch.float16) tensor(0.2427, device='cuda:0', dtype=torch.float16)
tensor(14.0469, device='cuda:0', dtype=torch.float16) tensor(0.2566, device='cuda:0', dtype=torch.float16)
tensor(13.6250, device='cuda:0', dtype=torch.float16) tensor(0.2646, device='cuda:0', dtype=torch.float16)
tensor(14.0312, device='cuda:0', dtype=torch.float16) tensor(0.2499, device='cuda:0', dtype=torch.float16)
tensor(0.0407, device='cuda:0')
old_score: tensor(0.2534, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1073, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.91079807281494
Validation after dual ascent:
out_inf: tensor(30.0781, device='cuda:0', dtype=torch.float16) tensor(0.6016, device='cuda:0', dtype=torch.float16)
tensor(2.4199, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
tensor(3.5742, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(2.6367, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(3.0527, device='cuda:0', dtype=torch.float16) tensor(0.0990, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.up_proj
Validation after prune:
out_inf: tensor(33.8125, device='cuda:0', dtype=torch.float16) tensor(0.6318, device='cuda:0', dtype=torch.float16)
tensor(17.2812, device='cuda:0', dtype=torch.float16) tensor(0.2400, device='cuda:0', dtype=torch.float16)
tensor(21.7031, device='cuda:0', dtype=torch.float16) tensor(0.2546, device='cuda:0', dtype=torch.float16)
tensor(18.4219, device='cuda:0', dtype=torch.float16) tensor(0.2646, device='cuda:0', dtype=torch.float16)
tensor(18.2188, device='cuda:0', dtype=torch.float16) tensor(0.2435, device='cuda:0', dtype=torch.float16)
tensor(0.0377, device='cuda:0')
old_score: tensor(0.2507, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1019, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.92910122871399
Validation after dual ascent:
out_inf: tensor(33.8125, device='cuda:0', dtype=torch.float16) tensor(0.6318, device='cuda:0', dtype=torch.float16)
tensor(4.6953, device='cuda:0', dtype=torch.float16) tensor(0.0959, device='cuda:0', dtype=torch.float16)
tensor(2.9219, device='cuda:0', dtype=torch.float16) tensor(0.1015, device='cuda:0', dtype=torch.float16)
tensor(3.9766, device='cuda:0', dtype=torch.float16) tensor(0.1164, device='cuda:0', dtype=torch.float16)
tensor(6.4531, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.down_proj
Validation after prune:
out_inf: tensor(153.6250, device='cuda:0', dtype=torch.float16) tensor(1.6084, device='cuda:0', dtype=torch.float16)
tensor(5., device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(5.9688, device='cuda:0', dtype=torch.float16) tensor(0.1710, device='cuda:0', dtype=torch.float16)
tensor(6.2500, device='cuda:0', dtype=torch.float16) tensor(0.1808, device='cuda:0', dtype=torch.float16)
tensor(5.0625, device='cuda:0', dtype=torch.float16) tensor(0.1691, device='cuda:0', dtype=torch.float16)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.02it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.68it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.56it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25': 0, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.799840
layer 1 sparsity 0.799840
layer 2 sparsity 0.799840
layer 3 sparsity 0.799840
layer 4 sparsity 0.799840
layer 5 sparsity 0.799840
layer 6 sparsity 0.799840
layer 7 sparsity 0.799840
layer 8 sparsity 0.799840
layer 9 sparsity 0.799840
layer 10 sparsity 0.799840
layer 11 sparsity 0.799840
layer 12 sparsity 0.799840
layer 13 sparsity 0.799840
layer 14 sparsity 0.799840
layer 15 sparsity 0.799840
layer 16 sparsity 0.799840
layer 17 sparsity 0.799840
layer 18 sparsity 0.799840
layer 19 sparsity 0.799840
layer 20 sparsity 0.799840
layer 21 sparsity 0.799840
layer 22 sparsity 0.799840
layer 23 sparsity 0.799840
layer 24 sparsity 0.799840
layer 25 sparsity 0.799840
layer 26 sparsity 0.799840
layer 27 sparsity 0.799840
layer 28 sparsity 0.799840
layer 29 sparsity 0.799840
layer 30 sparsity 0.799840
layer 31 sparsity 0.799840
sparsity sanity check 0.7998
******************************
evaluating on wikitext2
nsamples 83
sample 0
sample 50
wikitext perplexity 87.20243072509766
wanda_dual_3	0.7998	87.2024	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.8, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='wanda_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
2025-04-24 03:41:45.223382: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 03:41:45.421071: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 03:41:45.426515: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 03:41:45.426540: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 03:41:48.955655: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 03:41:48.956195: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 03:41:48.956212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.85it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.26it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.19it/s]
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
model.embed_tokens.weight torch.Size([32000, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([32000, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:00<03:21,  1.26it/s]  1%|          | 2/256 [00:01<03:13,  1.31it/s]  2%|▏         | 4/256 [00:01<01:37,  2.59it/s]  2%|▏         | 5/256 [00:02<01:54,  2.19it/s]  2%|▏         | 6/256 [00:02<01:32,  2.70it/s]  3%|▎         | 7/256 [00:03<02:32,  1.64it/s]  3%|▎         | 8/256 [00:03<01:59,  2.08it/s]  4%|▎         | 9/256 [00:04<01:32,  2.68it/s]  4%|▍         | 11/256 [00:04<00:59,  4.12it/s]  5%|▍         | 12/256 [00:04<00:52,  4.65it/s]  5%|▌         | 13/256 [00:05<01:37,  2.49it/s]  5%|▌         | 14/256 [00:05<01:33,  2.60it/s]  6%|▌         | 15/256 [00:05<01:18,  3.08it/s]  6%|▋         | 16/256 [00:06<01:07,  3.57it/s]  7%|▋         | 18/256 [00:06<01:08,  3.47it/s]  8%|▊         | 20/256 [00:06<00:51,  4.60it/s]  8%|▊         | 21/256 [00:06<00:45,  5.15it/s]  9%|▊         | 22/256 [00:07<00:48,  4.80it/s]  9%|▉         | 24/256 [00:07<00:42,  5.46it/s] 10%|▉         | 25/256 [00:07<00:40,  5.73it/s] 10%|█         | 26/256 [00:08<00:53,  4.29it/s] 11%|█         | 28/256 [00:08<00:44,  5.16it/s] 11%|█▏        | 29/256 [00:08<00:45,  5.00it/s] 12%|█▏        | 31/256 [00:08<00:37,  5.93it/s] 12%|█▎        | 32/256 [00:09<00:45,  4.89it/s] 13%|█▎        | 33/256 [00:09<00:56,  3.93it/s] 13%|█▎        | 34/256 [00:09<01:00,  3.66it/s] 14%|█▎        | 35/256 [00:10<01:07,  3.26it/s] 14%|█▍        | 36/256 [00:10<01:18,  2.80it/s] 14%|█▍        | 37/256 [00:11<01:13,  2.99it/s] 15%|█▍        | 38/256 [00:11<01:07,  3.23it/s] 16%|█▌        | 40/256 [00:11<01:02,  3.47it/s] 16%|█▋        | 42/256 [00:11<00:43,  4.90it/s] 17%|█▋        | 43/256 [00:12<00:38,  5.49it/s] 17%|█▋        | 44/256 [00:12<00:38,  5.56it/s] 18%|█▊        | 46/256 [00:12<00:32,  6.43it/s] 18%|█▊        | 47/256 [00:12<00:33,  6.24it/s] 19%|█▉        | 48/256 [00:12<00:36,  5.64it/s] 19%|█▉        | 49/256 [00:13<00:33,  6.12it/s] 20%|█▉        | 50/256 [00:13<00:48,  4.25it/s] 21%|██        | 53/256 [00:14<00:47,  4.26it/s] 21%|██        | 54/256 [00:14<00:46,  4.34it/s] 21%|██▏       | 55/256 [00:14<00:40,  4.97it/s] 22%|██▏       | 56/256 [00:14<00:47,  4.22it/s] 22%|██▏       | 57/256 [00:14<00:43,  4.55it/s] 23%|██▎       | 58/256 [00:15<00:48,  4.06it/s] 23%|██▎       | 59/256 [00:15<00:42,  4.61it/s] 23%|██▎       | 60/256 [00:15<00:45,  4.28it/s] 24%|██▍       | 61/256 [00:16<00:53,  3.64it/s] 24%|██▍       | 62/256 [00:16<00:58,  3.32it/s] 25%|██▍       | 63/256 [00:16<00:50,  3.80it/s] 25%|██▌       | 64/256 [00:16<00:42,  4.56it/s] 25%|██▌       | 65/256 [00:17<01:08,  2.78it/s] 26%|██▌       | 67/256 [00:17<00:43,  4.32it/s] 27%|██▋       | 68/256 [00:17<00:42,  4.42it/s] 27%|██▋       | 69/256 [00:18<00:42,  4.35it/s] 28%|██▊       | 71/256 [00:18<00:33,  5.58it/s] 29%|██▊       | 73/256 [00:18<00:26,  6.86it/s] 29%|██▉       | 74/256 [00:18<00:26,  6.78it/s] 29%|██▉       | 75/256 [00:18<00:31,  5.67it/s] 30%|██▉       | 76/256 [00:19<00:45,  3.98it/s] 30%|███       | 78/256 [00:19<00:30,  5.77it/s] 31%|███       | 79/256 [00:19<00:38,  4.59it/s] 31%|███▏      | 80/256 [00:20<00:49,  3.56it/s] 32%|███▏      | 81/256 [00:20<00:54,  3.24it/s] 32%|███▏      | 82/256 [00:20<00:44,  3.90it/s] 32%|███▏      | 83/256 [00:21<00:55,  3.10it/s] 33%|███▎      | 84/256 [00:21<00:52,  3.27it/s] 33%|███▎      | 85/256 [00:21<00:48,  3.54it/s] 34%|███▎      | 86/256 [00:22<00:44,  3.81it/s] 34%|███▍      | 87/256 [00:22<01:02,  2.71it/s] 34%|███▍      | 88/256 [00:23<01:04,  2.62it/s] 35%|███▍      | 89/256 [00:23<00:59,  2.79it/s] 35%|███▌      | 90/256 [00:23<01:02,  2.65it/s] 36%|███▌      | 91/256 [00:24<01:00,  2.75it/s] 36%|███▌      | 92/256 [00:24<00:49,  3.28it/s] 36%|███▋      | 93/256 [00:24<00:43,  3.77it/s] 37%|███▋      | 94/256 [00:24<00:50,  3.18it/s] 37%|███▋      | 95/256 [00:25<01:04,  2.50it/s] 38%|███▊      | 96/256 [00:25<00:51,  3.12it/s] 38%|███▊      | 97/256 [00:26<00:55,  2.87it/s] 38%|███▊      | 98/256 [00:26<00:46,  3.40it/s] 39%|███▊      | 99/256 [00:26<00:44,  3.52it/s] 39%|███▉      | 100/256 [00:26<00:42,  3.68it/s] 39%|███▉      | 101/256 [00:27<01:14,  2.09it/s] 40%|███▉      | 102/256 [00:27<01:04,  2.40it/s] 41%|████      | 104/256 [00:28<00:41,  3.68it/s] 41%|████▏     | 106/256 [00:28<00:33,  4.42it/s] 42%|████▏     | 107/256 [00:28<00:33,  4.44it/s] 42%|████▏     | 108/256 [00:29<00:48,  3.07it/s] 43%|████▎     | 111/256 [00:29<00:30,  4.79it/s] 44%|████▍     | 112/256 [00:29<00:31,  4.56it/s] 44%|████▍     | 113/256 [00:30<00:31,  4.55it/s] 45%|████▍     | 114/256 [00:30<00:28,  4.97it/s] 45%|████▍     | 115/256 [00:30<00:27,  5.21it/s] 45%|████▌     | 116/256 [00:30<00:37,  3.70it/s] 46%|████▌     | 117/256 [00:30<00:31,  4.46it/s] 46%|████▌     | 118/256 [00:31<00:29,  4.71it/s] 47%|████▋     | 120/256 [00:31<00:20,  6.58it/s] 47%|████▋     | 121/256 [00:31<00:19,  6.94it/s] 48%|████▊     | 122/256 [00:32<00:37,  3.61it/s] 48%|████▊     | 123/256 [00:32<00:40,  3.31it/s] 48%|████▊     | 124/256 [00:33<00:52,  2.54it/s] 49%|████▉     | 125/256 [00:34<01:22,  1.59it/s] 49%|████▉     | 126/256 [00:34<01:09,  1.88it/s] 50%|████▉     | 127/256 [00:35<01:15,  1.72it/s] 50%|█████     | 129/256 [00:35<00:45,  2.80it/s] 51%|█████     | 130/256 [00:35<00:41,  3.05it/s] 51%|█████     | 131/256 [00:35<00:38,  3.24it/s] 52%|█████▏    | 132/256 [00:36<00:36,  3.36it/s] 52%|█████▏    | 133/256 [00:36<00:44,  2.74it/s] 52%|█████▏    | 134/256 [00:37<00:44,  2.73it/s] 53%|█████▎    | 135/256 [00:37<00:35,  3.37it/s] 53%|█████▎    | 136/256 [00:37<00:36,  3.33it/s] 54%|█████▎    | 137/256 [00:37<00:30,  3.94it/s] 54%|█████▍    | 138/256 [00:37<00:26,  4.37it/s] 54%|█████▍    | 139/256 [00:38<00:24,  4.79it/s] 55%|█████▍    | 140/256 [00:38<00:22,  5.19it/s] 55%|█████▌    | 142/256 [00:38<00:16,  6.73it/s] 56%|█████▌    | 143/256 [00:38<00:16,  6.92it/s] 57%|█████▋    | 145/256 [00:39<00:34,  3.21it/s] 57%|█████▋    | 146/256 [00:40<00:38,  2.87it/s] 57%|█████▋    | 147/256 [00:40<00:35,  3.09it/s] 58%|█████▊    | 148/256 [00:40<00:36,  3.00it/s] 59%|█████▊    | 150/256 [00:41<00:29,  3.63it/s] 59%|█████▉    | 151/256 [00:41<00:25,  4.19it/s] 59%|█████▉    | 152/256 [00:41<00:28,  3.70it/s] 60%|█████▉    | 153/256 [00:41<00:25,  4.10it/s] 60%|██████    | 154/256 [00:42<00:29,  3.52it/s] 61%|██████    | 155/256 [00:42<00:26,  3.87it/s] 61%|██████    | 156/256 [00:42<00:21,  4.59it/s] 61%|██████▏   | 157/256 [00:42<00:27,  3.64it/s] 62%|██████▏   | 158/256 [00:43<00:23,  4.14it/s] 62%|██████▏   | 159/256 [00:43<00:42,  2.29it/s] 62%|██████▎   | 160/256 [00:44<00:32,  2.94it/s] 63%|██████▎   | 162/256 [00:44<00:36,  2.57it/s] 64%|██████▎   | 163/256 [00:45<00:32,  2.88it/s] 64%|██████▍   | 164/256 [00:45<00:26,  3.43it/s] 65%|██████▍   | 166/256 [00:45<00:22,  4.02it/s] 65%|██████▌   | 167/256 [00:46<00:24,  3.59it/s] 66%|██████▌   | 168/256 [00:46<00:27,  3.16it/s] 66%|██████▌   | 169/256 [00:47<00:31,  2.74it/s] 66%|██████▋   | 170/256 [00:47<00:31,  2.75it/s] 67%|██████▋   | 172/256 [00:47<00:21,  3.83it/s] 68%|██████▊   | 173/256 [00:47<00:21,  3.95it/s] 68%|██████▊   | 174/256 [00:48<00:28,  2.90it/s] 68%|██████▊   | 175/256 [00:49<00:40,  2.01it/s] 69%|██████▉   | 176/256 [00:49<00:35,  2.28it/s] 69%|██████▉   | 177/256 [00:49<00:29,  2.71it/s] 70%|██████▉   | 179/256 [00:50<00:19,  3.91it/s] 70%|███████   | 180/256 [00:51<00:37,  2.05it/s] 71%|███████   | 181/256 [00:51<00:29,  2.55it/s] 71%|███████   | 182/256 [00:52<00:38,  1.95it/s] 72%|███████▏  | 184/256 [00:53<00:35,  2.03it/s] 72%|███████▏  | 185/256 [00:53<00:28,  2.50it/s] 73%|███████▎  | 186/256 [00:53<00:22,  3.07it/s] 73%|███████▎  | 187/256 [00:54<00:27,  2.50it/s] 73%|███████▎  | 188/256 [00:54<00:23,  2.92it/s] 74%|███████▍  | 189/256 [00:54<00:22,  2.96it/s] 74%|███████▍  | 190/256 [00:54<00:20,  3.22it/s] 75%|███████▍  | 191/256 [00:54<00:18,  3.53it/s] 75%|███████▌  | 192/256 [00:55<00:21,  2.93it/s] 75%|███████▌  | 193/256 [00:55<00:20,  3.04it/s] 77%|███████▋  | 196/256 [00:56<00:13,  4.54it/s] 77%|███████▋  | 197/256 [00:56<00:15,  3.90it/s] 78%|███████▊  | 199/256 [00:56<00:11,  4.97it/s] 79%|███████▊  | 201/256 [00:57<00:09,  5.60it/s] 79%|███████▉  | 202/256 [00:57<00:11,  4.60it/s] 80%|███████▉  | 204/256 [00:57<00:08,  5.83it/s] 80%|████████  | 206/256 [00:57<00:06,  7.22it/s] 81%|████████  | 207/256 [00:57<00:06,  7.53it/s] 81%|████████▏ | 208/256 [00:58<00:07,  6.51it/s] 82%|████████▏ | 210/256 [00:58<00:05,  8.45it/s] 83%|████████▎ | 212/256 [00:58<00:05,  8.24it/s] 83%|████████▎ | 213/256 [00:58<00:05,  7.33it/s] 84%|████████▎ | 214/256 [00:59<00:07,  5.47it/s] 84%|████████▍ | 215/256 [00:59<00:09,  4.42it/s] 84%|████████▍ | 216/256 [00:59<00:09,  4.34it/s] 85%|████████▌ | 218/256 [00:59<00:07,  5.12it/s] 86%|████████▌ | 219/256 [01:01<00:15,  2.45it/s] 86%|████████▌ | 220/256 [01:01<00:12,  2.87it/s] 86%|████████▋ | 221/256 [01:01<00:12,  2.83it/s] 87%|████████▋ | 222/256 [01:01<00:12,  2.79it/s] 87%|████████▋ | 223/256 [01:02<00:12,  2.68it/s] 88%|████████▊ | 224/256 [01:04<00:24,  1.32it/s] 88%|████████▊ | 225/256 [01:04<00:22,  1.35it/s] 88%|████████▊ | 226/256 [01:04<00:17,  1.75it/s] 89%|████████▊ | 227/256 [01:05<00:13,  2.08it/s] 89%|████████▉ | 228/256 [01:05<00:12,  2.23it/s] 89%|████████▉ | 229/256 [01:06<00:18,  1.43it/s] 90%|████████▉ | 230/256 [01:06<00:13,  1.89it/s] 90%|█████████ | 231/256 [01:07<00:12,  1.92it/s] 91%|█████████ | 232/256 [01:07<00:10,  2.20it/s] 91%|█████████ | 233/256 [01:07<00:08,  2.65it/s] 92%|█████████▏| 235/256 [01:08<00:05,  3.69it/s] 92%|█████████▏| 236/256 [01:08<00:05,  3.56it/s] 93%|█████████▎| 237/256 [01:08<00:04,  3.94it/s] 93%|█████████▎| 238/256 [01:08<00:03,  4.61it/s] 93%|█████████▎| 239/256 [01:09<00:03,  4.52it/s] 94%|█████████▍| 241/256 [01:09<00:02,  5.75it/s] 95%|█████████▍| 242/256 [01:10<00:04,  2.82it/s] 95%|█████████▌| 244/256 [01:10<00:02,  4.30it/s] 96%|█████████▌| 245/256 [01:10<00:02,  4.27it/s] 96%|█████████▌| 246/256 [01:10<00:02,  4.74it/s] 97%|█████████▋| 248/256 [01:10<00:01,  6.31it/s] 97%|█████████▋| 249/256 [01:11<00:01,  3.84it/s] 98%|█████████▊| 251/256 [01:11<00:00,  5.38it/s] 98%|█████████▊| 252/256 [01:12<00:01,  3.47it/s] 99%|█████████▉| 253/256 [01:12<00:01,  2.92it/s]100%|█████████▉| 255/256 [01:13<00:00,  3.03it/s]100%|██████████| 256/256 [01:13<00:00,  3.08it/s]100%|██████████| 256/256 [01:13<00:00,  3.47it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
0 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.8555, device='cuda:0', dtype=torch.float16) tensor(0.6099, device='cuda:0', dtype=torch.float16)
tensor(0.0156, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0317, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0371, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0215, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
0 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.0205, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0293, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0469, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0273, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
0 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0121, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0111, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0133, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0125, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
0 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0109, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0099, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0100, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0111, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0169, device='cuda:0')
tensor(0.0494, device='cuda:0')
old_score: tensor(0.0005, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0004, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.059605836868286
Validation after dual ascent:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0088, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0114, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
tensor(0.0089, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
tensor(0.0106, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
0 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1724, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.1602, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0160, device='cuda:0')
tensor(0.0236, device='cuda:0')
old_score: tensor(0.0066, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0052, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 23.329121589660645
Validation after dual ascent:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.1484, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.1421, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.1724, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.1387, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
0 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.1890, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.1455, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0159, device='cuda:0')
tensor(0.0234, device='cuda:0')
old_score: tensor(0.0066, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0052, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 23.435608386993408
Validation after dual ascent:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1587, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.1313, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1738, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.1265, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
0 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0157, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0193, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0233, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0250, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0574, device='cuda:0')
old_score: tensor(0.0009, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.43872737884521
Validation after dual ascent:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0154, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0176, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0237, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0240, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
layer 0 done
1 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.2344, device='cuda:0', dtype=torch.float16) tensor(0.7808, device='cuda:0', dtype=torch.float16)
tensor(0.2700, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.2729, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.2920, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2690, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
1 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.6523, device='cuda:0', dtype=torch.float16) tensor(0.7861, device='cuda:0', dtype=torch.float16)
tensor(0.3638, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.3662, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.3799, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
1 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5713, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.0488, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.0499, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.0542, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.0503, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0135, device='cuda:0')
tensor(0.0208, device='cuda:0')
old_score: tensor(0.0039, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0031, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.220295667648315
Validation after dual ascent:
out_inf: tensor(1.5713, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.0451, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0511, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0514, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0538, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
1 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.5747, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.0262, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0276, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0279, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0294, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0192, device='cuda:0')
old_score: tensor(0.0016, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0015, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.90311074256897
Validation after dual ascent:
out_inf: tensor(0.5747, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.0275, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0265, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0294, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0267, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
1 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(43.7500, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.2188, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.2090, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.2637, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0144, device='cuda:0')
tensor(0.0251, device='cuda:0')
old_score: tensor(0.0152, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 33.09399151802063
Validation after dual ascent:
out_inf: tensor(43.7500, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.1816, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.2178, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.2266, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
1 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(37.6562, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.2285, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.1973, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.2305, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.2383, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0186, device='cuda:0')
tensor(0.0233, device='cuda:0')
old_score: tensor(0.0143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0118, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 25.374443769454956
Validation after dual ascent:
out_inf: tensor(37.6562, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1938, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.2100, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
1 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(2672., device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.0659, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0764, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0868, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(3.9786, device='cuda:0')
old_score: tensor(0.0039, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0168, device='cuda:0', dtype=torch.float16)
Not converged!
Dual ascent finished!
Time: 98.37301254272461
Validation after dual ascent:
out_inf: tensor(2672., device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.0659, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0764, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0868, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
layer 1 done
2 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.2344, device='cuda:0', dtype=torch.float16) tensor(0.9028, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0348, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
2 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.6328, device='cuda:0', dtype=torch.float16) tensor(1.0547, device='cuda:0', dtype=torch.float16)
tensor(0.6260, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.5225, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
2 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9570, device='cuda:0', dtype=torch.float16) tensor(0.1318, device='cuda:0', dtype=torch.float16)
tensor(0.2190, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.2322, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.2378, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(0.2467, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0133, device='cuda:0')
tensor(0.0423, device='cuda:0')
old_score: tensor(0.0228, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0196, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1774067878723145
Validation after dual ascent:
out_inf: tensor(2.9570, device='cuda:0', dtype=torch.float16) tensor(0.1318, device='cuda:0', dtype=torch.float16)
tensor(0.2191, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
tensor(0.2264, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
tensor(0.2186, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.2443, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
2 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0366, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0339, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0396, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0421, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0344, device='cuda:0')
old_score: tensor(0.0022, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0021, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.927200317382812
Validation after dual ascent:
out_inf: tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0350, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0307, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0320, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0364, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
2 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(0.2571, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.2693, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.2607, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.2681, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(0.0210, device='cuda:0')
old_score: tensor(0.0248, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0220, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.866960287094116
Validation after dual ascent:
out_inf: tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(0.2444, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.2576, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(0.2395, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
tensor(0.2598, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
2 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.2266, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
tensor(0.2324, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
tensor(0.2664, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.2769, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0190, device='cuda:0')
tensor(0.0276, device='cuda:0')
old_score: tensor(0.0230, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0205, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 31.11285376548767
Validation after dual ascent:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.2211, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
tensor(0.2432, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.2490, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(0.2871, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
2 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
tensor(0.0676, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0692, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0681, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0715, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0854, device='cuda:0')
old_score: tensor(0.0046, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0043, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.6202301979065
Validation after dual ascent:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
tensor(0.0641, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0677, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0688, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.0724, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
layer 2 done
3 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.0625, device='cuda:0', dtype=torch.float16) tensor(0.8184, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
tensor(0.8643, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(0.7568, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
3 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.4531, device='cuda:0', dtype=torch.float16) tensor(0.9819, device='cuda:0', dtype=torch.float16)
tensor(0.6978, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(0.6924, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
3 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7637, device='cuda:0', dtype=torch.float16) tensor(0.1967, device='cuda:0', dtype=torch.float16)
tensor(0.3931, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(0.3853, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.3845, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.3787, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0196, device='cuda:0')
tensor(0.2256, device='cuda:0')
old_score: tensor(0.0415, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0375, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7246651649475098
Validation after dual ascent:
out_inf: tensor(2.7637, device='cuda:0', dtype=torch.float16) tensor(0.1967, device='cuda:0', dtype=torch.float16)
tensor(0.3748, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.3860, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.3726, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.3726, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
3 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3994, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.0561, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0528, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0555, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0592, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0257, device='cuda:0')
old_score: tensor(0.0032, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0030, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.93046522140503
Validation after dual ascent:
out_inf: tensor(1.3994, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.0515, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.0536, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0452, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0590, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
3 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8242, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(0.3276, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.3569, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.3572, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0198, device='cuda:0')
tensor(0.0233, device='cuda:0')
old_score: tensor(0.0342, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0312, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.885669708251953
Validation after dual ascent:
out_inf: tensor(4.8242, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(0.3179, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.3379, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.3708, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.3442, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
3 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.5098, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(0.3176, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.3362, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.3086, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0176, device='cuda:0')
tensor(0.0198, device='cuda:0')
old_score: tensor(0.0316, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0290, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.904176235198975
Validation after dual ascent:
out_inf: tensor(2.5098, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.3069, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.3376, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
3 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.4404, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.0873, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.0781, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0776, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0925, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0127, device='cuda:0')
tensor(0.0209, device='cuda:0')
old_score: tensor(0.0069, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 89.16070032119751
Validation after dual ascent:
out_inf: tensor(1.4404, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.0828, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0750, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.0822, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.0854, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
layer 3 done
4 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.0625, device='cuda:0', dtype=torch.float16) tensor(0.8042, device='cuda:0', dtype=torch.float16)
tensor(0.7065, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(0.6929, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.7900, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.8887, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
4 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.6562, device='cuda:0', dtype=torch.float16) tensor(1.0273, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.0700, device='cuda:0', dtype=torch.float16)
tensor(0.7744, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
4 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.1582, device='cuda:0', dtype=torch.float16) tensor(0.2001, device='cuda:0', dtype=torch.float16)
tensor(0.3579, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.4077, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0067, device='cuda:0')
tensor(0.0291, device='cuda:0')
old_score: tensor(0.0439, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0401, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.189244031906128
Validation after dual ascent:
out_inf: tensor(3.1582, device='cuda:0', dtype=torch.float16) tensor(0.2001, device='cuda:0', dtype=torch.float16)
tensor(0.3474, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.3569, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.3877, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.4641, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
4 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2207, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.0758, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.0734, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.0704, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0813, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0170, device='cuda:0')
old_score: tensor(0.0055, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.923715353012085
Validation after dual ascent:
out_inf: tensor(3.2207, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.0746, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0778, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0677, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.0939, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
4 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.7734, device='cuda:0', dtype=torch.float16) tensor(0.1951, device='cuda:0', dtype=torch.float16)
tensor(0.4065, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.3896, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4097, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.4360, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0178, device='cuda:0')
tensor(0.1915, device='cuda:0')
old_score: tensor(0.0417, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0384, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.1768481731414795
Validation after dual ascent:
out_inf: tensor(4.7734, device='cuda:0', dtype=torch.float16) tensor(0.1951, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.4065, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.4268, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
4 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.0332, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(0.3467, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.3562, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.4351, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0139, device='cuda:0')
tensor(0.1729, device='cuda:0')
old_score: tensor(0.0377, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0347, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.180768013000488
Validation after dual ascent:
out_inf: tensor(3.0332, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(0.3364, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.3689, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
4 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.3906, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
tensor(0.0921, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.0850, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.0922, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1028, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0121, device='cuda:0')
tensor(0.0193, device='cuda:0')
old_score: tensor(0.0103, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0098, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.91418766975403
Validation after dual ascent:
out_inf: tensor(9.3906, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
tensor(0.0898, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0876, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.0950, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1049, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
layer 4 done
5 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.7266, device='cuda:0', dtype=torch.float16) tensor(0.8120, device='cuda:0', dtype=torch.float16)
tensor(0.7041, device='cuda:0', dtype=torch.float16) tensor(0.0788, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.9160, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
5 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.9688, device='cuda:0', dtype=torch.float16) tensor(1.0664, device='cuda:0', dtype=torch.float16)
tensor(0.7393, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.6958, device='cuda:0', dtype=torch.float16) tensor(0.0794, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
5 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4473, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(0.3857, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.3987, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.4978, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0194, device='cuda:0')
tensor(0.0409, device='cuda:0')
old_score: tensor(0.0480, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0444, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4612598419189453
Validation after dual ascent:
out_inf: tensor(2.4473, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.4211, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.3735, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
5 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.5898, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.0887, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0924, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0870, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0849, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.0186, device='cuda:0')
old_score: tensor(0.0065, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0060, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.935433626174927
Validation after dual ascent:
out_inf: tensor(4.5898, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.0768, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0789, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0806, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.0852, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
5 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3086, device='cuda:0', dtype=torch.float16) tensor(0.2266, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(0.4448, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.3884, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
tensor(0.3799, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0117, device='cuda:0')
tensor(0.0183, device='cuda:0')
old_score: tensor(0.0465, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0429, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.965028762817383
Validation after dual ascent:
out_inf: tensor(3.3086, device='cuda:0', dtype=torch.float16) tensor(0.2266, device='cuda:0', dtype=torch.float16)
tensor(0.3784, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.3833, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.3801, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.3816, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
5 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0938, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
tensor(0.3657, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.0241, device='cuda:0')
old_score: tensor(0.0420, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0388, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.118016004562378
Validation after dual ascent:
out_inf: tensor(4.0938, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.3396, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.3745, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
5 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5566, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.1213, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1567, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1072, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1198, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0195, device='cuda:0')
tensor(0.0129, device='cuda:0')
old_score: tensor(0.0128, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0123, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 31.526385068893433
Validation after dual ascent:
out_inf: tensor(1.5566, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.1265, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.1389, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1019, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1224, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
layer 5 done
6 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.5859, device='cuda:0', dtype=torch.float16) tensor(0.8325, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(0.7705, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0134, device='cuda:0')
tensor(0.0563, device='cuda:0')
old_score: tensor(0.0944, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0870, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2075130939483643
Validation after dual ascent:
out_inf: tensor(13.5859, device='cuda:0', dtype=torch.float16) tensor(0.8325, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
tensor(0.7998, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
tensor(0.7817, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.7627, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
6 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.5312, device='cuda:0', dtype=torch.float16) tensor(1.0098, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(0.7666, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
6 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.4316, device='cuda:0', dtype=torch.float16) tensor(0.2515, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.4229, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.4253, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0119, device='cuda:0')
tensor(0.0562, device='cuda:0')
old_score: tensor(0.0567, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0525, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.466082811355591
Validation after dual ascent:
out_inf: tensor(3.4316, device='cuda:0', dtype=torch.float16) tensor(0.2515, device='cuda:0', dtype=torch.float16)
tensor(0.4106, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.4517, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
6 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2500, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
tensor(0.1105, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1129, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1154, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.0991, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0131, device='cuda:0')
tensor(0.0234, device='cuda:0')
old_score: tensor(0.0094, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.345090627670288
Validation after dual ascent:
out_inf: tensor(4.2500, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
tensor(0.1129, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.1128, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1077, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.0977, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
6 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4805, device='cuda:0', dtype=torch.float16) tensor(0.2800, device='cuda:0', dtype=torch.float16)
tensor(0.4329, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0492, device='cuda:0', dtype=torch.float16)
tensor(0.4150, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0239, device='cuda:0')
old_score: tensor(0.0513, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0475, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.108148813247681
Validation after dual ascent:
out_inf: tensor(4.4805, device='cuda:0', dtype=torch.float16) tensor(0.2800, device='cuda:0', dtype=torch.float16)
tensor(0.4009, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.4280, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.4106, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
6 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9727, device='cuda:0', dtype=torch.float16) tensor(0.1781, device='cuda:0', dtype=torch.float16)
tensor(0.3828, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.4414, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.3867, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.3911, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0178, device='cuda:0')
tensor(0.2606, device='cuda:0')
old_score: tensor(0.0455, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0421, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.185664415359497
Validation after dual ascent:
out_inf: tensor(2.9727, device='cuda:0', dtype=torch.float16) tensor(0.1781, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.3730, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
6 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.4756, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.1609, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
tensor(0.1384, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.1261, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.1367, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0091, device='cuda:0')
tensor(0.0170, device='cuda:0')
old_score: tensor(0.0152, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0145, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.92258644104004
Validation after dual ascent:
out_inf: tensor(1.4756, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.1667, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1354, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.1255, device='cuda:0', dtype=torch.float16) tensor(0.0136, device='cuda:0', dtype=torch.float16)
tensor(0.1442, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
layer 6 done
7 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.0156, device='cuda:0', dtype=torch.float16) tensor(0.8291, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
tensor(0.8623, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0105, device='cuda:0')
tensor(0.0550, device='cuda:0')
old_score: tensor(0.0979, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0902, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2051444053649902
Validation after dual ascent:
out_inf: tensor(17.0156, device='cuda:0', dtype=torch.float16) tensor(0.8291, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(0.9414, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
7 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.0938, device='cuda:0', dtype=torch.float16) tensor(0.9863, device='cuda:0', dtype=torch.float16)
tensor(0.7549, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.8335, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(0.7202, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(0.8540, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
7 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8828, device='cuda:0', dtype=torch.float16) tensor(0.2634, device='cuda:0', dtype=torch.float16)
tensor(0.4888, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.4695, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.4646, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0061, device='cuda:0')
tensor(0.0633, device='cuda:0')
old_score: tensor(0.0596, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0552, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.464404344558716
Validation after dual ascent:
out_inf: tensor(4.8828, device='cuda:0', dtype=torch.float16) tensor(0.2634, device='cuda:0', dtype=torch.float16)
tensor(0.4761, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.4255, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4312, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.4368, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
7 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0977, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.1428, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1076, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1295, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1230, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0166, device='cuda:0')
tensor(0.0270, device='cuda:0')
old_score: tensor(0.0118, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.401767253875732
Validation after dual ascent:
out_inf: tensor(4.0977, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.1287, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1008, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1117, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1115, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
7 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.8359, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.4595, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.4600, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0043, device='cuda:0')
tensor(0.0263, device='cuda:0')
old_score: tensor(0.0537, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0496, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.109084129333496
Validation after dual ascent:
out_inf: tensor(5.8359, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(0.4236, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
tensor(0.4714, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.4304, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.4563, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
7 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.1920, device='cuda:0', dtype=torch.float16)
tensor(0.4297, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.3691, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.4067, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0193, device='cuda:0')
tensor(0.2892, device='cuda:0')
old_score: tensor(0.0479, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0443, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.187642335891724
Validation after dual ascent:
out_inf: tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.1920, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.4031, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.4185, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
7 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
tensor(0.1726, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.1616, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.1396, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.1653, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0116, device='cuda:0')
tensor(0.0216, device='cuda:0')
old_score: tensor(0.0172, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0164, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.119359731674194
Validation after dual ascent:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
tensor(0.1711, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.1533, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.1339, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.1588, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
layer 7 done
8 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16., device='cuda:0', dtype=torch.float16) tensor(0.7974, device='cuda:0', dtype=torch.float16)
tensor(0.7861, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.0992, device='cuda:0', dtype=torch.float16)
tensor(0.7974, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(0.0901, device='cuda:0')
old_score: tensor(0.0986, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0906, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.974984884262085
Validation after dual ascent:
out_inf: tensor(16., device='cuda:0', dtype=torch.float16) tensor(0.7974, device='cuda:0', dtype=torch.float16)
tensor(0.7393, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
8 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.7188, device='cuda:0', dtype=torch.float16) tensor(1.0195, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(0.8169, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(0.8140, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
8 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8789, device='cuda:0', dtype=torch.float16) tensor(0.2744, device='cuda:0', dtype=torch.float16)
tensor(0.5298, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.4521, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0157, device='cuda:0')
tensor(0.0716, device='cuda:0')
old_score: tensor(0.0612, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0565, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.203667640686035
Validation after dual ascent:
out_inf: tensor(4.8789, device='cuda:0', dtype=torch.float16) tensor(0.2744, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.4573, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
8 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0625, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.1470, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1569, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.1393, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0111, device='cuda:0')
tensor(0.0243, device='cuda:0')
old_score: tensor(0.0143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.676705837249756
Validation after dual ascent:
out_inf: tensor(4.0625, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.1288, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1476, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.1403, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.1232, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
8 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.1445, device='cuda:0', dtype=torch.float16) tensor(0.3164, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(0.4526, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0296, device='cuda:0')
old_score: tensor(0.0555, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0513, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.118210077285767
Validation after dual ascent:
out_inf: tensor(6.1445, device='cuda:0', dtype=torch.float16) tensor(0.3164, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.4583, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.5732, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.4441, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
8 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.8984, device='cuda:0', dtype=torch.float16) tensor(0.2063, device='cuda:0', dtype=torch.float16)
tensor(0.4370, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.4263, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0024, device='cuda:0')
tensor(0.0275, device='cuda:0')
old_score: tensor(0.0511, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0472, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.123396873474121
Validation after dual ascent:
out_inf: tensor(7.8984, device='cuda:0', dtype=torch.float16) tensor(0.2063, device='cuda:0', dtype=torch.float16)
tensor(0.4077, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(0.3972, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
8 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0664, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.1713, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
tensor(0.1713, device='cuda:0', dtype=torch.float16) tensor(0.0185, device='cuda:0', dtype=torch.float16)
tensor(0.1608, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.1781, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.0070, device='cuda:0')
old_score: tensor(0.0191, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0182, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.124250411987305
Validation after dual ascent:
out_inf: tensor(4.0664, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.1776, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.1792, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.1719, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
layer 8 done
9 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.4141, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(0.8638, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.1070, device='cuda:0', dtype=torch.float16)
tensor(0.8926, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0195, device='cuda:0')
tensor(0.0895, device='cuda:0')
old_score: tensor(0.1062, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0980, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.764986515045166
Validation after dual ascent:
out_inf: tensor(14.4141, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(0.8228, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.0979, device='cuda:0', dtype=torch.float16)
tensor(0.8408, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
9 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.7188, device='cuda:0', dtype=torch.float16) tensor(1.0420, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(0.9512, device='cuda:0', dtype=torch.float16) tensor(0.1057, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
tensor(0.0781, device='cuda:0')
old_score: tensor(0.1066, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0983, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.992538690567017
Validation after dual ascent:
out_inf: tensor(19.7188, device='cuda:0', dtype=torch.float16) tensor(1.0420, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.0982, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
9 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.2803, device='cuda:0', dtype=torch.float16)
tensor(0.5200, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.4924, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.4692, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0114, device='cuda:0')
tensor(0.0570, device='cuda:0')
old_score: tensor(0.0648, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0601, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.202313184738159
Validation after dual ascent:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.2803, device='cuda:0', dtype=torch.float16)
tensor(0.5396, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
tensor(0.5239, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.4897, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
9 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.1594, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1693, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.2014, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.1499, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0176, device='cuda:0')
tensor(0.0235, device='cuda:0')
old_score: tensor(0.0163, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0149, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.937110662460327
Validation after dual ascent:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.1381, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.1558, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
tensor(0.1903, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.1387, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
9 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.8008, device='cuda:0', dtype=torch.float16) tensor(0.3196, device='cuda:0', dtype=torch.float16)
tensor(0.4309, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.5444, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0037, device='cuda:0')
tensor(0.0336, device='cuda:0')
old_score: tensor(0.0577, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0535, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.118459463119507
Validation after dual ascent:
out_inf: tensor(6.8008, device='cuda:0', dtype=torch.float16) tensor(0.3196, device='cuda:0', dtype=torch.float16)
tensor(0.4592, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(0.4932, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4919, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
9 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6738, device='cuda:0', dtype=torch.float16) tensor(0.2181, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(0.4241, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.4126, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
tensor(0.4297, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0026, device='cuda:0')
tensor(0.0321, device='cuda:0')
old_score: tensor(0.0540, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0502, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.121838092803955
Validation after dual ascent:
out_inf: tensor(3.6738, device='cuda:0', dtype=torch.float16) tensor(0.2181, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.3936, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.4087, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4080, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
9 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.0215, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.1858, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.1676, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.1863, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0057, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.0211, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0202, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.30640697479248
Validation after dual ascent:
out_inf: tensor(3.0215, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.1775, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(0.1627, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.1718, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.1757, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
layer 9 done
10 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.6172, device='cuda:0', dtype=torch.float16) tensor(0.7827, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.1611, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
tensor(0.9561, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0106, device='cuda:0')
tensor(0.1411, device='cuda:0')
old_score: tensor(0.1083, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1004, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.468647003173828
Validation after dual ascent:
out_inf: tensor(13.6172, device='cuda:0', dtype=torch.float16) tensor(0.7827, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
tensor(0.9912, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(0.8486, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.9268, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
10 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.6562, device='cuda:0', dtype=torch.float16) tensor(1.0508, device='cuda:0', dtype=torch.float16)
tensor(0.8018, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(1.4707, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(1.2031, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0125, device='cuda:0')
tensor(0.1451, device='cuda:0')
old_score: tensor(0.1085, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4717583656311035
Validation after dual ascent:
out_inf: tensor(16.6562, device='cuda:0', dtype=torch.float16) tensor(1.0508, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0992, device='cuda:0', dtype=torch.float16)
tensor(1.3252, device='cuda:0', dtype=torch.float16) tensor(0.0990, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.8062, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
10 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.1953, device='cuda:0', dtype=torch.float16) tensor(0.2876, device='cuda:0', dtype=torch.float16)
tensor(0.4619, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.4736, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.5571, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.5356, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0043, device='cuda:0')
tensor(0.0782, device='cuda:0')
old_score: tensor(0.0668, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0622, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4666547775268555
Validation after dual ascent:
out_inf: tensor(7.1953, device='cuda:0', dtype=torch.float16) tensor(0.2876, device='cuda:0', dtype=torch.float16)
tensor(0.4822, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
tensor(0.4514, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.5127, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.5127, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
10 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.7773, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(0.2129, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
tensor(0.1898, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.2007, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.1813, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0037, device='cuda:0')
tensor(0.0370, device='cuda:0')
old_score: tensor(0.0195, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0178, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.727306604385376
Validation after dual ascent:
out_inf: tensor(5.7773, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(0.1877, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.1759, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.1997, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.1606, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
10 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.3789, device='cuda:0', dtype=torch.float16) tensor(0.3396, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0362, device='cuda:0')
old_score: tensor(0.0591, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0550, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.106621980667114
Validation after dual ascent:
out_inf: tensor(6.3789, device='cuda:0', dtype=torch.float16) tensor(0.3396, device='cuda:0', dtype=torch.float16)
tensor(0.4565, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.4639, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.4497, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.4785, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
10 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.2369, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.4502, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.5049, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0028, device='cuda:0')
tensor(0.0346, device='cuda:0')
old_score: tensor(0.0565, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0527, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.113541603088379
Validation after dual ascent:
out_inf: tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.2369, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.4683, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
10 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.0838, device='cuda:0', dtype=torch.float16)
tensor(0.2028, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.2094, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.1763, device='cuda:0', dtype=torch.float16) tensor(0.0229, device='cuda:0', dtype=torch.float16)
tensor(0.2155, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0045, device='cuda:0')
tensor(0.0217, device='cuda:0')
old_score: tensor(0.0235, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0225, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.28029465675354
Validation after dual ascent:
out_inf: tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.0838, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.2008, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.1794, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
tensor(0.2083, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
layer 10 done
11 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.7500, device='cuda:0', dtype=torch.float16) tensor(0.7822, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.1091, device='cuda:0', dtype=torch.float16)
tensor(1.0488, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.1865, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.1895, device='cuda:0')
old_score: tensor(0.1105, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1029, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.468315839767456
Validation after dual ascent:
out_inf: tensor(18.7500, device='cuda:0', dtype=torch.float16) tensor(0.7822, device='cuda:0', dtype=torch.float16)
tensor(0.9072, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1020, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.1063, device='cuda:0', dtype=torch.float16)
11 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.5938, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.1084, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0129, device='cuda:0')
tensor(0.1905, device='cuda:0')
old_score: tensor(0.1096, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1019, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4691693782806396
Validation after dual ascent:
out_inf: tensor(16.5938, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(0.7729, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(0.8096, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(0.7915, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
11 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.2891, device='cuda:0', dtype=torch.float16) tensor(0.3269, device='cuda:0', dtype=torch.float16)
tensor(0.5688, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.5981, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.5962, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0064, device='cuda:0')
tensor(0.1221, device='cuda:0')
old_score: tensor(0.0779, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.463956594467163
Validation after dual ascent:
out_inf: tensor(8.2891, device='cuda:0', dtype=torch.float16) tensor(0.3269, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(0.5718, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.5459, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
11 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.2266, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.1810, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.1960, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
tensor(0.2593, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.2153, device='cuda:0', dtype=torch.float16) tensor(0.0194, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0064, device='cuda:0')
tensor(0.0382, device='cuda:0')
old_score: tensor(0.0208, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0192, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.730759859085083
Validation after dual ascent:
out_inf: tensor(5.2266, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.1741, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.2021, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.2588, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.1899, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
11 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3491, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.4966, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.5068, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0041, device='cuda:0')
tensor(0.0415, device='cuda:0')
old_score: tensor(0.0623, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0582, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1023924350738525
Validation after dual ascent:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3491, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.4390, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.4585, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
11 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2305, device='cuda:0', dtype=torch.float16) tensor(0.2426, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.4561, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0030, device='cuda:0')
tensor(0.0402, device='cuda:0')
old_score: tensor(0.0602, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0562, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.104696989059448
Validation after dual ascent:
out_inf: tensor(4.2305, device='cuda:0', dtype=torch.float16) tensor(0.2426, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.4304, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
11 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2578, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
tensor(0.2046, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(0.1995, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.1871, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.2075, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
Converged at iteration 50
tensor(0.0198, device='cuda:0')
tensor(0.3034, device='cuda:0')
old_score: tensor(0.0250, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.483483076095581
Validation after dual ascent:
out_inf: tensor(3.2578, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
tensor(0.1969, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.1925, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.1825, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(0.2024, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
layer 11 done
12 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.7656, device='cuda:0', dtype=torch.float16) tensor(0.7852, device='cuda:0', dtype=torch.float16)
tensor(0.9048, device='cuda:0', dtype=torch.float16) tensor(0.1181, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.1199, device='cuda:0', dtype=torch.float16)
tensor(0.9902, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0159, device='cuda:0')
tensor(0.2007, device='cuda:0')
old_score: tensor(0.1200, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1121, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4677319526672363
Validation after dual ascent:
out_inf: tensor(17.7656, device='cuda:0', dtype=torch.float16) tensor(0.7852, device='cuda:0', dtype=torch.float16)
tensor(0.9194, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(0.9736, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(0.8394, device='cuda:0', dtype=torch.float16) tensor(0.1109, device='cuda:0', dtype=torch.float16)
tensor(0.9634, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
12 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.6328, device='cuda:0', dtype=torch.float16) tensor(1.0449, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.1195, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1206, device='cuda:0', dtype=torch.float16)
tensor(0.9521, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0171, device='cuda:0')
tensor(0.2071, device='cuda:0')
old_score: tensor(0.1213, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1131, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4710121154785156
Validation after dual ascent:
out_inf: tensor(15.6328, device='cuda:0', dtype=torch.float16) tensor(1.0449, device='cuda:0', dtype=torch.float16)
tensor(0.8599, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
tensor(0.9004, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
12 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3225, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.5752, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.5376, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0078, device='cuda:0')
tensor(0.1238, device='cuda:0')
old_score: tensor(0.0782, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0732, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.463034152984619
Validation after dual ascent:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3225, device='cuda:0', dtype=torch.float16)
tensor(0.5908, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.5630, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
12 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.5625, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.2107, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.2048, device='cuda:0', dtype=torch.float16) tensor(0.0229, device='cuda:0', dtype=torch.float16)
tensor(0.2244, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.2146, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0159, device='cuda:0')
tensor(0.0452, device='cuda:0')
old_score: tensor(0.0227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0209, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7280256748199463
Validation after dual ascent:
out_inf: tensor(4.5625, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.1985, device='cuda:0', dtype=torch.float16) tensor(0.0196, device='cuda:0', dtype=torch.float16)
tensor(0.1979, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.2087, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.1979, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
12 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.6836, device='cuda:0', dtype=torch.float16) tensor(0.3547, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0041, device='cuda:0')
tensor(0.0463, device='cuda:0')
old_score: tensor(0.0647, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0605, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.099662780761719
Validation after dual ascent:
out_inf: tensor(6.6836, device='cuda:0', dtype=torch.float16) tensor(0.3547, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.5176, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
12 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.9453, device='cuda:0', dtype=torch.float16) tensor(0.2542, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0033, device='cuda:0')
tensor(0.0455, device='cuda:0')
old_score: tensor(0.0632, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0592, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.099503040313721
Validation after dual ascent:
out_inf: tensor(4.9453, device='cuda:0', dtype=torch.float16) tensor(0.2542, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.4631, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
12 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5293, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(0.2252, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.2207, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.2505, device='cuda:0', dtype=torch.float16) tensor(0.0285, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0018, device='cuda:0')
tensor(0.0287, device='cuda:0')
old_score: tensor(0.0270, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0260, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.272564888000488
Validation after dual ascent:
out_inf: tensor(3.5293, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(0.2063, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.2115, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
tensor(0.2384, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
tensor(0.2478, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
layer 12 done
13 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.2891, device='cuda:0', dtype=torch.float16) tensor(0.7974, device='cuda:0', dtype=torch.float16)
tensor(0.9331, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
tensor(0.9971, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(0.9678, device='cuda:0', dtype=torch.float16) tensor(0.1219, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0115, device='cuda:0')
tensor(0.2108, device='cuda:0')
old_score: tensor(0.1224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1145, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4716570377349854
Validation after dual ascent:
out_inf: tensor(14.2891, device='cuda:0', dtype=torch.float16) tensor(0.7974, device='cuda:0', dtype=torch.float16)
tensor(0.8696, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(0.9644, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(0.8774, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
13 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.8906, device='cuda:0', dtype=torch.float16) tensor(1.0078, device='cuda:0', dtype=torch.float16)
tensor(0.9697, device='cuda:0', dtype=torch.float16) tensor(0.1210, device='cuda:0', dtype=torch.float16)
tensor(0.9014, device='cuda:0', dtype=torch.float16) tensor(0.1219, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.1222, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.1260, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0126, device='cuda:0')
tensor(0.2134, device='cuda:0')
old_score: tensor(0.1228, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1147, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.472951650619507
Validation after dual ascent:
out_inf: tensor(18.8906, device='cuda:0', dtype=torch.float16) tensor(1.0078, device='cuda:0', dtype=torch.float16)
tensor(0.8896, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.1131, device='cuda:0', dtype=torch.float16)
tensor(0.9233, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
13 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.2031, device='cuda:0', dtype=torch.float16) tensor(0.3276, device='cuda:0', dtype=torch.float16)
tensor(0.5913, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(0.6235, device='cuda:0', dtype=torch.float16) tensor(0.0855, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0066, device='cuda:0')
tensor(0.1362, device='cuda:0')
old_score: tensor(0.0831, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0780, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4685440063476562
Validation after dual ascent:
out_inf: tensor(5.2031, device='cuda:0', dtype=torch.float16) tensor(0.3276, device='cuda:0', dtype=torch.float16)
tensor(0.5903, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.5439, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.6226, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
13 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.2183, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.2087, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.2417, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0183, device='cuda:0')
tensor(0.0161, device='cuda:0')
old_score: tensor(0.0233, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0213, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1922762393951416
Validation after dual ascent:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.2244, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(0.2068, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.1945, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.2313, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
13 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.4258, device='cuda:0', dtype=torch.float16) tensor(0.3718, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0686, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0044, device='cuda:0')
tensor(0.0514, device='cuda:0')
old_score: tensor(0.0664, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0620, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.103144884109497
Validation after dual ascent:
out_inf: tensor(7.4258, device='cuda:0', dtype=torch.float16) tensor(0.3718, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
13 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6836, device='cuda:0', dtype=torch.float16) tensor(0.2703, device='cuda:0', dtype=torch.float16)
tensor(0.5186, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.4800, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0680, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0037, device='cuda:0')
tensor(0.0511, device='cuda:0')
old_score: tensor(0.0658, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0615, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.107898235321045
Validation after dual ascent:
out_inf: tensor(4.6836, device='cuda:0', dtype=torch.float16) tensor(0.2703, device='cuda:0', dtype=torch.float16)
tensor(0.5166, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.4763, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.4897, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
13 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.0859, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(0.2671, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.2515, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.2316, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0022, device='cuda:0')
tensor(0.0356, device='cuda:0')
old_score: tensor(0.0302, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0289, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.257932901382446
Validation after dual ascent:
out_inf: tensor(5.0859, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(0.2754, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.2126, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
tensor(0.2607, device='cuda:0', dtype=torch.float16) tensor(0.0312, device='cuda:0', dtype=torch.float16)
layer 13 done
14 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.8125, device='cuda:0', dtype=torch.float16) tensor(0.8008, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(1.1055, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(0.9893, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0134, device='cuda:0')
tensor(0.2288, device='cuda:0')
old_score: tensor(0.1240, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1157, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.471773624420166
Validation after dual ascent:
out_inf: tensor(13.8125, device='cuda:0', dtype=torch.float16) tensor(0.8008, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.4980, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(0.9194, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
14 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19., device='cuda:0', dtype=torch.float16) tensor(1.0801, device='cuda:0', dtype=torch.float16)
tensor(0.9136, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(0.9512, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0155, device='cuda:0')
tensor(0.2302, device='cuda:0')
old_score: tensor(0.1245, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1160, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4728152751922607
Validation after dual ascent:
out_inf: tensor(19., device='cuda:0', dtype=torch.float16) tensor(1.0801, device='cuda:0', dtype=torch.float16)
tensor(0.8506, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(0.8955, device='cuda:0', dtype=torch.float16) tensor(0.1142, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
14 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6992, device='cuda:0', dtype=torch.float16) tensor(0.3250, device='cuda:0', dtype=torch.float16)
tensor(0.5967, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0819, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(0.6851, device='cuda:0', dtype=torch.float16) tensor(0.0860, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0070, device='cuda:0')
tensor(0.1448, device='cuda:0')
old_score: tensor(0.0831, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0778, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.467280387878418
Validation after dual ascent:
out_inf: tensor(4.6992, device='cuda:0', dtype=torch.float16) tensor(0.3250, device='cuda:0', dtype=torch.float16)
tensor(0.6128, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.6011, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(0.5513, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.6182, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
14 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.1406, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(0.2280, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.2874, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.2573, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0046, device='cuda:0')
tensor(0.0573, device='cuda:0')
old_score: tensor(0.0259, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0238, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7290918827056885
Validation after dual ascent:
out_inf: tensor(7.1406, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(0.2026, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(0.2286, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(0.2803, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.2461, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
14 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.3801, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0694, device='cuda:0', dtype=torch.float16)
tensor(0.5869, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0047, device='cuda:0')
tensor(0.0593, device='cuda:0')
old_score: tensor(0.0699, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0654, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.100609540939331
Validation after dual ascent:
out_inf: tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.3801, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0647, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
14 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3555, device='cuda:0', dtype=torch.float16) tensor(0.2832, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(0.5161, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0041, device='cuda:0')
tensor(0.0589, device='cuda:0')
old_score: tensor(0.0694, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0650, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1089842319488525
Validation after dual ascent:
out_inf: tensor(4.3555, device='cuda:0', dtype=torch.float16) tensor(0.2832, device='cuda:0', dtype=torch.float16)
tensor(0.4949, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.4775, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.6089, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
14 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6660, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.2698, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
tensor(0.2563, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.2920, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0025, device='cuda:0')
tensor(0.0418, device='cuda:0')
old_score: tensor(0.0326, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0313, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.270493984222412
Validation after dual ascent:
out_inf: tensor(2.6660, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.2661, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.2537, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.2410, device='cuda:0', dtype=torch.float16) tensor(0.0292, device='cuda:0', dtype=torch.float16)
tensor(0.2737, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
layer 14 done
15 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.9141, device='cuda:0', dtype=torch.float16) tensor(0.7905, device='cuda:0', dtype=torch.float16)
tensor(0.8677, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(1.2061, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0110, device='cuda:0')
tensor(0.2087, device='cuda:0')
old_score: tensor(0.1216, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1138, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4710869789123535
Validation after dual ascent:
out_inf: tensor(15.9141, device='cuda:0', dtype=torch.float16) tensor(0.7905, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
tensor(1.1885, device='cuda:0', dtype=torch.float16) tensor(0.1198, device='cuda:0', dtype=torch.float16)
15 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(1.0459, device='cuda:0', dtype=torch.float16)
tensor(0.8989, device='cuda:0', dtype=torch.float16) tensor(0.1222, device='cuda:0', dtype=torch.float16)
tensor(0.9497, device='cuda:0', dtype=torch.float16) tensor(0.1214, device='cuda:0', dtype=torch.float16)
tensor(0.9634, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.4189, device='cuda:0', dtype=torch.float16) tensor(0.1283, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0117, device='cuda:0')
tensor(0.2158, device='cuda:0')
old_score: tensor(0.1237, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1154, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4742114543914795
Validation after dual ascent:
out_inf: tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(1.0459, device='cuda:0', dtype=torch.float16)
tensor(0.8667, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(0.9009, device='cuda:0', dtype=torch.float16) tensor(0.1123, device='cuda:0', dtype=torch.float16)
tensor(0.8276, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(1.4033, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
15 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.0078, device='cuda:0', dtype=torch.float16) tensor(0.3374, device='cuda:0', dtype=torch.float16)
tensor(0.6177, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
tensor(0.6431, device='cuda:0', dtype=torch.float16) tensor(0.0834, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0067, device='cuda:0')
tensor(0.1421, device='cuda:0')
old_score: tensor(0.0853, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0800, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.468864917755127
Validation after dual ascent:
out_inf: tensor(5.0078, device='cuda:0', dtype=torch.float16) tensor(0.3374, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.6001, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6553, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
15 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.8789, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(0.2262, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.2311, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.2263, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0059, device='cuda:0')
tensor(0.0708, device='cuda:0')
old_score: tensor(0.0269, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7293193340301514
Validation after dual ascent:
out_inf: tensor(5.8789, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(0.2144, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.2286, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.2125, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(0.2476, device='cuda:0', dtype=torch.float16) tensor(0.0252, device='cuda:0', dtype=torch.float16)
15 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.6562, device='cuda:0', dtype=torch.float16) tensor(0.3955, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0052, device='cuda:0')
tensor(0.0666, device='cuda:0')
old_score: tensor(0.0719, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0673, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.104133605957031
Validation after dual ascent:
out_inf: tensor(9.6562, device='cuda:0', dtype=torch.float16) tensor(0.3955, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
15 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.9258, device='cuda:0', dtype=torch.float16) tensor(0.2976, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
tensor(0.5557, device='cuda:0', dtype=torch.float16) tensor(0.0748, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0046, device='cuda:0')
tensor(0.0660, device='cuda:0')
old_score: tensor(0.0714, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0669, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1032023429870605
Validation after dual ascent:
out_inf: tensor(4.9258, device='cuda:0', dtype=torch.float16) tensor(0.2976, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(0.5054, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
15 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.6016, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(0.3066, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.2676, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.2874, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.3477, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0031, device='cuda:0')
tensor(0.0514, device='cuda:0')
old_score: tensor(0.0354, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0340, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.262282133102417
Validation after dual ascent:
out_inf: tensor(6.6016, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(0.2905, device='cuda:0', dtype=torch.float16) tensor(0.0347, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.2739, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.3364, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
layer 15 done
16 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.6562, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(1.6494, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(0.9634, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.0840, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0114, device='cuda:0')
tensor(0.2208, device='cuda:0')
old_score: tensor(0.1212, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470170497894287
Validation after dual ascent:
out_inf: tensor(17.6562, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.1124, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1198, device='cuda:0', dtype=torch.float16)
16 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0703, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.5352, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(0.9854, device='cuda:0', dtype=torch.float16) tensor(0.1210, device='cuda:0', dtype=torch.float16)
tensor(1.2334, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0123, device='cuda:0')
tensor(0.2268, device='cuda:0')
old_score: tensor(0.1222, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1138, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4748711585998535
Validation after dual ascent:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0703, device='cuda:0', dtype=torch.float16)
tensor(0.9653, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1098, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.1117, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
16 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.0195, device='cuda:0', dtype=torch.float16) tensor(0.3428, device='cuda:0', dtype=torch.float16)
tensor(0.6558, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
tensor(0.6650, device='cuda:0', dtype=torch.float16) tensor(0.0888, device='cuda:0', dtype=torch.float16)
tensor(0.7041, device='cuda:0', dtype=torch.float16) tensor(0.0940, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0074, device='cuda:0')
tensor(0.1569, device='cuda:0')
old_score: tensor(0.0898, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0841, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.468278646469116
Validation after dual ascent:
out_inf: tensor(5.0195, device='cuda:0', dtype=torch.float16) tensor(0.3428, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.7007, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(0.7085, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
16 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.3789, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(0.3250, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.2861, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.3228, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.3430, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0058, device='cuda:0')
tensor(0.0819, device='cuda:0')
old_score: tensor(0.0320, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0296, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.729393482208252
Validation after dual ascent:
out_inf: tensor(6.3789, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(0.3010, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.2720, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.2830, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.3240, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
16 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.9219, device='cuda:0', dtype=torch.float16) tensor(0.4229, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0761, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0755, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.0789, device='cuda:0')
old_score: tensor(0.0762, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0707, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.103827714920044
Validation after dual ascent:
out_inf: tensor(7.9219, device='cuda:0', dtype=torch.float16) tensor(0.4229, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0672, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0755, device='cuda:0', dtype=torch.float16)
16 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.2852, device='cuda:0', dtype=torch.float16) tensor(0.3167, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.5444, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0744, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0053, device='cuda:0')
tensor(0.0769, device='cuda:0')
old_score: tensor(0.0750, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0697, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.108201026916504
Validation after dual ascent:
out_inf: tensor(5.2852, device='cuda:0', dtype=torch.float16) tensor(0.3167, device='cuda:0', dtype=torch.float16)
tensor(0.5835, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
16 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.3203, device='cuda:0', dtype=torch.float16) tensor(0.1497, device='cuda:0', dtype=torch.float16)
tensor(0.4478, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.3291, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.2959, device='cuda:0', dtype=torch.float16) tensor(0.0373, device='cuda:0', dtype=torch.float16)
tensor(0.3984, device='cuda:0', dtype=torch.float16) tensor(0.0437, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0042, device='cuda:0')
tensor(0.0680, device='cuda:0')
old_score: tensor(0.0400, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0384, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.263731956481934
Validation after dual ascent:
out_inf: tensor(6.3203, device='cuda:0', dtype=torch.float16) tensor(0.1497, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.3330, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.3054, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.3794, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
layer 16 done
17 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.7031, device='cuda:0', dtype=torch.float16) tensor(0.8003, device='cuda:0', dtype=torch.float16)
tensor(1.3066, device='cuda:0', dtype=torch.float16) tensor(0.1222, device='cuda:0', dtype=torch.float16)
tensor(1.3965, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
tensor(1.2881, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
tensor(0.1414, device='cuda:0')
old_score: tensor(0.1226, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1137, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.94104790687561
Validation after dual ascent:
out_inf: tensor(16.7031, device='cuda:0', dtype=torch.float16) tensor(0.8003, device='cuda:0', dtype=torch.float16)
tensor(1.1768, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
17 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.1875, device='cuda:0', dtype=torch.float16) tensor(1.0254, device='cuda:0', dtype=torch.float16)
tensor(1.0342, device='cuda:0', dtype=torch.float16) tensor(0.1233, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.1186, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(0.1573, device='cuda:0')
old_score: tensor(0.1235, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1144, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.984439611434937
Validation after dual ascent:
out_inf: tensor(17.1875, device='cuda:0', dtype=torch.float16) tensor(1.0254, device='cuda:0', dtype=torch.float16)
tensor(0.9326, device='cuda:0', dtype=torch.float16) tensor(0.1145, device='cuda:0', dtype=torch.float16)
tensor(0.9590, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(0.9790, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
17 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3320, device='cuda:0', dtype=torch.float16) tensor(0.3538, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
tensor(0.6880, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(0.6802, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
tensor(0.6929, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0175, device='cuda:0')
tensor(0.0804, device='cuda:0')
old_score: tensor(0.0904, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0840, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.760569334030151
Validation after dual ascent:
out_inf: tensor(4.3320, device='cuda:0', dtype=torch.float16) tensor(0.3538, device='cuda:0', dtype=torch.float16)
tensor(0.6909, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.6021, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
17 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.2617, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.2922, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.2491, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.2917, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0053, device='cuda:0')
tensor(0.0651, device='cuda:0')
old_score: tensor(0.0280, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0257, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7309374809265137
Validation after dual ascent:
out_inf: tensor(6.2617, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(0.2422, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.2522, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.2612, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
17 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.7422, device='cuda:0', dtype=torch.float16) tensor(0.4421, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0803, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0068, device='cuda:0')
tensor(0.0942, device='cuda:0')
old_score: tensor(0.0811, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0754, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.114645481109619
Validation after dual ascent:
out_inf: tensor(8.7422, device='cuda:0', dtype=torch.float16) tensor(0.4421, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
17 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3188, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.6660, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.0900, device='cuda:0')
old_score: tensor(0.0786, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0732, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.120534420013428
Validation after dual ascent:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3188, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0735, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.5439, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.6611, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
17 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.0508, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.3506, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(0.3269, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.4341, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0044, device='cuda:0')
tensor(0.0728, device='cuda:0')
old_score: tensor(0.0409, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0393, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.283223390579224
Validation after dual ascent:
out_inf: tensor(5.0508, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(0.4194, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.3347, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.3196, device='cuda:0', dtype=torch.float16) tensor(0.0362, device='cuda:0', dtype=torch.float16)
tensor(0.4028, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
layer 17 done
18 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.8193, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.1209, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(2.1211, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.2677, device='cuda:0')
old_score: tensor(0.1273, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1182, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.475010395050049
Validation after dual ascent:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.8193, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1109, device='cuda:0', dtype=torch.float16)
tensor(1.0283, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
18 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.5781, device='cuda:0', dtype=torch.float16) tensor(0.9922, device='cuda:0', dtype=torch.float16)
tensor(0.9976, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(0.9590, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0198, device='cuda:0')
tensor(0.2709, device='cuda:0')
old_score: tensor(0.1282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1189, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4753577709198
Validation after dual ascent:
out_inf: tensor(17.5781, device='cuda:0', dtype=torch.float16) tensor(0.9922, device='cuda:0', dtype=torch.float16)
tensor(0.9971, device='cuda:0', dtype=torch.float16) tensor(0.1198, device='cuda:0', dtype=torch.float16)
tensor(1.0322, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
18 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.9844, device='cuda:0', dtype=torch.float16) tensor(0.3733, device='cuda:0', dtype=torch.float16)
tensor(0.8062, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0984, device='cuda:0', dtype=torch.float16)
tensor(0.8613, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0097, device='cuda:0')
tensor(0.2037, device='cuda:0')
old_score: tensor(0.0994, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0926, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4710323810577393
Validation after dual ascent:
out_inf: tensor(4.9844, device='cuda:0', dtype=torch.float16) tensor(0.3733, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0866, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
18 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3242, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.3499, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.2917, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.2915, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.3284, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0178, device='cuda:0')
tensor(0.0124, device='cuda:0')
old_score: tensor(0.0289, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0267, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4616270065307617
Validation after dual ascent:
out_inf: tensor(4.3242, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.2991, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.2627, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.2903, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.2942, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
18 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.7812, device='cuda:0', dtype=torch.float16) tensor(0.4558, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.6812, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0079, device='cuda:0')
tensor(0.1139, device='cuda:0')
old_score: tensor(0.0852, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0789, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.107667446136475
Validation after dual ascent:
out_inf: tensor(9.7812, device='cuda:0', dtype=torch.float16) tensor(0.4558, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0772, device='cuda:0', dtype=torch.float16)
tensor(0.7563, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
18 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.8320, device='cuda:0', dtype=torch.float16) tensor(0.3245, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.6206, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0808, device='cuda:0', dtype=torch.float16)
tensor(0.7217, device='cuda:0', dtype=torch.float16) tensor(0.0866, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0070, device='cuda:0')
tensor(0.1071, device='cuda:0')
old_score: tensor(0.0817, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0757, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110896825790405
Validation after dual ascent:
out_inf: tensor(5.8320, device='cuda:0', dtype=torch.float16) tensor(0.3245, device='cuda:0', dtype=torch.float16)
tensor(0.6396, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.6255, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
18 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.6797, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(0.4360, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.3589, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0054, device='cuda:0')
tensor(0.0859, device='cuda:0')
old_score: tensor(0.0435, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.254936218261719
Validation after dual ascent:
out_inf: tensor(5.6797, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(0.4287, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.3550, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.3411, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.4224, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
layer 18 done
19 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.9062, device='cuda:0', dtype=torch.float16) tensor(0.7827, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.1228, device='cuda:0', dtype=torch.float16)
tensor(1.3682, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
tensor(1.1279, device='cuda:0', dtype=torch.float16) tensor(0.1211, device='cuda:0', dtype=torch.float16)
tensor(1.4189, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0135, device='cuda:0')
tensor(0.2563, device='cuda:0')
old_score: tensor(0.1222, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4747865200042725
Validation after dual ascent:
out_inf: tensor(12.9062, device='cuda:0', dtype=torch.float16) tensor(0.7827, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.2705, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(1.0215, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.3955, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
19 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.6250, device='cuda:0', dtype=torch.float16) tensor(1.0225, device='cuda:0', dtype=torch.float16)
tensor(1.0400, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(0.9810, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1296, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.2597, device='cuda:0')
old_score: tensor(0.1226, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.472942590713501
Validation after dual ascent:
out_inf: tensor(19.6250, device='cuda:0', dtype=torch.float16) tensor(1.0225, device='cuda:0', dtype=torch.float16)
tensor(0.9248, device='cuda:0', dtype=torch.float16) tensor(0.1145, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
19 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2695, device='cuda:0', dtype=torch.float16) tensor(0.3848, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0995, device='cuda:0', dtype=torch.float16)
tensor(0.7368, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(0.8115, device='cuda:0', dtype=torch.float16) tensor(0.1045, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0096, device='cuda:0')
tensor(0.1987, device='cuda:0')
old_score: tensor(0.0986, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0914, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4672112464904785
Validation after dual ascent:
out_inf: tensor(4.2695, device='cuda:0', dtype=torch.float16) tensor(0.3848, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0926, device='cuda:0', dtype=torch.float16)
tensor(0.7534, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.7329, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
19 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.7773, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(0.2947, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.3677, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.2812, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.3169, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0067, device='cuda:0')
tensor(0.0670, device='cuda:0')
old_score: tensor(0.0293, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0270, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7263572216033936
Validation after dual ascent:
out_inf: tensor(5.7773, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(0.2866, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.2922, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.3108, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.3242, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
19 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.1875, device='cuda:0', dtype=torch.float16) tensor(0.4492, device='cuda:0', dtype=torch.float16)
tensor(0.6904, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.7822, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0086, device='cuda:0')
tensor(0.1286, device='cuda:0')
old_score: tensor(0.0883, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0817, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.099076747894287
Validation after dual ascent:
out_inf: tensor(8.1875, device='cuda:0', dtype=torch.float16) tensor(0.4492, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.7920, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0883, device='cuda:0', dtype=torch.float16)
19 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.5781, device='cuda:0', dtype=torch.float16) tensor(0.3333, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.0851, device='cuda:0', dtype=torch.float16)
tensor(0.7417, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0077, device='cuda:0')
tensor(0.1205, device='cuda:0')
old_score: tensor(0.0840, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0779, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.104169607162476
Validation after dual ascent:
out_inf: tensor(7.5781, device='cuda:0', dtype=torch.float16) tensor(0.3333, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0791, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0763, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
19 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.3359, device='cuda:0', dtype=torch.float16) tensor(0.1764, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.3938, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.3706, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.4595, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0058, device='cuda:0')
tensor(0.0930, device='cuda:0')
old_score: tensor(0.0452, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0434, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.243581771850586
Validation after dual ascent:
out_inf: tensor(5.3359, device='cuda:0', dtype=torch.float16) tensor(0.1764, device='cuda:0', dtype=torch.float16)
tensor(0.4319, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.3728, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
layer 19 done
20 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.4297, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.2441, device='cuda:0', dtype=torch.float16) tensor(0.1219, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0131, device='cuda:0')
tensor(0.2622, device='cuda:0')
old_score: tensor(0.1224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4719152450561523
Validation after dual ascent:
out_inf: tensor(15.4297, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(1.0889, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(1.0947, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
20 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.2500, device='cuda:0', dtype=torch.float16) tensor(1.0205, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
tensor(1.0137, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0138, device='cuda:0')
tensor(0.2654, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.47192645072937
Validation after dual ascent:
out_inf: tensor(18.2500, device='cuda:0', dtype=torch.float16) tensor(1.0205, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1145, device='cuda:0', dtype=torch.float16)
tensor(1.0869, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(0.9487, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
20 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.3755, device='cuda:0', dtype=torch.float16)
tensor(0.7686, device='cuda:0', dtype=torch.float16) tensor(0.1020, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0946, device='cuda:0', dtype=torch.float16)
tensor(0.7603, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.1062, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0098, device='cuda:0')
tensor(0.2049, device='cuda:0')
old_score: tensor(0.1007, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0933, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4688527584075928
Validation after dual ascent:
out_inf: tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.3755, device='cuda:0', dtype=torch.float16)
tensor(0.7764, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
20 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.6328, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(0.3262, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.3311, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.3354, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.3760, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0064, device='cuda:0')
tensor(0.0885, device='cuda:0')
old_score: tensor(0.0344, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0313, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7296147346496582
Validation after dual ascent:
out_inf: tensor(12.6328, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(0.3127, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
tensor(0.3113, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
tensor(0.2874, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.3369, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
20 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.1172, device='cuda:0', dtype=torch.float16) tensor(0.4634, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(0.8726, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.0946, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0092, device='cuda:0')
tensor(0.1373, device='cuda:0')
old_score: tensor(0.0898, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0828, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.097319602966309
Validation after dual ascent:
out_inf: tensor(11.1172, device='cuda:0', dtype=torch.float16) tensor(0.4634, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.8701, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
20 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.9062, device='cuda:0', dtype=torch.float16) tensor(0.3430, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0860, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.7959, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0082, device='cuda:0')
tensor(0.1278, device='cuda:0')
old_score: tensor(0.0848, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0782, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.101884126663208
Validation after dual ascent:
out_inf: tensor(5.9062, device='cuda:0', dtype=torch.float16) tensor(0.3430, device='cuda:0', dtype=torch.float16)
tensor(0.8062, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.7100, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.7412, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
20 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.2109, device='cuda:0', dtype=torch.float16) tensor(0.1891, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4126, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.3916, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.5264, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0068, device='cuda:0')
tensor(0.1074, device='cuda:0')
old_score: tensor(0.0474, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0455, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.196163415908813
Validation after dual ascent:
out_inf: tensor(7.2109, device='cuda:0', dtype=torch.float16) tensor(0.1891, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.3943, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(0.3931, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.5200, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
layer 20 done
21 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.7847, device='cuda:0', dtype=torch.float16)
tensor(1.0400, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(1.4248, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0143, device='cuda:0')
tensor(0.2867, device='cuda:0')
old_score: tensor(0.1224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1127, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4709770679473877
Validation after dual ascent:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.7847, device='cuda:0', dtype=torch.float16)
tensor(1.1104, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.5342, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(1.0518, device='cuda:0', dtype=torch.float16) tensor(0.1126, device='cuda:0', dtype=torch.float16)
tensor(1.2520, device='cuda:0', dtype=torch.float16) tensor(0.1204, device='cuda:0', dtype=torch.float16)
21 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.2812, device='cuda:0', dtype=torch.float16) tensor(0.9834, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0153, device='cuda:0')
tensor(0.2903, device='cuda:0')
old_score: tensor(0.1218, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1121, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.47283935546875
Validation after dual ascent:
out_inf: tensor(18.2812, device='cuda:0', dtype=torch.float16) tensor(0.9834, device='cuda:0', dtype=torch.float16)
tensor(1.2041, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(0.9443, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.0732, device='cuda:0', dtype=torch.float16) tensor(0.1196, device='cuda:0', dtype=torch.float16)
21 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.5586, device='cuda:0', dtype=torch.float16) tensor(0.3943, device='cuda:0', dtype=torch.float16)
tensor(0.8486, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0996, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0112, device='cuda:0')
tensor(0.2371, device='cuda:0')
old_score: tensor(0.1069, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0986, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.467250347137451
Validation after dual ascent:
out_inf: tensor(5.5586, device='cuda:0', dtype=torch.float16) tensor(0.3943, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.9014, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
tensor(0.8853, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(0.9741, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
21 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.2422, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(0.3457, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
tensor(0.3970, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.4431, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.4382, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0082, device='cuda:0')
tensor(0.1049, device='cuda:0')
old_score: tensor(0.0337, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0310, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7232105731964111
Validation after dual ascent:
out_inf: tensor(9.2422, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(0.3735, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.3972, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.3813, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.4797, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
21 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.5234, device='cuda:0', dtype=torch.float16) tensor(0.4587, device='cuda:0', dtype=torch.float16)
tensor(0.8740, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0100, device='cuda:0')
tensor(0.1533, device='cuda:0')
old_score: tensor(0.0927, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0856, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.094805479049683
Validation after dual ascent:
out_inf: tensor(10.5234, device='cuda:0', dtype=torch.float16) tensor(0.4587, device='cuda:0', dtype=torch.float16)
tensor(0.7959, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
21 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.4648, device='cuda:0', dtype=torch.float16) tensor(0.3408, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0089, device='cuda:0')
tensor(0.1414, device='cuda:0')
old_score: tensor(0.0867, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.10287880897522
Validation after dual ascent:
out_inf: tensor(6.4648, device='cuda:0', dtype=torch.float16) tensor(0.3408, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.7300, device='cuda:0', dtype=torch.float16) tensor(0.0802, device='cuda:0', dtype=torch.float16)
tensor(0.8257, device='cuda:0', dtype=torch.float16) tensor(0.0857, device='cuda:0', dtype=torch.float16)
21 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.1837, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.4504, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.5073, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0066, device='cuda:0')
tensor(0.1064, device='cuda:0')
old_score: tensor(0.0470, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0453, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.23585820198059
Validation after dual ascent:
out_inf: tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.1837, device='cuda:0', dtype=torch.float16)
tensor(0.5171, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.4509, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
layer 21 done
22 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.0938, device='cuda:0', dtype=torch.float16) tensor(0.8369, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(1.1514, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.2129, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
tensor(0.1280, device='cuda:0')
old_score: tensor(0.1281, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1181, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.946707248687744
Validation after dual ascent:
out_inf: tensor(18.0938, device='cuda:0', dtype=torch.float16) tensor(0.8369, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(1.1055, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.3506, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
22 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.3594, device='cuda:0', dtype=torch.float16) tensor(1.0107, device='cuda:0', dtype=torch.float16)
tensor(1.2207, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.1533, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(1.0879, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0175, device='cuda:0')
tensor(0.1234, device='cuda:0')
old_score: tensor(0.1279, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1179, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.21281361579895
Validation after dual ascent:
out_inf: tensor(20.3594, device='cuda:0', dtype=torch.float16) tensor(1.0107, device='cuda:0', dtype=torch.float16)
tensor(1.1533, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1079, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.1189, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
22 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.5000, device='cuda:0', dtype=torch.float16) tensor(0.4165, device='cuda:0', dtype=torch.float16)
tensor(0.9072, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(0.9429, device='cuda:0', dtype=torch.float16) tensor(0.1005, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(1.0498, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.2502, device='cuda:0')
old_score: tensor(0.1086, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.471200704574585
Validation after dual ascent:
out_inf: tensor(7.5000, device='cuda:0', dtype=torch.float16) tensor(0.4165, device='cuda:0', dtype=torch.float16)
tensor(0.9146, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.9028, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.1072, device='cuda:0', dtype=torch.float16)
22 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.0469, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
tensor(0.3760, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0357, device='cuda:0', dtype=torch.float16)
tensor(0.3833, device='cuda:0', dtype=torch.float16) tensor(0.0373, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0123, device='cuda:0')
tensor(0.1346, device='cuda:0')
old_score: tensor(0.0369, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0342, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7303087711334229
Validation after dual ascent:
out_inf: tensor(12.0469, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.4097, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.3872, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
22 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.9297, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.8311, device='cuda:0', dtype=torch.float16) tensor(0.0951, device='cuda:0', dtype=torch.float16)
tensor(0.9453, device='cuda:0', dtype=torch.float16) tensor(0.0874, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0105, device='cuda:0')
tensor(0.1611, device='cuda:0')
old_score: tensor(0.0940, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0865, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.105728387832642
Validation after dual ascent:
out_inf: tensor(10.9297, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0794, device='cuda:0', dtype=torch.float16)
tensor(0.7847, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
22 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.1133, device='cuda:0', dtype=torch.float16) tensor(0.3484, device='cuda:0', dtype=torch.float16)
tensor(0.8730, device='cuda:0', dtype=torch.float16) tensor(0.0883, device='cuda:0', dtype=torch.float16)
tensor(0.7373, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0910, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0093, device='cuda:0')
tensor(0.1477, device='cuda:0')
old_score: tensor(0.0873, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0804, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.109140396118164
Validation after dual ascent:
out_inf: tensor(6.1133, device='cuda:0', dtype=torch.float16) tensor(0.3484, device='cuda:0', dtype=torch.float16)
tensor(0.9292, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.7407, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.8428, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
22 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.1982, device='cuda:0', dtype=torch.float16)
tensor(0.5747, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.4868, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.5103, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0075, device='cuda:0')
tensor(0.1214, device='cuda:0')
old_score: tensor(0.0496, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0476, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.263323068618774
Validation after dual ascent:
out_inf: tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.1982, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.4741, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.5264, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
layer 22 done
23 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.0781, device='cuda:0', dtype=torch.float16) tensor(0.8228, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0166, device='cuda:0')
tensor(0.3590, device='cuda:0')
old_score: tensor(0.1360, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1255, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.473693370819092
Validation after dual ascent:
out_inf: tensor(16.0781, device='cuda:0', dtype=torch.float16) tensor(0.8228, device='cuda:0', dtype=torch.float16)
tensor(1.5088, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.7559, device='cuda:0', dtype=torch.float16) tensor(0.1151, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1321, device='cuda:0', dtype=torch.float16)
23 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.8125, device='cuda:0', dtype=torch.float16) tensor(0.9771, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.3037, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0174, device='cuda:0')
tensor(0.3632, device='cuda:0')
old_score: tensor(0.1357, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1250, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.474661111831665
Validation after dual ascent:
out_inf: tensor(19.8125, device='cuda:0', dtype=torch.float16) tensor(0.9771, device='cuda:0', dtype=torch.float16)
tensor(1.2314, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.2314, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
23 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.6758, device='cuda:0', dtype=torch.float16) tensor(0.4553, device='cuda:0', dtype=torch.float16)
tensor(1.0205, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(0.9507, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0139, device='cuda:0')
tensor(0.3088, device='cuda:0')
old_score: tensor(0.1205, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1113, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470735549926758
Validation after dual ascent:
out_inf: tensor(5.6758, device='cuda:0', dtype=torch.float16) tensor(0.4553, device='cuda:0', dtype=torch.float16)
tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.1126, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(0.9541, device='cuda:0', dtype=torch.float16) tensor(0.1133, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
23 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.9062, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.4500, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.4231, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0100, device='cuda:0')
tensor(0.1322, device='cuda:0')
old_score: tensor(0.0364, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0338, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.725074052810669
Validation after dual ascent:
out_inf: tensor(18.9062, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(0.4536, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.4045, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
tensor(0.4067, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.3838, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
23 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.3281, device='cuda:0', dtype=torch.float16) tensor(0.4663, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(0.8193, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(0.8882, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.1932, device='cuda:0')
old_score: tensor(0.0985, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0910, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.106395244598389
Validation after dual ascent:
out_inf: tensor(10.3281, device='cuda:0', dtype=torch.float16) tensor(0.4663, device='cuda:0', dtype=torch.float16)
tensor(0.8838, device='cuda:0', dtype=torch.float16) tensor(0.0921, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(0.8369, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(0.9639, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
23 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.3281, device='cuda:0', dtype=torch.float16) tensor(0.3550, device='cuda:0', dtype=torch.float16)
tensor(0.8032, device='cuda:0', dtype=torch.float16) tensor(0.0929, device='cuda:0', dtype=torch.float16)
tensor(0.7759, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
tensor(0.8530, device='cuda:0', dtype=torch.float16) tensor(0.0949, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.1777, device='cuda:0')
old_score: tensor(0.0918, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0848, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.108855247497559
Validation after dual ascent:
out_inf: tensor(7.3281, device='cuda:0', dtype=torch.float16) tensor(0.3550, device='cuda:0', dtype=torch.float16)
tensor(0.8374, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0775, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0866, device='cuda:0', dtype=torch.float16)
tensor(0.8643, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
23 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.9922, device='cuda:0', dtype=torch.float16) tensor(0.2026, device='cuda:0', dtype=torch.float16)
tensor(0.5767, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.6011, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.6064, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0085, device='cuda:0')
tensor(0.1384, device='cuda:0')
old_score: tensor(0.0521, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.263448476791382
Validation after dual ascent:
out_inf: tensor(3.9922, device='cuda:0', dtype=torch.float16) tensor(0.2026, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.6396, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
layer 23 done
24 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.8672, device='cuda:0', dtype=torch.float16) tensor(0.7915, device='cuda:0', dtype=torch.float16)
tensor(1.2041, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(1.8945, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
tensor(1.1553, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0170, device='cuda:0')
tensor(0.3338, device='cuda:0')
old_score: tensor(0.1255, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1160, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.473863124847412
Validation after dual ascent:
out_inf: tensor(15.8672, device='cuda:0', dtype=torch.float16) tensor(0.7915, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(1.8301, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.1188, device='cuda:0', dtype=torch.float16)
tensor(1.1807, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
24 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.3906, device='cuda:0', dtype=torch.float16) tensor(1.0059, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(1.0723, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0190, device='cuda:0')
tensor(0.3369, device='cuda:0')
old_score: tensor(0.1246, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1150, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4763965606689453
Validation after dual ascent:
out_inf: tensor(17.3906, device='cuda:0', dtype=torch.float16) tensor(1.0059, device='cuda:0', dtype=torch.float16)
tensor(1.0361, device='cuda:0', dtype=torch.float16) tensor(0.1162, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(0.9561, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
24 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.4336, device='cuda:0', dtype=torch.float16) tensor(0.4377, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.1189, device='cuda:0', dtype=torch.float16)
tensor(0.9561, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
tensor(0.9502, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(1.2520, device='cuda:0', dtype=torch.float16) tensor(0.1214, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0139, device='cuda:0')
tensor(0.2932, device='cuda:0')
old_score: tensor(0.1177, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1090, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470065116882324
Validation after dual ascent:
out_inf: tensor(6.4336, device='cuda:0', dtype=torch.float16) tensor(0.4377, device='cuda:0', dtype=torch.float16)
tensor(1.0488, device='cuda:0', dtype=torch.float16) tensor(0.1103, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.9629, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.1143, device='cuda:0', dtype=torch.float16)
24 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.1797, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(0.4368, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
tensor(0.4673, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.4646, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(0.4771, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0168, device='cuda:0')
tensor(0.0149, device='cuda:0')
old_score: tensor(0.0426, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0395, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2003965377807617
Validation after dual ascent:
out_inf: tensor(14.1797, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(0.4028, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.4768, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.4434, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.4387, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
24 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.1875, device='cuda:0', dtype=torch.float16) tensor(0.4717, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(0.9307, device='cuda:0', dtype=torch.float16) tensor(0.1032, device='cuda:0', dtype=torch.float16)
tensor(1.0381, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0126, device='cuda:0')
tensor(0.2053, device='cuda:0')
old_score: tensor(0.1004, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0929, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.107684373855591
Validation after dual ascent:
out_inf: tensor(12.1875, device='cuda:0', dtype=torch.float16) tensor(0.4717, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
tensor(0.9019, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
tensor(0.8604, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
24 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.5039, device='cuda:0', dtype=torch.float16) tensor(0.3611, device='cuda:0', dtype=torch.float16)
tensor(0.8335, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(0.8569, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(0.9292, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(0.8447, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0113, device='cuda:0')
tensor(0.1891, device='cuda:0')
old_score: tensor(0.0936, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0867, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.109848260879517
Validation after dual ascent:
out_inf: tensor(7.5039, device='cuda:0', dtype=torch.float16) tensor(0.3611, device='cuda:0', dtype=torch.float16)
tensor(0.8354, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0796, device='cuda:0', dtype=torch.float16)
tensor(0.9912, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
24 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8047, device='cuda:0', dtype=torch.float16) tensor(0.2096, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.6260, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0089, device='cuda:0')
tensor(0.1464, device='cuda:0')
old_score: tensor(0.0535, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0517, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.233754634857178
Validation after dual ascent:
out_inf: tensor(4.8047, device='cuda:0', dtype=torch.float16) tensor(0.2096, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.5884, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.4966, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
layer 24 done
25 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.9141, device='cuda:0', dtype=torch.float16) tensor(0.8037, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(1.3076, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
tensor(1.6553, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0177, device='cuda:0')
tensor(0.4005, device='cuda:0')
old_score: tensor(0.1390, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1288, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4755733013153076
Validation after dual ascent:
out_inf: tensor(11.9141, device='cuda:0', dtype=torch.float16) tensor(0.8037, device='cuda:0', dtype=torch.float16)
tensor(1.3096, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.7168, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
25 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.2656, device='cuda:0', dtype=torch.float16) tensor(0.9512, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.1295, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(1.3564, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0186, device='cuda:0')
tensor(0.4021, device='cuda:0')
old_score: tensor(0.1387, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1285, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.477545976638794
Validation after dual ascent:
out_inf: tensor(17.2656, device='cuda:0', dtype=torch.float16) tensor(0.9512, device='cuda:0', dtype=torch.float16)
tensor(1.3887, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.1181, device='cuda:0', dtype=torch.float16)
tensor(1.3936, device='cuda:0', dtype=torch.float16) tensor(0.1324, device='cuda:0', dtype=torch.float16)
tensor(1.4307, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
25 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.3477, device='cuda:0', dtype=torch.float16) tensor(0.4790, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.3646, device='cuda:0')
old_score: tensor(0.1306, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1212, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4727909564971924
Validation after dual ascent:
out_inf: tensor(5.3477, device='cuda:0', dtype=torch.float16) tensor(0.4790, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.1225, device='cuda:0', dtype=torch.float16)
tensor(0.9819, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
tensor(1.1982, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
25 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
tensor(0.3853, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0373, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0078, device='cuda:0')
tensor(0.0159, device='cuda:0')
old_score: tensor(0.0347, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0319, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.925149917602539
Validation after dual ascent:
out_inf: tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(0.3911, device='cuda:0', dtype=torch.float16) tensor(0.0285, device='cuda:0', dtype=torch.float16)
tensor(0.3760, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.4126, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
25 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.8047, device='cuda:0', dtype=torch.float16) tensor(0.4980, device='cuda:0', dtype=torch.float16)
tensor(0.9365, device='cuda:0', dtype=torch.float16) tensor(0.1051, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1071, device='cuda:0', dtype=torch.float16)
tensor(0.9287, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0140, device='cuda:0')
tensor(0.2361, device='cuda:0')
old_score: tensor(0.1040, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0961, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.11229395866394
Validation after dual ascent:
out_inf: tensor(9.8047, device='cuda:0', dtype=torch.float16) tensor(0.4980, device='cuda:0', dtype=torch.float16)
tensor(0.9229, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(0.9028, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(0.9443, device='cuda:0', dtype=torch.float16) tensor(0.1004, device='cuda:0', dtype=torch.float16)
25 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.6797, device='cuda:0', dtype=torch.float16) tensor(0.3743, device='cuda:0', dtype=torch.float16)
tensor(0.9097, device='cuda:0', dtype=torch.float16) tensor(0.0985, device='cuda:0', dtype=torch.float16)
tensor(0.8682, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(0.9023, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.9287, device='cuda:0', dtype=torch.float16) tensor(0.1001, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0127, device='cuda:0')
tensor(0.2184, device='cuda:0')
old_score: tensor(0.0974, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0902, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.12111496925354
Validation after dual ascent:
out_inf: tensor(8.6797, device='cuda:0', dtype=torch.float16) tensor(0.3743, device='cuda:0', dtype=torch.float16)
tensor(0.9385, device='cuda:0', dtype=torch.float16) tensor(0.0913, device='cuda:0', dtype=torch.float16)
tensor(0.8721, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
25 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.9258, device='cuda:0', dtype=torch.float16) tensor(0.2206, device='cuda:0', dtype=torch.float16)
tensor(0.7007, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.6421, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.5698, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0103, device='cuda:0')
tensor(0.1668, device='cuda:0')
old_score: tensor(0.0557, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0539, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.213191986083984
Validation after dual ascent:
out_inf: tensor(5.9258, device='cuda:0', dtype=torch.float16) tensor(0.2206, device='cuda:0', dtype=torch.float16)
tensor(0.6284, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
layer 25 done
26 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.0312, device='cuda:0', dtype=torch.float16) tensor(0.8335, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(1.4473, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0074, device='cuda:0')
tensor(0.1220, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1244, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2093355655670166
Validation after dual ascent:
out_inf: tensor(14.0312, device='cuda:0', dtype=torch.float16) tensor(0.8335, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.1250, device='cuda:0', dtype=torch.float16)
tensor(1.3057, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.2881, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
26 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.9844, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(1.2959, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(1.4551, device='cuda:0', dtype=torch.float16) tensor(0.1368, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.1287, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2119975090026855
Validation after dual ascent:
out_inf: tensor(17.9844, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1250, device='cuda:0', dtype=torch.float16)
tensor(1.2236, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
26 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4775, device='cuda:0', dtype=torch.float16)
tensor(1.1221, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1343, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0170, device='cuda:0')
tensor(0.3550, device='cuda:0')
old_score: tensor(0.1301, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1209, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4729745388031006
Validation after dual ascent:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4775, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(1.0967, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
26 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.4219, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(0.4346, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(0.5303, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(0.5161, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0106, device='cuda:0')
tensor(0.0300, device='cuda:0')
old_score: tensor(0.0485, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0446, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.065834999084473
Validation after dual ascent:
out_inf: tensor(22.4219, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(0.4622, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.4958, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.4595, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
26 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.7422, device='cuda:0', dtype=torch.float16) tensor(0.5195, device='cuda:0', dtype=torch.float16)
tensor(0.9902, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(0.9912, device='cuda:0', dtype=torch.float16) tensor(0.0979, device='cuda:0', dtype=torch.float16)
tensor(0.9839, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.2479, device='cuda:0')
old_score: tensor(0.1050, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0972, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.129063367843628
Validation after dual ascent:
out_inf: tensor(9.7422, device='cuda:0', dtype=torch.float16) tensor(0.5195, device='cuda:0', dtype=torch.float16)
tensor(0.9897, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(0.9111, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
tensor(0.9399, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
26 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.3828, device='cuda:0', dtype=torch.float16) tensor(0.3943, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(1.0840, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.9453, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0133, device='cuda:0')
tensor(0.2296, device='cuda:0')
old_score: tensor(0.0989, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0915, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.119335889816284
Validation after dual ascent:
out_inf: tensor(8.3828, device='cuda:0', dtype=torch.float16) tensor(0.3943, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.0925, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
26 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.6562, device='cuda:0', dtype=torch.float16) tensor(0.2285, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.5684, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0118, device='cuda:0')
tensor(0.1877, device='cuda:0')
old_score: tensor(0.0577, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0557, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.215457201004028
Validation after dual ascent:
out_inf: tensor(5.6562, device='cuda:0', dtype=torch.float16) tensor(0.2285, device='cuda:0', dtype=torch.float16)
tensor(0.6763, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.6045, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.6274, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
layer 26 done
27 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.7422, device='cuda:0', dtype=torch.float16) tensor(0.8335, device='cuda:0', dtype=torch.float16)
tensor(1.4414, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.3447, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.1494, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0185, device='cuda:0')
tensor(0.3848, device='cuda:0')
old_score: tensor(0.1443, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1335, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.476392984390259
Validation after dual ascent:
out_inf: tensor(15.7422, device='cuda:0', dtype=torch.float16) tensor(0.8335, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(1.3350, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.2197, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
27 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.7344, device='cuda:0', dtype=torch.float16) tensor(0.9790, device='cuda:0', dtype=torch.float16)
tensor(1.2959, device='cuda:0', dtype=torch.float16) tensor(0.1461, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0195, device='cuda:0')
tensor(0.3891, device='cuda:0')
old_score: tensor(0.1454, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1345, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4897146224975586
Validation after dual ascent:
out_inf: tensor(18.7344, device='cuda:0', dtype=torch.float16) tensor(0.9790, device='cuda:0', dtype=torch.float16)
tensor(1.4502, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(1.2002, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.3486, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
27 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.2266, device='cuda:0', dtype=torch.float16) tensor(0.4866, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.1162, device='cuda:0', dtype=torch.float16) tensor(0.1359, device='cuda:0', dtype=torch.float16)
tensor(1.1465, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.3482, device='cuda:0')
old_score: tensor(0.1311, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1216, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4734251499176025
Validation after dual ascent:
out_inf: tensor(10.2266, device='cuda:0', dtype=torch.float16) tensor(0.4866, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.1436, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(1.0166, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.1455, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
27 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.8008, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.4451, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.4014, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
tensor(0.4834, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0190, device='cuda:0')
tensor(0.1323, device='cuda:0')
old_score: tensor(0.0312, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0290, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7311279773712158
Validation after dual ascent:
out_inf: tensor(5.8008, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(0.4836, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
tensor(0.3601, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.4087, device='cuda:0', dtype=torch.float16) tensor(0.0290, device='cuda:0', dtype=torch.float16)
tensor(0.4548, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
27 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.3203, device='cuda:0', dtype=torch.float16) tensor(0.5488, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.1086, device='cuda:0', dtype=torch.float16)
tensor(0.9868, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0161, device='cuda:0')
tensor(0.2768, device='cuda:0')
old_score: tensor(0.1076, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0994, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.117617130279541
Validation after dual ascent:
out_inf: tensor(11.3203, device='cuda:0', dtype=torch.float16) tensor(0.5488, device='cuda:0', dtype=torch.float16)
tensor(1.0010, device='cuda:0', dtype=torch.float16) tensor(0.1005, device='cuda:0', dtype=torch.float16)
tensor(0.9771, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(1.0420, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
tensor(1.0879, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
27 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.1289, device='cuda:0', dtype=torch.float16) tensor(0.4209, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(0.9673, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.1055, device='cuda:0', dtype=torch.float16)
tensor(0.9624, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.2582, device='cuda:0')
old_score: tensor(0.1022, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0944, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.12278938293457
Validation after dual ascent:
out_inf: tensor(7.1289, device='cuda:0', dtype=torch.float16) tensor(0.4209, device='cuda:0', dtype=torch.float16)
tensor(0.9355, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(0.9990, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(0.8667, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
tensor(1.0146, device='cuda:0', dtype=torch.float16) tensor(0.0978, device='cuda:0', dtype=torch.float16)
27 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2891, device='cuda:0', dtype=torch.float16) tensor(0.2527, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(0.6475, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0142, device='cuda:0')
tensor(0.2243, device='cuda:0')
old_score: tensor(0.0615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0593, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.137284994125366
Validation after dual ascent:
out_inf: tensor(4.2891, device='cuda:0', dtype=torch.float16) tensor(0.2527, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.6968, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.6729, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
layer 27 done
28 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.3672, device='cuda:0', dtype=torch.float16) tensor(0.8496, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(1.4033, device='cuda:0', dtype=torch.float16) tensor(0.1335, device='cuda:0', dtype=torch.float16)
tensor(1.8066, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(1.6787, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0141, device='cuda:0')
tensor(0.1166, device='cuda:0')
old_score: tensor(0.1416, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1307, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2108771800994873
Validation after dual ascent:
out_inf: tensor(14.3672, device='cuda:0', dtype=torch.float16) tensor(0.8496, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1312, device='cuda:0', dtype=torch.float16)
tensor(1.3223, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
28 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.7656, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(1.2627, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1482, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0120, device='cuda:0')
tensor(0.1146, device='cuda:0')
old_score: tensor(0.1429, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1318, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2124786376953125
Validation after dual ascent:
out_inf: tensor(20.7656, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(1.2080, device='cuda:0', dtype=torch.float16) tensor(0.1326, device='cuda:0', dtype=torch.float16)
tensor(1.1611, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(1.2373, device='cuda:0', dtype=torch.float16) tensor(0.1368, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1360, device='cuda:0', dtype=torch.float16)
28 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.1172, device='cuda:0', dtype=torch.float16) tensor(0.5239, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0073, device='cuda:0')
tensor(0.0989, device='cuda:0')
old_score: tensor(0.1377, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1274, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.209885597229004
Validation after dual ascent:
out_inf: tensor(7.1172, device='cuda:0', dtype=torch.float16) tensor(0.5239, device='cuda:0', dtype=torch.float16)
tensor(1.2100, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.0830, device='cuda:0', dtype=torch.float16) tensor(0.1181, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
28 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(9., device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(0.5825, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.6392, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.5596, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0176, device='cuda:0')
tensor(0.0413, device='cuda:0')
old_score: tensor(0.0444, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0412, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.664749622344971
Validation after dual ascent:
out_inf: tensor(9., device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
28 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.6250, device='cuda:0', dtype=torch.float16) tensor(0.5757, device='cuda:0', dtype=torch.float16)
tensor(0.9946, device='cuda:0', dtype=torch.float16) tensor(0.1106, device='cuda:0', dtype=torch.float16)
tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
tensor(1.0283, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.3057, device='cuda:0')
old_score: tensor(0.1098, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.125759840011597
Validation after dual ascent:
out_inf: tensor(14.6250, device='cuda:0', dtype=torch.float16) tensor(0.5757, device='cuda:0', dtype=torch.float16)
tensor(1.0635, device='cuda:0', dtype=torch.float16) tensor(0.1022, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
28 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.7812, device='cuda:0', dtype=torch.float16) tensor(0.4607, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(1.0303, device='cuda:0', dtype=torch.float16) tensor(0.1098, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0162, device='cuda:0')
tensor(0.2904, device='cuda:0')
old_score: tensor(0.1061, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0978, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.128556728363037
Validation after dual ascent:
out_inf: tensor(12.7812, device='cuda:0', dtype=torch.float16) tensor(0.4607, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.0811, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
28 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.1016, device='cuda:0', dtype=torch.float16) tensor(0.2874, device='cuda:0', dtype=torch.float16)
tensor(0.8130, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.6904, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0185, device='cuda:0')
tensor(0.2925, device='cuda:0')
old_score: tensor(0.0679, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0654, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.099971771240234
Validation after dual ascent:
out_inf: tensor(8.1016, device='cuda:0', dtype=torch.float16) tensor(0.2874, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
tensor(0.7651, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
layer 28 done
29 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.9219, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(1.8105, device='cuda:0', dtype=torch.float16) tensor(0.1311, device='cuda:0', dtype=torch.float16)
tensor(1.4805, device='cuda:0', dtype=torch.float16) tensor(0.1242, device='cuda:0', dtype=torch.float16)
tensor(1.3369, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
tensor(2.1895, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0076, device='cuda:0')
tensor(0.0410, device='cuda:0')
old_score: tensor(0.1312, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1210, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.416493892669678
Validation after dual ascent:
out_inf: tensor(12.9219, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(1.7158, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
tensor(1.3105, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
29 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.7812, device='cuda:0', dtype=torch.float16) tensor(1.0439, device='cuda:0', dtype=torch.float16)
tensor(1.1709, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1332, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0198, device='cuda:0')
tensor(0.1001, device='cuda:0')
old_score: tensor(0.1320, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1215, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.215846300125122
Validation after dual ascent:
out_inf: tensor(20.7812, device='cuda:0', dtype=torch.float16) tensor(1.0439, device='cuda:0', dtype=torch.float16)
tensor(1.1123, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
29 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.4922, device='cuda:0', dtype=torch.float16) tensor(0.4988, device='cuda:0', dtype=torch.float16)
tensor(1.2900, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0180, device='cuda:0')
tensor(0.3502, device='cuda:0')
old_score: tensor(0.1346, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.475827217102051
Validation after dual ascent:
out_inf: tensor(8.4922, device='cuda:0', dtype=torch.float16) tensor(0.4988, device='cuda:0', dtype=torch.float16)
tensor(1.1318, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
tensor(1.0713, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
29 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.6406, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(0.5190, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.5674, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.5161, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.5649, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0029, device='cuda:0')
tensor(0.0182, device='cuda:0')
old_score: tensor(0.0457, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0427, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.468491315841675
Validation after dual ascent:
out_inf: tensor(16.6406, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.4741, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
29 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.6016, device='cuda:0', dtype=torch.float16) tensor(0.5908, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(1.0283, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.3266, device='cuda:0')
old_score: tensor(0.1116, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1027, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.128344535827637
Validation after dual ascent:
out_inf: tensor(11.6016, device='cuda:0', dtype=torch.float16) tensor(0.5908, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(0.9575, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(1.0684, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
29 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.5161, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.1095, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(1.0811, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.1084, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0175, device='cuda:0')
tensor(0.3135, device='cuda:0')
old_score: tensor(0.1089, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1002, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.132437229156494
Validation after dual ascent:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.5161, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(1.0596, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(0.9731, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(1.0420, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
29 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(23.4844, device='cuda:0', dtype=torch.float16) tensor(0.3423, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(0.8867, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.7866, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(0.9092, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0032, device='cuda:0')
tensor(0.0409, device='cuda:0')
old_score: tensor(0.0752, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0723, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.868678092956543
Validation after dual ascent:
out_inf: tensor(23.4844, device='cuda:0', dtype=torch.float16) tensor(0.3423, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(0.8647, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.7837, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(0.9419, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
layer 29 done
30 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.7109, device='cuda:0', dtype=torch.float16) tensor(0.8638, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(1.5449, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1415, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0095, device='cuda:0')
tensor(0.0826, device='cuda:0')
old_score: tensor(0.1395, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1282, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.214630126953125
Validation after dual ascent:
out_inf: tensor(14.7109, device='cuda:0', dtype=torch.float16) tensor(0.8638, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(1.3926, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1324, device='cuda:0', dtype=torch.float16)
tensor(1.3027, device='cuda:0', dtype=torch.float16) tensor(0.1321, device='cuda:0', dtype=torch.float16)
30 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.8281, device='cuda:0', dtype=torch.float16) tensor(1.0156, device='cuda:0', dtype=torch.float16)
tensor(1.3291, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.1466, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0113, device='cuda:0')
tensor(0.0867, device='cuda:0')
old_score: tensor(0.1416, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1300, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.217097759246826
Validation after dual ascent:
out_inf: tensor(18.8281, device='cuda:0', dtype=torch.float16) tensor(1.0156, device='cuda:0', dtype=torch.float16)
tensor(1.2939, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
tensor(1.2676, device='cuda:0', dtype=torch.float16) tensor(0.1206, device='cuda:0', dtype=torch.float16)
tensor(1.2168, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
30 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.8984, device='cuda:0', dtype=torch.float16) tensor(0.5610, device='cuda:0', dtype=torch.float16)
tensor(1.2705, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
tensor(1.2939, device='cuda:0', dtype=torch.float16) tensor(0.1444, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.3809, device='cuda:0')
old_score: tensor(0.1421, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1307, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4785726070404053
Validation after dual ascent:
out_inf: tensor(9.8984, device='cuda:0', dtype=torch.float16) tensor(0.5610, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.3770, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
30 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.1406, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.7881, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0046, device='cuda:0')
tensor(0.0223, device='cuda:0')
old_score: tensor(0.0392, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0366, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4704782962799072
Validation after dual ascent:
out_inf: tensor(21.1406, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.5908, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
30 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(34.9062, device='cuda:0', dtype=torch.float16) tensor(0.6455, device='cuda:0', dtype=torch.float16)
tensor(1.1279, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.0674, device='cuda:0', dtype=torch.float16) tensor(0.1133, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.3171, device='cuda:0')
old_score: tensor(0.1115, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1023, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.131103515625
Validation after dual ascent:
out_inf: tensor(34.9062, device='cuda:0', dtype=torch.float16) tensor(0.6455, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
30 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(35.4062, device='cuda:0', dtype=torch.float16) tensor(0.5981, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.0332, device='cuda:0', dtype=torch.float16) tensor(0.1023, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.1123, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1102, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0183, device='cuda:0')
tensor(0.3029, device='cuda:0')
old_score: tensor(0.1084, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0994, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.142497539520264
Validation after dual ascent:
out_inf: tensor(35.4062, device='cuda:0', dtype=torch.float16) tensor(0.5981, device='cuda:0', dtype=torch.float16)
tensor(0.9248, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.9658, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
tensor(0.9775, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
30 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1515., device='cuda:0', dtype=torch.float16) tensor(0.5356, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0802, device='cuda:0', dtype=torch.float16)
tensor(1.0264, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(1.0459, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0159, device='cuda:0')
tensor(0.0800, device='cuda:0')
old_score: tensor(0.0809, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0773, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.794711112976074
Validation after dual ascent:
out_inf: tensor(1515., device='cuda:0', dtype=torch.float16) tensor(0.5356, device='cuda:0', dtype=torch.float16)
tensor(1.3799, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(1.3584, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
layer 30 done
31 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.7031, device='cuda:0', dtype=torch.float16) tensor(0.8511, device='cuda:0', dtype=torch.float16)
tensor(2.8750, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(2.3906, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0129, device='cuda:0')
tensor(0.2002, device='cuda:0')
old_score: tensor(0.1139, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1035, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.476628065109253
Validation after dual ascent:
out_inf: tensor(19.7031, device='cuda:0', dtype=torch.float16) tensor(0.8511, device='cuda:0', dtype=torch.float16)
tensor(2.7656, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(2.5234, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(1.9180, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
31 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(23.6250, device='cuda:0', dtype=torch.float16) tensor(1.0850, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(2.1953, device='cuda:0', dtype=torch.float16) tensor(0.1101, device='cuda:0', dtype=torch.float16)
tensor(2.4336, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0150, device='cuda:0')
tensor(0.2116, device='cuda:0')
old_score: tensor(0.1165, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1058, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4779491424560547
Validation after dual ascent:
out_inf: tensor(23.6250, device='cuda:0', dtype=torch.float16) tensor(1.0850, device='cuda:0', dtype=torch.float16)
tensor(2.3594, device='cuda:0', dtype=torch.float16) tensor(0.1063, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(2.2070, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.6426, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
31 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.0352, device='cuda:0', dtype=torch.float16) tensor(0.4277, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1043, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(0.9565, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0096, device='cuda:0')
tensor(0.1737, device='cuda:0')
old_score: tensor(0.1040, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0947, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4736592769622803
Validation after dual ascent:
out_inf: tensor(7.0352, device='cuda:0', dtype=torch.float16) tensor(0.4277, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(0.8965, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
31 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(129.1250, device='cuda:0', dtype=torch.float16) tensor(0.2478, device='cuda:0', dtype=torch.float16)
tensor(0.5317, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.5513, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0132, device='cuda:0')
tensor(0.0953, device='cuda:0')
old_score: tensor(0.0465, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0404, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4637584686279297
Validation after dual ascent:
out_inf: tensor(129.1250, device='cuda:0', dtype=torch.float16) tensor(0.2478, device='cuda:0', dtype=torch.float16)
tensor(0.5166, device='cuda:0', dtype=torch.float16) tensor(0.0419, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
31 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(31.3281, device='cuda:0', dtype=torch.float16) tensor(0.6870, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.1020, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.1957, device='cuda:0')
old_score: tensor(0.1018, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0922, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.137434482574463
Validation after dual ascent:
out_inf: tensor(31.3281, device='cuda:0', dtype=torch.float16) tensor(0.6870, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(1.1182, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
tensor(1.1006, device='cuda:0', dtype=torch.float16) tensor(0.0962, device='cuda:0', dtype=torch.float16)
tensor(1.0586, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
31 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(34.4375, device='cuda:0', dtype=torch.float16) tensor(0.7021, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0979, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0926, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.9893, device='cuda:0', dtype=torch.float16) tensor(0.0987, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.1844, device='cuda:0')
old_score: tensor(0.0977, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0884, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.146339178085327
Validation after dual ascent:
out_inf: tensor(34.4375, device='cuda:0', dtype=torch.float16) tensor(0.7021, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0888, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(0.9834, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
31 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(193.7500, device='cuda:0', dtype=torch.float16) tensor(1.5225, device='cuda:0', dtype=torch.float16)
tensor(1.0479, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(1.2432, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0882, device='cuda:0', dtype=torch.float16)
layer 31 done
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.13it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.86it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.73it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25': 0, 'model.layers.26': 0, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.600001
layer 1 sparsity 0.600001
layer 2 sparsity 0.600001
layer 3 sparsity 0.600001
layer 4 sparsity 0.600001
layer 5 sparsity 0.600001
layer 6 sparsity 0.600001
layer 7 sparsity 0.600001
layer 8 sparsity 0.600001
layer 9 sparsity 0.600001
layer 10 sparsity 0.600001
layer 11 sparsity 0.600001
layer 12 sparsity 0.600001
layer 13 sparsity 0.600001
layer 14 sparsity 0.600001
layer 15 sparsity 0.600001
layer 16 sparsity 0.600001
layer 17 sparsity 0.600001
layer 18 sparsity 0.600001
layer 19 sparsity 0.600001
layer 20 sparsity 0.600001
layer 21 sparsity 0.600001
layer 22 sparsity 0.600001
layer 23 sparsity 0.600001
layer 24 sparsity 0.600001
layer 25 sparsity 0.600001
layer 26 sparsity 0.600001
layer 27 sparsity 0.600001
layer 28 sparsity 0.600001
layer 29 sparsity 0.600001
layer 30 sparsity 0.600001
layer 31 sparsity 0.600001
sparsity sanity check 0.6000
******************************
evaluating on wikitext2
nsamples 83
sample 0
sample 50
wikitext perplexity 9.012979507446289
sparsegpt_dual_3	0.6000	9.0130	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf', seed=0, nsamples=256, dual_theld=0.0, n_batch=8, sparsity_ratio=0.6, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='sparsegpt_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
2025-04-24 05:00:05.252110: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 05:00:05.454869: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 05:00:05.460162: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 05:00:05.460190: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 05:00:08.938982: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 05:00:08.939466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 05:00:08.939481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.84it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.31it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.23it/s]
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
model.embed_tokens.weight torch.Size([32000, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([32000, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:00<03:21,  1.27it/s]  1%|          | 2/256 [00:01<03:13,  1.31it/s]  2%|▏         | 4/256 [00:01<01:37,  2.59it/s]  2%|▏         | 5/256 [00:02<01:51,  2.26it/s]  2%|▏         | 6/256 [00:02<01:25,  2.92it/s]  3%|▎         | 7/256 [00:03<01:58,  2.10it/s]  3%|▎         | 8/256 [00:03<01:31,  2.72it/s]  4%|▎         | 9/256 [00:03<01:10,  3.48it/s]  4%|▍         | 11/256 [00:03<00:47,  5.16it/s]  5%|▍         | 12/256 [00:03<00:43,  5.63it/s]  5%|▌         | 13/256 [00:04<01:30,  2.70it/s]  5%|▌         | 14/256 [00:05<01:28,  2.74it/s]  6%|▌         | 15/256 [00:05<01:15,  3.20it/s]  6%|▋         | 16/256 [00:05<01:05,  3.67it/s]  7%|▋         | 18/256 [00:06<01:08,  3.50it/s]  8%|▊         | 20/256 [00:06<00:50,  4.63it/s]  8%|▊         | 21/256 [00:06<00:44,  5.23it/s]  9%|▊         | 22/256 [00:06<00:47,  4.88it/s]  9%|▉         | 24/256 [00:06<00:41,  5.58it/s] 10%|▉         | 25/256 [00:07<00:39,  5.83it/s] 10%|█         | 26/256 [00:07<00:52,  4.39it/s] 11%|█         | 28/256 [00:07<00:43,  5.25it/s] 11%|█▏        | 29/256 [00:07<00:45,  5.04it/s] 12%|█▏        | 31/256 [00:08<00:38,  5.88it/s] 12%|█▎        | 32/256 [00:08<00:46,  4.86it/s] 13%|█▎        | 33/256 [00:08<00:57,  3.88it/s] 13%|█▎        | 34/256 [00:09<01:01,  3.62it/s] 14%|█▎        | 35/256 [00:09<01:08,  3.23it/s] 14%|█▍        | 36/256 [00:10<01:19,  2.76it/s] 14%|█▍        | 37/256 [00:10<01:14,  2.95it/s] 15%|█▍        | 38/256 [00:10<01:08,  3.19it/s] 16%|█▌        | 40/256 [00:11<01:03,  3.39it/s] 16%|█▋        | 42/256 [00:11<00:44,  4.81it/s] 17%|█▋        | 43/256 [00:11<00:39,  5.37it/s] 17%|█▋        | 44/256 [00:11<00:38,  5.45it/s] 18%|█▊        | 45/256 [00:11<00:34,  6.14it/s] 18%|█▊        | 46/256 [00:11<00:33,  6.33it/s] 18%|█▊        | 47/256 [00:12<00:34,  6.12it/s] 19%|█▉        | 48/256 [00:12<00:37,  5.49it/s] 19%|█▉        | 49/256 [00:12<00:34,  6.03it/s] 20%|█▉        | 50/256 [00:12<00:50,  4.09it/s] 21%|██        | 53/256 [00:13<00:48,  4.17it/s] 21%|██        | 54/256 [00:13<00:47,  4.25it/s] 21%|██▏       | 55/256 [00:13<00:41,  4.89it/s] 22%|██▏       | 56/256 [00:14<00:48,  4.10it/s] 22%|██▏       | 57/256 [00:14<00:45,  4.41it/s] 23%|██▎       | 58/256 [00:14<00:50,  3.90it/s] 23%|██▎       | 59/256 [00:14<00:44,  4.39it/s] 23%|██▎       | 60/256 [00:15<00:47,  4.10it/s] 24%|██▍       | 61/256 [00:15<00:54,  3.56it/s] 24%|██▍       | 62/256 [00:15<00:59,  3.27it/s] 25%|██▍       | 63/256 [00:16<00:51,  3.76it/s] 25%|██▌       | 64/256 [00:16<00:42,  4.55it/s] 25%|██▌       | 65/256 [00:16<01:08,  2.80it/s] 26%|██▌       | 67/256 [00:17<00:43,  4.31it/s] 27%|██▋       | 68/256 [00:17<00:42,  4.38it/s] 27%|██▋       | 69/256 [00:17<00:43,  4.31it/s] 28%|██▊       | 71/256 [00:17<00:33,  5.55it/s] 29%|██▊       | 73/256 [00:17<00:26,  6.82it/s] 29%|██▉       | 74/256 [00:18<00:26,  6.87it/s] 29%|██▉       | 75/256 [00:18<00:31,  5.75it/s] 30%|██▉       | 76/256 [00:18<00:44,  4.08it/s] 30%|███       | 78/256 [00:18<00:30,  5.88it/s] 31%|███       | 79/256 [00:19<00:37,  4.67it/s] 31%|███▏      | 80/256 [00:19<00:48,  3.61it/s] 32%|███▏      | 81/256 [00:20<00:54,  3.24it/s] 32%|███▏      | 82/256 [00:20<00:44,  3.89it/s] 32%|███▏      | 83/256 [00:20<00:54,  3.17it/s] 33%|███▎      | 84/256 [00:21<00:52,  3.29it/s] 33%|███▎      | 85/256 [00:21<00:47,  3.58it/s] 34%|███▎      | 86/256 [00:21<00:43,  3.91it/s] 34%|███▍      | 87/256 [00:22<01:00,  2.78it/s] 34%|███▍      | 88/256 [00:22<01:03,  2.66it/s] 35%|███▍      | 89/256 [00:22<00:58,  2.88it/s] 35%|███▌      | 90/256 [00:23<00:59,  2.78it/s] 36%|███▌      | 91/256 [00:23<00:57,  2.85it/s] 36%|███▌      | 92/256 [00:23<00:48,  3.38it/s] 36%|███▋      | 93/256 [00:23<00:42,  3.84it/s] 37%|███▋      | 94/256 [00:24<00:50,  3.22it/s] 37%|███▋      | 95/256 [00:24<01:04,  2.50it/s] 38%|███▊      | 96/256 [00:25<00:51,  3.12it/s] 38%|███▊      | 97/256 [00:25<00:54,  2.90it/s] 38%|███▊      | 98/256 [00:25<00:45,  3.45it/s] 39%|███▊      | 99/256 [00:25<00:44,  3.55it/s] 39%|███▉      | 100/256 [00:26<00:42,  3.67it/s] 39%|███▉      | 101/256 [00:27<01:14,  2.07it/s] 40%|███▉      | 102/256 [00:27<01:04,  2.39it/s] 41%|████      | 104/256 [00:27<00:41,  3.69it/s] 41%|████▏     | 106/256 [00:27<00:33,  4.46it/s] 42%|████▏     | 107/256 [00:28<00:33,  4.47it/s] 42%|████▏     | 108/256 [00:28<00:47,  3.10it/s] 43%|████▎     | 111/256 [00:29<00:30,  4.81it/s] 44%|████▍     | 112/256 [00:29<00:31,  4.55it/s] 44%|████▍     | 113/256 [00:29<00:31,  4.52it/s] 45%|████▍     | 114/256 [00:29<00:28,  4.93it/s] 45%|████▍     | 115/256 [00:29<00:27,  5.17it/s] 45%|████▌     | 116/256 [00:30<00:38,  3.59it/s] 46%|████▌     | 117/256 [00:30<00:31,  4.36it/s] 46%|████▌     | 118/256 [00:30<00:29,  4.63it/s] 47%|████▋     | 120/256 [00:30<00:20,  6.50it/s] 47%|████▋     | 121/256 [00:30<00:19,  6.87it/s] 48%|████▊     | 122/256 [00:31<00:37,  3.60it/s] 48%|████▊     | 123/256 [00:31<00:40,  3.30it/s] 48%|████▊     | 124/256 [00:32<00:53,  2.46it/s] 49%|████▉     | 125/256 [00:33<01:23,  1.57it/s] 49%|████▉     | 126/256 [00:34<01:09,  1.87it/s] 50%|████▉     | 127/256 [00:34<01:14,  1.72it/s] 50%|█████     | 129/256 [00:34<00:45,  2.81it/s] 51%|█████     | 130/256 [00:35<00:41,  3.03it/s] 51%|█████     | 131/256 [00:35<00:38,  3.21it/s] 52%|█████▏    | 132/256 [00:35<00:37,  3.34it/s] 52%|█████▏    | 133/256 [00:36<00:45,  2.71it/s] 52%|█████▏    | 134/256 [00:36<00:44,  2.72it/s] 53%|█████▎    | 135/256 [00:36<00:36,  3.36it/s] 53%|█████▎    | 136/256 [00:37<00:36,  3.33it/s] 54%|█████▎    | 137/256 [00:37<00:30,  3.95it/s] 54%|█████▍    | 138/256 [00:37<00:26,  4.47it/s] 54%|█████▍    | 139/256 [00:37<00:24,  4.87it/s] 55%|█████▍    | 140/256 [00:37<00:22,  5.25it/s] 55%|█████▌    | 142/256 [00:37<00:16,  6.78it/s] 56%|█████▌    | 143/256 [00:38<00:16,  6.86it/s] 57%|█████▋    | 145/256 [00:39<00:34,  3.18it/s] 57%|█████▋    | 146/256 [00:39<00:38,  2.86it/s] 57%|█████▋    | 147/256 [00:39<00:35,  3.08it/s] 58%|█████▊    | 148/256 [00:40<00:36,  2.98it/s] 59%|█████▊    | 150/256 [00:40<00:28,  3.67it/s] 59%|█████▉    | 151/256 [00:40<00:24,  4.23it/s] 59%|█████▉    | 152/256 [00:41<00:28,  3.68it/s] 60%|█████▉    | 153/256 [00:41<00:25,  4.07it/s] 60%|██████    | 154/256 [00:41<00:29,  3.50it/s] 61%|██████    | 155/256 [00:41<00:26,  3.86it/s] 61%|██████    | 156/256 [00:41<00:21,  4.56it/s] 61%|██████▏   | 157/256 [00:42<00:27,  3.64it/s] 62%|██████▏   | 158/256 [00:42<00:23,  4.15it/s] 62%|██████▏   | 159/256 [00:43<00:41,  2.32it/s] 62%|██████▎   | 160/256 [00:43<00:32,  2.97it/s] 63%|██████▎   | 162/256 [00:44<00:36,  2.56it/s] 64%|██████▎   | 163/256 [00:44<00:32,  2.87it/s] 64%|██████▍   | 164/256 [00:44<00:26,  3.42it/s] 65%|██████▍   | 166/256 [00:45<00:22,  3.99it/s] 65%|██████▌   | 167/256 [00:45<00:24,  3.58it/s] 66%|██████▌   | 168/256 [00:45<00:27,  3.15it/s] 66%|██████▌   | 169/256 [00:46<00:31,  2.77it/s] 66%|██████▋   | 170/256 [00:46<00:31,  2.77it/s] 67%|██████▋   | 172/256 [00:47<00:21,  3.84it/s] 68%|██████▊   | 173/256 [00:47<00:21,  3.90it/s] 68%|██████▊   | 174/256 [00:47<00:28,  2.88it/s] 68%|██████▊   | 175/256 [00:48<00:40,  1.99it/s] 69%|██████▉   | 176/256 [00:49<00:35,  2.26it/s] 69%|██████▉   | 177/256 [00:49<00:29,  2.70it/s] 70%|██████▉   | 179/256 [00:49<00:19,  3.90it/s] 70%|███████   | 180/256 [00:50<00:37,  2.03it/s] 71%|███████   | 181/256 [00:50<00:29,  2.52it/s] 71%|███████   | 182/256 [00:51<00:38,  1.90it/s] 72%|███████▏  | 184/256 [00:52<00:35,  2.02it/s] 73%|███████▎  | 186/256 [00:52<00:24,  2.90it/s] 73%|███████▎  | 187/256 [00:53<00:27,  2.47it/s] 73%|███████▎  | 188/256 [00:53<00:24,  2.83it/s] 74%|███████▍  | 189/256 [00:54<00:23,  2.85it/s] 74%|███████▍  | 190/256 [00:54<00:21,  3.09it/s] 75%|███████▍  | 191/256 [00:54<00:19,  3.35it/s] 75%|███████▌  | 192/256 [00:55<00:22,  2.83it/s] 75%|███████▌  | 193/256 [00:55<00:21,  2.95it/s] 77%|███████▋  | 196/256 [00:55<00:14,  4.26it/s] 77%|███████▋  | 197/256 [00:56<00:15,  3.70it/s] 78%|███████▊  | 199/256 [00:56<00:12,  4.70it/s] 79%|███████▊  | 201/256 [00:56<00:10,  5.38it/s] 79%|███████▉  | 202/256 [00:57<00:12,  4.46it/s] 80%|███████▉  | 204/256 [00:57<00:09,  5.69it/s] 80%|████████  | 206/256 [00:57<00:07,  6.99it/s] 81%|████████  | 207/256 [00:57<00:06,  7.29it/s] 81%|████████▏ | 208/256 [00:57<00:07,  6.48it/s] 82%|████████▏ | 210/256 [00:57<00:05,  8.62it/s] 83%|████████▎ | 212/256 [00:58<00:05,  7.55it/s] 83%|████████▎ | 213/256 [00:58<00:07,  6.10it/s] 84%|████████▎ | 214/256 [00:58<00:09,  4.26it/s] 84%|████████▍ | 215/256 [00:59<00:11,  3.46it/s] 84%|████████▍ | 216/256 [00:59<00:11,  3.57it/s] 85%|████████▌ | 218/256 [00:59<00:08,  4.47it/s] 86%|████████▌ | 219/256 [01:01<00:15,  2.40it/s] 86%|████████▌ | 220/256 [01:01<00:12,  2.83it/s] 86%|████████▋ | 221/256 [01:01<00:12,  2.82it/s] 87%|████████▋ | 222/256 [01:01<00:12,  2.81it/s] 87%|████████▋ | 223/256 [01:02<00:13,  2.43it/s] 88%|████████▊ | 224/256 [01:04<00:31,  1.02it/s] 88%|████████▊ | 225/256 [01:05<00:27,  1.12it/s] 88%|████████▊ | 226/256 [01:05<00:20,  1.47it/s] 89%|████████▊ | 227/256 [01:05<00:16,  1.80it/s] 89%|████████▉ | 228/256 [01:06<00:14,  2.00it/s] 89%|████████▉ | 229/256 [01:07<00:19,  1.36it/s] 90%|████████▉ | 230/256 [01:07<00:14,  1.80it/s] 90%|█████████ | 231/256 [01:08<00:13,  1.87it/s] 91%|█████████ | 232/256 [01:08<00:11,  2.15it/s] 91%|█████████ | 233/256 [01:08<00:08,  2.62it/s] 92%|█████████▏| 235/256 [01:09<00:05,  3.61it/s] 92%|█████████▏| 236/256 [01:09<00:05,  3.53it/s] 93%|█████████▎| 237/256 [01:09<00:04,  3.89it/s] 93%|█████████▎| 238/256 [01:09<00:03,  4.56it/s] 93%|█████████▎| 239/256 [01:09<00:03,  4.52it/s] 94%|█████████▍| 241/256 [01:10<00:02,  5.72it/s] 95%|█████████▍| 242/256 [01:11<00:04,  2.86it/s] 95%|█████████▌| 244/256 [01:11<00:02,  4.37it/s] 96%|█████████▌| 245/256 [01:11<00:02,  4.28it/s] 96%|█████████▌| 246/256 [01:11<00:02,  4.75it/s] 97%|█████████▋| 248/256 [01:11<00:01,  6.45it/s] 97%|█████████▋| 249/256 [01:12<00:01,  3.88it/s] 98%|█████████▊| 251/256 [01:12<00:00,  5.43it/s] 98%|█████████▊| 252/256 [01:13<00:01,  3.49it/s] 99%|█████████▉| 253/256 [01:13<00:01,  2.96it/s]100%|█████████▉| 255/256 [01:14<00:00,  3.04it/s]100%|██████████| 256/256 [01:14<00:00,  3.10it/s]100%|██████████| 256/256 [01:14<00:00,  3.44it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
0 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.8555, device='cuda:0', dtype=torch.float16) tensor(0.6099, device='cuda:0', dtype=torch.float16)
tensor(0.0156, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0317, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0371, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0215, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
0 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.0205, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0293, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0469, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0273, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
0 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0121, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0111, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0133, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0125, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
0 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0109, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0099, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0100, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0111, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0169, device='cuda:0')
tensor(0.0494, device='cuda:0')
old_score: tensor(0.0005, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0004, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.067745208740234
Validation after dual ascent:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0088, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0114, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
tensor(0.0089, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
tensor(0.0106, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
0 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1724, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.1602, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0160, device='cuda:0')
tensor(0.0236, device='cuda:0')
old_score: tensor(0.0066, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0052, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 23.39214324951172
Validation after dual ascent:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.1484, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.1421, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
tensor(0.1724, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.1387, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
0 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.1890, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.1455, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0159, device='cuda:0')
tensor(0.0234, device='cuda:0')
old_score: tensor(0.0066, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0052, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 23.43109965324402
Validation after dual ascent:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1587, device='cuda:0', dtype=torch.float16) tensor(0.0050, device='cuda:0', dtype=torch.float16)
tensor(0.1313, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1738, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.1265, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
0 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0157, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0193, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0233, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0250, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0574, device='cuda:0')
old_score: tensor(0.0009, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.66274380683899
Validation after dual ascent:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0154, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0176, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0237, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0240, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
layer 0 done
1 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.2344, device='cuda:0', dtype=torch.float16) tensor(0.7808, device='cuda:0', dtype=torch.float16)
tensor(0.2700, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.2729, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.2920, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2690, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
1 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.6523, device='cuda:0', dtype=torch.float16) tensor(0.7861, device='cuda:0', dtype=torch.float16)
tensor(0.3638, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.3662, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.3799, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
1 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5713, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.0488, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.0499, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.0542, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.0503, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0135, device='cuda:0')
tensor(0.0208, device='cuda:0')
old_score: tensor(0.0039, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0031, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.25165343284607
Validation after dual ascent:
out_inf: tensor(1.5713, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.0451, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0511, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0514, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0538, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
1 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.5747, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.0262, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0276, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0279, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0294, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0192, device='cuda:0')
old_score: tensor(0.0016, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0015, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.870001077651978
Validation after dual ascent:
out_inf: tensor(0.5747, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.0275, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0265, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0294, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0267, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
1 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(43.7500, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.2188, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.2090, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
tensor(0.2637, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0144, device='cuda:0')
tensor(0.0251, device='cuda:0')
old_score: tensor(0.0152, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 33.0731041431427
Validation after dual ascent:
out_inf: tensor(43.7500, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.1816, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.2178, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.2266, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
1 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(37.6562, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.2285, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.1973, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.2305, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.2383, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0186, device='cuda:0')
tensor(0.0233, device='cuda:0')
old_score: tensor(0.0143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0118, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 25.405890941619873
Validation after dual ascent:
out_inf: tensor(37.6562, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1938, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.2100, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
1 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(2672., device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.0659, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0764, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0868, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(3.9786, device='cuda:0')
old_score: tensor(0.0039, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0168, device='cuda:0', dtype=torch.float16)
Not converged!
Dual ascent finished!
Time: 98.39152550697327
Validation after dual ascent:
out_inf: tensor(2672., device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.0659, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0764, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0868, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
layer 1 done
2 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.2344, device='cuda:0', dtype=torch.float16) tensor(0.9028, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0348, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
2 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.6328, device='cuda:0', dtype=torch.float16) tensor(1.0547, device='cuda:0', dtype=torch.float16)
tensor(0.6260, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.5225, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
2 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9570, device='cuda:0', dtype=torch.float16) tensor(0.1318, device='cuda:0', dtype=torch.float16)
tensor(0.2190, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.2322, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.2378, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(0.2467, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0133, device='cuda:0')
tensor(0.0423, device='cuda:0')
old_score: tensor(0.0228, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0196, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1758944988250732
Validation after dual ascent:
out_inf: tensor(2.9570, device='cuda:0', dtype=torch.float16) tensor(0.1318, device='cuda:0', dtype=torch.float16)
tensor(0.2191, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
tensor(0.2264, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
tensor(0.2186, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.2443, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
2 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0366, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0339, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0396, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0421, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0344, device='cuda:0')
old_score: tensor(0.0022, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0021, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.92650556564331
Validation after dual ascent:
out_inf: tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0350, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0307, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0320, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0364, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
2 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(0.2571, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.2693, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.2607, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.2681, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(0.0210, device='cuda:0')
old_score: tensor(0.0248, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0220, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.81401610374451
Validation after dual ascent:
out_inf: tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(0.2444, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.2576, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(0.2395, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
tensor(0.2598, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
2 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.2266, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
tensor(0.2324, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
tensor(0.2664, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.2769, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0190, device='cuda:0')
tensor(0.0276, device='cuda:0')
old_score: tensor(0.0230, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0205, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 31.10207223892212
Validation after dual ascent:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.2211, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
tensor(0.2432, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.2490, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(0.2871, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
2 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
tensor(0.0676, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0692, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0681, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0715, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.0854, device='cuda:0')
old_score: tensor(0.0046, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0043, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.55358147621155
Validation after dual ascent:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
tensor(0.0641, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0677, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0688, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.0724, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
layer 2 done
3 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.0625, device='cuda:0', dtype=torch.float16) tensor(0.8184, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
tensor(0.8643, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(0.7568, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
3 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.4531, device='cuda:0', dtype=torch.float16) tensor(0.9819, device='cuda:0', dtype=torch.float16)
tensor(0.6978, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(0.6924, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
3 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.7637, device='cuda:0', dtype=torch.float16) tensor(0.1967, device='cuda:0', dtype=torch.float16)
tensor(0.3931, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(0.3853, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.3845, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.3787, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0196, device='cuda:0')
tensor(0.2256, device='cuda:0')
old_score: tensor(0.0415, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0375, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7269558906555176
Validation after dual ascent:
out_inf: tensor(2.7637, device='cuda:0', dtype=torch.float16) tensor(0.1967, device='cuda:0', dtype=torch.float16)
tensor(0.3748, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.3860, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.3726, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.3726, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
3 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.3994, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.0561, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0528, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0555, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.0592, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0257, device='cuda:0')
old_score: tensor(0.0032, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0030, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.904082298278809
Validation after dual ascent:
out_inf: tensor(1.3994, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.0515, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.0536, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0452, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0590, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
3 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8242, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(0.3276, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.3569, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.3572, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0198, device='cuda:0')
tensor(0.0233, device='cuda:0')
old_score: tensor(0.0342, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0312, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.877057075500488
Validation after dual ascent:
out_inf: tensor(4.8242, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(0.3179, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.3379, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.3708, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.3442, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
3 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.5098, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(0.3176, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.3362, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.3086, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0176, device='cuda:0')
tensor(0.0198, device='cuda:0')
old_score: tensor(0.0316, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0290, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.88961410522461
Validation after dual ascent:
out_inf: tensor(2.5098, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.3069, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.3376, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
3 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.4404, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.0873, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.0781, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0776, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0925, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0127, device='cuda:0')
tensor(0.0209, device='cuda:0')
old_score: tensor(0.0069, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 88.98944425582886
Validation after dual ascent:
out_inf: tensor(1.4404, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.0828, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0750, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.0822, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.0854, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
layer 3 done
4 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.0625, device='cuda:0', dtype=torch.float16) tensor(0.8042, device='cuda:0', dtype=torch.float16)
tensor(0.7065, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(0.6929, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.7900, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.8887, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
4 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.6562, device='cuda:0', dtype=torch.float16) tensor(1.0273, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.0700, device='cuda:0', dtype=torch.float16)
tensor(0.7744, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
4 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.1582, device='cuda:0', dtype=torch.float16) tensor(0.2001, device='cuda:0', dtype=torch.float16)
tensor(0.3579, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.4077, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0067, device='cuda:0')
tensor(0.0291, device='cuda:0')
old_score: tensor(0.0439, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0401, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1869213581085205
Validation after dual ascent:
out_inf: tensor(3.1582, device='cuda:0', dtype=torch.float16) tensor(0.2001, device='cuda:0', dtype=torch.float16)
tensor(0.3474, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.3569, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.3877, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.4641, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
4 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2207, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.0758, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.0734, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.0704, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0813, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0170, device='cuda:0')
old_score: tensor(0.0055, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.901056289672852
Validation after dual ascent:
out_inf: tensor(3.2207, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.0746, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0778, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0677, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.0939, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
4 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.7734, device='cuda:0', dtype=torch.float16) tensor(0.1951, device='cuda:0', dtype=torch.float16)
tensor(0.4065, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.3896, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4097, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.4360, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0178, device='cuda:0')
tensor(0.1915, device='cuda:0')
old_score: tensor(0.0417, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0384, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.1722846031188965
Validation after dual ascent:
out_inf: tensor(4.7734, device='cuda:0', dtype=torch.float16) tensor(0.1951, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.4065, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.4268, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
4 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.0332, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(0.3467, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.3562, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.4351, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0139, device='cuda:0')
tensor(0.1729, device='cuda:0')
old_score: tensor(0.0377, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0347, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.179770231246948
Validation after dual ascent:
out_inf: tensor(3.0332, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(0.3364, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.3689, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
4 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.3906, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
tensor(0.0921, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.0850, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.0922, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1028, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0121, device='cuda:0')
tensor(0.0193, device='cuda:0')
old_score: tensor(0.0103, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0098, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.82427144050598
Validation after dual ascent:
out_inf: tensor(9.3906, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
tensor(0.0898, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0876, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.0950, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1049, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
layer 4 done
5 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.7266, device='cuda:0', dtype=torch.float16) tensor(0.8120, device='cuda:0', dtype=torch.float16)
tensor(0.7041, device='cuda:0', dtype=torch.float16) tensor(0.0788, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.9160, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
5 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.9688, device='cuda:0', dtype=torch.float16) tensor(1.0664, device='cuda:0', dtype=torch.float16)
tensor(0.7393, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.6958, device='cuda:0', dtype=torch.float16) tensor(0.0794, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
5 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4473, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(0.3857, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.3987, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.4978, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0194, device='cuda:0')
tensor(0.0409, device='cuda:0')
old_score: tensor(0.0480, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0444, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4592432975769043
Validation after dual ascent:
out_inf: tensor(2.4473, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
tensor(0.4211, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.3735, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
5 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.5898, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.0887, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0924, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.0870, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.0849, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.0186, device='cuda:0')
old_score: tensor(0.0065, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0060, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.904857158660889
Validation after dual ascent:
out_inf: tensor(4.5898, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.0768, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.0789, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0806, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.0852, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
5 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.3086, device='cuda:0', dtype=torch.float16) tensor(0.2266, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(0.4448, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.3884, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
tensor(0.3799, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0117, device='cuda:0')
tensor(0.0183, device='cuda:0')
old_score: tensor(0.0465, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0429, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.952178239822388
Validation after dual ascent:
out_inf: tensor(3.3086, device='cuda:0', dtype=torch.float16) tensor(0.2266, device='cuda:0', dtype=torch.float16)
tensor(0.3784, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.3833, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.3801, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.3816, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
5 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0938, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
tensor(0.3657, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.0241, device='cuda:0')
old_score: tensor(0.0420, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0388, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.116543769836426
Validation after dual ascent:
out_inf: tensor(4.0938, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.3396, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.3745, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
5 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.5566, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.1213, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1567, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1072, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1198, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0195, device='cuda:0')
tensor(0.0129, device='cuda:0')
old_score: tensor(0.0128, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0123, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 31.45415735244751
Validation after dual ascent:
out_inf: tensor(1.5566, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.1265, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.1389, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1019, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1224, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
layer 5 done
6 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.5859, device='cuda:0', dtype=torch.float16) tensor(0.8325, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(0.7705, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0134, device='cuda:0')
tensor(0.0563, device='cuda:0')
old_score: tensor(0.0944, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0870, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2031707763671875
Validation after dual ascent:
out_inf: tensor(13.5859, device='cuda:0', dtype=torch.float16) tensor(0.8325, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
tensor(0.7998, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
tensor(0.7817, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.7627, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
6 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.5312, device='cuda:0', dtype=torch.float16) tensor(1.0098, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(0.7666, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
6 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.4316, device='cuda:0', dtype=torch.float16) tensor(0.2515, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.4229, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.4253, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0119, device='cuda:0')
tensor(0.0562, device='cuda:0')
old_score: tensor(0.0567, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0525, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.462739944458008
Validation after dual ascent:
out_inf: tensor(3.4316, device='cuda:0', dtype=torch.float16) tensor(0.2515, device='cuda:0', dtype=torch.float16)
tensor(0.4106, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.4517, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
6 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2500, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
tensor(0.1105, device='cuda:0', dtype=torch.float16) tensor(0.0085, device='cuda:0', dtype=torch.float16)
tensor(0.1129, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1154, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.0991, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0131, device='cuda:0')
tensor(0.0234, device='cuda:0')
old_score: tensor(0.0094, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.327886819839478
Validation after dual ascent:
out_inf: tensor(4.2500, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
tensor(0.1129, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.1128, device='cuda:0', dtype=torch.float16) tensor(0.0091, device='cuda:0', dtype=torch.float16)
tensor(0.1077, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.0977, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
6 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.4805, device='cuda:0', dtype=torch.float16) tensor(0.2800, device='cuda:0', dtype=torch.float16)
tensor(0.4329, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0492, device='cuda:0', dtype=torch.float16)
tensor(0.4150, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0239, device='cuda:0')
old_score: tensor(0.0513, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0475, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.102146863937378
Validation after dual ascent:
out_inf: tensor(4.4805, device='cuda:0', dtype=torch.float16) tensor(0.2800, device='cuda:0', dtype=torch.float16)
tensor(0.4009, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.4280, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.4106, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
6 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9727, device='cuda:0', dtype=torch.float16) tensor(0.1781, device='cuda:0', dtype=torch.float16)
tensor(0.3828, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.4414, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.3867, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.3911, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0178, device='cuda:0')
tensor(0.2606, device='cuda:0')
old_score: tensor(0.0455, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0421, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.178920269012451
Validation after dual ascent:
out_inf: tensor(2.9727, device='cuda:0', dtype=torch.float16) tensor(0.1781, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.3730, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
6 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1.4756, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.1609, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
tensor(0.1384, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.1261, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.1367, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0091, device='cuda:0')
tensor(0.0170, device='cuda:0')
old_score: tensor(0.0152, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0145, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.864346742630005
Validation after dual ascent:
out_inf: tensor(1.4756, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.1667, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1354, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.1255, device='cuda:0', dtype=torch.float16) tensor(0.0136, device='cuda:0', dtype=torch.float16)
tensor(0.1442, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
layer 6 done
7 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.0156, device='cuda:0', dtype=torch.float16) tensor(0.8291, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
tensor(0.8623, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0105, device='cuda:0')
tensor(0.0550, device='cuda:0')
old_score: tensor(0.0979, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0902, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2045483589172363
Validation after dual ascent:
out_inf: tensor(17.0156, device='cuda:0', dtype=torch.float16) tensor(0.8291, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(0.9414, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
7 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.0938, device='cuda:0', dtype=torch.float16) tensor(0.9863, device='cuda:0', dtype=torch.float16)
tensor(0.7549, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.8335, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(0.7202, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(0.8540, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
7 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8828, device='cuda:0', dtype=torch.float16) tensor(0.2634, device='cuda:0', dtype=torch.float16)
tensor(0.4888, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.4695, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.4646, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0061, device='cuda:0')
tensor(0.0633, device='cuda:0')
old_score: tensor(0.0596, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0552, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4603805541992188
Validation after dual ascent:
out_inf: tensor(4.8828, device='cuda:0', dtype=torch.float16) tensor(0.2634, device='cuda:0', dtype=torch.float16)
tensor(0.4761, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.4255, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4312, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.4368, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
7 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0977, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.1428, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1076, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.1295, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.1230, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0166, device='cuda:0')
tensor(0.0270, device='cuda:0')
old_score: tensor(0.0118, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.393564701080322
Validation after dual ascent:
out_inf: tensor(4.0977, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.1287, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
tensor(0.1008, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1117, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.1115, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
7 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.8359, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.4595, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.4600, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0043, device='cuda:0')
tensor(0.0263, device='cuda:0')
old_score: tensor(0.0537, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0496, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.102705240249634
Validation after dual ascent:
out_inf: tensor(5.8359, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(0.4236, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
tensor(0.4714, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.4304, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.4563, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
7 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.1920, device='cuda:0', dtype=torch.float16)
tensor(0.4297, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.3691, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.4067, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0193, device='cuda:0')
tensor(0.2892, device='cuda:0')
old_score: tensor(0.0479, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0443, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.184964179992676
Validation after dual ascent:
out_inf: tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.1920, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.4031, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.4185, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
7 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
tensor(0.1726, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
tensor(0.1616, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.1396, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.1653, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0116, device='cuda:0')
tensor(0.0216, device='cuda:0')
old_score: tensor(0.0172, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0164, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.080860137939453
Validation after dual ascent:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
tensor(0.1711, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.1533, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.1339, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.1588, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
layer 7 done
8 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16., device='cuda:0', dtype=torch.float16) tensor(0.7974, device='cuda:0', dtype=torch.float16)
tensor(0.7861, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.0992, device='cuda:0', dtype=torch.float16)
tensor(0.7974, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(0.0901, device='cuda:0')
old_score: tensor(0.0986, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0906, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.932923316955566
Validation after dual ascent:
out_inf: tensor(16., device='cuda:0', dtype=torch.float16) tensor(0.7974, device='cuda:0', dtype=torch.float16)
tensor(0.7393, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
8 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.7188, device='cuda:0', dtype=torch.float16) tensor(1.0195, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(0.8169, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(0.8140, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
8 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8789, device='cuda:0', dtype=torch.float16) tensor(0.2744, device='cuda:0', dtype=torch.float16)
tensor(0.5298, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.4521, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0157, device='cuda:0')
tensor(0.0716, device='cuda:0')
old_score: tensor(0.0612, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0565, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.197390556335449
Validation after dual ascent:
out_inf: tensor(4.8789, device='cuda:0', dtype=torch.float16) tensor(0.2744, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.4573, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
8 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0625, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.1470, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.1569, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.1393, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0111, device='cuda:0')
tensor(0.0243, device='cuda:0')
old_score: tensor(0.0143, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.670743465423584
Validation after dual ascent:
out_inf: tensor(4.0625, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.1288, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.1476, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.1403, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.1232, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
8 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.1445, device='cuda:0', dtype=torch.float16) tensor(0.3164, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(0.4526, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0296, device='cuda:0')
old_score: tensor(0.0555, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0513, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115583896636963
Validation after dual ascent:
out_inf: tensor(6.1445, device='cuda:0', dtype=torch.float16) tensor(0.3164, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.4583, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.5732, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.4441, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
8 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.8984, device='cuda:0', dtype=torch.float16) tensor(0.2063, device='cuda:0', dtype=torch.float16)
tensor(0.4370, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.4263, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0024, device='cuda:0')
tensor(0.0275, device='cuda:0')
old_score: tensor(0.0511, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0472, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.11275577545166
Validation after dual ascent:
out_inf: tensor(7.8984, device='cuda:0', dtype=torch.float16) tensor(0.2063, device='cuda:0', dtype=torch.float16)
tensor(0.4077, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(0.3972, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
8 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.0664, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.1713, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
tensor(0.1713, device='cuda:0', dtype=torch.float16) tensor(0.0185, device='cuda:0', dtype=torch.float16)
tensor(0.1608, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.1781, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.0070, device='cuda:0')
old_score: tensor(0.0191, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0182, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.054762840270996
Validation after dual ascent:
out_inf: tensor(4.0664, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.1776, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.1792, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(0.1436, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.1719, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
layer 8 done
9 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.4141, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(0.8638, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.1070, device='cuda:0', dtype=torch.float16)
tensor(0.8926, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0195, device='cuda:0')
tensor(0.0895, device='cuda:0')
old_score: tensor(0.1062, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0980, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.756905794143677
Validation after dual ascent:
out_inf: tensor(14.4141, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(0.8228, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.0979, device='cuda:0', dtype=torch.float16)
tensor(0.8408, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
9 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.7188, device='cuda:0', dtype=torch.float16) tensor(1.0420, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(0.9512, device='cuda:0', dtype=torch.float16) tensor(0.1057, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
tensor(0.0781, device='cuda:0')
old_score: tensor(0.1066, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0983, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.925087690353394
Validation after dual ascent:
out_inf: tensor(19.7188, device='cuda:0', dtype=torch.float16) tensor(1.0420, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.0982, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
9 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.2803, device='cuda:0', dtype=torch.float16)
tensor(0.5200, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.4924, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.4692, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0114, device='cuda:0')
tensor(0.0570, device='cuda:0')
old_score: tensor(0.0648, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0601, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.189753532409668
Validation after dual ascent:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.2803, device='cuda:0', dtype=torch.float16)
tensor(0.5396, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
tensor(0.5239, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.4897, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
9 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.1594, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1693, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.2014, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.1499, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0176, device='cuda:0')
tensor(0.0235, device='cuda:0')
old_score: tensor(0.0163, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0149, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9178972244262695
Validation after dual ascent:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.1381, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.1558, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
tensor(0.1903, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.1387, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
9 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.8008, device='cuda:0', dtype=torch.float16) tensor(0.3196, device='cuda:0', dtype=torch.float16)
tensor(0.4309, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.5444, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0037, device='cuda:0')
tensor(0.0336, device='cuda:0')
old_score: tensor(0.0577, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0535, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.09211540222168
Validation after dual ascent:
out_inf: tensor(6.8008, device='cuda:0', dtype=torch.float16) tensor(0.3196, device='cuda:0', dtype=torch.float16)
tensor(0.4592, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(0.4932, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4919, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
9 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.6738, device='cuda:0', dtype=torch.float16) tensor(0.2181, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0535, device='cuda:0', dtype=torch.float16)
tensor(0.4241, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.4126, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
tensor(0.4297, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0026, device='cuda:0')
tensor(0.0321, device='cuda:0')
old_score: tensor(0.0540, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0502, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.096989154815674
Validation after dual ascent:
out_inf: tensor(3.6738, device='cuda:0', dtype=torch.float16) tensor(0.2181, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.3936, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.4087, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4080, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
9 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.0215, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.1858, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.1676, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.1863, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0057, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.0211, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0202, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.255882978439331
Validation after dual ascent:
out_inf: tensor(3.0215, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.1775, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(0.1627, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.1718, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.1757, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
layer 9 done
10 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.6172, device='cuda:0', dtype=torch.float16) tensor(0.7827, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.1611, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
tensor(0.9561, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0106, device='cuda:0')
tensor(0.1411, device='cuda:0')
old_score: tensor(0.1083, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1004, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.47041654586792
Validation after dual ascent:
out_inf: tensor(13.6172, device='cuda:0', dtype=torch.float16) tensor(0.7827, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
tensor(0.9912, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(0.8486, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.9268, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
10 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.6562, device='cuda:0', dtype=torch.float16) tensor(1.0508, device='cuda:0', dtype=torch.float16)
tensor(0.8018, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(1.4707, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(1.2031, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0125, device='cuda:0')
tensor(0.1451, device='cuda:0')
old_score: tensor(0.1085, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.472464084625244
Validation after dual ascent:
out_inf: tensor(16.6562, device='cuda:0', dtype=torch.float16) tensor(1.0508, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0992, device='cuda:0', dtype=torch.float16)
tensor(1.3252, device='cuda:0', dtype=torch.float16) tensor(0.0990, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.8062, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
10 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.1953, device='cuda:0', dtype=torch.float16) tensor(0.2876, device='cuda:0', dtype=torch.float16)
tensor(0.4619, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.4736, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.5571, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.5356, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0043, device='cuda:0')
tensor(0.0782, device='cuda:0')
old_score: tensor(0.0668, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0622, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4664347171783447
Validation after dual ascent:
out_inf: tensor(7.1953, device='cuda:0', dtype=torch.float16) tensor(0.2876, device='cuda:0', dtype=torch.float16)
tensor(0.4822, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
tensor(0.4514, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.5127, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.5127, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
10 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.7773, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(0.2129, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
tensor(0.1898, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.2007, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.1813, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0037, device='cuda:0')
tensor(0.0370, device='cuda:0')
old_score: tensor(0.0195, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0178, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7293660640716553
Validation after dual ascent:
out_inf: tensor(5.7773, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(0.1877, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.1759, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.1997, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.1606, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
10 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.3789, device='cuda:0', dtype=torch.float16) tensor(0.3396, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0362, device='cuda:0')
old_score: tensor(0.0591, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0550, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.112279415130615
Validation after dual ascent:
out_inf: tensor(6.3789, device='cuda:0', dtype=torch.float16) tensor(0.3396, device='cuda:0', dtype=torch.float16)
tensor(0.4565, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.4639, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.4497, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.4785, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
10 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.2369, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.4502, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.5049, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0028, device='cuda:0')
tensor(0.0346, device='cuda:0')
old_score: tensor(0.0565, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0527, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1174399852752686
Validation after dual ascent:
out_inf: tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.2369, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.4683, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
10 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.0838, device='cuda:0', dtype=torch.float16)
tensor(0.2028, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.2094, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.1763, device='cuda:0', dtype=torch.float16) tensor(0.0229, device='cuda:0', dtype=torch.float16)
tensor(0.2155, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0045, device='cuda:0')
tensor(0.0217, device='cuda:0')
old_score: tensor(0.0235, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0225, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.262803077697754
Validation after dual ascent:
out_inf: tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.0838, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.2008, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.1794, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
tensor(0.2083, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
layer 10 done
11 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.7500, device='cuda:0', dtype=torch.float16) tensor(0.7822, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.1091, device='cuda:0', dtype=torch.float16)
tensor(1.0488, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.1865, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.1895, device='cuda:0')
old_score: tensor(0.1105, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1029, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.469780683517456
Validation after dual ascent:
out_inf: tensor(18.7500, device='cuda:0', dtype=torch.float16) tensor(0.7822, device='cuda:0', dtype=torch.float16)
tensor(0.9072, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1020, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.1063, device='cuda:0', dtype=torch.float16)
11 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.5938, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.1084, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0129, device='cuda:0')
tensor(0.1905, device='cuda:0')
old_score: tensor(0.1096, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1019, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470919370651245
Validation after dual ascent:
out_inf: tensor(16.5938, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(0.7729, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(0.8096, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(0.7915, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
11 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.2891, device='cuda:0', dtype=torch.float16) tensor(0.3269, device='cuda:0', dtype=torch.float16)
tensor(0.5688, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.5981, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.5962, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0064, device='cuda:0')
tensor(0.1221, device='cuda:0')
old_score: tensor(0.0779, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.465628147125244
Validation after dual ascent:
out_inf: tensor(8.2891, device='cuda:0', dtype=torch.float16) tensor(0.3269, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(0.5718, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.5459, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
11 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.2266, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.1810, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.1960, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
tensor(0.2593, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.2153, device='cuda:0', dtype=torch.float16) tensor(0.0194, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0064, device='cuda:0')
tensor(0.0382, device='cuda:0')
old_score: tensor(0.0208, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0192, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7329680919647217
Validation after dual ascent:
out_inf: tensor(5.2266, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.1741, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.2021, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.2588, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.1899, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
11 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3491, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.4966, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.5068, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0041, device='cuda:0')
tensor(0.0415, device='cuda:0')
old_score: tensor(0.0623, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0582, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.10921049118042
Validation after dual ascent:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3491, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.4390, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.4585, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
11 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2305, device='cuda:0', dtype=torch.float16) tensor(0.2426, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.4561, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0030, device='cuda:0')
tensor(0.0402, device='cuda:0')
old_score: tensor(0.0602, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0562, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1166770458221436
Validation after dual ascent:
out_inf: tensor(4.2305, device='cuda:0', dtype=torch.float16) tensor(0.2426, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0559, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.4304, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
11 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.2578, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
tensor(0.2046, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(0.1995, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.1871, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.2075, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
Converged at iteration 50
tensor(0.0198, device='cuda:0')
tensor(0.3034, device='cuda:0')
old_score: tensor(0.0250, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.483763694763184
Validation after dual ascent:
out_inf: tensor(3.2578, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
tensor(0.1969, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.1925, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.1825, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(0.2024, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
layer 11 done
12 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.7656, device='cuda:0', dtype=torch.float16) tensor(0.7852, device='cuda:0', dtype=torch.float16)
tensor(0.9048, device='cuda:0', dtype=torch.float16) tensor(0.1181, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.1199, device='cuda:0', dtype=torch.float16)
tensor(0.9902, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0159, device='cuda:0')
tensor(0.2007, device='cuda:0')
old_score: tensor(0.1200, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1121, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4729039669036865
Validation after dual ascent:
out_inf: tensor(17.7656, device='cuda:0', dtype=torch.float16) tensor(0.7852, device='cuda:0', dtype=torch.float16)
tensor(0.9194, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(0.9736, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(0.8394, device='cuda:0', dtype=torch.float16) tensor(0.1109, device='cuda:0', dtype=torch.float16)
tensor(0.9634, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
12 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.6328, device='cuda:0', dtype=torch.float16) tensor(1.0449, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.1195, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1206, device='cuda:0', dtype=torch.float16)
tensor(0.9521, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0171, device='cuda:0')
tensor(0.2071, device='cuda:0')
old_score: tensor(0.1213, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1131, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.475148916244507
Validation after dual ascent:
out_inf: tensor(15.6328, device='cuda:0', dtype=torch.float16) tensor(1.0449, device='cuda:0', dtype=torch.float16)
tensor(0.8599, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
tensor(0.9004, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
12 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3225, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.5752, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.5376, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0078, device='cuda:0')
tensor(0.1238, device='cuda:0')
old_score: tensor(0.0782, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0732, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.468501329421997
Validation after dual ascent:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3225, device='cuda:0', dtype=torch.float16)
tensor(0.5908, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.5630, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
12 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.5625, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.2107, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.2048, device='cuda:0', dtype=torch.float16) tensor(0.0229, device='cuda:0', dtype=torch.float16)
tensor(0.2244, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.2146, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0159, device='cuda:0')
tensor(0.0452, device='cuda:0')
old_score: tensor(0.0227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0209, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7325286865234375
Validation after dual ascent:
out_inf: tensor(4.5625, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.1985, device='cuda:0', dtype=torch.float16) tensor(0.0196, device='cuda:0', dtype=torch.float16)
tensor(0.1979, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.2087, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.1979, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
12 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.6836, device='cuda:0', dtype=torch.float16) tensor(0.3547, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0041, device='cuda:0')
tensor(0.0463, device='cuda:0')
old_score: tensor(0.0647, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0605, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110379934310913
Validation after dual ascent:
out_inf: tensor(6.6836, device='cuda:0', dtype=torch.float16) tensor(0.3547, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
tensor(0.5176, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
12 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.9453, device='cuda:0', dtype=torch.float16) tensor(0.2542, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0033, device='cuda:0')
tensor(0.0455, device='cuda:0')
old_score: tensor(0.0632, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0592, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.113964796066284
Validation after dual ascent:
out_inf: tensor(4.9453, device='cuda:0', dtype=torch.float16) tensor(0.2542, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.4631, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
12 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.5293, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(0.2252, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.2207, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.2578, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.2505, device='cuda:0', dtype=torch.float16) tensor(0.0285, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0018, device='cuda:0')
tensor(0.0287, device='cuda:0')
old_score: tensor(0.0270, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0260, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.253154277801514
Validation after dual ascent:
out_inf: tensor(3.5293, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(0.2063, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.2115, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
tensor(0.2384, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
tensor(0.2478, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
layer 12 done
13 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.2891, device='cuda:0', dtype=torch.float16) tensor(0.7974, device='cuda:0', dtype=torch.float16)
tensor(0.9331, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
tensor(0.9971, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(0.9678, device='cuda:0', dtype=torch.float16) tensor(0.1219, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0115, device='cuda:0')
tensor(0.2108, device='cuda:0')
old_score: tensor(0.1224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1145, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4760901927948
Validation after dual ascent:
out_inf: tensor(14.2891, device='cuda:0', dtype=torch.float16) tensor(0.7974, device='cuda:0', dtype=torch.float16)
tensor(0.8696, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(0.9644, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(0.8774, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
13 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.8906, device='cuda:0', dtype=torch.float16) tensor(1.0078, device='cuda:0', dtype=torch.float16)
tensor(0.9697, device='cuda:0', dtype=torch.float16) tensor(0.1210, device='cuda:0', dtype=torch.float16)
tensor(0.9014, device='cuda:0', dtype=torch.float16) tensor(0.1219, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.1222, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.1260, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0126, device='cuda:0')
tensor(0.2134, device='cuda:0')
old_score: tensor(0.1228, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1147, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.476794481277466
Validation after dual ascent:
out_inf: tensor(18.8906, device='cuda:0', dtype=torch.float16) tensor(1.0078, device='cuda:0', dtype=torch.float16)
tensor(0.8896, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.1131, device='cuda:0', dtype=torch.float16)
tensor(0.9233, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
13 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.2031, device='cuda:0', dtype=torch.float16) tensor(0.3276, device='cuda:0', dtype=torch.float16)
tensor(0.5913, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(0.6235, device='cuda:0', dtype=torch.float16) tensor(0.0855, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0066, device='cuda:0')
tensor(0.1362, device='cuda:0')
old_score: tensor(0.0831, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0780, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4712846279144287
Validation after dual ascent:
out_inf: tensor(5.2031, device='cuda:0', dtype=torch.float16) tensor(0.3276, device='cuda:0', dtype=torch.float16)
tensor(0.5903, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.5439, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.6226, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
13 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.2183, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.2087, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.2417, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0183, device='cuda:0')
tensor(0.0161, device='cuda:0')
old_score: tensor(0.0233, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0213, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1991219520568848
Validation after dual ascent:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.2244, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(0.2068, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.1945, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.2313, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
13 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.4258, device='cuda:0', dtype=torch.float16) tensor(0.3718, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0686, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0044, device='cuda:0')
tensor(0.0514, device='cuda:0')
old_score: tensor(0.0664, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0620, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.116405248641968
Validation after dual ascent:
out_inf: tensor(7.4258, device='cuda:0', dtype=torch.float16) tensor(0.3718, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
13 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6836, device='cuda:0', dtype=torch.float16) tensor(0.2703, device='cuda:0', dtype=torch.float16)
tensor(0.5186, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.4800, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0680, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0037, device='cuda:0')
tensor(0.0511, device='cuda:0')
old_score: tensor(0.0658, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0615, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0875067710876465
Validation after dual ascent:
out_inf: tensor(4.6836, device='cuda:0', dtype=torch.float16) tensor(0.2703, device='cuda:0', dtype=torch.float16)
tensor(0.5166, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.4763, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.4897, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
13 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.0859, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(0.2671, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.2515, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.2316, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0022, device='cuda:0')
tensor(0.0356, device='cuda:0')
old_score: tensor(0.0302, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0289, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.240877628326416
Validation after dual ascent:
out_inf: tensor(5.0859, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(0.2754, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.2126, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
tensor(0.2607, device='cuda:0', dtype=torch.float16) tensor(0.0312, device='cuda:0', dtype=torch.float16)
layer 13 done
14 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(13.8125, device='cuda:0', dtype=torch.float16) tensor(0.8008, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(1.1055, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(0.9893, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0134, device='cuda:0')
tensor(0.2288, device='cuda:0')
old_score: tensor(0.1240, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1157, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.478052854537964
Validation after dual ascent:
out_inf: tensor(13.8125, device='cuda:0', dtype=torch.float16) tensor(0.8008, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.4980, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(0.9194, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
14 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19., device='cuda:0', dtype=torch.float16) tensor(1.0801, device='cuda:0', dtype=torch.float16)
tensor(0.9136, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(0.9512, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0155, device='cuda:0')
tensor(0.2302, device='cuda:0')
old_score: tensor(0.1245, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1160, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4807465076446533
Validation after dual ascent:
out_inf: tensor(19., device='cuda:0', dtype=torch.float16) tensor(1.0801, device='cuda:0', dtype=torch.float16)
tensor(0.8506, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(0.8955, device='cuda:0', dtype=torch.float16) tensor(0.1142, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
14 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.6992, device='cuda:0', dtype=torch.float16) tensor(0.3250, device='cuda:0', dtype=torch.float16)
tensor(0.5967, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0819, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(0.6851, device='cuda:0', dtype=torch.float16) tensor(0.0860, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0070, device='cuda:0')
tensor(0.1448, device='cuda:0')
old_score: tensor(0.0831, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0778, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4738402366638184
Validation after dual ascent:
out_inf: tensor(4.6992, device='cuda:0', dtype=torch.float16) tensor(0.3250, device='cuda:0', dtype=torch.float16)
tensor(0.6128, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.6011, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(0.5513, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.6182, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
14 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.1406, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(0.2280, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.2874, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.2573, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0046, device='cuda:0')
tensor(0.0573, device='cuda:0')
old_score: tensor(0.0259, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0238, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.734006404876709
Validation after dual ascent:
out_inf: tensor(7.1406, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(0.2026, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(0.2286, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(0.2803, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.2461, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
14 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.3801, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0694, device='cuda:0', dtype=torch.float16)
tensor(0.5869, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0047, device='cuda:0')
tensor(0.0593, device='cuda:0')
old_score: tensor(0.0699, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0654, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.10235333442688
Validation after dual ascent:
out_inf: tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.3801, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0647, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
14 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3555, device='cuda:0', dtype=torch.float16) tensor(0.2832, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0689, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(0.5161, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0041, device='cuda:0')
tensor(0.0589, device='cuda:0')
old_score: tensor(0.0694, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0650, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.092359304428101
Validation after dual ascent:
out_inf: tensor(4.3555, device='cuda:0', dtype=torch.float16) tensor(0.2832, device='cuda:0', dtype=torch.float16)
tensor(0.4949, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.4775, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.6089, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
14 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(2.6660, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.2698, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
tensor(0.2563, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.2920, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0025, device='cuda:0')
tensor(0.0418, device='cuda:0')
old_score: tensor(0.0326, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0313, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.240379810333252
Validation after dual ascent:
out_inf: tensor(2.6660, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.2661, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.2537, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.2410, device='cuda:0', dtype=torch.float16) tensor(0.0292, device='cuda:0', dtype=torch.float16)
tensor(0.2737, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
layer 14 done
15 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.9141, device='cuda:0', dtype=torch.float16) tensor(0.7905, device='cuda:0', dtype=torch.float16)
tensor(0.8677, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(1.2061, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0110, device='cuda:0')
tensor(0.2087, device='cuda:0')
old_score: tensor(0.1216, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1138, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4685182571411133
Validation after dual ascent:
out_inf: tensor(15.9141, device='cuda:0', dtype=torch.float16) tensor(0.7905, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
tensor(1.1885, device='cuda:0', dtype=torch.float16) tensor(0.1198, device='cuda:0', dtype=torch.float16)
15 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(1.0459, device='cuda:0', dtype=torch.float16)
tensor(0.8989, device='cuda:0', dtype=torch.float16) tensor(0.1222, device='cuda:0', dtype=torch.float16)
tensor(0.9497, device='cuda:0', dtype=torch.float16) tensor(0.1214, device='cuda:0', dtype=torch.float16)
tensor(0.9634, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.4189, device='cuda:0', dtype=torch.float16) tensor(0.1283, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0117, device='cuda:0')
tensor(0.2158, device='cuda:0')
old_score: tensor(0.1237, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1154, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4695916175842285
Validation after dual ascent:
out_inf: tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(1.0459, device='cuda:0', dtype=torch.float16)
tensor(0.8667, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(0.9009, device='cuda:0', dtype=torch.float16) tensor(0.1123, device='cuda:0', dtype=torch.float16)
tensor(0.8276, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(1.4033, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
15 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.0078, device='cuda:0', dtype=torch.float16) tensor(0.3374, device='cuda:0', dtype=torch.float16)
tensor(0.6177, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
tensor(0.6431, device='cuda:0', dtype=torch.float16) tensor(0.0834, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0067, device='cuda:0')
tensor(0.1421, device='cuda:0')
old_score: tensor(0.0853, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0800, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4616763591766357
Validation after dual ascent:
out_inf: tensor(5.0078, device='cuda:0', dtype=torch.float16) tensor(0.3374, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.6001, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6553, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
15 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.8789, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(0.2262, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.2311, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.2263, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.2773, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0059, device='cuda:0')
tensor(0.0708, device='cuda:0')
old_score: tensor(0.0269, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7259299755096436
Validation after dual ascent:
out_inf: tensor(5.8789, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(0.2144, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.2286, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.2125, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(0.2476, device='cuda:0', dtype=torch.float16) tensor(0.0252, device='cuda:0', dtype=torch.float16)
15 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.6562, device='cuda:0', dtype=torch.float16) tensor(0.3955, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0052, device='cuda:0')
tensor(0.0666, device='cuda:0')
old_score: tensor(0.0719, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0673, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.090164661407471
Validation after dual ascent:
out_inf: tensor(9.6562, device='cuda:0', dtype=torch.float16) tensor(0.3955, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
15 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.9258, device='cuda:0', dtype=torch.float16) tensor(0.2976, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
tensor(0.5557, device='cuda:0', dtype=torch.float16) tensor(0.0748, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0046, device='cuda:0')
tensor(0.0660, device='cuda:0')
old_score: tensor(0.0714, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0669, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.095588684082031
Validation after dual ascent:
out_inf: tensor(4.9258, device='cuda:0', dtype=torch.float16) tensor(0.2976, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(0.5054, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
15 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.6016, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(0.3066, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.2676, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.2874, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.3477, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0031, device='cuda:0')
tensor(0.0514, device='cuda:0')
old_score: tensor(0.0354, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0340, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.239922046661377
Validation after dual ascent:
out_inf: tensor(6.6016, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(0.2905, device='cuda:0', dtype=torch.float16) tensor(0.0347, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.2739, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.3364, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
layer 15 done
16 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.6562, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(1.6494, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(0.9634, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.0840, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0114, device='cuda:0')
tensor(0.2208, device='cuda:0')
old_score: tensor(0.1212, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4707279205322266
Validation after dual ascent:
out_inf: tensor(17.6562, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.1124, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1198, device='cuda:0', dtype=torch.float16)
16 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0703, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.5352, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(0.9854, device='cuda:0', dtype=torch.float16) tensor(0.1210, device='cuda:0', dtype=torch.float16)
tensor(1.2334, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0123, device='cuda:0')
tensor(0.2268, device='cuda:0')
old_score: tensor(0.1222, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1138, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.471701145172119
Validation after dual ascent:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0703, device='cuda:0', dtype=torch.float16)
tensor(0.9653, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1098, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.1117, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
16 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.0195, device='cuda:0', dtype=torch.float16) tensor(0.3428, device='cuda:0', dtype=torch.float16)
tensor(0.6558, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
tensor(0.6650, device='cuda:0', dtype=torch.float16) tensor(0.0888, device='cuda:0', dtype=torch.float16)
tensor(0.7041, device='cuda:0', dtype=torch.float16) tensor(0.0940, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0074, device='cuda:0')
tensor(0.1569, device='cuda:0')
old_score: tensor(0.0898, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0841, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.464179754257202
Validation after dual ascent:
out_inf: tensor(5.0195, device='cuda:0', dtype=torch.float16) tensor(0.3428, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.7007, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(0.7085, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
16 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.3789, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(0.3250, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.2861, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.3228, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.3430, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0058, device='cuda:0')
tensor(0.0819, device='cuda:0')
old_score: tensor(0.0320, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0296, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7266137599945068
Validation after dual ascent:
out_inf: tensor(6.3789, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(0.3010, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.2720, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.2830, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.3240, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
16 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.9219, device='cuda:0', dtype=torch.float16) tensor(0.4229, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0761, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0755, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.0789, device='cuda:0')
old_score: tensor(0.0762, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0707, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0970048904418945
Validation after dual ascent:
out_inf: tensor(7.9219, device='cuda:0', dtype=torch.float16) tensor(0.4229, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0672, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0755, device='cuda:0', dtype=torch.float16)
16 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.2852, device='cuda:0', dtype=torch.float16) tensor(0.3167, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.5444, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0744, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0053, device='cuda:0')
tensor(0.0769, device='cuda:0')
old_score: tensor(0.0750, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0697, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.096388339996338
Validation after dual ascent:
out_inf: tensor(5.2852, device='cuda:0', dtype=torch.float16) tensor(0.3167, device='cuda:0', dtype=torch.float16)
tensor(0.5835, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
16 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.3203, device='cuda:0', dtype=torch.float16) tensor(0.1497, device='cuda:0', dtype=torch.float16)
tensor(0.4478, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.3291, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.2959, device='cuda:0', dtype=torch.float16) tensor(0.0373, device='cuda:0', dtype=torch.float16)
tensor(0.3984, device='cuda:0', dtype=torch.float16) tensor(0.0437, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0042, device='cuda:0')
tensor(0.0680, device='cuda:0')
old_score: tensor(0.0400, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0384, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.238672256469727
Validation after dual ascent:
out_inf: tensor(6.3203, device='cuda:0', dtype=torch.float16) tensor(0.1497, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.3330, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.3054, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.3794, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
layer 16 done
17 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.7031, device='cuda:0', dtype=torch.float16) tensor(0.8003, device='cuda:0', dtype=torch.float16)
tensor(1.3066, device='cuda:0', dtype=torch.float16) tensor(0.1222, device='cuda:0', dtype=torch.float16)
tensor(1.3965, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
tensor(1.2881, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
tensor(0.1414, device='cuda:0')
old_score: tensor(0.1226, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1137, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.921962261199951
Validation after dual ascent:
out_inf: tensor(16.7031, device='cuda:0', dtype=torch.float16) tensor(0.8003, device='cuda:0', dtype=torch.float16)
tensor(1.1768, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
17 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.1875, device='cuda:0', dtype=torch.float16) tensor(1.0254, device='cuda:0', dtype=torch.float16)
tensor(1.0342, device='cuda:0', dtype=torch.float16) tensor(0.1233, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.1186, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(0.1573, device='cuda:0')
old_score: tensor(0.1235, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1144, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.95350456237793
Validation after dual ascent:
out_inf: tensor(17.1875, device='cuda:0', dtype=torch.float16) tensor(1.0254, device='cuda:0', dtype=torch.float16)
tensor(0.9326, device='cuda:0', dtype=torch.float16) tensor(0.1145, device='cuda:0', dtype=torch.float16)
tensor(0.9590, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(0.9790, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
17 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3320, device='cuda:0', dtype=torch.float16) tensor(0.3538, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
tensor(0.6880, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(0.6802, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
tensor(0.6929, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0175, device='cuda:0')
tensor(0.0804, device='cuda:0')
old_score: tensor(0.0904, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0840, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.741208791732788
Validation after dual ascent:
out_inf: tensor(4.3320, device='cuda:0', dtype=torch.float16) tensor(0.3538, device='cuda:0', dtype=torch.float16)
tensor(0.6909, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.6021, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
17 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.2617, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.2922, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.2491, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.2917, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0053, device='cuda:0')
tensor(0.0651, device='cuda:0')
old_score: tensor(0.0280, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0257, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7291834354400635
Validation after dual ascent:
out_inf: tensor(6.2617, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(0.2422, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.2522, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.2612, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
17 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.7422, device='cuda:0', dtype=torch.float16) tensor(0.4421, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0803, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0068, device='cuda:0')
tensor(0.0942, device='cuda:0')
old_score: tensor(0.0811, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0754, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1181886196136475
Validation after dual ascent:
out_inf: tensor(8.7422, device='cuda:0', dtype=torch.float16) tensor(0.4421, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
17 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3188, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.6660, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.0900, device='cuda:0')
old_score: tensor(0.0786, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0732, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.112364053726196
Validation after dual ascent:
out_inf: tensor(6.2578, device='cuda:0', dtype=torch.float16) tensor(0.3188, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0735, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.5439, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.6611, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
17 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.0508, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
tensor(0.3506, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(0.3269, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.4341, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0044, device='cuda:0')
tensor(0.0728, device='cuda:0')
old_score: tensor(0.0409, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0393, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.260193347930908
Validation after dual ascent:
out_inf: tensor(5.0508, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(0.4194, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.3347, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.3196, device='cuda:0', dtype=torch.float16) tensor(0.0362, device='cuda:0', dtype=torch.float16)
tensor(0.4028, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
layer 17 done
18 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.8193, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.1209, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(2.1211, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.2677, device='cuda:0')
old_score: tensor(0.1273, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1182, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4723598957061768
Validation after dual ascent:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.8193, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1109, device='cuda:0', dtype=torch.float16)
tensor(1.0283, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
18 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.5781, device='cuda:0', dtype=torch.float16) tensor(0.9922, device='cuda:0', dtype=torch.float16)
tensor(0.9976, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(0.9590, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0198, device='cuda:0')
tensor(0.2709, device='cuda:0')
old_score: tensor(0.1282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1189, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.471998929977417
Validation after dual ascent:
out_inf: tensor(17.5781, device='cuda:0', dtype=torch.float16) tensor(0.9922, device='cuda:0', dtype=torch.float16)
tensor(0.9971, device='cuda:0', dtype=torch.float16) tensor(0.1198, device='cuda:0', dtype=torch.float16)
tensor(1.0322, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
18 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.9844, device='cuda:0', dtype=torch.float16) tensor(0.3733, device='cuda:0', dtype=torch.float16)
tensor(0.8062, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0984, device='cuda:0', dtype=torch.float16)
tensor(0.8613, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0097, device='cuda:0')
tensor(0.2037, device='cuda:0')
old_score: tensor(0.0994, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0926, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.468573570251465
Validation after dual ascent:
out_inf: tensor(4.9844, device='cuda:0', dtype=torch.float16) tensor(0.3733, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0866, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
18 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.3242, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.3499, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.2917, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.2915, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.3284, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0178, device='cuda:0')
tensor(0.0124, device='cuda:0')
old_score: tensor(0.0289, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0267, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.459913969039917
Validation after dual ascent:
out_inf: tensor(4.3242, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.2991, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.2627, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.2903, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.2942, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
18 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.7812, device='cuda:0', dtype=torch.float16) tensor(0.4558, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.6812, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0079, device='cuda:0')
tensor(0.1139, device='cuda:0')
old_score: tensor(0.0852, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0789, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.098970890045166
Validation after dual ascent:
out_inf: tensor(9.7812, device='cuda:0', dtype=torch.float16) tensor(0.4558, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0772, device='cuda:0', dtype=torch.float16)
tensor(0.7563, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
18 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.8320, device='cuda:0', dtype=torch.float16) tensor(0.3245, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.6206, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0808, device='cuda:0', dtype=torch.float16)
tensor(0.7217, device='cuda:0', dtype=torch.float16) tensor(0.0866, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0070, device='cuda:0')
tensor(0.1071, device='cuda:0')
old_score: tensor(0.0817, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0757, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.107771158218384
Validation after dual ascent:
out_inf: tensor(5.8320, device='cuda:0', dtype=torch.float16) tensor(0.3245, device='cuda:0', dtype=torch.float16)
tensor(0.6396, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.6255, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
18 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.6797, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(0.4360, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.3589, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0054, device='cuda:0')
tensor(0.0859, device='cuda:0')
old_score: tensor(0.0435, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.241896629333496
Validation after dual ascent:
out_inf: tensor(5.6797, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(0.4287, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.3550, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.3411, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.4224, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
layer 18 done
19 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.9062, device='cuda:0', dtype=torch.float16) tensor(0.7827, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.1228, device='cuda:0', dtype=torch.float16)
tensor(1.3682, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
tensor(1.1279, device='cuda:0', dtype=torch.float16) tensor(0.1211, device='cuda:0', dtype=torch.float16)
tensor(1.4189, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0135, device='cuda:0')
tensor(0.2563, device='cuda:0')
old_score: tensor(0.1222, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.47039794921875
Validation after dual ascent:
out_inf: tensor(12.9062, device='cuda:0', dtype=torch.float16) tensor(0.7827, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.2705, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(1.0215, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.3955, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
19 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.6250, device='cuda:0', dtype=torch.float16) tensor(1.0225, device='cuda:0', dtype=torch.float16)
tensor(1.0400, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(0.9810, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1296, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.2597, device='cuda:0')
old_score: tensor(0.1226, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470802068710327
Validation after dual ascent:
out_inf: tensor(19.6250, device='cuda:0', dtype=torch.float16) tensor(1.0225, device='cuda:0', dtype=torch.float16)
tensor(0.9248, device='cuda:0', dtype=torch.float16) tensor(0.1145, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
19 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2695, device='cuda:0', dtype=torch.float16) tensor(0.3848, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0995, device='cuda:0', dtype=torch.float16)
tensor(0.7368, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(0.8115, device='cuda:0', dtype=torch.float16) tensor(0.1045, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0096, device='cuda:0')
tensor(0.1987, device='cuda:0')
old_score: tensor(0.0986, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0914, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4657251834869385
Validation after dual ascent:
out_inf: tensor(4.2695, device='cuda:0', dtype=torch.float16) tensor(0.3848, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0926, device='cuda:0', dtype=torch.float16)
tensor(0.7534, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.7329, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
19 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.7773, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(0.2947, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.3677, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
tensor(0.2812, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.3169, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0067, device='cuda:0')
tensor(0.0670, device='cuda:0')
old_score: tensor(0.0293, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0270, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7252693176269531
Validation after dual ascent:
out_inf: tensor(5.7773, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(0.2866, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.2922, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.3108, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.3242, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
19 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.1875, device='cuda:0', dtype=torch.float16) tensor(0.4492, device='cuda:0', dtype=torch.float16)
tensor(0.6904, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.7822, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0086, device='cuda:0')
tensor(0.1286, device='cuda:0')
old_score: tensor(0.0883, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0817, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.096180200576782
Validation after dual ascent:
out_inf: tensor(8.1875, device='cuda:0', dtype=torch.float16) tensor(0.4492, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.7920, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0883, device='cuda:0', dtype=torch.float16)
19 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.5781, device='cuda:0', dtype=torch.float16) tensor(0.3333, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.0851, device='cuda:0', dtype=torch.float16)
tensor(0.7417, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0077, device='cuda:0')
tensor(0.1205, device='cuda:0')
old_score: tensor(0.0840, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0779, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.09937310218811
Validation after dual ascent:
out_inf: tensor(7.5781, device='cuda:0', dtype=torch.float16) tensor(0.3333, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0791, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0763, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
19 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.3359, device='cuda:0', dtype=torch.float16) tensor(0.1764, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.3938, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.3706, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.4595, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0058, device='cuda:0')
tensor(0.0930, device='cuda:0')
old_score: tensor(0.0452, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0434, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.231413125991821
Validation after dual ascent:
out_inf: tensor(5.3359, device='cuda:0', dtype=torch.float16) tensor(0.1764, device='cuda:0', dtype=torch.float16)
tensor(0.4319, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.3728, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
layer 19 done
20 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.4297, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.2441, device='cuda:0', dtype=torch.float16) tensor(0.1219, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0131, device='cuda:0')
tensor(0.2622, device='cuda:0')
old_score: tensor(0.1224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.482915163040161
Validation after dual ascent:
out_inf: tensor(15.4297, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(1.0889, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(1.0947, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
20 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.2500, device='cuda:0', dtype=torch.float16) tensor(1.0205, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
tensor(1.0137, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0138, device='cuda:0')
tensor(0.2654, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4861109256744385
Validation after dual ascent:
out_inf: tensor(18.2500, device='cuda:0', dtype=torch.float16) tensor(1.0205, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1145, device='cuda:0', dtype=torch.float16)
tensor(1.0869, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(0.9487, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
20 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.3755, device='cuda:0', dtype=torch.float16)
tensor(0.7686, device='cuda:0', dtype=torch.float16) tensor(0.1020, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0946, device='cuda:0', dtype=torch.float16)
tensor(0.7603, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.1062, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0098, device='cuda:0')
tensor(0.2049, device='cuda:0')
old_score: tensor(0.1007, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0933, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.477870464324951
Validation after dual ascent:
out_inf: tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.3755, device='cuda:0', dtype=torch.float16)
tensor(0.7764, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
20 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.6328, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(0.3262, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.3311, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.3354, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.3760, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0064, device='cuda:0')
tensor(0.0885, device='cuda:0')
old_score: tensor(0.0344, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0313, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7292530536651611
Validation after dual ascent:
out_inf: tensor(12.6328, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(0.3127, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
tensor(0.3113, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
tensor(0.2874, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.3369, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
20 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.1172, device='cuda:0', dtype=torch.float16) tensor(0.4634, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(0.8726, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.0946, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0092, device='cuda:0')
tensor(0.1373, device='cuda:0')
old_score: tensor(0.0898, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0828, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.099152565002441
Validation after dual ascent:
out_inf: tensor(11.1172, device='cuda:0', dtype=torch.float16) tensor(0.4634, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.8701, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
20 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.9062, device='cuda:0', dtype=torch.float16) tensor(0.3430, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0860, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.7959, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0082, device='cuda:0')
tensor(0.1278, device='cuda:0')
old_score: tensor(0.0848, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0782, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1016316413879395
Validation after dual ascent:
out_inf: tensor(5.9062, device='cuda:0', dtype=torch.float16) tensor(0.3430, device='cuda:0', dtype=torch.float16)
tensor(0.8062, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.7100, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.7412, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
20 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.2109, device='cuda:0', dtype=torch.float16) tensor(0.1891, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4126, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.3916, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.5264, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0068, device='cuda:0')
tensor(0.1074, device='cuda:0')
old_score: tensor(0.0474, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0455, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.180751323699951
Validation after dual ascent:
out_inf: tensor(7.2109, device='cuda:0', dtype=torch.float16) tensor(0.1891, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.3943, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(0.3931, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.5200, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
layer 20 done
21 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.7847, device='cuda:0', dtype=torch.float16)
tensor(1.0400, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(1.4248, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0143, device='cuda:0')
tensor(0.2867, device='cuda:0')
old_score: tensor(0.1224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1127, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470682382583618
Validation after dual ascent:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.7847, device='cuda:0', dtype=torch.float16)
tensor(1.1104, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.5342, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(1.0518, device='cuda:0', dtype=torch.float16) tensor(0.1126, device='cuda:0', dtype=torch.float16)
tensor(1.2520, device='cuda:0', dtype=torch.float16) tensor(0.1204, device='cuda:0', dtype=torch.float16)
21 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.2812, device='cuda:0', dtype=torch.float16) tensor(0.9834, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0153, device='cuda:0')
tensor(0.2903, device='cuda:0')
old_score: tensor(0.1218, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1121, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4710183143615723
Validation after dual ascent:
out_inf: tensor(18.2812, device='cuda:0', dtype=torch.float16) tensor(0.9834, device='cuda:0', dtype=torch.float16)
tensor(1.2041, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(0.9443, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.0732, device='cuda:0', dtype=torch.float16) tensor(0.1196, device='cuda:0', dtype=torch.float16)
21 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.5586, device='cuda:0', dtype=torch.float16) tensor(0.3943, device='cuda:0', dtype=torch.float16)
tensor(0.8486, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0996, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0112, device='cuda:0')
tensor(0.2371, device='cuda:0')
old_score: tensor(0.1069, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0986, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4671294689178467
Validation after dual ascent:
out_inf: tensor(5.5586, device='cuda:0', dtype=torch.float16) tensor(0.3943, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.9014, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
tensor(0.8853, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(0.9741, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
21 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.2422, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(0.3457, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
tensor(0.3970, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.4431, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.4382, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0082, device='cuda:0')
tensor(0.1049, device='cuda:0')
old_score: tensor(0.0337, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0310, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.724766492843628
Validation after dual ascent:
out_inf: tensor(9.2422, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(0.3735, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.3972, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.3813, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.4797, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
21 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.5234, device='cuda:0', dtype=torch.float16) tensor(0.4587, device='cuda:0', dtype=torch.float16)
tensor(0.8740, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0100, device='cuda:0')
tensor(0.1533, device='cuda:0')
old_score: tensor(0.0927, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0856, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.101288318634033
Validation after dual ascent:
out_inf: tensor(10.5234, device='cuda:0', dtype=torch.float16) tensor(0.4587, device='cuda:0', dtype=torch.float16)
tensor(0.7959, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
21 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.4648, device='cuda:0', dtype=torch.float16) tensor(0.3408, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0089, device='cuda:0')
tensor(0.1414, device='cuda:0')
old_score: tensor(0.0867, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.102031469345093
Validation after dual ascent:
out_inf: tensor(6.4648, device='cuda:0', dtype=torch.float16) tensor(0.3408, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.7300, device='cuda:0', dtype=torch.float16) tensor(0.0802, device='cuda:0', dtype=torch.float16)
tensor(0.8257, device='cuda:0', dtype=torch.float16) tensor(0.0857, device='cuda:0', dtype=torch.float16)
21 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.1837, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.4504, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.5073, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0066, device='cuda:0')
tensor(0.1064, device='cuda:0')
old_score: tensor(0.0470, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0453, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.223346710205078
Validation after dual ascent:
out_inf: tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.1837, device='cuda:0', dtype=torch.float16)
tensor(0.5171, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.4509, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
layer 21 done
22 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.0938, device='cuda:0', dtype=torch.float16) tensor(0.8369, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(1.1514, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.2129, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
tensor(0.1280, device='cuda:0')
old_score: tensor(0.1281, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1181, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.92723274230957
Validation after dual ascent:
out_inf: tensor(18.0938, device='cuda:0', dtype=torch.float16) tensor(0.8369, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(1.1055, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.3506, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
22 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.3594, device='cuda:0', dtype=torch.float16) tensor(1.0107, device='cuda:0', dtype=torch.float16)
tensor(1.2207, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.1533, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(1.0879, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0175, device='cuda:0')
tensor(0.1234, device='cuda:0')
old_score: tensor(0.1279, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1179, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2079715728759766
Validation after dual ascent:
out_inf: tensor(20.3594, device='cuda:0', dtype=torch.float16) tensor(1.0107, device='cuda:0', dtype=torch.float16)
tensor(1.1533, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1079, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.1189, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
22 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.5000, device='cuda:0', dtype=torch.float16) tensor(0.4165, device='cuda:0', dtype=torch.float16)
tensor(0.9072, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(0.9429, device='cuda:0', dtype=torch.float16) tensor(0.1005, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(1.0498, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.2502, device='cuda:0')
old_score: tensor(0.1086, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4682271480560303
Validation after dual ascent:
out_inf: tensor(7.5000, device='cuda:0', dtype=torch.float16) tensor(0.4165, device='cuda:0', dtype=torch.float16)
tensor(0.9146, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.9028, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.1072, device='cuda:0', dtype=torch.float16)
22 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.0469, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
tensor(0.3760, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0357, device='cuda:0', dtype=torch.float16)
tensor(0.3833, device='cuda:0', dtype=torch.float16) tensor(0.0373, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0123, device='cuda:0')
tensor(0.1346, device='cuda:0')
old_score: tensor(0.0369, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0342, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7282586097717285
Validation after dual ascent:
out_inf: tensor(12.0469, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.4097, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.3872, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
22 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.9297, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.8311, device='cuda:0', dtype=torch.float16) tensor(0.0951, device='cuda:0', dtype=torch.float16)
tensor(0.9453, device='cuda:0', dtype=torch.float16) tensor(0.0874, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0105, device='cuda:0')
tensor(0.1611, device='cuda:0')
old_score: tensor(0.0940, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0865, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.096857070922852
Validation after dual ascent:
out_inf: tensor(10.9297, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0794, device='cuda:0', dtype=torch.float16)
tensor(0.7847, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
22 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.1133, device='cuda:0', dtype=torch.float16) tensor(0.3484, device='cuda:0', dtype=torch.float16)
tensor(0.8730, device='cuda:0', dtype=torch.float16) tensor(0.0883, device='cuda:0', dtype=torch.float16)
tensor(0.7373, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(0.8174, device='cuda:0', dtype=torch.float16) tensor(0.0910, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0093, device='cuda:0')
tensor(0.1477, device='cuda:0')
old_score: tensor(0.0873, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0804, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.102707147598267
Validation after dual ascent:
out_inf: tensor(6.1133, device='cuda:0', dtype=torch.float16) tensor(0.3484, device='cuda:0', dtype=torch.float16)
tensor(0.9292, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.7407, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.8428, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
22 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.1982, device='cuda:0', dtype=torch.float16)
tensor(0.5747, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.4868, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.5103, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0075, device='cuda:0')
tensor(0.1214, device='cuda:0')
old_score: tensor(0.0496, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0476, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.237738847732544
Validation after dual ascent:
out_inf: tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.1982, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.4741, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.5264, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
layer 22 done
23 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.0781, device='cuda:0', dtype=torch.float16) tensor(0.8228, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0166, device='cuda:0')
tensor(0.3590, device='cuda:0')
old_score: tensor(0.1360, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1255, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.475728988647461
Validation after dual ascent:
out_inf: tensor(16.0781, device='cuda:0', dtype=torch.float16) tensor(0.8228, device='cuda:0', dtype=torch.float16)
tensor(1.5088, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.7559, device='cuda:0', dtype=torch.float16) tensor(0.1151, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1321, device='cuda:0', dtype=torch.float16)
23 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.8125, device='cuda:0', dtype=torch.float16) tensor(0.9771, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.3037, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0174, device='cuda:0')
tensor(0.3632, device='cuda:0')
old_score: tensor(0.1357, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1250, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.478952646255493
Validation after dual ascent:
out_inf: tensor(19.8125, device='cuda:0', dtype=torch.float16) tensor(0.9771, device='cuda:0', dtype=torch.float16)
tensor(1.2314, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.2314, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
23 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.6758, device='cuda:0', dtype=torch.float16) tensor(0.4553, device='cuda:0', dtype=torch.float16)
tensor(1.0205, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(0.9507, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0139, device='cuda:0')
tensor(0.3088, device='cuda:0')
old_score: tensor(0.1205, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1113, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4740724563598633
Validation after dual ascent:
out_inf: tensor(5.6758, device='cuda:0', dtype=torch.float16) tensor(0.4553, device='cuda:0', dtype=torch.float16)
tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.1126, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(0.9541, device='cuda:0', dtype=torch.float16) tensor(0.1133, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
23 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.9062, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.4500, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.4231, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0100, device='cuda:0')
tensor(0.1322, device='cuda:0')
old_score: tensor(0.0364, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0338, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7292320728302002
Validation after dual ascent:
out_inf: tensor(18.9062, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(0.4536, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.4045, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
tensor(0.4067, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.3838, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
23 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.3281, device='cuda:0', dtype=torch.float16) tensor(0.4663, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(0.8193, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(0.8882, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.1932, device='cuda:0')
old_score: tensor(0.0985, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0910, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.116350173950195
Validation after dual ascent:
out_inf: tensor(10.3281, device='cuda:0', dtype=torch.float16) tensor(0.4663, device='cuda:0', dtype=torch.float16)
tensor(0.8838, device='cuda:0', dtype=torch.float16) tensor(0.0921, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(0.8369, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(0.9639, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
23 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.3281, device='cuda:0', dtype=torch.float16) tensor(0.3550, device='cuda:0', dtype=torch.float16)
tensor(0.8032, device='cuda:0', dtype=torch.float16) tensor(0.0929, device='cuda:0', dtype=torch.float16)
tensor(0.7759, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
tensor(0.8530, device='cuda:0', dtype=torch.float16) tensor(0.0949, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.1777, device='cuda:0')
old_score: tensor(0.0918, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0848, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.120664358139038
Validation after dual ascent:
out_inf: tensor(7.3281, device='cuda:0', dtype=torch.float16) tensor(0.3550, device='cuda:0', dtype=torch.float16)
tensor(0.8374, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0775, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0866, device='cuda:0', dtype=torch.float16)
tensor(0.8643, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
23 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(3.9922, device='cuda:0', dtype=torch.float16) tensor(0.2026, device='cuda:0', dtype=torch.float16)
tensor(0.5767, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(0.6011, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.6064, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0085, device='cuda:0')
tensor(0.1384, device='cuda:0')
old_score: tensor(0.0521, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.269972085952759
Validation after dual ascent:
out_inf: tensor(3.9922, device='cuda:0', dtype=torch.float16) tensor(0.2026, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.6396, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
layer 23 done
24 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.8672, device='cuda:0', dtype=torch.float16) tensor(0.7915, device='cuda:0', dtype=torch.float16)
tensor(1.2041, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(1.8945, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
tensor(1.1553, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0170, device='cuda:0')
tensor(0.3338, device='cuda:0')
old_score: tensor(0.1255, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1160, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.474205732345581
Validation after dual ascent:
out_inf: tensor(15.8672, device='cuda:0', dtype=torch.float16) tensor(0.7915, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(1.8301, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.1188, device='cuda:0', dtype=torch.float16)
tensor(1.1807, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
24 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.3906, device='cuda:0', dtype=torch.float16) tensor(1.0059, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(1.0723, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0190, device='cuda:0')
tensor(0.3369, device='cuda:0')
old_score: tensor(0.1246, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1150, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.477677822113037
Validation after dual ascent:
out_inf: tensor(17.3906, device='cuda:0', dtype=torch.float16) tensor(1.0059, device='cuda:0', dtype=torch.float16)
tensor(1.0361, device='cuda:0', dtype=torch.float16) tensor(0.1162, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(0.9561, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
24 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(6.4336, device='cuda:0', dtype=torch.float16) tensor(0.4377, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.1189, device='cuda:0', dtype=torch.float16)
tensor(0.9561, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
tensor(0.9502, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(1.2520, device='cuda:0', dtype=torch.float16) tensor(0.1214, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0139, device='cuda:0')
tensor(0.2932, device='cuda:0')
old_score: tensor(0.1177, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1090, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4737257957458496
Validation after dual ascent:
out_inf: tensor(6.4336, device='cuda:0', dtype=torch.float16) tensor(0.4377, device='cuda:0', dtype=torch.float16)
tensor(1.0488, device='cuda:0', dtype=torch.float16) tensor(0.1103, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.9629, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.1143, device='cuda:0', dtype=torch.float16)
24 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.1797, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(0.4368, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
tensor(0.4673, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.4646, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(0.4771, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0168, device='cuda:0')
tensor(0.0149, device='cuda:0')
old_score: tensor(0.0426, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0395, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.201167345046997
Validation after dual ascent:
out_inf: tensor(14.1797, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(0.4028, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.4768, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.4434, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.4387, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
24 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.1875, device='cuda:0', dtype=torch.float16) tensor(0.4717, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(0.9307, device='cuda:0', dtype=torch.float16) tensor(0.1032, device='cuda:0', dtype=torch.float16)
tensor(1.0381, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0126, device='cuda:0')
tensor(0.2053, device='cuda:0')
old_score: tensor(0.1004, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0929, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.113876819610596
Validation after dual ascent:
out_inf: tensor(12.1875, device='cuda:0', dtype=torch.float16) tensor(0.4717, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
tensor(0.9019, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
tensor(0.8604, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
24 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.5039, device='cuda:0', dtype=torch.float16) tensor(0.3611, device='cuda:0', dtype=torch.float16)
tensor(0.8335, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(0.8569, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(0.9292, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(0.8447, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0113, device='cuda:0')
tensor(0.1891, device='cuda:0')
old_score: tensor(0.0936, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0867, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.120398759841919
Validation after dual ascent:
out_inf: tensor(7.5039, device='cuda:0', dtype=torch.float16) tensor(0.3611, device='cuda:0', dtype=torch.float16)
tensor(0.8354, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0796, device='cuda:0', dtype=torch.float16)
tensor(0.9912, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
24 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.8047, device='cuda:0', dtype=torch.float16) tensor(0.2096, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.6260, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0089, device='cuda:0')
tensor(0.1464, device='cuda:0')
old_score: tensor(0.0535, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0517, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.239951610565186
Validation after dual ascent:
out_inf: tensor(4.8047, device='cuda:0', dtype=torch.float16) tensor(0.2096, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.5884, device='cuda:0', dtype=torch.float16) tensor(0.0456, device='cuda:0', dtype=torch.float16)
tensor(0.4966, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0553, device='cuda:0', dtype=torch.float16)
layer 24 done
25 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.9141, device='cuda:0', dtype=torch.float16) tensor(0.8037, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(1.3076, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
tensor(1.6553, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0177, device='cuda:0')
tensor(0.4005, device='cuda:0')
old_score: tensor(0.1390, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1288, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.477780818939209
Validation after dual ascent:
out_inf: tensor(11.9141, device='cuda:0', dtype=torch.float16) tensor(0.8037, device='cuda:0', dtype=torch.float16)
tensor(1.3096, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.7168, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
25 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.2656, device='cuda:0', dtype=torch.float16) tensor(0.9512, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.1295, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(1.3564, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0186, device='cuda:0')
tensor(0.4021, device='cuda:0')
old_score: tensor(0.1387, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1285, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4782652854919434
Validation after dual ascent:
out_inf: tensor(17.2656, device='cuda:0', dtype=torch.float16) tensor(0.9512, device='cuda:0', dtype=torch.float16)
tensor(1.3887, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.1181, device='cuda:0', dtype=torch.float16)
tensor(1.3936, device='cuda:0', dtype=torch.float16) tensor(0.1324, device='cuda:0', dtype=torch.float16)
tensor(1.4307, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
25 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.3477, device='cuda:0', dtype=torch.float16) tensor(0.4790, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.3646, device='cuda:0')
old_score: tensor(0.1306, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1212, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.474323034286499
Validation after dual ascent:
out_inf: tensor(5.3477, device='cuda:0', dtype=torch.float16) tensor(0.4790, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.1225, device='cuda:0', dtype=torch.float16)
tensor(0.9819, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
tensor(1.1982, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
25 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
tensor(0.3853, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0373, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0078, device='cuda:0')
tensor(0.0159, device='cuda:0')
old_score: tensor(0.0347, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0319, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9237706661224365
Validation after dual ascent:
out_inf: tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(0.3911, device='cuda:0', dtype=torch.float16) tensor(0.0285, device='cuda:0', dtype=torch.float16)
tensor(0.3760, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.4126, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
25 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.8047, device='cuda:0', dtype=torch.float16) tensor(0.4980, device='cuda:0', dtype=torch.float16)
tensor(0.9365, device='cuda:0', dtype=torch.float16) tensor(0.1051, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.1071, device='cuda:0', dtype=torch.float16)
tensor(0.9287, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0140, device='cuda:0')
tensor(0.2361, device='cuda:0')
old_score: tensor(0.1040, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0961, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.111814260482788
Validation after dual ascent:
out_inf: tensor(9.8047, device='cuda:0', dtype=torch.float16) tensor(0.4980, device='cuda:0', dtype=torch.float16)
tensor(0.9229, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(0.9028, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(0.9443, device='cuda:0', dtype=torch.float16) tensor(0.1004, device='cuda:0', dtype=torch.float16)
25 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.6797, device='cuda:0', dtype=torch.float16) tensor(0.3743, device='cuda:0', dtype=torch.float16)
tensor(0.9097, device='cuda:0', dtype=torch.float16) tensor(0.0985, device='cuda:0', dtype=torch.float16)
tensor(0.8682, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(0.9023, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.9287, device='cuda:0', dtype=torch.float16) tensor(0.1001, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0127, device='cuda:0')
tensor(0.2184, device='cuda:0')
old_score: tensor(0.0974, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0902, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.119794130325317
Validation after dual ascent:
out_inf: tensor(8.6797, device='cuda:0', dtype=torch.float16) tensor(0.3743, device='cuda:0', dtype=torch.float16)
tensor(0.9385, device='cuda:0', dtype=torch.float16) tensor(0.0913, device='cuda:0', dtype=torch.float16)
tensor(0.8721, device='cuda:0', dtype=torch.float16) tensor(0.0825, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
25 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.9258, device='cuda:0', dtype=torch.float16) tensor(0.2206, device='cuda:0', dtype=torch.float16)
tensor(0.7007, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.6421, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.5698, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0103, device='cuda:0')
tensor(0.1668, device='cuda:0')
old_score: tensor(0.0557, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0539, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.216179370880127
Validation after dual ascent:
out_inf: tensor(5.9258, device='cuda:0', dtype=torch.float16) tensor(0.2206, device='cuda:0', dtype=torch.float16)
tensor(0.6284, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
layer 25 done
26 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.0312, device='cuda:0', dtype=torch.float16) tensor(0.8335, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(1.4473, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0074, device='cuda:0')
tensor(0.1220, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1244, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.208277463912964
Validation after dual ascent:
out_inf: tensor(14.0312, device='cuda:0', dtype=torch.float16) tensor(0.8335, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.1250, device='cuda:0', dtype=torch.float16)
tensor(1.3057, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.2881, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
26 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(17.9844, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(1.2959, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(1.4551, device='cuda:0', dtype=torch.float16) tensor(0.1368, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.1287, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.209368944168091
Validation after dual ascent:
out_inf: tensor(17.9844, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1250, device='cuda:0', dtype=torch.float16)
tensor(1.2236, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
26 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4775, device='cuda:0', dtype=torch.float16)
tensor(1.1221, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1343, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0170, device='cuda:0')
tensor(0.3550, device='cuda:0')
old_score: tensor(0.1301, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1209, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4706294536590576
Validation after dual ascent:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4775, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(1.0967, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
26 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(22.4219, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(0.4346, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(0.5303, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(0.5161, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0106, device='cuda:0')
tensor(0.0300, device='cuda:0')
old_score: tensor(0.0485, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0446, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.060450077056885
Validation after dual ascent:
out_inf: tensor(22.4219, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(0.4622, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.4958, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.4595, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
26 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.7422, device='cuda:0', dtype=torch.float16) tensor(0.5195, device='cuda:0', dtype=torch.float16)
tensor(0.9902, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(0.9912, device='cuda:0', dtype=torch.float16) tensor(0.0979, device='cuda:0', dtype=torch.float16)
tensor(0.9839, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.2479, device='cuda:0')
old_score: tensor(0.1050, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0972, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.122101068496704
Validation after dual ascent:
out_inf: tensor(9.7422, device='cuda:0', dtype=torch.float16) tensor(0.5195, device='cuda:0', dtype=torch.float16)
tensor(0.9897, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(0.9111, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
tensor(0.9399, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
26 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.3828, device='cuda:0', dtype=torch.float16) tensor(0.3943, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(1.0840, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.9453, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0133, device='cuda:0')
tensor(0.2296, device='cuda:0')
old_score: tensor(0.0989, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0915, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.125800132751465
Validation after dual ascent:
out_inf: tensor(8.3828, device='cuda:0', dtype=torch.float16) tensor(0.3943, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.0925, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
26 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.6562, device='cuda:0', dtype=torch.float16) tensor(0.2285, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.5684, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0118, device='cuda:0')
tensor(0.1877, device='cuda:0')
old_score: tensor(0.0577, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0557, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.191954135894775
Validation after dual ascent:
out_inf: tensor(5.6562, device='cuda:0', dtype=torch.float16) tensor(0.2285, device='cuda:0', dtype=torch.float16)
tensor(0.6763, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(0.6045, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.6274, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
layer 26 done
27 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(15.7422, device='cuda:0', dtype=torch.float16) tensor(0.8335, device='cuda:0', dtype=torch.float16)
tensor(1.4414, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.3447, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.1494, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0185, device='cuda:0')
tensor(0.3848, device='cuda:0')
old_score: tensor(0.1443, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1335, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4781653881073
Validation after dual ascent:
out_inf: tensor(15.7422, device='cuda:0', dtype=torch.float16) tensor(0.8335, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(1.3350, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.2197, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
27 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.7344, device='cuda:0', dtype=torch.float16) tensor(0.9790, device='cuda:0', dtype=torch.float16)
tensor(1.2959, device='cuda:0', dtype=torch.float16) tensor(0.1461, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0195, device='cuda:0')
tensor(0.3891, device='cuda:0')
old_score: tensor(0.1454, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1345, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4759328365325928
Validation after dual ascent:
out_inf: tensor(18.7344, device='cuda:0', dtype=torch.float16) tensor(0.9790, device='cuda:0', dtype=torch.float16)
tensor(1.4502, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(1.2002, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.3486, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
27 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(10.2266, device='cuda:0', dtype=torch.float16) tensor(0.4866, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.1162, device='cuda:0', dtype=torch.float16) tensor(0.1359, device='cuda:0', dtype=torch.float16)
tensor(1.1465, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.3482, device='cuda:0')
old_score: tensor(0.1311, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1216, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.474334239959717
Validation after dual ascent:
out_inf: tensor(10.2266, device='cuda:0', dtype=torch.float16) tensor(0.4866, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.1436, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(1.0166, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.1455, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
27 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(5.8008, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.4451, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.4014, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
tensor(0.4834, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0190, device='cuda:0')
tensor(0.1323, device='cuda:0')
old_score: tensor(0.0312, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0290, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7307405471801758
Validation after dual ascent:
out_inf: tensor(5.8008, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(0.4836, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
tensor(0.3601, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.4087, device='cuda:0', dtype=torch.float16) tensor(0.0290, device='cuda:0', dtype=torch.float16)
tensor(0.4548, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
27 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.3203, device='cuda:0', dtype=torch.float16) tensor(0.5488, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.1086, device='cuda:0', dtype=torch.float16)
tensor(0.9868, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0161, device='cuda:0')
tensor(0.2768, device='cuda:0')
old_score: tensor(0.1076, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0994, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.114346027374268
Validation after dual ascent:
out_inf: tensor(11.3203, device='cuda:0', dtype=torch.float16) tensor(0.5488, device='cuda:0', dtype=torch.float16)
tensor(1.0010, device='cuda:0', dtype=torch.float16) tensor(0.1005, device='cuda:0', dtype=torch.float16)
tensor(0.9771, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(1.0420, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
tensor(1.0879, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
27 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.1289, device='cuda:0', dtype=torch.float16) tensor(0.4209, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(0.9673, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.1055, device='cuda:0', dtype=torch.float16)
tensor(0.9624, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0147, device='cuda:0')
tensor(0.2582, device='cuda:0')
old_score: tensor(0.1022, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0944, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1227030754089355
Validation after dual ascent:
out_inf: tensor(7.1289, device='cuda:0', dtype=torch.float16) tensor(0.4209, device='cuda:0', dtype=torch.float16)
tensor(0.9355, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(0.9990, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(0.8667, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
tensor(1.0146, device='cuda:0', dtype=torch.float16) tensor(0.0978, device='cuda:0', dtype=torch.float16)
27 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(4.2891, device='cuda:0', dtype=torch.float16) tensor(0.2527, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0631, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(0.6475, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0142, device='cuda:0')
tensor(0.2243, device='cuda:0')
old_score: tensor(0.0615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0593, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.128710746765137
Validation after dual ascent:
out_inf: tensor(4.2891, device='cuda:0', dtype=torch.float16) tensor(0.2527, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.6968, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.6729, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
layer 27 done
28 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.3672, device='cuda:0', dtype=torch.float16) tensor(0.8496, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(1.4033, device='cuda:0', dtype=torch.float16) tensor(0.1335, device='cuda:0', dtype=torch.float16)
tensor(1.8066, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(1.6787, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0141, device='cuda:0')
tensor(0.1166, device='cuda:0')
old_score: tensor(0.1416, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1307, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2092220783233643
Validation after dual ascent:
out_inf: tensor(14.3672, device='cuda:0', dtype=torch.float16) tensor(0.8496, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1312, device='cuda:0', dtype=torch.float16)
tensor(1.3223, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
28 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.7656, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(1.2627, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1482, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0120, device='cuda:0')
tensor(0.1146, device='cuda:0')
old_score: tensor(0.1429, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1318, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.211815357208252
Validation after dual ascent:
out_inf: tensor(20.7656, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(1.2080, device='cuda:0', dtype=torch.float16) tensor(0.1326, device='cuda:0', dtype=torch.float16)
tensor(1.1611, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(1.2373, device='cuda:0', dtype=torch.float16) tensor(0.1368, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1360, device='cuda:0', dtype=torch.float16)
28 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.1172, device='cuda:0', dtype=torch.float16) tensor(0.5239, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0073, device='cuda:0')
tensor(0.0989, device='cuda:0')
old_score: tensor(0.1377, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1274, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.208900213241577
Validation after dual ascent:
out_inf: tensor(7.1172, device='cuda:0', dtype=torch.float16) tensor(0.5239, device='cuda:0', dtype=torch.float16)
tensor(1.2100, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.0830, device='cuda:0', dtype=torch.float16) tensor(0.1181, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
28 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(9., device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(0.5825, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.6392, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.5596, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0176, device='cuda:0')
tensor(0.0413, device='cuda:0')
old_score: tensor(0.0444, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0412, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.664923191070557
Validation after dual ascent:
out_inf: tensor(9., device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
28 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.6250, device='cuda:0', dtype=torch.float16) tensor(0.5757, device='cuda:0', dtype=torch.float16)
tensor(0.9946, device='cuda:0', dtype=torch.float16) tensor(0.1106, device='cuda:0', dtype=torch.float16)
tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
tensor(1.0283, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.3057, device='cuda:0')
old_score: tensor(0.1098, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.121506929397583
Validation after dual ascent:
out_inf: tensor(14.6250, device='cuda:0', dtype=torch.float16) tensor(0.5757, device='cuda:0', dtype=torch.float16)
tensor(1.0635, device='cuda:0', dtype=torch.float16) tensor(0.1022, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
28 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.7812, device='cuda:0', dtype=torch.float16) tensor(0.4607, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(1.0303, device='cuda:0', dtype=torch.float16) tensor(0.1098, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0162, device='cuda:0')
tensor(0.2904, device='cuda:0')
old_score: tensor(0.1061, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0978, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.126342535018921
Validation after dual ascent:
out_inf: tensor(12.7812, device='cuda:0', dtype=torch.float16) tensor(0.4607, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.0811, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
28 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.1016, device='cuda:0', dtype=torch.float16) tensor(0.2874, device='cuda:0', dtype=torch.float16)
tensor(0.8130, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.6904, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0185, device='cuda:0')
tensor(0.2925, device='cuda:0')
old_score: tensor(0.0679, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0654, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.080734014511108
Validation after dual ascent:
out_inf: tensor(8.1016, device='cuda:0', dtype=torch.float16) tensor(0.2874, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
tensor(0.7651, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
layer 28 done
29 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(12.9219, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(1.8105, device='cuda:0', dtype=torch.float16) tensor(0.1311, device='cuda:0', dtype=torch.float16)
tensor(1.4805, device='cuda:0', dtype=torch.float16) tensor(0.1242, device='cuda:0', dtype=torch.float16)
tensor(1.3369, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
tensor(2.1895, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0076, device='cuda:0')
tensor(0.0410, device='cuda:0')
old_score: tensor(0.1312, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1210, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.416571855545044
Validation after dual ascent:
out_inf: tensor(12.9219, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(1.7158, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
tensor(1.3105, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
29 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(20.7812, device='cuda:0', dtype=torch.float16) tensor(1.0439, device='cuda:0', dtype=torch.float16)
tensor(1.1709, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1332, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0198, device='cuda:0')
tensor(0.1001, device='cuda:0')
old_score: tensor(0.1320, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1215, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.211562156677246
Validation after dual ascent:
out_inf: tensor(20.7812, device='cuda:0', dtype=torch.float16) tensor(1.0439, device='cuda:0', dtype=torch.float16)
tensor(1.1123, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
29 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(8.4922, device='cuda:0', dtype=torch.float16) tensor(0.4988, device='cuda:0', dtype=torch.float16)
tensor(1.2900, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0180, device='cuda:0')
tensor(0.3502, device='cuda:0')
old_score: tensor(0.1346, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.472679853439331
Validation after dual ascent:
out_inf: tensor(8.4922, device='cuda:0', dtype=torch.float16) tensor(0.4988, device='cuda:0', dtype=torch.float16)
tensor(1.1318, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
tensor(1.0713, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
29 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(16.6406, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(0.5190, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.5674, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.5161, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.5649, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0029, device='cuda:0')
tensor(0.0182, device='cuda:0')
old_score: tensor(0.0457, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0427, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4648540019989014
Validation after dual ascent:
out_inf: tensor(16.6406, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.4741, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
29 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(11.6016, device='cuda:0', dtype=torch.float16) tensor(0.5908, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(1.0283, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.3266, device='cuda:0')
old_score: tensor(0.1116, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1027, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.123550176620483
Validation after dual ascent:
out_inf: tensor(11.6016, device='cuda:0', dtype=torch.float16) tensor(0.5908, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(0.9575, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(1.0684, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
29 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.5161, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.1095, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(1.0811, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.1084, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0175, device='cuda:0')
tensor(0.3135, device='cuda:0')
old_score: tensor(0.1089, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1002, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.125558614730835
Validation after dual ascent:
out_inf: tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.5161, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(1.0596, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(0.9731, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(1.0420, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
29 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(23.4844, device='cuda:0', dtype=torch.float16) tensor(0.3423, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(0.8867, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.7866, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(0.9092, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0032, device='cuda:0')
tensor(0.0409, device='cuda:0')
old_score: tensor(0.0752, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0723, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.834030628204346
Validation after dual ascent:
out_inf: tensor(23.4844, device='cuda:0', dtype=torch.float16) tensor(0.3423, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(0.8647, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.7837, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(0.9419, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
layer 29 done
30 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(14.7109, device='cuda:0', dtype=torch.float16) tensor(0.8638, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(1.5449, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1415, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0095, device='cuda:0')
tensor(0.0826, device='cuda:0')
old_score: tensor(0.1395, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1282, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.20998477935791
Validation after dual ascent:
out_inf: tensor(14.7109, device='cuda:0', dtype=torch.float16) tensor(0.8638, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(1.3926, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1324, device='cuda:0', dtype=torch.float16)
tensor(1.3027, device='cuda:0', dtype=torch.float16) tensor(0.1321, device='cuda:0', dtype=torch.float16)
30 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(18.8281, device='cuda:0', dtype=torch.float16) tensor(1.0156, device='cuda:0', dtype=torch.float16)
tensor(1.3291, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.1466, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0113, device='cuda:0')
tensor(0.0867, device='cuda:0')
old_score: tensor(0.1416, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1300, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2117462158203125
Validation after dual ascent:
out_inf: tensor(18.8281, device='cuda:0', dtype=torch.float16) tensor(1.0156, device='cuda:0', dtype=torch.float16)
tensor(1.2939, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
tensor(1.2676, device='cuda:0', dtype=torch.float16) tensor(0.1206, device='cuda:0', dtype=torch.float16)
tensor(1.2168, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
30 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(9.8984, device='cuda:0', dtype=torch.float16) tensor(0.5610, device='cuda:0', dtype=torch.float16)
tensor(1.2705, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
tensor(1.2939, device='cuda:0', dtype=torch.float16) tensor(0.1444, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.3809, device='cuda:0')
old_score: tensor(0.1421, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1307, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.472656726837158
Validation after dual ascent:
out_inf: tensor(9.8984, device='cuda:0', dtype=torch.float16) tensor(0.5610, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.3770, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
30 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(21.1406, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.7881, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0046, device='cuda:0')
tensor(0.0223, device='cuda:0')
old_score: tensor(0.0392, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0366, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.464616537094116
Validation after dual ascent:
out_inf: tensor(21.1406, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.5908, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
30 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(34.9062, device='cuda:0', dtype=torch.float16) tensor(0.6455, device='cuda:0', dtype=torch.float16)
tensor(1.1279, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.0674, device='cuda:0', dtype=torch.float16) tensor(0.1133, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.3171, device='cuda:0')
old_score: tensor(0.1115, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1023, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.129464626312256
Validation after dual ascent:
out_inf: tensor(34.9062, device='cuda:0', dtype=torch.float16) tensor(0.6455, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
30 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(35.4062, device='cuda:0', dtype=torch.float16) tensor(0.5981, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.0332, device='cuda:0', dtype=torch.float16) tensor(0.1023, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.1123, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1102, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0183, device='cuda:0')
tensor(0.3029, device='cuda:0')
old_score: tensor(0.1084, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0994, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.130223751068115
Validation after dual ascent:
out_inf: tensor(35.4062, device='cuda:0', dtype=torch.float16) tensor(0.5981, device='cuda:0', dtype=torch.float16)
tensor(0.9248, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.9658, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
tensor(0.9775, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
30 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(1515., device='cuda:0', dtype=torch.float16) tensor(0.5356, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0802, device='cuda:0', dtype=torch.float16)
tensor(1.0264, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(1.0459, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0159, device='cuda:0')
tensor(0.0800, device='cuda:0')
old_score: tensor(0.0809, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0773, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.76028800010681
Validation after dual ascent:
out_inf: tensor(1515., device='cuda:0', dtype=torch.float16) tensor(0.5356, device='cuda:0', dtype=torch.float16)
tensor(1.3799, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(1.3584, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
layer 30 done
31 self_attn.q_proj
Pruning ...
Validation after prune:
out_inf: tensor(19.7031, device='cuda:0', dtype=torch.float16) tensor(0.8511, device='cuda:0', dtype=torch.float16)
tensor(2.8750, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(2.3906, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0129, device='cuda:0')
tensor(0.2002, device='cuda:0')
old_score: tensor(0.1139, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1035, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4749763011932373
Validation after dual ascent:
out_inf: tensor(19.7031, device='cuda:0', dtype=torch.float16) tensor(0.8511, device='cuda:0', dtype=torch.float16)
tensor(2.7656, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(2.5234, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(1.9180, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
31 self_attn.k_proj
Pruning ...
Validation after prune:
out_inf: tensor(23.6250, device='cuda:0', dtype=torch.float16) tensor(1.0850, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(2.1953, device='cuda:0', dtype=torch.float16) tensor(0.1101, device='cuda:0', dtype=torch.float16)
tensor(2.4336, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0150, device='cuda:0')
tensor(0.2116, device='cuda:0')
old_score: tensor(0.1165, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1058, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.474384069442749
Validation after dual ascent:
out_inf: tensor(23.6250, device='cuda:0', dtype=torch.float16) tensor(1.0850, device='cuda:0', dtype=torch.float16)
tensor(2.3594, device='cuda:0', dtype=torch.float16) tensor(0.1063, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(2.2070, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.6426, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
31 self_attn.v_proj
Pruning ...
Validation after prune:
out_inf: tensor(7.0352, device='cuda:0', dtype=torch.float16) tensor(0.4277, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1043, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(0.9565, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0096, device='cuda:0')
tensor(0.1737, device='cuda:0')
old_score: tensor(0.1040, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0947, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.470937967300415
Validation after dual ascent:
out_inf: tensor(7.0352, device='cuda:0', dtype=torch.float16) tensor(0.4277, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(0.8965, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
31 self_attn.o_proj
Pruning ...
Validation after prune:
out_inf: tensor(129.1250, device='cuda:0', dtype=torch.float16) tensor(0.2478, device='cuda:0', dtype=torch.float16)
tensor(0.5317, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.5513, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0132, device='cuda:0')
tensor(0.0953, device='cuda:0')
old_score: tensor(0.0465, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0404, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4601073265075684
Validation after dual ascent:
out_inf: tensor(129.1250, device='cuda:0', dtype=torch.float16) tensor(0.2478, device='cuda:0', dtype=torch.float16)
tensor(0.5166, device='cuda:0', dtype=torch.float16) tensor(0.0419, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
31 mlp.gate_proj
Pruning ...
Validation after prune:
out_inf: tensor(31.3281, device='cuda:0', dtype=torch.float16) tensor(0.6870, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.1020, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.1957, device='cuda:0')
old_score: tensor(0.1018, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0922, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1284098625183105
Validation after dual ascent:
out_inf: tensor(31.3281, device='cuda:0', dtype=torch.float16) tensor(0.6870, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(1.1182, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
tensor(1.1006, device='cuda:0', dtype=torch.float16) tensor(0.0962, device='cuda:0', dtype=torch.float16)
tensor(1.0586, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
31 mlp.up_proj
Pruning ...
Validation after prune:
out_inf: tensor(34.4375, device='cuda:0', dtype=torch.float16) tensor(0.7021, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0979, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0926, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.9893, device='cuda:0', dtype=torch.float16) tensor(0.0987, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.1844, device='cuda:0')
old_score: tensor(0.0977, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0884, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.137080192565918
Validation after dual ascent:
out_inf: tensor(34.4375, device='cuda:0', dtype=torch.float16) tensor(0.7021, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0888, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(0.9834, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
31 mlp.down_proj
Pruning ...
Validation after prune:
out_inf: tensor(193.7500, device='cuda:0', dtype=torch.float16) tensor(1.5225, device='cuda:0', dtype=torch.float16)
tensor(1.0479, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(1.2432, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0882, device='cuda:0', dtype=torch.float16)
layer 31 done
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.13it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.09it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.92it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25': 0, 'model.layers.26': 0, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.600001
layer 1 sparsity 0.600001
layer 2 sparsity 0.600001
layer 3 sparsity 0.600001
layer 4 sparsity 0.600001
layer 5 sparsity 0.600001
layer 6 sparsity 0.600001
layer 7 sparsity 0.600001
layer 8 sparsity 0.600001
layer 9 sparsity 0.600001
layer 10 sparsity 0.600001
layer 11 sparsity 0.600001
layer 12 sparsity 0.600001
layer 13 sparsity 0.600001
layer 14 sparsity 0.600001
layer 15 sparsity 0.600001
layer 16 sparsity 0.600001
layer 17 sparsity 0.600001
layer 18 sparsity 0.600001
layer 19 sparsity 0.600001
layer 20 sparsity 0.600001
layer 21 sparsity 0.600001
layer 22 sparsity 0.600001
layer 23 sparsity 0.600001
layer 24 sparsity 0.600001
layer 25 sparsity 0.600001
layer 26 sparsity 0.600001
layer 27 sparsity 0.600001
layer 28 sparsity 0.600001
layer 29 sparsity 0.600001
layer 30 sparsity 0.600001
layer 31 sparsity 0.600001
sparsity sanity check 0.6000
******************************
evaluating on wikitext2
nsamples 83
sample 0
sample 50
wikitext perplexity 9.012979507446289
sparsegpt_dual_3	0.6000	9.0130	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.6, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='sparsegpt_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
