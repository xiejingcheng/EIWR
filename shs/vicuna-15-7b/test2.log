nohup: ignoring input
2025-04-23 23:52:51.707067: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-23 23:52:51.907312: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-23 23:52:51.912546: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-23 23:52:51.912574: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-23 23:52:55.698451: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-23 23:52:55.699033: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-23 23:52:55.699053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.64it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.60it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.42it/s]
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
model.embed_tokens.weight torch.Size([32000, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([32000, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:00<03:25,  1.24it/s]  1%|          | 2/256 [00:01<03:15,  1.30it/s]  2%|▏         | 4/256 [00:01<01:38,  2.56it/s]  2%|▏         | 5/256 [00:02<01:55,  2.18it/s]  2%|▏         | 6/256 [00:02<01:33,  2.68it/s]  3%|▎         | 7/256 [00:03<02:19,  1.79it/s]  3%|▎         | 8/256 [00:03<01:46,  2.32it/s]  4%|▎         | 9/256 [00:03<01:22,  3.01it/s]  4%|▍         | 11/256 [00:04<00:53,  4.56it/s]  5%|▍         | 12/256 [00:04<00:48,  5.08it/s]  5%|▌         | 13/256 [00:05<01:34,  2.57it/s]  5%|▌         | 14/256 [00:05<01:31,  2.66it/s]  6%|▌         | 15/256 [00:05<01:16,  3.14it/s]  6%|▋         | 16/256 [00:05<01:07,  3.55it/s]  7%|▋         | 18/256 [00:06<01:10,  3.37it/s]  8%|▊         | 20/256 [00:06<00:52,  4.46it/s]  8%|▊         | 21/256 [00:06<00:46,  5.06it/s]  9%|▊         | 22/256 [00:07<00:50,  4.68it/s]  9%|▉         | 24/256 [00:07<00:43,  5.40it/s] 10%|▉         | 25/256 [00:07<00:41,  5.56it/s] 10%|█         | 26/256 [00:07<00:53,  4.26it/s] 11%|█         | 28/256 [00:08<00:44,  5.14it/s] 11%|█▏        | 29/256 [00:08<00:45,  4.98it/s] 12%|█▏        | 31/256 [00:08<00:38,  5.79it/s] 12%|█▎        | 32/256 [00:09<00:47,  4.71it/s] 13%|█▎        | 33/256 [00:09<01:02,  3.58it/s] 13%|█▎        | 34/256 [00:09<01:05,  3.39it/s] 14%|█▎        | 35/256 [00:10<01:11,  3.08it/s] 14%|█▍        | 36/256 [00:10<01:21,  2.70it/s] 14%|█▍        | 37/256 [00:11<01:15,  2.90it/s] 15%|█▍        | 38/256 [00:11<01:09,  3.14it/s] 16%|█▌        | 40/256 [00:11<01:04,  3.33it/s] 16%|█▋        | 42/256 [00:11<00:45,  4.71it/s] 17%|█▋        | 43/256 [00:12<00:40,  5.26it/s] 17%|█▋        | 44/256 [00:12<00:39,  5.31it/s] 18%|█▊        | 46/256 [00:12<00:33,  6.21it/s] 18%|█▊        | 47/256 [00:12<00:35,  5.96it/s] 19%|█▉        | 48/256 [00:12<00:38,  5.40it/s] 19%|█▉        | 49/256 [00:13<00:34,  5.96it/s] 20%|█▉        | 50/256 [00:13<00:50,  4.10it/s] 21%|██        | 53/256 [00:14<00:48,  4.21it/s] 21%|██        | 54/256 [00:14<00:47,  4.23it/s] 21%|██▏       | 55/256 [00:14<00:41,  4.85it/s] 22%|██▏       | 56/256 [00:14<00:49,  4.05it/s] 22%|██▏       | 57/256 [00:15<00:45,  4.38it/s] 23%|██▎       | 58/256 [00:15<00:51,  3.87it/s] 23%|██▎       | 59/256 [00:15<00:44,  4.41it/s] 23%|██▎       | 60/256 [00:15<00:47,  4.09it/s] 24%|██▍       | 61/256 [00:16<00:56,  3.47it/s] 24%|██▍       | 62/256 [00:16<01:00,  3.22it/s] 25%|██▍       | 63/256 [00:16<00:51,  3.71it/s] 25%|██▌       | 64/256 [00:16<00:42,  4.49it/s] 25%|██▌       | 65/256 [00:17<01:08,  2.78it/s] 26%|██▌       | 67/256 [00:17<00:43,  4.31it/s] 27%|██▋       | 68/256 [00:17<00:42,  4.38it/s] 27%|██▋       | 69/256 [00:18<00:43,  4.28it/s] 28%|██▊       | 71/256 [00:18<00:33,  5.50it/s] 29%|██▊       | 73/256 [00:18<00:27,  6.75it/s] 29%|██▉       | 74/256 [00:18<00:26,  6.77it/s] 29%|██▉       | 75/256 [00:19<00:32,  5.61it/s] 30%|██▉       | 76/256 [00:19<00:45,  3.98it/s] 30%|███       | 78/256 [00:19<00:30,  5.76it/s] 31%|███       | 79/256 [00:20<00:38,  4.61it/s] 31%|███▏      | 80/256 [00:20<00:49,  3.57it/s] 32%|███▏      | 81/256 [00:20<00:54,  3.21it/s] 32%|███▏      | 82/256 [00:21<00:45,  3.84it/s] 32%|███▏      | 83/256 [00:21<00:55,  3.13it/s] 33%|███▎      | 84/256 [00:21<00:52,  3.29it/s] 33%|███▎      | 85/256 [00:21<00:47,  3.57it/s] 34%|███▎      | 86/256 [00:22<00:43,  3.88it/s] 34%|███▍      | 87/256 [00:22<01:01,  2.76it/s] 34%|███▍      | 88/256 [00:23<01:03,  2.64it/s] 35%|███▍      | 89/256 [00:23<00:58,  2.85it/s] 35%|███▌      | 90/256 [00:23<01:00,  2.77it/s] 36%|███▌      | 91/256 [00:24<00:58,  2.80it/s] 36%|███▌      | 92/256 [00:24<00:49,  3.30it/s] 36%|███▋      | 93/256 [00:24<00:43,  3.77it/s] 37%|███▋      | 94/256 [00:25<00:51,  3.14it/s] 37%|███▋      | 95/256 [00:25<01:05,  2.47it/s] 38%|███▊      | 96/256 [00:25<00:52,  3.06it/s] 38%|███▊      | 97/256 [00:26<00:56,  2.82it/s] 38%|███▊      | 98/256 [00:26<00:47,  3.36it/s] 39%|███▊      | 99/256 [00:26<00:45,  3.44it/s] 39%|███▉      | 100/256 [00:26<00:44,  3.54it/s] 39%|███▉      | 101/256 [00:27<01:18,  1.98it/s] 40%|███▉      | 102/256 [00:28<01:06,  2.31it/s] 41%|████      | 104/256 [00:28<00:42,  3.58it/s] 41%|████▏     | 106/256 [00:28<00:34,  4.35it/s] 42%|████▏     | 107/256 [00:28<00:34,  4.38it/s] 42%|████▏     | 108/256 [00:29<00:48,  3.05it/s] 43%|████▎     | 111/256 [00:29<00:30,  4.71it/s] 44%|████▍     | 112/256 [00:30<00:32,  4.40it/s] 44%|████▍     | 113/256 [00:30<00:32,  4.37it/s] 45%|████▍     | 114/256 [00:30<00:29,  4.79it/s] 45%|████▍     | 115/256 [00:30<00:28,  5.02it/s] 45%|████▌     | 116/256 [00:31<00:38,  3.60it/s] 46%|████▌     | 117/256 [00:31<00:31,  4.37it/s] 46%|████▌     | 118/256 [00:31<00:29,  4.66it/s] 47%|████▋     | 120/256 [00:31<00:20,  6.52it/s] 47%|████▋     | 121/256 [00:31<00:19,  6.89it/s] 48%|████▊     | 122/256 [00:32<00:36,  3.64it/s] 48%|████▊     | 123/256 [00:32<00:41,  3.17it/s] 48%|████▊     | 124/256 [00:33<01:05,  2.02it/s] 49%|████▉     | 125/256 [00:35<01:35,  1.37it/s] 49%|████▉     | 126/256 [00:35<01:18,  1.65it/s] 50%|████▉     | 127/256 [00:36<01:21,  1.57it/s] 50%|█████     | 129/256 [00:36<00:49,  2.59it/s] 51%|█████     | 130/256 [00:36<00:44,  2.85it/s] 51%|█████     | 131/256 [00:36<00:41,  3.02it/s] 52%|█████▏    | 132/256 [00:37<00:39,  3.17it/s] 52%|█████▏    | 133/256 [00:37<00:46,  2.64it/s] 52%|█████▏    | 134/256 [00:38<00:45,  2.67it/s] 53%|█████▎    | 135/256 [00:38<00:36,  3.29it/s] 53%|█████▎    | 136/256 [00:38<00:36,  3.27it/s] 54%|█████▎    | 137/256 [00:38<00:30,  3.90it/s] 54%|█████▍    | 138/256 [00:38<00:26,  4.38it/s] 54%|█████▍    | 139/256 [00:38<00:24,  4.71it/s] 55%|█████▍    | 140/256 [00:39<00:22,  5.05it/s] 55%|█████▌    | 141/256 [00:39<00:19,  5.87it/s] 55%|█████▌    | 142/256 [00:39<00:17,  6.61it/s] 56%|█████▌    | 143/256 [00:39<00:16,  6.74it/s] 57%|█████▋    | 145/256 [00:40<00:37,  2.93it/s] 57%|█████▋    | 146/256 [00:41<00:41,  2.68it/s] 57%|█████▋    | 147/256 [00:41<00:37,  2.94it/s] 58%|█████▊    | 148/256 [00:41<00:37,  2.85it/s] 59%|█████▊    | 150/256 [00:42<00:30,  3.50it/s] 59%|█████▉    | 151/256 [00:42<00:25,  4.08it/s] 59%|█████▉    | 152/256 [00:42<00:28,  3.61it/s] 60%|█████▉    | 153/256 [00:42<00:25,  3.99it/s] 60%|██████    | 154/256 [00:43<00:30,  3.39it/s] 61%|██████    | 155/256 [00:43<00:26,  3.76it/s] 61%|██████    | 156/256 [00:43<00:22,  4.49it/s] 61%|██████▏   | 157/256 [00:43<00:27,  3.59it/s] 62%|██████▏   | 158/256 [00:44<00:24,  4.04it/s] 62%|██████▏   | 159/256 [00:44<00:42,  2.26it/s] 62%|██████▎   | 160/256 [00:45<00:33,  2.89it/s] 63%|██████▎   | 162/256 [00:46<00:38,  2.46it/s] 64%|██████▎   | 163/256 [00:46<00:34,  2.72it/s] 64%|██████▍   | 164/256 [00:46<00:28,  3.20it/s] 65%|██████▍   | 166/256 [00:46<00:23,  3.77it/s] 65%|██████▌   | 167/256 [00:47<00:26,  3.39it/s] 66%|██████▌   | 168/256 [00:47<00:29,  3.02it/s] 66%|██████▌   | 169/256 [00:48<00:33,  2.63it/s] 66%|██████▋   | 170/256 [00:48<00:32,  2.67it/s] 67%|██████▋   | 172/256 [00:48<00:22,  3.67it/s] 68%|██████▊   | 173/256 [00:49<00:22,  3.62it/s] 68%|██████▊   | 174/256 [00:50<00:36,  2.26it/s] 68%|██████▊   | 175/256 [00:51<00:51,  1.58it/s] 69%|██████▉   | 176/256 [00:51<00:42,  1.86it/s] 69%|██████▉   | 177/256 [00:51<00:34,  2.29it/s] 70%|██████▉   | 179/256 [00:51<00:22,  3.39it/s] 70%|███████   | 180/256 [00:53<00:39,  1.94it/s] 71%|███████   | 181/256 [00:53<00:30,  2.42it/s] 71%|███████   | 182/256 [00:54<00:38,  1.91it/s] 72%|███████▏  | 184/256 [00:54<00:35,  2.01it/s] 73%|███████▎  | 186/256 [00:55<00:24,  2.89it/s] 73%|███████▎  | 187/256 [00:55<00:27,  2.48it/s] 73%|███████▎  | 188/256 [00:55<00:23,  2.83it/s] 74%|███████▍  | 189/256 [00:56<00:23,  2.89it/s] 74%|███████▍  | 190/256 [00:56<00:21,  3.13it/s] 75%|███████▍  | 191/256 [00:56<00:18,  3.45it/s] 75%|███████▌  | 192/256 [00:57<00:22,  2.86it/s] 75%|███████▌  | 193/256 [00:57<00:21,  2.99it/s] 77%|███████▋  | 196/256 [00:57<00:13,  4.44it/s] 77%|███████▋  | 197/256 [00:58<00:15,  3.85it/s] 78%|███████▊  | 199/256 [00:58<00:11,  4.90it/s] 79%|███████▊  | 201/256 [00:58<00:10,  5.49it/s] 79%|███████▉  | 202/256 [00:59<00:11,  4.56it/s] 80%|███████▉  | 204/256 [00:59<00:09,  5.78it/s] 80%|████████  | 206/256 [00:59<00:06,  7.16it/s] 81%|████████  | 207/256 [00:59<00:06,  7.50it/s] 81%|████████▏ | 208/256 [00:59<00:07,  6.57it/s] 82%|████████▏ | 210/256 [01:00<00:05,  8.71it/s] 83%|████████▎ | 212/256 [01:00<00:05,  8.21it/s] 83%|████████▎ | 213/256 [01:00<00:05,  7.33it/s] 84%|████████▎ | 214/256 [01:00<00:07,  5.57it/s] 84%|████████▍ | 215/256 [01:01<00:09,  4.49it/s] 84%|████████▍ | 216/256 [01:01<00:09,  4.38it/s] 85%|████████▌ | 218/256 [01:01<00:07,  5.24it/s] 86%|████████▌ | 219/256 [01:02<00:14,  2.56it/s] 86%|████████▌ | 220/256 [01:02<00:11,  3.00it/s] 86%|████████▋ | 221/256 [01:03<00:12,  2.88it/s] 87%|████████▋ | 222/256 [01:03<00:11,  2.85it/s] 87%|████████▋ | 223/256 [01:04<00:12,  2.69it/s] 88%|████████▊ | 224/256 [01:05<00:24,  1.33it/s] 88%|████████▊ | 225/256 [01:06<00:22,  1.36it/s] 88%|████████▊ | 226/256 [01:06<00:17,  1.76it/s] 89%|████████▊ | 227/256 [01:06<00:13,  2.09it/s] 89%|████████▉ | 228/256 [01:07<00:12,  2.25it/s] 89%|████████▉ | 229/256 [01:08<00:18,  1.46it/s] 90%|████████▉ | 230/256 [01:08<00:13,  1.93it/s] 90%|█████████ | 231/256 [01:09<00:12,  1.95it/s] 91%|█████████ | 232/256 [01:09<00:10,  2.22it/s] 91%|█████████ | 233/256 [01:09<00:08,  2.70it/s] 92%|█████████▏| 235/256 [01:09<00:05,  3.71it/s] 92%|█████████▏| 236/256 [01:10<00:05,  3.60it/s] 93%|█████████▎| 237/256 [01:10<00:04,  3.98it/s] 93%|█████████▎| 238/256 [01:10<00:03,  4.64it/s] 93%|█████████▎| 239/256 [01:10<00:03,  4.59it/s] 94%|█████████▍| 241/256 [01:10<00:02,  5.86it/s] 95%|█████████▍| 242/256 [01:11<00:04,  2.86it/s] 95%|█████████▌| 244/256 [01:11<00:02,  4.35it/s] 96%|█████████▌| 245/256 [01:12<00:02,  4.10it/s] 96%|█████████▌| 246/256 [01:12<00:02,  4.59it/s] 97%|█████████▋| 248/256 [01:12<00:01,  6.27it/s] 97%|█████████▋| 249/256 [01:13<00:01,  3.87it/s] 98%|█████████▊| 251/256 [01:13<00:00,  5.42it/s] 98%|█████████▊| 252/256 [01:13<00:01,  3.46it/s] 99%|█████████▉| 253/256 [01:14<00:01,  2.95it/s]100%|█████████▉| 255/256 [01:15<00:00,  3.03it/s]100%|██████████| 256/256 [01:15<00:00,  3.11it/s]100%|██████████| 256/256 [01:15<00:00,  3.40it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
pruning layer 0 name self_attn.q_proj
Validation after prune:
out_inf: tensor(7.8555, device='cuda:0', dtype=torch.float16) tensor(0.6099, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.k_proj
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0703, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.v_proj
Validation after prune:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0474, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0388, device='cuda:0')
old_score: tensor(0.0018, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.749347448348999
Validation after dual ascent:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0230, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0309, device='cuda:0', dtype=torch.float16) tensor(0.0007, device='cuda:0', dtype=torch.float16)
tensor(0.0248, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0245, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0055, device='cuda:0', dtype=torch.float16) tensor(8.7202e-05, device='cuda:0', dtype=torch.float16)
tensor(0.0033, device='cuda:0', dtype=torch.float16) tensor(0.0001, device='cuda:0', dtype=torch.float16)
tensor(0.0053, device='cuda:0', dtype=torch.float16) tensor(0.0001, device='cuda:0', dtype=torch.float16)
tensor(0.0068, device='cuda:0', dtype=torch.float16) tensor(9.0718e-05, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.4131, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0164, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.0107, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0060, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.294554948806763
Validation after dual ascent:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.2842, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.2859, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.up_proj
Validation after prune:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0102, device='cuda:0', dtype=torch.float16)
tensor(0.1738, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.1665, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0158, device='cuda:0')
tensor(0.0181, device='cuda:0')
old_score: tensor(0.0105, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0059, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.44106960296631
Validation after dual ascent:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1079, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.1211, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.1284, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.1123, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0476, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0431, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0389, device='cuda:0', dtype=torch.float16) tensor(0.0015, device='cuda:0', dtype=torch.float16)
tensor(0.0459, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0726, device='cuda:0')
old_score: tensor(0.0013, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0009, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.52189779281616
Validation after dual ascent:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0203, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0225, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0222, device='cuda:0', dtype=torch.float16) tensor(0.0010, device='cuda:0', dtype=torch.float16)
tensor(0.0444, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.q_proj
Validation after prune:
out_inf: tensor(9.2500, device='cuda:0', dtype=torch.float16) tensor(0.7812, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
tensor(0.9629, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.k_proj
Validation after prune:
out_inf: tensor(7.7383, device='cuda:0', dtype=torch.float16) tensor(0.7896, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(1.0938, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.2666, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2744, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.2695, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0193, device='cuda:0')
tensor(0.0290, device='cuda:0')
old_score: tensor(0.0067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0037, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.144970417022705
Validation after dual ascent:
out_inf: tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.1572, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.1689, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.1631, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.5386, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.0273, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
tensor(0.0150, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0241, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0216, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.gate_proj
Validation after prune:
out_inf: tensor(43.6562, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(3.7188, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(3.4688, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(3.8750, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0160, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.0229, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0140, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.768713235855103
Validation after dual ascent:
out_inf: tensor(43.6562, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.up_proj
Validation after prune:
out_inf: tensor(37.7188, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(2.4688, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0130, device='cuda:0')
tensor(0.0198, device='cuda:0')
old_score: tensor(0.0209, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.816238403320312
Validation after dual ascent:
out_inf: tensor(37.7188, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.down_proj
Validation after prune:
out_inf: tensor(2674., device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0908, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0878, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(2.0303, device='cuda:0')
old_score: tensor(0.0037, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0135, device='cuda:0', dtype=torch.float16)
Not converged!
Dual ascent finished!
Time: 98.37398219108582
Validation after dual ascent:
out_inf: tensor(2674., device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0908, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0878, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12., device='cuda:0', dtype=torch.float16) tensor(0.9028, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.k_proj
Validation after prune:
out_inf: tensor(13.4219, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0680, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.9785, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.3418, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.4590, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.0207, device='cuda:0')
old_score: tensor(0.0332, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0216, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4272639751434326
Validation after dual ascent:
out_inf: tensor(2.9785, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
tensor(0.2539, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.2524, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.2668, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.2549, device='cuda:0', dtype=torch.float16) tensor(0.0214, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9341, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.2323, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0934, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.0762, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.1364, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0425, device='cuda:0')
old_score: tensor(0.0022, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0017, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.805336236953735
Validation after dual ascent:
out_inf: tensor(0.9341, device='cuda:0', dtype=torch.float16) tensor(0.0099, device='cuda:0', dtype=torch.float16)
tensor(0.1069, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.1520, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.1103, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0942, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.2324, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0166, device='cuda:0')
tensor(0.0158, device='cuda:0')
old_score: tensor(0.0334, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.885542154312134
Validation after dual ascent:
out_inf: tensor(2.2324, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(0.3552, device='cuda:0', dtype=torch.float16) tensor(0.0237, device='cuda:0', dtype=torch.float16)
tensor(0.4268, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.3782, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
tensor(0.4211, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.3125, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.2666, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.3730, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0166, device='cuda:0')
tensor(0.0247, device='cuda:0')
old_score: tensor(0.0306, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0222, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0723795890808105
Validation after dual ascent:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.2312, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.2405, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.2421, device='cuda:0', dtype=torch.float16) tensor(0.0237, device='cuda:0', dtype=torch.float16)
tensor(0.2595, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.0884, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.1057, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1099, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1192, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0774, device='cuda:0')
old_score: tensor(0.0054, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0046, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.67492747306824
Validation after dual ascent:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.0664, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.0763, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.0721, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0824, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(0.8271, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(0.0742, device='cuda:0')
old_score: tensor(0.1021, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0714, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.804150342941284
Validation after dual ascent:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(0.8271, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(1.1748, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.0778, device='cuda:0', dtype=torch.float16)
tensor(1.1846, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.1034, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0150, device='cuda:0')
tensor(0.0522, device='cuda:0')
old_score: tensor(0.1058, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0734, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.667277097702026
Validation after dual ascent:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(1.0557, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(1.1377, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.7051, device='cuda:0', dtype=torch.float16) tensor(0.1945, device='cuda:0', dtype=torch.float16)
tensor(0.4468, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.4751, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.4448, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0176, device='cuda:0')
tensor(0.0302, device='cuda:0')
old_score: tensor(0.0546, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0404, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.458237409591675
Validation after dual ascent:
out_inf: tensor(2.7051, device='cuda:0', dtype=torch.float16) tensor(0.1945, device='cuda:0', dtype=torch.float16)
tensor(0.4058, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.4714, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.5620, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.4412, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.1746, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.1528, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.1562, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.1484, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.0376, device='cuda:0')
old_score: tensor(0.0031, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0025, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.907297372817993
Validation after dual ascent:
out_inf: tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.1494, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0933, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1138, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.1045, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.0820, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0067, device='cuda:0')
tensor(0.0184, device='cuda:0')
old_score: tensor(0.0430, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0334, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.092597723007202
Validation after dual ascent:
out_inf: tensor(5.0820, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(0.6006, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0188, device='cuda:0')
tensor(0.1437, device='cuda:0')
old_score: tensor(0.0396, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0309, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.171296119689941
Validation after dual ascent:
out_inf: tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
tensor(0.3037, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.3445, device='cuda:0', dtype=torch.float16) tensor(0.0290, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.3101, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5771, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.1238, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1736, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1309, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.1255, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0199, device='cuda:0')
tensor(0.0524, device='cuda:0')
old_score: tensor(0.0079, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0069, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 69.91794538497925
Validation after dual ascent:
out_inf: tensor(1.5771, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.0862, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1395, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1021, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0961, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.1797, device='cuda:0', dtype=torch.float16) tensor(0.8057, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.1396, device='cuda:0', dtype=torch.float16) tensor(0.1078, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1032, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0187, device='cuda:0')
tensor(0.0536, device='cuda:0')
old_score: tensor(0.1036, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0760, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1704764366149902
Validation after dual ascent:
out_inf: tensor(13.1797, device='cuda:0', dtype=torch.float16) tensor(0.8057, device='cuda:0', dtype=torch.float16)
tensor(0.9580, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.9263, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(1.0420, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(1.0215, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.0254, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0183, device='cuda:0')
tensor(0.0405, device='cuda:0')
old_score: tensor(0.1060, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0768, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.728378057479858
Validation after dual ascent:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.0254, device='cuda:0', dtype=torch.float16)
tensor(1.1357, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.0137, device='cuda:0', dtype=torch.float16) tensor(0.0819, device='cuda:0', dtype=torch.float16)
tensor(1.0479, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.4746, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(0.6006, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.0301, device='cuda:0')
old_score: tensor(0.0569, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0433, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4436490535736084
Validation after dual ascent:
out_inf: tensor(3.4746, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(0.4116, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.4128, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.4465, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.3203, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.2217, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.2148, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.2949, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.2158, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.0269, device='cuda:0')
old_score: tensor(0.0061, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0047, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.813511610031128
Validation after dual ascent:
out_inf: tensor(3.3203, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0046, device='cuda:0', dtype=torch.float16)
tensor(0.1348, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1768, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0049, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.7617, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0172, device='cuda:0')
tensor(0.2353, device='cuda:0')
old_score: tensor(0.0524, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0416, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.1658148765563965
Validation after dual ascent:
out_inf: tensor(4.7617, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.6255, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.6040, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.1191, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0144, device='cuda:0')
tensor(0.2109, device='cuda:0')
old_score: tensor(0.0468, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0374, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.171422719955444
Validation after dual ascent:
out_inf: tensor(3.1191, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(0.3699, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.3481, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.down_proj
Validation after prune:
out_inf: tensor(9.3359, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.2061, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.2295, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1914, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.2275, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0108, device='cuda:0')
tensor(0.0148, device='cuda:0')
old_score: tensor(0.0117, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.85849690437317
Validation after dual ascent:
out_inf: tensor(9.3359, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.1584, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.1378, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1326, device='cuda:0', dtype=torch.float16) tensor(0.0105, device='cuda:0', dtype=torch.float16)
tensor(0.1582, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.5234, device='cuda:0', dtype=torch.float16) tensor(0.8149, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.1092, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1115, device='cuda:0', dtype=torch.float16)
tensor(0.0869, device='cuda:0')
old_score: tensor(0.1113, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0845, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.810171127319336
Validation after dual ascent:
out_inf: tensor(14.5234, device='cuda:0', dtype=torch.float16) tensor(0.8149, device='cuda:0', dtype=torch.float16)
tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(0.9746, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4062, device='cuda:0', dtype=torch.float16) tensor(1.0625, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1196, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0152, device='cuda:0')
tensor(0.0609, device='cuda:0')
old_score: tensor(0.1166, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0867, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.67498779296875
Validation after dual ascent:
out_inf: tensor(19.4062, device='cuda:0', dtype=torch.float16) tensor(1.0625, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
tensor(1.0840, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.3711, device='cuda:0', dtype=torch.float16) tensor(0.2059, device='cuda:0', dtype=torch.float16)
tensor(0.4468, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.4741, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.5073, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0168, device='cuda:0')
tensor(0.0345, device='cuda:0')
old_score: tensor(0.0608, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0483, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.452265739440918
Validation after dual ascent:
out_inf: tensor(2.3711, device='cuda:0', dtype=torch.float16) tensor(0.2059, device='cuda:0', dtype=torch.float16)
tensor(0.4045, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.3359, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.2310, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.2197, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.2383, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2214, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.0319, device='cuda:0')
old_score: tensor(0.0067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0051, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.898242473602295
Validation after dual ascent:
out_inf: tensor(4.3359, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.2034, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.1482, device='cuda:0', dtype=torch.float16) tensor(0.0054, device='cuda:0', dtype=torch.float16)
tensor(0.1888, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.2021, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.7988, device='cuda:0', dtype=torch.float16) tensor(0.2249, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0131, device='cuda:0')
tensor(0.0272, device='cuda:0')
old_score: tensor(0.0593, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0466, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.100677728652954
Validation after dual ascent:
out_inf: tensor(3.7988, device='cuda:0', dtype=torch.float16) tensor(0.2249, device='cuda:0', dtype=torch.float16)
tensor(0.6846, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.6943, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.5728, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4258, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0069, device='cuda:0')
tensor(0.0242, device='cuda:0')
old_score: tensor(0.0526, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.105776071548462
Validation after dual ascent:
out_inf: tensor(4.4258, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(0.3767, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5576, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.2134, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.3267, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.2078, device='cuda:0', dtype=torch.float16) tensor(0.0148, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0167, device='cuda:0')
tensor(0.0127, device='cuda:0')
old_score: tensor(0.0144, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0128, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 31.482433795928955
Validation after dual ascent:
out_inf: tensor(1.5576, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.1804, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
tensor(0.2446, device='cuda:0', dtype=torch.float16) tensor(0.0127, device='cuda:0', dtype=torch.float16)
tensor(0.1323, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.1699, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.5547, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(2.0586, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.7773, device='cuda:0', dtype=torch.float16) tensor(0.1350, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0154, device='cuda:0')
tensor(0.0523, device='cuda:0')
old_score: tensor(0.1345, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1001, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.177870512008667
Validation after dual ascent:
out_inf: tensor(13.5547, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(1.4307, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
tensor(1.4199, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.6875, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.7520, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0176, device='cuda:0')
tensor(0.0565, device='cuda:0')
old_score: tensor(0.1379, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.18147873878479
Validation after dual ascent:
out_inf: tensor(16.6875, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(1.4678, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(1.5254, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.5488, device='cuda:0', dtype=torch.float16) tensor(0.2539, device='cuda:0', dtype=torch.float16)
tensor(0.5815, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.5864, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(0.6177, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.5796, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.0594, device='cuda:0')
old_score: tensor(0.0724, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.451031446456909
Validation after dual ascent:
out_inf: tensor(3.5488, device='cuda:0', dtype=torch.float16) tensor(0.2539, device='cuda:0', dtype=torch.float16)
tensor(0.4717, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5122, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.5913, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.7383, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.3271, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.2988, device='cuda:0', dtype=torch.float16) tensor(0.0104, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0118, device='cuda:0')
tensor(0.0213, device='cuda:0')
old_score: tensor(0.0112, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0083, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.176081418991089
Validation after dual ascent:
out_inf: tensor(4.7383, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.2739, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2568, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.5664, device='cuda:0', dtype=torch.float16) tensor(0.2866, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
tensor(0.8887, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0034, device='cuda:0')
tensor(0.0291, device='cuda:0')
old_score: tensor(0.0659, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0688087940216064
Validation after dual ascent:
out_inf: tensor(4.5664, device='cuda:0', dtype=torch.float16) tensor(0.2866, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.9453, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0020, device='cuda:0')
tensor(0.0252, device='cuda:0')
old_score: tensor(0.0569, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0449, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.096728563308716
Validation after dual ascent:
out_inf: tensor(2.9453, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.2637, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
tensor(0.3193, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.2354, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0081, device='cuda:0')
tensor(0.0137, device='cuda:0')
old_score: tensor(0.0176, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0153, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.848097801208496
Validation after dual ascent:
out_inf: tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
tensor(0.1968, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.2188, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.1499, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.2454, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1371, device='cuda:0', dtype=torch.float16)
tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(2.0625, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0471, device='cuda:0')
old_score: tensor(0.1401, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1041, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.182408094406128
Validation after dual ascent:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(0.8301, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.4121, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.9858, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1436, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1406, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0405, device='cuda:0')
old_score: tensor(0.1415, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1043, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.184710741043091
Validation after dual ascent:
out_inf: tensor(16.8594, device='cuda:0', dtype=torch.float16) tensor(0.9858, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.3691, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8242, device='cuda:0', dtype=torch.float16) tensor(0.2639, device='cuda:0', dtype=torch.float16)
tensor(0.6079, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0114, device='cuda:0')
tensor(0.0677, device='cuda:0')
old_score: tensor(0.0765, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0599, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.449916124343872
Validation after dual ascent:
out_inf: tensor(4.8242, device='cuda:0', dtype=torch.float16) tensor(0.2639, device='cuda:0', dtype=torch.float16)
tensor(0.5405, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.5571, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(0.5249, device='cuda:0', dtype=torch.float16) tensor(0.0593, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.9082, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3516, device='cuda:0', dtype=torch.float16) tensor(0.0163, device='cuda:0', dtype=torch.float16)
tensor(0.4502, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0177, device='cuda:0')
tensor(0.0276, device='cuda:0')
old_score: tensor(0.0144, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0106, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.268665552139282
Validation after dual ascent:
out_inf: tensor(3.9082, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.2480, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.2529, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.3721, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.3286, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.0713, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0326, device='cuda:0')
old_score: tensor(0.0703, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0539, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0693981647491455
Validation after dual ascent:
out_inf: tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.3286, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.9473, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.8765, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0781, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0022, device='cuda:0')
tensor(0.0285, device='cuda:0')
old_score: tensor(0.0608, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0475, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.086968660354614
Validation after dual ascent:
out_inf: tensor(4.0781, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.3982, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.4980, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.5742, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.3818, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(0.3721, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.3320, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0075, device='cuda:0')
tensor(0.0157, device='cuda:0')
old_score: tensor(0.0206, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0175, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 17.056891918182373
Validation after dual ascent:
out_inf: tensor(2.5742, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(0.2693, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.2556, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.2434, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.2822, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(2.1719, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(2.1367, device='cuda:0', dtype=torch.float16) tensor(0.1367, device='cuda:0', dtype=torch.float16)
tensor(0.1500, device='cuda:0')
old_score: tensor(0.1379, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.811595439910889
Validation after dual ascent:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1029, device='cuda:0', dtype=torch.float16)
tensor(1.4795, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(1.4443, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(1.0127, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(1.5449, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
tensor(0.1496, device='cuda:0')
old_score: tensor(0.1395, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1039, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.885344743728638
Validation after dual ascent:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(1.0127, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.2188, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.3535, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(1.2490, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0766, device='cuda:0', dtype=torch.float16)
tensor(0.6304, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.5752, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(0.0670, device='cuda:0')
old_score: tensor(0.0782, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0608, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.894759893417358
Validation after dual ascent:
out_inf: tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
tensor(0.5278, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.5396, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.4180, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0150, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0187, device='cuda:0')
tensor(0.0217, device='cuda:0')
old_score: tensor(0.0168, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.868257761001587
Validation after dual ascent:
out_inf: tensor(4.4180, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.2305, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3018, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.2876, device='cuda:0', dtype=torch.float16) tensor(0.0128, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.7227, device='cuda:0', dtype=torch.float16) tensor(0.3235, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(1.2012, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0038, device='cuda:0')
tensor(0.0355, device='cuda:0')
old_score: tensor(0.0709, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0553, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1094582080841064
Validation after dual ascent:
out_inf: tensor(5.7227, device='cuda:0', dtype=torch.float16) tensor(0.3235, device='cuda:0', dtype=torch.float16)
tensor(0.7544, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
tensor(0.7803, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.5352, device='cuda:0', dtype=torch.float16) tensor(0.2090, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0025, device='cuda:0')
tensor(0.0324, device='cuda:0')
old_score: tensor(0.0638, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110907316207886
Validation after dual ascent:
out_inf: tensor(7.5352, device='cuda:0', dtype=torch.float16) tensor(0.2090, device='cuda:0', dtype=torch.float16)
tensor(0.4375, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.6543, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.3892, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.4526, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0177, device='cuda:0')
tensor(0.0236, device='cuda:0')
old_score: tensor(0.0225, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0193, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.26530909538269
Validation after dual ascent:
out_inf: tensor(2.6543, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.3135, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.2471, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.2656, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.2891, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.7920, device='cuda:0', dtype=torch.float16)
tensor(1.5918, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.7910, device='cuda:0', dtype=torch.float16) tensor(0.1460, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(0.2079, device='cuda:0')
old_score: tensor(0.1440, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.825654745101929
Validation after dual ascent:
out_inf: tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.7920, device='cuda:0', dtype=torch.float16)
tensor(1.2979, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1079, device='cuda:0', dtype=torch.float16)
tensor(1.1865, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4219, device='cuda:0', dtype=torch.float16) tensor(1.0342, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1431, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.1494, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.1517, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1459, device='cuda:0', dtype=torch.float16)
tensor(0.2171, device='cuda:0')
old_score: tensor(0.1476, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1116, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.887945175170898
Validation after dual ascent:
out_inf: tensor(19.4219, device='cuda:0', dtype=torch.float16) tensor(1.0342, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.2812, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.6904, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.0829, device='cuda:0')
old_score: tensor(0.0818, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0647, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.899475574493408
Validation after dual ascent:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.2812, device='cuda:0', dtype=torch.float16)
tensor(0.5459, device='cuda:0', dtype=torch.float16) tensor(0.0640, device='cuda:0', dtype=torch.float16)
tensor(0.5825, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
tensor(0.5825, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.8320, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.4180, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0196, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0196, device='cuda:0')
tensor(0.0400, device='cuda:0')
old_score: tensor(0.0185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0141, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.661064147949219
Validation after dual ascent:
out_inf: tensor(3.8320, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(0.3223, device='cuda:0', dtype=torch.float16) tensor(0.0130, device='cuda:0', dtype=torch.float16)
tensor(0.3926, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.2793, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.3389, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.4766, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(1.4326, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0403, device='cuda:0')
old_score: tensor(0.0728, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0578, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1039698123931885
Validation after dual ascent:
out_inf: tensor(6.4766, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
tensor(0.8916, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.2213, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0029, device='cuda:0')
tensor(0.0380, device='cuda:0')
old_score: tensor(0.0668, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0536, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.105939626693726
Validation after dual ascent:
out_inf: tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.2213, device='cuda:0', dtype=torch.float16)
tensor(0.4961, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
tensor(0.4736, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.3740, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.3564, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.3320, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0044, device='cuda:0')
tensor(0.0208, device='cuda:0')
old_score: tensor(0.0244, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0214, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.277849197387695
Validation after dual ascent:
out_inf: tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.2676, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.3462, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
tensor(0.2350, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.9844, device='cuda:0', dtype=torch.float16) tensor(0.7798, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.1495, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(0.1227, device='cuda:0')
old_score: tensor(0.1455, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.817654848098755
Validation after dual ascent:
out_inf: tensor(13.9844, device='cuda:0', dtype=torch.float16) tensor(0.7798, device='cuda:0', dtype=torch.float16)
tensor(1.3135, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
tensor(1.2256, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(1.0469, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1534, device='cuda:0', dtype=torch.float16)
tensor(1.7461, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
tensor(0.1277, device='cuda:0')
old_score: tensor(0.1498, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1151, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.882988691329956
Validation after dual ascent:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(1.0469, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.4307, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1183, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.1875, device='cuda:0', dtype=torch.float16) tensor(0.2869, device='cuda:0', dtype=torch.float16)
tensor(0.6401, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(0.6724, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0192, device='cuda:0')
tensor(0.0843, device='cuda:0')
old_score: tensor(0.0826, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0663, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.199204206466675
Validation after dual ascent:
out_inf: tensor(7.1875, device='cuda:0', dtype=torch.float16) tensor(0.2869, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.5283, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(0.6538, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.0039, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.4316, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(0.4404, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0076, device='cuda:0')
tensor(0.0309, device='cuda:0')
old_score: tensor(0.0238, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0175, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7279934883117676
Validation after dual ascent:
out_inf: tensor(5.0039, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.3311, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.4023, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.3599, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.7812, device='cuda:0', dtype=torch.float16) tensor(0.3398, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.2129, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(1.3311, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0040, device='cuda:0')
tensor(0.0430, device='cuda:0')
old_score: tensor(0.0741, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0592, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.100759029388428
Validation after dual ascent:
out_inf: tensor(6.7812, device='cuda:0', dtype=torch.float16) tensor(0.3398, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.9248, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.1045, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.6621, device='cuda:0', dtype=torch.float16) tensor(0.2379, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.5591, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0031, device='cuda:0')
tensor(0.0408, device='cuda:0')
old_score: tensor(0.0692, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0558, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.104671001434326
Validation after dual ascent:
out_inf: tensor(3.6621, device='cuda:0', dtype=torch.float16) tensor(0.2379, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.5293, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.0586, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.4858, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0044, device='cuda:0')
tensor(0.0240, device='cuda:0')
old_score: tensor(0.0269, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0234, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.261321067810059
Validation after dual ascent:
out_inf: tensor(3.0586, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.3364, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.2451, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.2964, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
tensor(0.3691, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(0.7793, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
tensor(2.4961, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
tensor(0.1669, device='cuda:0')
old_score: tensor(0.1511, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1180, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.81071138381958
Validation after dual ascent:
out_inf: tensor(19.9219, device='cuda:0', dtype=torch.float16) tensor(0.7793, device='cuda:0', dtype=torch.float16)
tensor(1.7305, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(1.9082, device='cuda:0', dtype=torch.float16) tensor(0.1159, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
tensor(1.9121, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.9297, device='cuda:0', dtype=torch.float16) tensor(1.0166, device='cuda:0', dtype=torch.float16)
tensor(1.7930, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.9033, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
tensor(1.8027, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(0.1729, device='cuda:0')
old_score: tensor(0.1520, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1174, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.89071273803711
Validation after dual ascent:
out_inf: tensor(15.9297, device='cuda:0', dtype=torch.float16) tensor(1.0166, device='cuda:0', dtype=torch.float16)
tensor(1.5068, device='cuda:0', dtype=torch.float16) tensor(0.1168, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(1.3818, device='cuda:0', dtype=torch.float16) tensor(0.1167, device='cuda:0', dtype=torch.float16)
tensor(1.5605, device='cuda:0', dtype=torch.float16) tensor(0.1212, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.3438, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.7490, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(0.7778, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(0.7534, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0174, device='cuda:0')
tensor(0.0799, device='cuda:0')
old_score: tensor(0.0961, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0775, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.713348150253296
Validation after dual ascent:
out_inf: tensor(8.3438, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.6514, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.6450, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(0.5757, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0063, device='cuda:0')
tensor(0.0361, device='cuda:0')
old_score: tensor(0.0269, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0192, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7319762706756592
Validation after dual ascent:
out_inf: tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.4297, device='cuda:0', dtype=torch.float16) tensor(0.3511, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(1.5801, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
tensor(1.5723, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0044, device='cuda:0')
tensor(0.0475, device='cuda:0')
old_score: tensor(0.0771, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0616, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.104422092437744
Validation after dual ascent:
out_inf: tensor(6.4297, device='cuda:0', dtype=torch.float16) tensor(0.3511, device='cuda:0', dtype=torch.float16)
tensor(1.1768, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(1.1123, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.9717, device='cuda:0', dtype=torch.float16) tensor(0.0615, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.8691, device='cuda:0', dtype=torch.float16) tensor(0.2423, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.6045, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.6084, device='cuda:0', dtype=torch.float16) tensor(0.0727, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0034, device='cuda:0')
tensor(0.0455, device='cuda:0')
old_score: tensor(0.0726, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0587, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.106023550033569
Validation after dual ascent:
out_inf: tensor(3.8691, device='cuda:0', dtype=torch.float16) tensor(0.2423, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.4917, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.2148, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.4634, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.4956, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0022, device='cuda:0')
tensor(0.0265, device='cuda:0')
old_score: tensor(0.0286, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.258111000061035
Validation after dual ascent:
out_inf: tensor(3.2148, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.3101, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.4094, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.4375, device='cuda:0', dtype=torch.float16) tensor(0.7842, device='cuda:0', dtype=torch.float16)
tensor(2.1055, device='cuda:0', dtype=torch.float16) tensor(0.1538, device='cuda:0', dtype=torch.float16)
tensor(2.0273, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.1617, device='cuda:0', dtype=torch.float16)
tensor(1.8086, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.2244, device='cuda:0')
old_score: tensor(0.1570, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4524896144866943
Validation after dual ascent:
out_inf: tensor(17.4375, device='cuda:0', dtype=torch.float16) tensor(0.7842, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1225, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.6562, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
tensor(1.7090, device='cuda:0', dtype=torch.float16) tensor(0.1626, device='cuda:0', dtype=torch.float16)
tensor(2.2461, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.1606, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0171, device='cuda:0')
tensor(0.2298, device='cuda:0')
old_score: tensor(0.1624, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1265, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.452277421951294
Validation after dual ascent:
out_inf: tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1241, device='cuda:0', dtype=torch.float16)
tensor(1.3926, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(1.3730, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.2266, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(0.7466, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(0.7783, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0084, device='cuda:0')
tensor(0.1414, device='cuda:0')
old_score: tensor(0.0950, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0771, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.447044849395752
Validation after dual ascent:
out_inf: tensor(6.2266, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(0.6255, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(0.6343, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.1680, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.5840, device='cuda:0', dtype=torch.float16) tensor(0.0262, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0063, device='cuda:0')
tensor(0.0139, device='cuda:0')
old_score: tensor(0.0282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0203, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.9002695083618164
Validation after dual ascent:
out_inf: tensor(5.1680, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.4116, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.8086, device='cuda:0', dtype=torch.float16) tensor(0.3567, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.0791, device='cuda:0', dtype=torch.float16)
tensor(1.3418, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0045, device='cuda:0')
tensor(0.0528, device='cuda:0')
old_score: tensor(0.0795, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0636, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.062699556350708
Validation after dual ascent:
out_inf: tensor(6.8086, device='cuda:0', dtype=torch.float16) tensor(0.3567, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9727, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0037, device='cuda:0')
tensor(0.0517, device='cuda:0')
old_score: tensor(0.0760, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0615, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.064148426055908
Validation after dual ascent:
out_inf: tensor(4.9727, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.4995, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.4951, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
tensor(0.5088, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
tensor(0.5186, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0020, device='cuda:0')
tensor(0.0310, device='cuda:0')
old_score: tensor(0.0305, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0266, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.212394714355469
Validation after dual ascent:
out_inf: tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.2781, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.3276, device='cuda:0', dtype=torch.float16) tensor(0.0258, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.5859, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1561, device='cuda:0', dtype=torch.float16)
tensor(2.1211, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1632, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0161, device='cuda:0')
tensor(0.2444, device='cuda:0')
old_score: tensor(0.1593, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1259, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4534711837768555
Validation after dual ascent:
out_inf: tensor(13.5859, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
tensor(1.4854, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(1.6074, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9990, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1624, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1611, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.2466, device='cuda:0')
old_score: tensor(0.1622, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1272, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4560697078704834
Validation after dual ascent:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9990, device='cuda:0', dtype=torch.float16)
tensor(1.3721, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
tensor(1.5352, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.5342, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.1797, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.7852, device='cuda:0', dtype=torch.float16) tensor(0.1020, device='cuda:0', dtype=torch.float16)
tensor(0.7905, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0088, device='cuda:0')
tensor(0.1586, device='cuda:0')
old_score: tensor(0.1002, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0818, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.451559543609619
Validation after dual ascent:
out_inf: tensor(5.1797, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0801, device='cuda:0', dtype=torch.float16)
tensor(0.6597, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(0.6724, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0173, device='cuda:0')
tensor(0.0305, device='cuda:0')
old_score: tensor(0.0295, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0212, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.8985230922698975
Validation after dual ascent:
out_inf: tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.4619, device='cuda:0', dtype=torch.float16) tensor(0.0214, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.0078, device='cuda:0', dtype=torch.float16) tensor(0.3726, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(1.3789, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0049, device='cuda:0')
tensor(0.0586, device='cuda:0')
old_score: tensor(0.0822, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0652, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.062631368637085
Validation after dual ascent:
out_inf: tensor(7.0078, device='cuda:0', dtype=torch.float16) tensor(0.3726, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.7461, device='cuda:0', dtype=torch.float16) tensor(0.2693, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(0.7363, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.0584, device='cuda:0')
old_score: tensor(0.0797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0640, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.068630218505859
Validation after dual ascent:
out_inf: tensor(4.7461, device='cuda:0', dtype=torch.float16) tensor(0.2693, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0634, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.1172, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.6187, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.4824, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.5869, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0024, device='cuda:0')
tensor(0.0387, device='cuda:0')
old_score: tensor(0.0342, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0297, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.233387231826782
Validation after dual ascent:
out_inf: tensor(5.1172, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.3804, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.3701, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.6953, device='cuda:0', dtype=torch.float16) tensor(0.7998, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(1.9258, device='cuda:0', dtype=torch.float16) tensor(0.1633, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1692, device='cuda:0', dtype=torch.float16)
tensor(2.2402, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0076, device='cuda:0')
tensor(0.0607, device='cuda:0')
old_score: tensor(0.1641, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1277, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1798574924468994
Validation after dual ascent:
out_inf: tensor(13.6953, device='cuda:0', dtype=torch.float16) tensor(0.7998, device='cuda:0', dtype=torch.float16)
tensor(1.7246, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(1.4824, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
tensor(1.4971, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.4375, device='cuda:0', dtype=torch.float16) tensor(1.0713, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
tensor(1.7559, device='cuda:0', dtype=torch.float16) tensor(0.1681, device='cuda:0', dtype=torch.float16)
tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.1730, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.1669, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0093, device='cuda:0')
tensor(0.0557, device='cuda:0')
old_score: tensor(0.1682, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1290, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.185166120529175
Validation after dual ascent:
out_inf: tensor(19.4375, device='cuda:0', dtype=torch.float16) tensor(1.0713, device='cuda:0', dtype=torch.float16)
tensor(1.4189, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1343, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.3240, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0996, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(0.8037, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0130, device='cuda:0')
tensor(0.1722, device='cuda:0')
old_score: tensor(0.1010, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0816, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4518914222717285
Validation after dual ascent:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.3240, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.7231, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0851, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.2852, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0088, device='cuda:0')
tensor(0.0547, device='cuda:0')
old_score: tensor(0.0328, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7188382148742676
Validation after dual ascent:
out_inf: tensor(7.2852, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(0.3711, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.3926, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.3721, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1914, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(1.6309, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.0685, device='cuda:0')
old_score: tensor(0.0857, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0687, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0597991943359375
Validation after dual ascent:
out_inf: tensor(7.1914, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(1.2012, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(1.0752, device='cuda:0', dtype=torch.float16) tensor(0.0686, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4336, device='cuda:0', dtype=torch.float16) tensor(0.2827, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(0.7910, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0048, device='cuda:0')
tensor(0.0680, device='cuda:0')
old_score: tensor(0.0832, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0674, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.06580662727356
Validation after dual ascent:
out_inf: tensor(4.4336, device='cuda:0', dtype=torch.float16) tensor(0.2827, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.6099, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.8926, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.5664, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.4258, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(0.5322, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0028, device='cuda:0')
tensor(0.0457, device='cuda:0')
old_score: tensor(0.0368, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0322, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.21329379081726
Validation after dual ascent:
out_inf: tensor(2.8926, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.3438, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.4373, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.2188, device='cuda:0', dtype=torch.float16) tensor(0.7871, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1538, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1562, device='cuda:0', dtype=torch.float16)
tensor(1.8945, device='cuda:0', dtype=torch.float16) tensor(0.1611, device='cuda:0', dtype=torch.float16)
tensor(1.8350, device='cuda:0', dtype=torch.float16) tensor(0.1576, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0145, device='cuda:0')
tensor(0.2424, device='cuda:0')
old_score: tensor(0.1572, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.451101541519165
Validation after dual ascent:
out_inf: tensor(15.2188, device='cuda:0', dtype=torch.float16) tensor(0.7871, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.2744, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6797, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1641, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1681, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.2491, device='cuda:0')
old_score: tensor(0.1646, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1274, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4552533626556396
Validation after dual ascent:
out_inf: tensor(15.6797, device='cuda:0', dtype=torch.float16) tensor(1.0361, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.3506, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.3359, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.1029, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0089, device='cuda:0')
tensor(0.1645, device='cuda:0')
old_score: tensor(0.1023, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0833, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4487438201904297
Validation after dual ascent:
out_inf: tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.3359, device='cuda:0', dtype=torch.float16)
tensor(0.6509, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.6382, device='cuda:0', dtype=torch.float16) tensor(0.0806, device='cuda:0', dtype=torch.float16)
tensor(0.6313, device='cuda:0', dtype=torch.float16) tensor(0.0827, device='cuda:0', dtype=torch.float16)
tensor(0.6392, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.4336, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.5386, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0043, device='cuda:0')
tensor(0.0583, device='cuda:0')
old_score: tensor(0.0331, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0242, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7205770015716553
Validation after dual ascent:
out_inf: tensor(5.4336, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
tensor(0.4229, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
tensor(0.3848, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.4863, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.1641, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(1.7070, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0902, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.0768, device='cuda:0')
old_score: tensor(0.0895, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0707, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.064817905426025
Validation after dual ascent:
out_inf: tensor(9.1641, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(1.0361, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(1.0723, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9805, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(0.8076, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(0.8867, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0054, device='cuda:0')
tensor(0.0765, device='cuda:0')
old_score: tensor(0.0868, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0696, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.068202018737793
Validation after dual ascent:
out_inf: tensor(4.9805, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.5312, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
tensor(0.5518, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0383, device='cuda:0', dtype=torch.float16)
tensor(0.5752, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0035, device='cuda:0')
tensor(0.0562, device='cuda:0')
old_score: tensor(0.0405, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0352, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.185045957565308
Validation after dual ascent:
out_inf: tensor(6.5312, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
tensor(0.4224, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.3394, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.3513, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.4390, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2812, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.1582, device='cuda:0', dtype=torch.float16)
tensor(2.3828, device='cuda:0', dtype=torch.float16) tensor(0.1586, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.1638, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1603, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0157, device='cuda:0')
tensor(0.2654, device='cuda:0')
old_score: tensor(0.1603, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4514496326446533
Validation after dual ascent:
out_inf: tensor(17.2812, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(1.8564, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(1.6758, device='cuda:0', dtype=torch.float16) tensor(0.1195, device='cuda:0', dtype=torch.float16)
tensor(1.5020, device='cuda:0', dtype=torch.float16) tensor(0.1231, device='cuda:0', dtype=torch.float16)
tensor(1.6494, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.6094, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(2.0586, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1698, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.2708, device='cuda:0')
old_score: tensor(0.1661, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1266, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.453660011291504
Validation after dual ascent:
out_inf: tensor(16.6094, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(1.4570, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.3857, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5., device='cuda:0', dtype=torch.float16) tensor(0.3425, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0099, device='cuda:0')
tensor(0.1862, device='cuda:0')
old_score: tensor(0.1093, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0879, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4500532150268555
Validation after dual ascent:
out_inf: tensor(5., device='cuda:0', dtype=torch.float16) tensor(0.3425, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(0.7642, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(0.6860, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.6016, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(0.8013, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0056, device='cuda:0')
tensor(0.0790, device='cuda:0')
old_score: tensor(0.0395, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0287, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7201292514801025
Validation after dual ascent:
out_inf: tensor(5.6016, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(0.6538, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.1172, device='cuda:0', dtype=torch.float16) tensor(0.4260, device='cuda:0', dtype=torch.float16)
tensor(1.4746, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.4580, device='cuda:0', dtype=torch.float16) tensor(0.0992, device='cuda:0', dtype=torch.float16)
tensor(1.4785, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0074, device='cuda:0')
tensor(0.0953, device='cuda:0')
old_score: tensor(0.0973, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0746, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.065798282623291
Validation after dual ascent:
out_inf: tensor(8.1172, device='cuda:0', dtype=torch.float16) tensor(0.4260, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0740, device='cuda:0', dtype=torch.float16)
tensor(1.3799, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.4258, device='cuda:0', dtype=torch.float16) tensor(0.3174, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.1836, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0067, device='cuda:0')
tensor(0.0934, device='cuda:0')
old_score: tensor(0.0934, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0728, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.071480751037598
Validation after dual ascent:
out_inf: tensor(5.4258, device='cuda:0', dtype=torch.float16) tensor(0.3174, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.0469, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(0.4897, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.5146, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.5332, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0047, device='cuda:0')
tensor(0.0745, device='cuda:0')
old_score: tensor(0.0460, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0397, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.194000720977783
Validation after dual ascent:
out_inf: tensor(6.0469, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.4463, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.8750, device='cuda:0', dtype=torch.float16) tensor(0.7983, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1636, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1630, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1686, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1652, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0100, device='cuda:0')
tensor(0.0637, device='cuda:0')
old_score: tensor(0.1650, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1778602600097656
Validation after dual ascent:
out_inf: tensor(16.8750, device='cuda:0', dtype=torch.float16) tensor(0.7983, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.4014, device='cuda:0', dtype=torch.float16) tensor(0.1174, device='cuda:0', dtype=torch.float16)
tensor(1.2236, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.3604, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.3125, device='cuda:0', dtype=torch.float16) tensor(1.0176, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.1682, device='cuda:0', dtype=torch.float16)
tensor(2.3438, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0117, device='cuda:0')
tensor(0.0631, device='cuda:0')
old_score: tensor(0.1697, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1259, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1808629035949707
Validation after dual ascent:
out_inf: tensor(17.3125, device='cuda:0', dtype=torch.float16) tensor(1.0176, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.3528, device='cuda:0', dtype=torch.float16)
tensor(0.8247, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.1110, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0183, device='cuda:0')
tensor(0.1985, device='cuda:0')
old_score: tensor(0.1121, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0878, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4500675201416016
Validation after dual ascent:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.3528, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
tensor(0.7437, device='cuda:0', dtype=torch.float16) tensor(0.0832, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(0.7466, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.0195, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.5073, device='cuda:0', dtype=torch.float16) tensor(0.0310, device='cuda:0', dtype=torch.float16)
tensor(0.7080, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(0.7290, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0106, device='cuda:0')
tensor(0.0558, device='cuda:0')
old_score: tensor(0.0318, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0234, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7158913612365723
Validation after dual ascent:
out_inf: tensor(6.0195, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.8164, device='cuda:0', dtype=torch.float16) tensor(0.4419, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1011, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0085, device='cuda:0')
tensor(0.1163, device='cuda:0')
old_score: tensor(0.1031, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0794, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.059464693069458
Validation after dual ascent:
out_inf: tensor(7.8164, device='cuda:0', dtype=torch.float16) tensor(0.4419, device='cuda:0', dtype=torch.float16)
tensor(1.1973, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.3176, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(0.8115, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0077, device='cuda:0')
tensor(0.1116, device='cuda:0')
old_score: tensor(0.0973, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0763, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.063279628753662
Validation after dual ascent:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.3176, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.6079, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.6118, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.9492, device='cuda:0', dtype=torch.float16) tensor(0.1515, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(0.5400, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.4673, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.6167, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0049, device='cuda:0')
tensor(0.0788, device='cuda:0')
old_score: tensor(0.0465, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0403, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.196819543838501
Validation after dual ascent:
out_inf: tensor(4.9492, device='cuda:0', dtype=torch.float16) tensor(0.1515, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.4148, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.4048, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.5303, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.9766, device='cuda:0', dtype=torch.float16) tensor(0.8169, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1682, device='cuda:0', dtype=torch.float16)
tensor(1.8984, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1699, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0121, device='cuda:0')
tensor(0.0768, device='cuda:0')
old_score: tensor(0.1694, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1279, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1793951988220215
Validation after dual ascent:
out_inf: tensor(13.9766, device='cuda:0', dtype=torch.float16) tensor(0.8169, device='cuda:0', dtype=torch.float16)
tensor(1.2246, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(1.2227, device='cuda:0', dtype=torch.float16) tensor(0.1199, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.5723, device='cuda:0', dtype=torch.float16) tensor(0.1365, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.6250, device='cuda:0', dtype=torch.float16) tensor(0.9839, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(2.2422, device='cuda:0', dtype=torch.float16) tensor(0.1711, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0776, device='cuda:0')
old_score: tensor(0.1742, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1296, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.181518316268921
Validation after dual ascent:
out_inf: tensor(17.6250, device='cuda:0', dtype=torch.float16) tensor(0.9839, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
tensor(1.2803, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.4014, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.3716, device='cuda:0', dtype=torch.float16)
tensor(0.8779, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(0.9487, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(0.9160, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0065, device='cuda:0')
tensor(0.0696, device='cuda:0')
old_score: tensor(0.1224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0966, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.177625894546509
Validation after dual ascent:
out_inf: tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.3716, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0973, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(0.7607, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(0.8740, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.3164, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.9346, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0140, device='cuda:0')
tensor(0.0259, device='cuda:0')
old_score: tensor(0.0305, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0220, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.8964738845825195
Validation after dual ascent:
out_inf: tensor(4.3164, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.8584, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.7520, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.9688, device='cuda:0', dtype=torch.float16) tensor(0.4546, device='cuda:0', dtype=torch.float16)
tensor(1.7285, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1112, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0102, device='cuda:0')
tensor(0.1435, device='cuda:0')
old_score: tensor(0.1091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0831, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.06534218788147
Validation after dual ascent:
out_inf: tensor(8.9688, device='cuda:0', dtype=torch.float16) tensor(0.4546, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.1367, device='cuda:0', dtype=torch.float16) tensor(0.3230, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.1015, device='cuda:0', dtype=torch.float16)
tensor(0.8418, device='cuda:0', dtype=torch.float16) tensor(0.0995, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.1034, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0093, device='cuda:0')
tensor(0.1358, device='cuda:0')
old_score: tensor(0.1016, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0790, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.070030689239502
Validation after dual ascent:
out_inf: tensor(6.1367, device='cuda:0', dtype=torch.float16) tensor(0.3230, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(0.6226, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(0.7485, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.8633, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.5127, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0059, device='cuda:0')
tensor(0.0919, device='cuda:0')
old_score: tensor(0.0492, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0429, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.224023580551147
Validation after dual ascent:
out_inf: tensor(5.8633, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(0.4561, device='cuda:0', dtype=torch.float16) tensor(0.0448, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.4448, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.0938, device='cuda:0', dtype=torch.float16) tensor(0.7803, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(1.6602, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1688, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.3225, device='cuda:0')
old_score: tensor(0.1646, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.452176809310913
Validation after dual ascent:
out_inf: tensor(13.0938, device='cuda:0', dtype=torch.float16) tensor(0.7803, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1244, device='cuda:0', dtype=torch.float16)
tensor(1.4043, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(1.3105, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.5781, device='cuda:0', dtype=torch.float16) tensor(1.0088, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(2.3672, device='cuda:0', dtype=torch.float16) tensor(0.1733, device='cuda:0', dtype=torch.float16)
tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0191, device='cuda:0')
tensor(0.3278, device='cuda:0')
old_score: tensor(0.1685, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1246, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.455099105834961
Validation after dual ascent:
out_inf: tensor(19.5781, device='cuda:0', dtype=torch.float16) tensor(1.0088, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.2822, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.3457, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1335, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.1758, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(0.9390, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0129, device='cuda:0')
tensor(0.2467, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0956, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4513602256774902
Validation after dual ascent:
out_inf: tensor(4.1758, device='cuda:0', dtype=torch.float16) tensor(0.3828, device='cuda:0', dtype=torch.float16)
tensor(0.9136, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.7817, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(0.7905, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(0.9897, device='cuda:0', dtype=torch.float16) tensor(0.1024, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.9961, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0088, device='cuda:0')
tensor(0.0547, device='cuda:0')
old_score: tensor(0.0312, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0233, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.716291904449463
Validation after dual ascent:
out_inf: tensor(5.9961, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0222, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.8740, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.0938, device='cuda:0', dtype=torch.float16) tensor(0.4470, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1103, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.6143, device='cuda:0', dtype=torch.float16) tensor(0.1126, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0113, device='cuda:0')
tensor(0.1634, device='cuda:0')
old_score: tensor(0.1124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0859, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.058020114898682
Validation after dual ascent:
out_inf: tensor(8.0938, device='cuda:0', dtype=torch.float16) tensor(0.4470, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(1.1064, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.8828, device='cuda:0', dtype=torch.float16) tensor(0.3315, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.1051, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0103, device='cuda:0')
tensor(0.1537, device='cuda:0')
old_score: tensor(0.1046, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0813, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.065033435821533
Validation after dual ascent:
out_inf: tensor(7.8828, device='cuda:0', dtype=torch.float16) tensor(0.3315, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.6602, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(0.5928, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.5737, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0063, device='cuda:0')
tensor(0.0990, device='cuda:0')
old_score: tensor(0.0510, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0444, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.162957906723022
Validation after dual ascent:
out_inf: tensor(5.6602, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.3931, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.4609, device='cuda:0', dtype=torch.float16) tensor(0.8032, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.1709, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1661, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0080, device='cuda:0')
tensor(0.0639, device='cuda:0')
old_score: tensor(0.1666, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.17989182472229
Validation after dual ascent:
out_inf: tensor(15.4609, device='cuda:0', dtype=torch.float16) tensor(0.8032, device='cuda:0', dtype=torch.float16)
tensor(1.2949, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1233, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.5625, device='cuda:0', dtype=torch.float16) tensor(1.0146, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1697, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1744, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0616, device='cuda:0')
old_score: tensor(0.1705, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1252, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.185655117034912
Validation after dual ascent:
out_inf: tensor(17.5625, device='cuda:0', dtype=torch.float16) tensor(1.0146, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.1332, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.3740, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
tensor(0.9131, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(0.9326, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(0.9756, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2548, device='cuda:0')
old_score: tensor(0.1252, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0973, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4511024951934814
Validation after dual ascent:
out_inf: tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.3740, device='cuda:0', dtype=torch.float16)
tensor(0.8882, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(0.8574, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.7031, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(0.7891, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0052, device='cuda:0')
tensor(0.0745, device='cuda:0')
old_score: tensor(0.0390, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0284, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7201974391937256
Validation after dual ascent:
out_inf: tensor(11.7031, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
tensor(0.7075, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.0312, device='cuda:0', dtype=torch.float16) tensor(0.4629, device='cuda:0', dtype=torch.float16)
tensor(1.9727, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1137, device='cuda:0', dtype=torch.float16)
tensor(1.6338, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.1161, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0123, device='cuda:0')
tensor(0.1765, device='cuda:0')
old_score: tensor(0.1162, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0869, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.06178092956543
Validation after dual ascent:
out_inf: tensor(11.0312, device='cuda:0', dtype=torch.float16) tensor(0.4629, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0923, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.3406, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0111, device='cuda:0')
tensor(0.1647, device='cuda:0')
old_score: tensor(0.1071, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0815, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.065024137496948
Validation after dual ascent:
out_inf: tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.3406, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0827, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(0.7612, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.down_proj
Validation after prune:
out_inf: tensor(7.1250, device='cuda:0', dtype=torch.float16) tensor(0.1860, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0566, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0073, device='cuda:0')
tensor(0.1132, device='cuda:0')
old_score: tensor(0.0536, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0464, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.13139533996582
Validation after dual ascent:
out_inf: tensor(7.1250, device='cuda:0', dtype=torch.float16) tensor(0.1860, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(0.7832, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.1670, device='cuda:0', dtype=torch.float16)
tensor(1.6855, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(1.7617, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1666, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0065, device='cuda:0')
tensor(0.0659, device='cuda:0')
old_score: tensor(0.1678, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.177990674972534
Validation after dual ascent:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(0.7832, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(1.3770, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
tensor(1.4717, device='cuda:0', dtype=torch.float16) tensor(0.1310, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9722, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1659, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1748, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0080, device='cuda:0')
tensor(0.0642, device='cuda:0')
old_score: tensor(0.1692, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1825082302093506
Validation after dual ascent:
out_inf: tensor(18.3906, device='cuda:0', dtype=torch.float16) tensor(0.9722, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.3916, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.4922, device='cuda:0', dtype=torch.float16) tensor(0.3914, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0150, device='cuda:0')
tensor(0.2955, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1029, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.451605796813965
Validation after dual ascent:
out_inf: tensor(5.4922, device='cuda:0', dtype=torch.float16) tensor(0.3914, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(0.9111, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(0.9189, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.0303, device='cuda:0', dtype=torch.float16) tensor(0.1091, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.o_proj
Validation after prune:
out_inf: tensor(9.7578, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.7002, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.7012, device='cuda:0', dtype=torch.float16) tensor(0.0310, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0096, device='cuda:0')
tensor(0.0650, device='cuda:0')
old_score: tensor(0.0332, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0249, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.715890884399414
Validation after dual ascent:
out_inf: tensor(9.7578, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.7295, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.6704, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.4297, device='cuda:0', dtype=torch.float16) tensor(0.4578, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(1.7334, device='cuda:0', dtype=torch.float16) tensor(0.1155, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.4736, device='cuda:0', dtype=torch.float16) tensor(0.1184, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0134, device='cuda:0')
tensor(0.1970, device='cuda:0')
old_score: tensor(0.1185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0896, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.062631845474243
Validation after dual ascent:
out_inf: tensor(9.4297, device='cuda:0', dtype=torch.float16) tensor(0.4578, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(1.7480, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.0907, device='cuda:0', dtype=torch.float16)
tensor(1.6904, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.8906, device='cuda:0', dtype=torch.float16) tensor(0.3374, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(0.9414, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0120, device='cuda:0')
tensor(0.1819, device='cuda:0')
old_score: tensor(0.1085, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0833, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0732128620147705
Validation after dual ascent:
out_inf: tensor(6.8906, device='cuda:0', dtype=torch.float16) tensor(0.3374, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.7358, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.8037, device='cuda:0', dtype=torch.float16) tensor(0.0843, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.3633, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0070, device='cuda:0')
tensor(0.1100, device='cuda:0')
old_score: tensor(0.0522, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0457, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.194483757019043
Validation after dual ascent:
out_inf: tensor(4.3633, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
tensor(0.4219, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.4836, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
tensor(0.6475, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.5312, device='cuda:0', dtype=torch.float16) tensor(0.8374, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1698, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1724, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0115, device='cuda:0')
tensor(0.0814, device='cuda:0')
old_score: tensor(0.1738, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1284, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.176302433013916
Validation after dual ascent:
out_inf: tensor(18.5312, device='cuda:0', dtype=torch.float16) tensor(0.8374, device='cuda:0', dtype=torch.float16)
tensor(1.3115, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.0156, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1750, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1719, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.1831, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.1753, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0134, device='cuda:0')
tensor(0.0832, device='cuda:0')
old_score: tensor(0.1764, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1292, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.181643486022949
Validation after dual ascent:
out_inf: tensor(20.0156, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(1.2900, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.4219, device='cuda:0', dtype=torch.float16) tensor(0.4133, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
tensor(1.1826, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0062, device='cuda:0')
tensor(0.0771, device='cuda:0')
old_score: tensor(0.1361, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1045, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1770801544189453
Validation after dual ascent:
out_inf: tensor(7.4219, device='cuda:0', dtype=torch.float16) tensor(0.4133, device='cuda:0', dtype=torch.float16)
tensor(0.9297, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(0.8872, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(0.9312, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(0.9756, device='cuda:0', dtype=torch.float16) tensor(0.1103, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.7500, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.5527, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0071, device='cuda:0')
tensor(0.0109, device='cuda:0')
old_score: tensor(0.0323, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.445270299911499
Validation after dual ascent:
out_inf: tensor(11.7500, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.7500, device='cuda:0', dtype=torch.float16) tensor(0.4585, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1209, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1180, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1239, device='cuda:0', dtype=torch.float16)
tensor(1.9824, device='cuda:0', dtype=torch.float16) tensor(0.1206, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0139, device='cuda:0')
tensor(0.2056, device='cuda:0')
old_score: tensor(0.1208, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0903, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.064589500427246
Validation after dual ascent:
out_inf: tensor(10.7500, device='cuda:0', dtype=torch.float16) tensor(0.4585, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0832, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(1.3311, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.2891, device='cuda:0', dtype=torch.float16) tensor(0.3438, device='cuda:0', dtype=torch.float16)
tensor(0.9277, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0125, device='cuda:0')
tensor(0.1884, device='cuda:0')
old_score: tensor(0.1099, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0835, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0905797481536865
Validation after dual ascent:
out_inf: tensor(6.2891, device='cuda:0', dtype=torch.float16) tensor(0.3438, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0769, device='cuda:0', dtype=torch.float16)
tensor(0.7476, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.1942, device='cuda:0', dtype=torch.float16)
tensor(0.6069, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0079, device='cuda:0')
tensor(0.1232, device='cuda:0')
old_score: tensor(0.0548, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0477, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.215459108352661
Validation after dual ascent:
out_inf: tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.1942, device='cuda:0', dtype=torch.float16)
tensor(0.6128, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.5737, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.4888, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.6084, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1777, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1735, device='cuda:0', dtype=torch.float16)
tensor(1.9766, device='cuda:0', dtype=torch.float16) tensor(0.1835, device='cuda:0', dtype=torch.float16)
tensor(1.9180, device='cuda:0', dtype=torch.float16) tensor(0.1758, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0074, device='cuda:0')
tensor(0.0787, device='cuda:0')
old_score: tensor(0.1776, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1321, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1822774410247803
Validation after dual ascent:
out_inf: tensor(15.4062, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(1.4434, device='cuda:0', dtype=torch.float16) tensor(0.1334, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.3428, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.5410, device='cuda:0', dtype=torch.float16) tensor(0.1378, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.8438, device='cuda:0', dtype=torch.float16) tensor(0.9473, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1794, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1855, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1780, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0783, device='cuda:0')
old_score: tensor(0.1797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1326, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1852948665618896
Validation after dual ascent:
out_inf: tensor(18.8438, device='cuda:0', dtype=torch.float16) tensor(0.9473, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
tensor(1.6689, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.7148, device='cuda:0', dtype=torch.float16) tensor(0.4414, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(1.3799, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.1650, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0173, device='cuda:0')
tensor(0.3587, device='cuda:0')
old_score: tensor(0.1475, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4540185928344727
Validation after dual ascent:
out_inf: tensor(5.7148, device='cuda:0', dtype=torch.float16) tensor(0.4414, device='cuda:0', dtype=torch.float16)
tensor(1.0674, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(0.9663, device='cuda:0', dtype=torch.float16) tensor(0.1160, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.o_proj
Validation after prune:
out_inf: tensor(17.4688, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.8989, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0183, device='cuda:0')
tensor(0.0639, device='cuda:0')
old_score: tensor(0.0309, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0233, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7172842025756836
Validation after dual ascent:
out_inf: tensor(17.4688, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(0.6885, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(0.4976, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.2344, device='cuda:0', dtype=torch.float16) tensor(0.4558, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1228, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1199, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0148, device='cuda:0')
tensor(0.2238, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0923, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0763468742370605
Validation after dual ascent:
out_inf: tensor(10.2344, device='cuda:0', dtype=torch.float16) tensor(0.4558, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0848, device='cuda:0', dtype=torch.float16)
tensor(1.2432, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.4570, device='cuda:0', dtype=torch.float16) tensor(0.0960, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.1172, device='cuda:0', dtype=torch.float16) tensor(0.3433, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0134, device='cuda:0')
tensor(0.2061, device='cuda:0')
old_score: tensor(0.1122, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0856, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.099313735961914
Validation after dual ascent:
out_inf: tensor(7.1172, device='cuda:0', dtype=torch.float16) tensor(0.3433, device='cuda:0', dtype=torch.float16)
tensor(0.8159, device='cuda:0', dtype=torch.float16) tensor(0.0866, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(0.7954, device='cuda:0', dtype=torch.float16) tensor(0.0882, device='cuda:0', dtype=torch.float16)
tensor(0.8472, device='cuda:0', dtype=torch.float16) tensor(0.0890, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.8379, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(0.6709, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.5811, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.5981, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0081, device='cuda:0')
tensor(0.1269, device='cuda:0')
old_score: tensor(0.0546, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0481, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.233484268188477
Validation after dual ascent:
out_inf: tensor(3.8379, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.5166, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.5708, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.8984, device='cuda:0', dtype=torch.float16) tensor(0.7778, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1675, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1742, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0079, device='cuda:0')
tensor(0.0746, device='cuda:0')
old_score: tensor(0.1678, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1248, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1784753799438477
Validation after dual ascent:
out_inf: tensor(15.8984, device='cuda:0', dtype=torch.float16) tensor(0.7778, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.4346, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1250, device='cuda:0', dtype=torch.float16) tensor(0.9795, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1686, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1748, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0105, device='cuda:0')
tensor(0.0750, device='cuda:0')
old_score: tensor(0.1686, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1245, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.182438850402832
Validation after dual ascent:
out_inf: tensor(17.1250, device='cuda:0', dtype=torch.float16) tensor(0.9795, device='cuda:0', dtype=torch.float16)
tensor(1.4355, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.5488, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.4551, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.6055, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.3555, device='cuda:0', dtype=torch.float16) tensor(0.4246, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
tensor(1.2607, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
tensor(1.1045, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.3359, device='cuda:0')
old_score: tensor(0.1436, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.449694871902466
Validation after dual ascent:
out_inf: tensor(6.3555, device='cuda:0', dtype=torch.float16) tensor(0.4246, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(1.0068, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(1.1631, device='cuda:0', dtype=torch.float16) tensor(0.1142, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.o_proj
Validation after prune:
out_inf: tensor(14.0234, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0124, device='cuda:0')
tensor(0.0293, device='cuda:0')
old_score: tensor(0.0339, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0252, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.628801584243774
Validation after dual ascent:
out_inf: tensor(14.0234, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(0.6958, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.5762, device='cuda:0', dtype=torch.float16) tensor(0.0250, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.7422, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.1225, device='cuda:0', dtype=torch.float16)
tensor(1.7070, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.2388, device='cuda:0')
old_score: tensor(0.1250, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0941, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.072440147399902
Validation after dual ascent:
out_inf: tensor(11.7422, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(1.1748, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.4102, device='cuda:0', dtype=torch.float16) tensor(0.3496, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1153, device='cuda:0', dtype=torch.float16)
tensor(0.9502, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.2203, device='cuda:0')
old_score: tensor(0.1146, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0875, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.10029935836792
Validation after dual ascent:
out_inf: tensor(7.4102, device='cuda:0', dtype=torch.float16) tensor(0.3496, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.8979, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.8438, device='cuda:0', dtype=torch.float16) tensor(0.1978, device='cuda:0', dtype=torch.float16)
tensor(0.6553, device='cuda:0', dtype=torch.float16) tensor(0.0581, device='cuda:0', dtype=torch.float16)
tensor(0.7222, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.7207, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0085, device='cuda:0')
tensor(0.1348, device='cuda:0')
old_score: tensor(0.0560, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0495, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.19231390953064
Validation after dual ascent:
out_inf: tensor(4.8438, device='cuda:0', dtype=torch.float16) tensor(0.1978, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.6157, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(0.5967, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.q_proj
Validation after prune:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(1.8770, device='cuda:0', dtype=torch.float16) tensor(0.1819, device='cuda:0', dtype=torch.float16)
tensor(1.6963, device='cuda:0', dtype=torch.float16) tensor(0.1776, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1885, device='cuda:0', dtype=torch.float16)
tensor(1.7617, device='cuda:0', dtype=torch.float16) tensor(0.1796, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0073, device='cuda:0')
tensor(0.0905, device='cuda:0')
old_score: tensor(0.1819, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1357, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1831414699554443
Validation after dual ascent:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
tensor(1.4180, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.1406, device='cuda:0', dtype=torch.float16)
tensor(1.6572, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(0.9268, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.1835, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1785, device='cuda:0', dtype=torch.float16)
tensor(2.2422, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1798, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0086, device='cuda:0')
tensor(0.0902, device='cuda:0')
old_score: tensor(0.1830, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1360, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.187879800796509
Validation after dual ascent:
out_inf: tensor(17.0625, device='cuda:0', dtype=torch.float16) tensor(0.9268, device='cuda:0', dtype=torch.float16)
tensor(1.4053, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(1.5957, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(1.5029, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.3984, device='cuda:0', dtype=torch.float16) tensor(0.4639, device='cuda:0', dtype=torch.float16)
tensor(1.4297, device='cuda:0', dtype=torch.float16) tensor(0.1595, device='cuda:0', dtype=torch.float16)
tensor(1.1904, device='cuda:0', dtype=torch.float16) tensor(0.1566, device='cuda:0', dtype=torch.float16)
tensor(1.2871, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(1.2803, device='cuda:0', dtype=torch.float16) tensor(0.1570, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0190, device='cuda:0')
tensor(0.4185, device='cuda:0')
old_score: tensor(0.1594, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1223, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.454559087753296
Validation after dual ascent:
out_inf: tensor(5.3984, device='cuda:0', dtype=torch.float16) tensor(0.4639, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.1127, device='cuda:0', dtype=torch.float16)
tensor(1.1182, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.2373, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.5693, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.7881, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0134, device='cuda:0')
tensor(0.0227, device='cuda:0')
old_score: tensor(0.0282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0199, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.810867547988892
Validation after dual ascent:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(0.5674, device='cuda:0', dtype=torch.float16) tensor(0.0163, device='cuda:0', dtype=torch.float16)
tensor(0.5107, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.7500, device='cuda:0', dtype=torch.float16) tensor(0.4858, device='cuda:0', dtype=torch.float16)
tensor(1.7793, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0175, device='cuda:0')
tensor(0.2749, device='cuda:0')
old_score: tensor(0.1295, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0974, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.088881015777588
Validation after dual ascent:
out_inf: tensor(9.7500, device='cuda:0', dtype=torch.float16) tensor(0.4858, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(1.2236, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(1.2168, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.up_proj
Validation after prune:
out_inf: tensor(8.6016, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1178, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.2539, device='cuda:0')
old_score: tensor(0.1189, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0908, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.106061220169067
Validation after dual ascent:
out_inf: tensor(8.6016, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
tensor(0.8813, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0940, device='cuda:0', dtype=torch.float16)
tensor(0.8896, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.2089, device='cuda:0', dtype=torch.float16)
tensor(0.7314, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.6870, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.6025, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.7197, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0096, device='cuda:0')
tensor(0.1501, device='cuda:0')
old_score: tensor(0.0582, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0515, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.156944990158081
Validation after dual ascent:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.2089, device='cuda:0', dtype=torch.float16)
tensor(0.6729, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.6323, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.5571, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.6948, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.2812, device='cuda:0', dtype=torch.float16) tensor(0.8257, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1849, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1761, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0074, device='cuda:0')
tensor(0.0859, device='cuda:0')
old_score: tensor(0.1797, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1323, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.186906337738037
Validation after dual ascent:
out_inf: tensor(14.2812, device='cuda:0', dtype=torch.float16) tensor(0.8257, device='cuda:0', dtype=torch.float16)
tensor(1.4795, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.5088, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.1562, device='cuda:0', dtype=torch.float16) tensor(1.0078, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1816, device='cuda:0', dtype=torch.float16)
tensor(2.1289, device='cuda:0', dtype=torch.float16) tensor(0.1812, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.1886, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1782, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0856, device='cuda:0')
old_score: tensor(0.1824, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1328, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.187056541442871
Validation after dual ascent:
out_inf: tensor(18.1562, device='cuda:0', dtype=torch.float16) tensor(1.0078, device='cuda:0', dtype=torch.float16)
tensor(1.4727, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
tensor(1.4229, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
tensor(1.5293, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4661, device='cuda:0', dtype=torch.float16)
tensor(1.3721, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
tensor(1.2988, device='cuda:0', dtype=torch.float16) tensor(0.1594, device='cuda:0', dtype=torch.float16)
tensor(1.3867, device='cuda:0', dtype=torch.float16) tensor(0.1641, device='cuda:0', dtype=torch.float16)
tensor(1.4785, device='cuda:0', dtype=torch.float16) tensor(0.1575, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.4085, device='cuda:0')
old_score: tensor(0.1602, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1227, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4547245502471924
Validation after dual ascent:
out_inf: tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.4661, device='cuda:0', dtype=torch.float16)
tensor(1.2871, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.1299, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.o_proj
Validation after prune:
out_inf: tensor(21.7344, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0194, device='cuda:0')
tensor(0.0387, device='cuda:0')
old_score: tensor(0.0349, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0258, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.173291683197021
Validation after dual ascent:
out_inf: tensor(21.7344, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(0.8994, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.0234, device='cuda:0', dtype=torch.float16) tensor(0.5088, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1312, device='cuda:0', dtype=torch.float16)
tensor(1.8008, device='cuda:0', dtype=torch.float16) tensor(0.1360, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0185, device='cuda:0')
tensor(0.2934, device='cuda:0')
old_score: tensor(0.1328, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0990, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.103808164596558
Validation after dual ascent:
out_inf: tensor(9.0234, device='cuda:0', dtype=torch.float16) tensor(0.5088, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(1.2275, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(1.4141, device='cuda:0', dtype=torch.float16) tensor(0.1026, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.up_proj
Validation after prune:
out_inf: tensor(8.2578, device='cuda:0', dtype=torch.float16) tensor(0.3833, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2711, device='cuda:0')
old_score: tensor(0.1223, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0925, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110273122787476
Validation after dual ascent:
out_inf: tensor(8.2578, device='cuda:0', dtype=torch.float16) tensor(0.3833, device='cuda:0', dtype=torch.float16)
tensor(0.9126, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(1.0127, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(0.9028, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(0.9780, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.3398, device='cuda:0', dtype=torch.float16) tensor(0.2195, device='cuda:0', dtype=torch.float16)
tensor(0.6338, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.6465, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(0.7466, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0110, device='cuda:0')
tensor(0.1693, device='cuda:0')
old_score: tensor(0.0611, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0537, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.137857913970947
Validation after dual ascent:
out_inf: tensor(5.3398, device='cuda:0', dtype=torch.float16) tensor(0.2195, device='cuda:0', dtype=torch.float16)
tensor(0.6279, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
tensor(0.6323, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.7373, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1953, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(2.5547, device='cuda:0', dtype=torch.float16) tensor(0.1918, device='cuda:0', dtype=torch.float16)
tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
tensor(2.5000, device='cuda:0', dtype=torch.float16) tensor(0.1976, device='cuda:0', dtype=torch.float16)
tensor(2.4922, device='cuda:0', dtype=torch.float16) tensor(0.1871, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0843, device='cuda:0')
old_score: tensor(0.1910, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1383, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.183448076248169
Validation after dual ascent:
out_inf: tensor(15.1953, device='cuda:0', dtype=torch.float16) tensor(0.8223, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
tensor(1.5098, device='cuda:0', dtype=torch.float16) tensor(0.1420, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.5000, device='cuda:0', dtype=torch.float16) tensor(0.9604, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.1964, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1925, device='cuda:0', dtype=torch.float16)
tensor(3.2734, device='cuda:0', dtype=torch.float16) tensor(0.2041, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.1923, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0112, device='cuda:0')
tensor(0.0860, device='cuda:0')
old_score: tensor(0.1963, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1396, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1867613792419434
Validation after dual ascent:
out_inf: tensor(18.5000, device='cuda:0', dtype=torch.float16) tensor(0.9604, device='cuda:0', dtype=torch.float16)
tensor(1.8203, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(1.5566, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.v_proj
Validation after prune:
out_inf: tensor(10.0469, device='cuda:0', dtype=torch.float16) tensor(0.4722, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1609, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.1663, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1587, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0048, device='cuda:0')
tensor(0.0789, device='cuda:0')
old_score: tensor(0.1614, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1228, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.181647539138794
Validation after dual ascent:
out_inf: tensor(10.0469, device='cuda:0', dtype=torch.float16) tensor(0.4722, device='cuda:0', dtype=torch.float16)
tensor(1.2529, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.5195, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(1.0752, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0073, device='cuda:0')
tensor(0.0132, device='cuda:0')
old_score: tensor(0.0227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0172, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1765365600585938
Validation after dual ascent:
out_inf: tensor(5.5195, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(1.0850, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.8438, device='cuda:0', dtype=torch.float16) tensor(0.5366, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.9727, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(1.8320, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0051, device='cuda:0')
tensor(0.0370, device='cuda:0')
old_score: tensor(0.1375, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.001830101013184
Validation after dual ascent:
out_inf: tensor(10.8438, device='cuda:0', dtype=torch.float16) tensor(0.5366, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.1797, device='cuda:0', dtype=torch.float16) tensor(0.4080, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1265, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0184, device='cuda:0')
tensor(0.3036, device='cuda:0')
old_score: tensor(0.1274, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0951, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110527992248535
Validation after dual ascent:
out_inf: tensor(7.1797, device='cuda:0', dtype=torch.float16) tensor(0.4080, device='cuda:0', dtype=torch.float16)
tensor(1.0713, device='cuda:0', dtype=torch.float16) tensor(0.0963, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.0977, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.2427, device='cuda:0', dtype=torch.float16)
tensor(0.7046, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(0.6470, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.8325, device='cuda:0', dtype=torch.float16) tensor(0.0675, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0130, device='cuda:0')
tensor(0.1984, device='cuda:0')
old_score: tensor(0.0653, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0569, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.085164546966553
Validation after dual ascent:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.2427, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.7861, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.6699, device='cuda:0', dtype=torch.float16) tensor(0.0571, device='cuda:0', dtype=torch.float16)
tensor(0.7017, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.3828, device='cuda:0', dtype=torch.float16) tensor(0.8398, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.1931, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1914, device='cuda:0', dtype=torch.float16)
tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1987, device='cuda:0', dtype=torch.float16)
tensor(2.8438, device='cuda:0', dtype=torch.float16) tensor(0.1887, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0159, device='cuda:0')
tensor(0.0725, device='cuda:0')
old_score: tensor(0.1929, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1372, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.676554918289185
Validation after dual ascent:
out_inf: tensor(14.3828, device='cuda:0', dtype=torch.float16) tensor(0.8398, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.5361, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.8594, device='cuda:0', dtype=torch.float16) tensor(0.9941, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.1978, device='cuda:0', dtype=torch.float16)
tensor(3.2422, device='cuda:0', dtype=torch.float16) tensor(0.1957, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0169, device='cuda:0')
tensor(0.0771, device='cuda:0')
old_score: tensor(0.1981, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1385, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.752162218093872
Validation after dual ascent:
out_inf: tensor(20.8594, device='cuda:0', dtype=torch.float16) tensor(0.9941, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.1133, device='cuda:0', dtype=torch.float16) tensor(0.5107, device='cuda:0', dtype=torch.float16)
tensor(1.5029, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1716, device='cuda:0', dtype=torch.float16)
tensor(1.4502, device='cuda:0', dtype=torch.float16) tensor(0.1763, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0188, device='cuda:0')
tensor(0.1177, device='cuda:0')
old_score: tensor(0.1719, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1298, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2068841457366943
Validation after dual ascent:
out_inf: tensor(7.1133, device='cuda:0', dtype=torch.float16) tensor(0.5107, device='cuda:0', dtype=torch.float16)
tensor(1.5137, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(1.3613, device='cuda:0', dtype=torch.float16) tensor(0.1206, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.o_proj
Validation after prune:
out_inf: tensor(9.1250, device='cuda:0', dtype=torch.float16) tensor(0.1389, device='cuda:0', dtype=torch.float16)
tensor(1.2285, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(1.0469, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0093, device='cuda:0')
tensor(0.0234, device='cuda:0')
old_score: tensor(0.0343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0222, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.525839805603027
Validation after dual ascent:
out_inf: tensor(9.1250, device='cuda:0', dtype=torch.float16) tensor(0.1389, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.8438, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.gate_proj
Validation after prune:
out_inf: tensor(11.7969, device='cuda:0', dtype=torch.float16) tensor(0.5630, device='cuda:0', dtype=torch.float16)
tensor(1.9297, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0054, device='cuda:0')
tensor(0.0447, device='cuda:0')
old_score: tensor(0.1417, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.058271408081055
Validation after dual ascent:
out_inf: tensor(11.7969, device='cuda:0', dtype=torch.float16) tensor(0.5630, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1048, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1063, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.up_proj
Validation after prune:
out_inf: tensor(12.3828, device='cuda:0', dtype=torch.float16) tensor(0.4485, device='cuda:0', dtype=torch.float16)
tensor(2.0820, device='cuda:0', dtype=torch.float16) tensor(0.1335, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(2.4180, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1321, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0043, device='cuda:0')
tensor(0.0422, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0988, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.06130075454712
Validation after dual ascent:
out_inf: tensor(12.3828, device='cuda:0', dtype=torch.float16) tensor(0.4485, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0913, device='cuda:0', dtype=torch.float16)
tensor(1.0781, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.down_proj
Validation after prune:
out_inf: tensor(8.6094, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(0.8608, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(0.7354, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0170, device='cuda:0')
tensor(0.2569, device='cuda:0')
old_score: tensor(0.0734, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0634, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.083157062530518
Validation after dual ascent:
out_inf: tensor(8.6094, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(0.7676, device='cuda:0', dtype=torch.float16) tensor(0.0585, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0639, device='cuda:0', dtype=torch.float16)
tensor(0.7451, device='cuda:0', dtype=torch.float16) tensor(0.0670, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.9531, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1808, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.1824, device='cuda:0', dtype=torch.float16)
tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1902, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.1786, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0073, device='cuda:0')
tensor(0.0381, device='cuda:0')
old_score: tensor(0.1831, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1283, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.378021001815796
Validation after dual ascent:
out_inf: tensor(12.9531, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
tensor(1.6279, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.2188, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(2.9453, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
tensor(2.4453, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.1953, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.1836, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0187, device='cuda:0')
tensor(0.0783, device='cuda:0')
old_score: tensor(0.1885, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1292, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1895570755004883
Validation after dual ascent:
out_inf: tensor(20.2188, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(1.5049, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.4844, device='cuda:0', dtype=torch.float16)
tensor(1.4658, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1740, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1652, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0194, device='cuda:0')
tensor(0.4090, device='cuda:0')
old_score: tensor(0.1686, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1261, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.455782413482666
Validation after dual ascent:
out_inf: tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.4844, device='cuda:0', dtype=torch.float16)
tensor(1.5410, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(1.2744, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.o_proj
Validation after prune:
out_inf: tensor(17.3281, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0311, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0060, device='cuda:0')
tensor(0.0118, device='cuda:0')
old_score: tensor(0.0376, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0263, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4508347511291504
Validation after dual ascent:
out_inf: tensor(17.3281, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(0.7593, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.gate_proj
Validation after prune:
out_inf: tensor(12.1875, device='cuda:0', dtype=torch.float16) tensor(0.5771, device='cuda:0', dtype=torch.float16)
tensor(2.7891, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(2.8203, device='cuda:0', dtype=torch.float16) tensor(0.1476, device='cuda:0', dtype=torch.float16)
tensor(3.2617, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0060, device='cuda:0')
tensor(0.0479, device='cuda:0')
old_score: tensor(0.1442, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1047, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.018152952194214
Validation after dual ascent:
out_inf: tensor(12.1875, device='cuda:0', dtype=torch.float16) tensor(0.5771, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(2.4258, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.up_proj
Validation after prune:
out_inf: tensor(9.5000, device='cuda:0', dtype=torch.float16) tensor(0.4985, device='cuda:0', dtype=torch.float16)
tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0055, device='cuda:0')
tensor(0.0457, device='cuda:0')
old_score: tensor(0.1396, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.052168369293213
Validation after dual ascent:
out_inf: tensor(9.5000, device='cuda:0', dtype=torch.float16) tensor(0.4985, device='cuda:0', dtype=torch.float16)
tensor(3.2109, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(2.6074, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
tensor(3.1680, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.down_proj
Validation after prune:
out_inf: tensor(22.2812, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(0.9556, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(1.0127, device='cuda:0', dtype=torch.float16) tensor(0.0799, device='cuda:0', dtype=torch.float16)
tensor(0.8721, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.9697, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0029, device='cuda:0')
tensor(0.0312, device='cuda:0')
old_score: tensor(0.0811, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0688, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.81636381149292
Validation after dual ascent:
out_inf: tensor(22.2812, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(0.9722, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.9546, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.8271, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.8467, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.8438, device='cuda:0', dtype=torch.float16)
tensor(2.6211, device='cuda:0', dtype=torch.float16) tensor(0.1946, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.1948, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.2004, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.1921, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0131, device='cuda:0')
tensor(0.0596, device='cuda:0')
old_score: tensor(0.1956, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1333, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.674539566040039
Validation after dual ascent:
out_inf: tensor(14.1953, device='cuda:0', dtype=torch.float16) tensor(0.8438, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1343, device='cuda:0', dtype=torch.float16)
tensor(1.6689, device='cuda:0', dtype=torch.float16) tensor(0.1239, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.5938, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(3.2344, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(2.6797, device='cuda:0', dtype=torch.float16) tensor(0.2007, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.2080, device='cuda:0', dtype=torch.float16)
tensor(3.0859, device='cuda:0', dtype=torch.float16) tensor(0.1992, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0131, device='cuda:0')
tensor(0.0592, device='cuda:0')
old_score: tensor(0.2025, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1353, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.699050903320312
Validation after dual ascent:
out_inf: tensor(18.5938, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(1.6787, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
tensor(1.4971, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.v_proj
Validation after prune:
out_inf: tensor(9.5625, device='cuda:0', dtype=torch.float16) tensor(0.5439, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1787, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.1810, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.1854, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1779, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0152, device='cuda:0')
tensor(0.1022, device='cuda:0')
old_score: tensor(0.1808, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1322, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1934115886688232
Validation after dual ascent:
out_inf: tensor(9.5625, device='cuda:0', dtype=torch.float16) tensor(0.5439, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1228, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.o_proj
Validation after prune:
out_inf: tensor(19.3438, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0085, device='cuda:0')
tensor(0.0162, device='cuda:0')
old_score: tensor(0.0284, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0201, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1812126636505127
Validation after dual ascent:
out_inf: tensor(19.3438, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(0.9033, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(1.1758, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.gate_proj
Validation after prune:
out_inf: tensor(33.5625, device='cuda:0', dtype=torch.float16) tensor(0.6353, device='cuda:0', dtype=torch.float16)
tensor(17.1875, device='cuda:0', dtype=torch.float16) tensor(0.1499, device='cuda:0', dtype=torch.float16)
tensor(13.4219, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
tensor(14.4375, device='cuda:0', dtype=torch.float16) tensor(0.1541, device='cuda:0', dtype=torch.float16)
tensor(13.5625, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0086, device='cuda:0')
tensor(0.0471, device='cuda:0')
old_score: tensor(0.1508, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1049, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.05209231376648
Validation after dual ascent:
out_inf: tensor(33.5625, device='cuda:0', dtype=torch.float16) tensor(0.6353, device='cuda:0', dtype=torch.float16)
tensor(9.1094, device='cuda:0', dtype=torch.float16) tensor(0.1059, device='cuda:0', dtype=torch.float16)
tensor(7.6562, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
tensor(7.4062, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(7.5938, device='cuda:0', dtype=torch.float16) tensor(0.1072, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.up_proj
Validation after prune:
out_inf: tensor(34.0938, device='cuda:0', dtype=torch.float16) tensor(0.5845, device='cuda:0', dtype=torch.float16)
tensor(16.4375, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(14.7031, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(17.6875, device='cuda:0', dtype=torch.float16) tensor(0.1501, device='cuda:0', dtype=torch.float16)
tensor(16.1875, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0084, device='cuda:0')
tensor(0.0448, device='cuda:0')
old_score: tensor(0.1467, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.056565523147583
Validation after dual ascent:
out_inf: tensor(34.0938, device='cuda:0', dtype=torch.float16) tensor(0.5845, device='cuda:0', dtype=torch.float16)
tensor(7.7188, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(9.0625, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(9.3438, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(10.8906, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.down_proj
Validation after prune:
out_inf: tensor(1407., device='cuda:0', dtype=torch.float16) tensor(0.5200, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(1.2148, device='cuda:0', dtype=torch.float16) tensor(0.0893, device='cuda:0', dtype=torch.float16)
tensor(1.0928, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(1.2744, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0133, device='cuda:0')
tensor(0.0527, device='cuda:0')
old_score: tensor(0.0906, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0743, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.73555588722229
Validation after dual ascent:
out_inf: tensor(1407., device='cuda:0', dtype=torch.float16) tensor(0.5200, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.4922, device='cuda:0', dtype=torch.float16) tensor(0.8408, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.1775, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.1798, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.1849, device='cuda:0', dtype=torch.float16)
tensor(3.1094, device='cuda:0', dtype=torch.float16) tensor(0.1781, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2382, device='cuda:0')
old_score: tensor(0.1802, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1091, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4507744312286377
Validation after dual ascent:
out_inf: tensor(13.4922, device='cuda:0', dtype=torch.float16) tensor(0.8408, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1012, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.1106, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.k_proj
Validation after prune:
out_inf: tensor(24.2812, device='cuda:0', dtype=torch.float16) tensor(1.0664, device='cuda:0', dtype=torch.float16)
tensor(3.3438, device='cuda:0', dtype=torch.float16) tensor(0.1912, device='cuda:0', dtype=torch.float16)
tensor(3.2656, device='cuda:0', dtype=torch.float16) tensor(0.1915, device='cuda:0', dtype=torch.float16)
tensor(3.3906, device='cuda:0', dtype=torch.float16) tensor(0.1981, device='cuda:0', dtype=torch.float16)
tensor(3.6328, device='cuda:0', dtype=torch.float16) tensor(0.1923, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.2487, device='cuda:0')
old_score: tensor(0.1934, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1122, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.455064535140991
Validation after dual ascent:
out_inf: tensor(24.2812, device='cuda:0', dtype=torch.float16) tensor(1.0664, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.6953, device='cuda:0', dtype=torch.float16) tensor(0.4180, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
tensor(1.1768, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(1.2842, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0124, device='cuda:0')
tensor(0.2069, device='cuda:0')
old_score: tensor(0.1387, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0968, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4509925842285156
Validation after dual ascent:
out_inf: tensor(6.6953, device='cuda:0', dtype=torch.float16) tensor(0.4180, device='cuda:0', dtype=torch.float16)
tensor(0.9619, device='cuda:0', dtype=torch.float16) tensor(0.0977, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
tensor(1.0205, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.o_proj
Validation after prune:
out_inf: tensor(129.6250, device='cuda:0', dtype=torch.float16) tensor(0.2457, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0419, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0110, device='cuda:0')
tensor(0.1127, device='cuda:0')
old_score: tensor(0.0441, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0277, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 1.7170817852020264
Validation after dual ascent:
out_inf: tensor(129.6250, device='cuda:0', dtype=torch.float16) tensor(0.2457, device='cuda:0', dtype=torch.float16)
tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0280, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0286, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.gate_proj
Validation after prune:
out_inf: tensor(29.9375, device='cuda:0', dtype=torch.float16) tensor(0.6763, device='cuda:0', dtype=torch.float16)
tensor(6.0781, device='cuda:0', dtype=torch.float16) tensor(0.1550, device='cuda:0', dtype=torch.float16)
tensor(5.7578, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.1580, device='cuda:0', dtype=torch.float16)
tensor(5.9688, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0199, device='cuda:0')
tensor(0.2271, device='cuda:0')
old_score: tensor(0.1567, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0953, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0907838344573975
Validation after dual ascent:
out_inf: tensor(29.9375, device='cuda:0', dtype=torch.float16) tensor(0.6763, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(2.1602, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.up_proj
Validation after prune:
out_inf: tensor(33.4375, device='cuda:0', dtype=torch.float16) tensor(0.6929, device='cuda:0', dtype=torch.float16)
tensor(9.4531, device='cuda:0', dtype=torch.float16) tensor(0.1505, device='cuda:0', dtype=torch.float16)
tensor(8.0312, device='cuda:0', dtype=torch.float16) tensor(0.1526, device='cuda:0', dtype=torch.float16)
tensor(7.6562, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(7.8750, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.2132, device='cuda:0')
old_score: tensor(0.1516, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0904, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.103227376937866
Validation after dual ascent:
out_inf: tensor(33.4375, device='cuda:0', dtype=torch.float16) tensor(0.6929, device='cuda:0', dtype=torch.float16)
tensor(2.9375, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(2.5117, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
tensor(2.8398, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.down_proj
Validation after prune:
out_inf: tensor(198.5000, device='cuda:0', dtype=torch.float16) tensor(1.5518, device='cuda:0', dtype=torch.float16)
tensor(2.7852, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(3.1250, device='cuda:0', dtype=torch.float16) tensor(0.1055, device='cuda:0', dtype=torch.float16)
tensor(3.4375, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.14it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.10it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.93it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25': 0, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.599870
layer 1 sparsity 0.599870
layer 2 sparsity 0.599870
layer 3 sparsity 0.599870
layer 4 sparsity 0.599870
layer 5 sparsity 0.599870
layer 6 sparsity 0.599870
layer 7 sparsity 0.599870
layer 8 sparsity 0.599870
layer 9 sparsity 0.599870
layer 10 sparsity 0.599870
layer 11 sparsity 0.599870
layer 12 sparsity 0.599870
layer 13 sparsity 0.599870
layer 14 sparsity 0.599870
layer 15 sparsity 0.599870
layer 16 sparsity 0.599870
layer 17 sparsity 0.599870
layer 18 sparsity 0.599870
layer 19 sparsity 0.599870
layer 20 sparsity 0.599870
layer 21 sparsity 0.599870
layer 22 sparsity 0.599870
layer 23 sparsity 0.599870
layer 24 sparsity 0.599870
layer 25 sparsity 0.599870
layer 26 sparsity 0.599870
layer 27 sparsity 0.599870
layer 28 sparsity 0.599870
layer 29 sparsity 0.599870
layer 30 sparsity 0.599870
layer 31 sparsity 0.599870
sparsity sanity check 0.5999
******************************
evaluating on wikitext2
nsamples 83
sample 0
sample 50
wikitext perplexity 9.791441917419434
wanda_dual_3	0.5999	9.7914	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.6, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='wanda_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
2025-04-24 01:09:37.446312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 01:09:37.657818: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 01:09:37.663088: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 01:09:37.663116: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 01:09:41.467009: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 01:09:41.467636: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 01:09:41.467656: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.72it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.65it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.48it/s]
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
model.embed_tokens.weight torch.Size([32000, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([32000, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:00<03:23,  1.25it/s]  1%|          | 2/256 [00:01<03:14,  1.30it/s]  2%|▏         | 4/256 [00:01<01:38,  2.57it/s]  2%|▏         | 5/256 [00:02<01:55,  2.18it/s]  2%|▏         | 6/256 [00:02<01:28,  2.81it/s]  3%|▎         | 7/256 [00:03<01:59,  2.08it/s]  3%|▎         | 8/256 [00:03<01:32,  2.69it/s]  4%|▎         | 9/256 [00:03<01:11,  3.44it/s]  4%|▍         | 11/256 [00:03<00:47,  5.12it/s]  5%|▍         | 12/256 [00:03<00:43,  5.60it/s]  5%|▌         | 13/256 [00:04<01:30,  2.70it/s]  5%|▌         | 14/256 [00:05<01:27,  2.77it/s]  6%|▌         | 15/256 [00:05<01:14,  3.24it/s]  6%|▋         | 16/256 [00:05<01:04,  3.71it/s]  7%|▋         | 18/256 [00:06<01:08,  3.47it/s]  8%|▊         | 20/256 [00:06<00:51,  4.57it/s]  8%|▊         | 21/256 [00:06<00:45,  5.16it/s]  9%|▊         | 22/256 [00:06<00:48,  4.84it/s]  9%|▉         | 24/256 [00:06<00:41,  5.54it/s] 10%|▉         | 25/256 [00:07<00:39,  5.79it/s] 10%|█         | 26/256 [00:07<00:52,  4.39it/s] 11%|█         | 28/256 [00:07<00:43,  5.24it/s] 11%|█▏        | 29/256 [00:08<00:45,  5.03it/s] 12%|█▏        | 31/256 [00:08<00:38,  5.84it/s] 12%|█▎        | 32/256 [00:08<00:46,  4.86it/s] 13%|█▎        | 33/256 [00:09<00:57,  3.87it/s] 13%|█▎        | 34/256 [00:09<01:01,  3.62it/s] 14%|█▎        | 35/256 [00:09<01:08,  3.23it/s] 14%|█▍        | 36/256 [00:10<01:25,  2.56it/s] 14%|█▍        | 37/256 [00:10<01:27,  2.51it/s] 15%|█▍        | 38/256 [00:11<01:25,  2.55it/s] 16%|█▌        | 40/256 [00:11<01:13,  2.96it/s] 16%|█▋        | 42/256 [00:11<00:50,  4.27it/s] 17%|█▋        | 43/256 [00:11<00:44,  4.81it/s] 17%|█▋        | 44/256 [00:12<00:42,  4.97it/s] 18%|█▊        | 45/256 [00:12<00:37,  5.58it/s] 18%|█▊        | 46/256 [00:12<00:35,  5.92it/s] 18%|█▊        | 47/256 [00:12<00:35,  5.84it/s] 19%|█▉        | 48/256 [00:12<00:39,  5.28it/s] 19%|█▉        | 49/256 [00:12<00:34,  5.93it/s] 20%|█▉        | 50/256 [00:13<00:50,  4.10it/s] 21%|██        | 53/256 [00:14<00:48,  4.17it/s] 21%|██        | 54/256 [00:14<00:47,  4.23it/s] 21%|██▏       | 55/256 [00:14<00:41,  4.80it/s] 22%|██▏       | 56/256 [00:14<00:50,  3.95it/s] 22%|██▏       | 57/256 [00:14<00:46,  4.29it/s] 23%|██▎       | 58/256 [00:15<00:50,  3.91it/s] 23%|██▎       | 59/256 [00:15<00:43,  4.48it/s] 23%|██▎       | 60/256 [00:15<00:47,  4.12it/s] 24%|██▍       | 61/256 [00:16<00:54,  3.55it/s] 24%|██▍       | 62/256 [00:16<00:59,  3.27it/s] 25%|██▍       | 63/256 [00:16<00:51,  3.77it/s] 25%|██▌       | 64/256 [00:16<00:42,  4.56it/s] 25%|██▌       | 65/256 [00:17<01:08,  2.80it/s] 26%|██▌       | 67/256 [00:17<00:43,  4.31it/s] 27%|██▋       | 68/256 [00:17<00:42,  4.39it/s] 27%|██▋       | 69/256 [00:18<00:43,  4.29it/s] 28%|██▊       | 71/256 [00:18<00:33,  5.53it/s] 29%|██▊       | 73/256 [00:18<00:26,  6.84it/s] 29%|██▉       | 74/256 [00:18<00:26,  6.91it/s] 29%|██▉       | 75/256 [00:18<00:31,  5.77it/s] 30%|██▉       | 76/256 [00:19<00:43,  4.10it/s] 30%|███       | 78/256 [00:19<00:30,  5.85it/s] 31%|███       | 79/256 [00:19<00:38,  4.65it/s] 31%|███▏      | 80/256 [00:20<00:49,  3.55it/s] 32%|███▏      | 81/256 [00:20<00:54,  3.23it/s] 32%|███▏      | 82/256 [00:20<00:44,  3.90it/s] 32%|███▏      | 83/256 [00:21<00:54,  3.15it/s] 33%|███▎      | 84/256 [00:21<00:51,  3.31it/s] 33%|███▎      | 85/256 [00:21<00:47,  3.60it/s] 34%|███▎      | 86/256 [00:21<00:43,  3.94it/s] 34%|███▍      | 87/256 [00:22<01:00,  2.80it/s] 34%|███▍      | 88/256 [00:22<01:02,  2.69it/s] 35%|███▍      | 89/256 [00:23<00:58,  2.84it/s] 35%|███▌      | 90/256 [00:23<00:59,  2.80it/s] 36%|███▌      | 91/256 [00:23<00:57,  2.85it/s] 36%|███▌      | 92/256 [00:24<00:48,  3.38it/s] 36%|███▋      | 93/256 [00:24<00:42,  3.86it/s] 37%|███▋      | 94/256 [00:24<00:49,  3.24it/s] 37%|███▋      | 95/256 [00:25<01:04,  2.50it/s] 38%|███▊      | 96/256 [00:25<00:51,  3.13it/s] 38%|███▊      | 97/256 [00:25<00:55,  2.87it/s] 38%|███▊      | 98/256 [00:26<00:46,  3.39it/s] 39%|███▊      | 99/256 [00:26<00:45,  3.47it/s] 39%|███▉      | 100/256 [00:26<00:42,  3.64it/s] 39%|███▉      | 101/256 [00:27<01:15,  2.06it/s] 40%|███▉      | 102/256 [00:27<01:04,  2.38it/s] 41%|████      | 104/256 [00:28<00:41,  3.68it/s] 41%|████▏     | 106/256 [00:28<00:33,  4.44it/s] 42%|████▏     | 107/256 [00:28<00:33,  4.46it/s] 42%|████▏     | 108/256 [00:29<00:49,  3.02it/s] 43%|████▎     | 111/256 [00:29<00:30,  4.71it/s] 44%|████▍     | 112/256 [00:29<00:32,  4.49it/s] 44%|████▍     | 113/256 [00:30<00:32,  4.44it/s] 45%|████▍     | 114/256 [00:30<00:29,  4.85it/s] 45%|████▍     | 115/256 [00:30<00:27,  5.11it/s] 45%|████▌     | 116/256 [00:30<00:38,  3.63it/s] 46%|████▌     | 118/256 [00:31<00:29,  4.62it/s] 47%|████▋     | 120/256 [00:31<00:22,  6.14it/s] 47%|████▋     | 121/256 [00:31<00:20,  6.51it/s] 48%|████▊     | 122/256 [00:32<00:36,  3.72it/s] 48%|████▊     | 123/256 [00:32<00:39,  3.37it/s] 48%|████▊     | 124/256 [00:33<00:50,  2.59it/s] 49%|████▉     | 125/256 [00:34<01:19,  1.65it/s] 49%|████▉     | 126/256 [00:34<01:07,  1.93it/s] 50%|████▉     | 127/256 [00:35<01:13,  1.77it/s] 50%|█████     | 129/256 [00:35<00:44,  2.85it/s] 51%|█████     | 130/256 [00:35<00:40,  3.10it/s] 51%|█████     | 131/256 [00:35<00:38,  3.27it/s] 52%|█████▏    | 132/256 [00:36<00:37,  3.35it/s] 52%|█████▏    | 133/256 [00:36<00:44,  2.75it/s] 52%|█████▏    | 134/256 [00:37<00:44,  2.76it/s] 53%|█████▎    | 135/256 [00:37<00:35,  3.40it/s] 53%|█████▎    | 136/256 [00:37<00:35,  3.37it/s] 54%|█████▎    | 137/256 [00:37<00:29,  3.99it/s] 54%|█████▍    | 138/256 [00:37<00:26,  4.51it/s] 54%|█████▍    | 139/256 [00:37<00:24,  4.85it/s] 55%|█████▍    | 140/256 [00:38<00:22,  5.16it/s] 55%|█████▌    | 142/256 [00:38<00:17,  6.67it/s] 56%|█████▌    | 143/256 [00:38<00:16,  6.89it/s] 57%|█████▋    | 145/256 [00:39<00:34,  3.21it/s] 57%|█████▋    | 146/256 [00:39<00:38,  2.86it/s] 57%|█████▋    | 147/256 [00:40<00:35,  3.06it/s] 58%|█████▊    | 148/256 [00:40<00:36,  2.98it/s] 59%|█████▊    | 150/256 [00:40<00:29,  3.65it/s] 59%|█████▉    | 151/256 [00:41<00:24,  4.20it/s] 59%|█████▉    | 152/256 [00:41<00:28,  3.65it/s] 60%|█████▉    | 153/256 [00:41<00:25,  4.03it/s] 60%|██████    | 154/256 [00:42<00:29,  3.44it/s] 61%|██████    | 155/256 [00:42<00:26,  3.82it/s] 61%|██████    | 156/256 [00:42<00:21,  4.55it/s] 61%|██████▏   | 157/256 [00:42<00:27,  3.65it/s] 62%|██████▏   | 158/256 [00:42<00:23,  4.17it/s] 62%|██████▏   | 159/256 [00:43<00:41,  2.32it/s] 62%|██████▎   | 160/256 [00:43<00:32,  2.97it/s] 63%|██████▎   | 162/256 [00:44<00:36,  2.59it/s] 64%|██████▎   | 163/256 [00:45<00:32,  2.89it/s] 64%|██████▍   | 164/256 [00:45<00:26,  3.45it/s] 65%|██████▍   | 166/256 [00:45<00:22,  3.99it/s] 65%|██████▌   | 167/256 [00:45<00:25,  3.55it/s] 66%|██████▌   | 168/256 [00:46<00:28,  3.14it/s] 66%|██████▌   | 169/256 [00:46<00:31,  2.75it/s] 66%|██████▋   | 170/256 [00:47<00:31,  2.72it/s] 67%|██████▋   | 172/256 [00:47<00:22,  3.79it/s] 68%|██████▊   | 173/256 [00:47<00:21,  3.92it/s] 68%|██████▊   | 174/256 [00:48<00:28,  2.87it/s] 68%|██████▊   | 175/256 [00:49<00:40,  1.99it/s] 69%|██████▉   | 176/256 [00:49<00:35,  2.25it/s] 69%|██████▉   | 177/256 [00:49<00:29,  2.70it/s] 70%|██████▉   | 179/256 [00:50<00:19,  3.87it/s] 70%|███████   | 180/256 [00:51<00:37,  2.01it/s] 71%|███████   | 181/256 [00:51<00:30,  2.48it/s] 71%|███████   | 182/256 [00:52<00:38,  1.94it/s] 72%|███████▏  | 184/256 [00:53<00:35,  2.05it/s] 73%|███████▎  | 186/256 [00:53<00:23,  2.93it/s] 73%|███████▎  | 187/256 [00:53<00:27,  2.53it/s] 73%|███████▎  | 188/256 [00:54<00:23,  2.88it/s] 74%|███████▍  | 189/256 [00:54<00:22,  2.93it/s] 74%|███████▍  | 190/256 [00:54<00:20,  3.17it/s] 75%|███████▍  | 191/256 [00:54<00:18,  3.48it/s] 75%|███████▌  | 192/256 [00:55<00:21,  2.95it/s] 75%|███████▌  | 193/256 [00:55<00:20,  3.06it/s] 77%|███████▋  | 196/256 [00:56<00:13,  4.54it/s] 77%|███████▋  | 197/256 [00:56<00:15,  3.89it/s] 78%|███████▊  | 199/256 [00:56<00:11,  4.95it/s] 79%|███████▊  | 201/256 [00:56<00:09,  5.55it/s] 79%|███████▉  | 202/256 [00:57<00:11,  4.62it/s] 80%|███████▉  | 204/256 [00:57<00:08,  5.87it/s] 80%|████████  | 206/256 [00:57<00:06,  7.26it/s] 81%|████████  | 207/256 [00:57<00:06,  7.59it/s] 81%|████████▏ | 208/256 [00:57<00:07,  6.67it/s] 82%|████████▏ | 210/256 [00:58<00:05,  8.74it/s] 83%|████████▎ | 212/256 [00:58<00:05,  8.33it/s] 83%|████████▎ | 213/256 [00:58<00:05,  7.46it/s] 84%|████████▎ | 214/256 [00:58<00:07,  5.74it/s] 84%|████████▍ | 215/256 [00:59<00:09,  4.49it/s] 84%|████████▍ | 216/256 [00:59<00:09,  4.36it/s] 85%|████████▌ | 218/256 [00:59<00:07,  5.23it/s] 86%|████████▌ | 219/256 [01:00<00:14,  2.53it/s] 86%|████████▌ | 220/256 [01:00<00:12,  2.97it/s] 86%|████████▋ | 221/256 [01:01<00:12,  2.90it/s] 87%|████████▋ | 222/256 [01:01<00:11,  2.89it/s] 87%|████████▋ | 223/256 [01:02<00:12,  2.73it/s] 88%|████████▊ | 224/256 [01:03<00:23,  1.33it/s] 88%|████████▊ | 225/256 [01:04<00:22,  1.38it/s] 88%|████████▊ | 226/256 [01:04<00:16,  1.78it/s] 89%|████████▊ | 227/256 [01:04<00:13,  2.14it/s] 89%|████████▉ | 228/256 [01:05<00:12,  2.26it/s] 89%|████████▉ | 229/256 [01:06<00:18,  1.45it/s] 90%|████████▉ | 230/256 [01:06<00:13,  1.92it/s] 90%|█████████ | 231/256 [01:07<00:12,  1.98it/s] 91%|█████████ | 232/256 [01:07<00:10,  2.25it/s] 91%|█████████ | 233/256 [01:07<00:08,  2.73it/s] 92%|█████████▏| 235/256 [01:07<00:05,  3.80it/s] 92%|█████████▏| 236/256 [01:08<00:05,  3.60it/s] 93%|█████████▎| 237/256 [01:08<00:04,  3.99it/s] 93%|█████████▎| 238/256 [01:08<00:03,  4.66it/s] 93%|█████████▎| 239/256 [01:08<00:03,  4.62it/s] 94%|█████████▍| 241/256 [01:08<00:02,  5.81it/s] 95%|█████████▍| 242/256 [01:09<00:04,  2.92it/s] 95%|█████████▌| 244/256 [01:09<00:02,  4.45it/s] 96%|█████████▌| 245/256 [01:10<00:02,  4.37it/s] 96%|█████████▌| 246/256 [01:10<00:02,  4.86it/s] 97%|█████████▋| 248/256 [01:10<00:01,  6.58it/s] 97%|█████████▋| 249/256 [01:11<00:01,  3.92it/s] 98%|█████████▊| 251/256 [01:11<00:00,  5.38it/s] 98%|█████████▊| 252/256 [01:11<00:01,  3.46it/s] 99%|█████████▉| 253/256 [01:12<00:01,  2.92it/s]100%|█████████▉| 255/256 [01:13<00:00,  3.08it/s]100%|██████████| 256/256 [01:13<00:00,  3.16it/s]100%|██████████| 256/256 [01:13<00:00,  3.49it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
pruning layer 0 name self_attn.q_proj
Validation after prune:
out_inf: tensor(7.8555, device='cuda:0', dtype=torch.float16) tensor(0.6099, device='cuda:0', dtype=torch.float16)
tensor(0.1230, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1328, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.1230, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.1328, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.k_proj
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.1191, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.1191, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.1191, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
tensor(0.1191, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.v_proj
Validation after prune:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0796, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0771, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0771, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.0771, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0476, device='cuda:0')
old_score: tensor(0.0026, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0012, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.690325736999512
Validation after dual ascent:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0381, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0381, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0396, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0396, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0083, device='cuda:0', dtype=torch.float16) tensor(0.0001, device='cuda:0', dtype=torch.float16)
tensor(0.0048, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
tensor(0.0081, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
tensor(0.0100, device='cuda:0', dtype=torch.float16) tensor(0.0001, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.5928, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.6006, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0157, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0191, device='cuda:0')
tensor(0.0211, device='cuda:0')
old_score: tensor(0.0147, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0086, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 23.214054107666016
Validation after dual ascent:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.3594, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.4438, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.4045, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.4561, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.up_proj
Validation after prune:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.2646, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
tensor(0.2739, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.2920, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.2759, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0190, device='cuda:0')
tensor(0.0204, device='cuda:0')
old_score: tensor(0.0142, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0084, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 23.38709855079651
Validation after dual ascent:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.1821, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.2061, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1975, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0701, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0684, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0610, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0767, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0946, device='cuda:0')
old_score: tensor(0.0018, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0012, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.36496353149414
Validation after dual ascent:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0293, device='cuda:0', dtype=torch.float16) tensor(0.0011, device='cuda:0', dtype=torch.float16)
tensor(0.0377, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0360, device='cuda:0', dtype=torch.float16) tensor(0.0014, device='cuda:0', dtype=torch.float16)
tensor(0.0518, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.q_proj
Validation after prune:
out_inf: tensor(9.3281, device='cuda:0', dtype=torch.float16) tensor(0.7861, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.0279, device='cuda:0', dtype=torch.float16)
tensor(1.4160, device='cuda:0', dtype=torch.float16) tensor(0.0284, device='cuda:0', dtype=torch.float16)
tensor(1.3965, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(1.3848, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.k_proj
Validation after prune:
out_inf: tensor(7.7930, device='cuda:0', dtype=torch.float16) tensor(0.7974, device='cuda:0', dtype=torch.float16)
tensor(1.4043, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.0311, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(1.3887, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.4263, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.4272, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.4521, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.4351, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0196, device='cuda:0')
tensor(0.0274, device='cuda:0')
old_score: tensor(0.0091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0053, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.070617914199829
Validation after dual ascent:
out_inf: tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(0.2974, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.2939, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.3247, device='cuda:0', dtype=torch.float16) tensor(0.0057, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.4958, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.0381, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0229, device='cuda:0', dtype=torch.float16) tensor(0.0009, device='cuda:0', dtype=torch.float16)
tensor(0.0388, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
tensor(0.0393, device='cuda:0', dtype=torch.float16) tensor(0.0008, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.gate_proj
Validation after prune:
out_inf: tensor(43.5312, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(7.5312, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(7.4688, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
tensor(7.0938, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(7.7500, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0187, device='cuda:0')
tensor(0.0263, device='cuda:0')
old_score: tensor(0.0311, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0199, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.764838457107544
Validation after dual ascent:
out_inf: tensor(43.5312, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(1.8164, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.0197, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.up_proj
Validation after prune:
out_inf: tensor(37.7188, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(5.0938, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
tensor(5.0938, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(4.7188, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(5.3438, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0159, device='cuda:0')
tensor(0.0244, device='cuda:0')
old_score: tensor(0.0278, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0186, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.79294490814209
Validation after dual ascent:
out_inf: tensor(37.7188, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.down_proj
Validation after prune:
out_inf: tensor(2666., device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1038, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.1263, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
tensor(0.3028, device='cuda:0')
old_score: tensor(0.0050, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0093, device='cuda:0', dtype=torch.float16)
Not converged!
Dual ascent finished!
Time: 98.19850158691406
Validation after dual ascent:
out_inf: tensor(2666., device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0048, device='cuda:0', dtype=torch.float16)
tensor(0.1038, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.1263, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0047, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.4141, device='cuda:0', dtype=torch.float16) tensor(0.9238, device='cuda:0', dtype=torch.float16)
tensor(1.8398, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(1.8633, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
tensor(1.6914, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(1.9492, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.k_proj
Validation after prune:
out_inf: tensor(13.9297, device='cuda:0', dtype=torch.float16) tensor(1.0898, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(1.5898, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.7891, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(0.5488, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.4971, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0130, device='cuda:0')
tensor(0.0184, device='cuda:0')
old_score: tensor(0.0434, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0291, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4220669269561768
Validation after dual ascent:
out_inf: tensor(2.7891, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(0.3232, device='cuda:0', dtype=torch.float16) tensor(0.0285, device='cuda:0', dtype=torch.float16)
tensor(0.3188, device='cuda:0', dtype=torch.float16) tensor(0.0279, device='cuda:0', dtype=torch.float16)
tensor(0.3369, device='cuda:0', dtype=torch.float16) tensor(0.0314, device='cuda:0', dtype=torch.float16)
tensor(0.3457, device='cuda:0', dtype=torch.float16) tensor(0.0286, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9448, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.3296, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.1494, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.1147, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.1750, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0521, device='cuda:0')
old_score: tensor(0.0025, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0019, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.858848810195923
Validation after dual ascent:
out_inf: tensor(0.9448, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.0957, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.2135, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0798, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.1064, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.2285, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.8730, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.9453, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0174, device='cuda:0')
tensor(0.0192, device='cuda:0')
old_score: tensor(0.0435, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0322, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.851235389709473
Validation after dual ascent:
out_inf: tensor(2.2285, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.4150, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.4531, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.4600, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
tensor(0.4834, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.4756, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.3989, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0176, device='cuda:0')
tensor(0.0326, device='cuda:0')
old_score: tensor(0.0397, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0298, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.091664791107178
Validation after dual ascent:
out_inf: tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
tensor(0.3438, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.3262, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0319, device='cuda:0', dtype=torch.float16)
tensor(0.3350, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.0939, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1539, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(0.1483, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1383, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
tensor(0.1052, device='cuda:0')
old_score: tensor(0.0067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0057, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.63044810295105
Validation after dual ascent:
out_inf: tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.0830, device='cuda:0', dtype=torch.float16) tensor(0.0055, device='cuda:0', dtype=torch.float16)
tensor(0.0900, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.0989, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.0916, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.2656, device='cuda:0', dtype=torch.float16) tensor(0.8447, device='cuda:0', dtype=torch.float16)
tensor(2.1641, device='cuda:0', dtype=torch.float16) tensor(0.1334, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(2.0508, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
tensor(0.0946, device='cuda:0')
old_score: tensor(0.1365, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0933, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.837034940719604
Validation after dual ascent:
out_inf: tensor(16.2656, device='cuda:0', dtype=torch.float16) tensor(0.8447, device='cuda:0', dtype=torch.float16)
tensor(1.7314, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(1.5615, device='cuda:0', dtype=torch.float16) tensor(0.1022, device='cuda:0', dtype=torch.float16)
tensor(1.9316, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.3828, device='cuda:0', dtype=torch.float16) tensor(1.0098, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
tensor(2.3145, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
tensor(2.3828, device='cuda:0', dtype=torch.float16) tensor(0.1486, device='cuda:0', dtype=torch.float16)
tensor(2.2754, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(0.0486, device='cuda:0')
old_score: tensor(0.1411, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0959, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.909213066101074
Validation after dual ascent:
out_inf: tensor(15.3828, device='cuda:0', dtype=torch.float16) tensor(1.0098, device='cuda:0', dtype=torch.float16)
tensor(1.3789, device='cuda:0', dtype=torch.float16) tensor(0.0928, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(1.4941, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1896, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(0.7676, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0150, device='cuda:0')
tensor(0.0399, device='cuda:0')
old_score: tensor(0.0702, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0523, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4526658058166504
Validation after dual ascent:
out_inf: tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1896, device='cuda:0', dtype=torch.float16)
tensor(0.5532, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.5342, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.5654, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.5493, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.2170, device='cuda:0', dtype=torch.float16) tensor(0.0033, device='cuda:0', dtype=torch.float16)
tensor(0.1855, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.2168, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0496, device='cuda:0')
old_score: tensor(0.0034, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0027, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.905250549316406
Validation after dual ascent:
out_inf: tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.2590, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.1299, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.0955, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.1135, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.4570, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0080, device='cuda:0')
tensor(0.0255, device='cuda:0')
old_score: tensor(0.0555, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0434, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.095149517059326
Validation after dual ascent:
out_inf: tensor(4.4570, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(0.6880, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.7822, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.6074, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0073, device='cuda:0')
tensor(0.0225, device='cuda:0')
old_score: tensor(0.0510, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0401, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.10042142868042
Validation after dual ascent:
out_inf: tensor(2.6074, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.4241, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.4058, device='cuda:0', dtype=torch.float16) tensor(0.0437, device='cuda:0', dtype=torch.float16)
tensor(0.4287, device='cuda:0', dtype=torch.float16) tensor(0.0397, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.1493, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1426, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(0.1544, device='cuda:0', dtype=torch.float16) tensor(0.0107, device='cuda:0', dtype=torch.float16)
tensor(0.1514, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0529, device='cuda:0')
old_score: tensor(0.0099, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0085, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.58247375488281
Validation after dual ascent:
out_inf: tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.1370, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.1447, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.0988, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1165, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.5156, device='cuda:0', dtype=torch.float16) tensor(0.8179, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1353, device='cuda:0', dtype=torch.float16)
tensor(1.5566, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.6328, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1378, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0154, device='cuda:0')
tensor(0.0564, device='cuda:0')
old_score: tensor(0.1382, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0986, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.644572019577026
Validation after dual ascent:
out_inf: tensor(13.5156, device='cuda:0', dtype=torch.float16) tensor(0.8179, device='cuda:0', dtype=torch.float16)
tensor(1.2236, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(1.2441, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(1.3701, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.0469, device='cuda:0', dtype=torch.float16) tensor(1.0449, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1390, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.1479, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1405, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0184, device='cuda:0')
tensor(0.0438, device='cuda:0')
old_score: tensor(0.1417, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0995, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.120767116546631
Validation after dual ascent:
out_inf: tensor(19.0469, device='cuda:0', dtype=torch.float16) tensor(1.0449, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(1.2676, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.5693, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.3984, device='cuda:0', dtype=torch.float16) tensor(0.1996, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0766, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0103, device='cuda:0')
tensor(0.0390, device='cuda:0')
old_score: tensor(0.0740, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0558, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.451765775680542
Validation after dual ascent:
out_inf: tensor(3.3984, device='cuda:0', dtype=torch.float16) tensor(0.1996, device='cuda:0', dtype=torch.float16)
tensor(0.4675, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.5864, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.5444, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.2539, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.2373, device='cuda:0', dtype=torch.float16) tensor(0.0072, device='cuda:0', dtype=torch.float16)
tensor(0.2939, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.2573, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.3281, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.0385, device='cuda:0')
old_score: tensor(0.0074, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0056, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.885352611541748
Validation after dual ascent:
out_inf: tensor(3.2539, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.2417, device='cuda:0', dtype=torch.float16) tensor(0.0056, device='cuda:0', dtype=torch.float16)
tensor(0.1567, device='cuda:0', dtype=torch.float16) tensor(0.0058, device='cuda:0', dtype=torch.float16)
tensor(0.1465, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.1792, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.7461, device='cuda:0', dtype=torch.float16) tensor(0.1862, device='cuda:0', dtype=torch.float16)
tensor(1.1982, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.0688, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0080, device='cuda:0')
tensor(0.0271, device='cuda:0')
old_score: tensor(0.0686, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0539, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0889811515808105
Validation after dual ascent:
out_inf: tensor(4.7461, device='cuda:0', dtype=torch.float16) tensor(0.1862, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.6943, device='cuda:0', dtype=torch.float16) tensor(0.0575, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.1660, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.7168, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0074, device='cuda:0')
tensor(0.0238, device='cuda:0')
old_score: tensor(0.0608, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0484, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0974202156066895
Validation after dual ascent:
out_inf: tensor(3.1660, device='cuda:0', dtype=torch.float16) tensor(0.1433, device='cuda:0', dtype=torch.float16)
tensor(0.5146, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(0.4976, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0487, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.down_proj
Validation after prune:
out_inf: tensor(9.2734, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.3064, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.3145, device='cuda:0', dtype=torch.float16) tensor(0.0153, device='cuda:0', dtype=torch.float16)
tensor(0.2983, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0193, device='cuda:0')
tensor(0.0465, device='cuda:0')
old_score: tensor(0.0150, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0132, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.8189651966095
Validation after dual ascent:
out_inf: tensor(9.2734, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.2002, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.2451, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.2120, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.2119, device='cuda:0', dtype=torch.float16) tensor(0.0138, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1953, device='cuda:0', dtype=torch.float16) tensor(0.8267, device='cuda:0', dtype=torch.float16)
tensor(1.8633, device='cuda:0', dtype=torch.float16) tensor(0.1449, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1482, device='cuda:0', dtype=torch.float16)
tensor(2.1914, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
tensor(2.1328, device='cuda:0', dtype=torch.float16) tensor(0.1482, device='cuda:0', dtype=torch.float16)
tensor(0.2685, device='cuda:0')
old_score: tensor(0.1481, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1077, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.848213911056519
Validation after dual ascent:
out_inf: tensor(15.1953, device='cuda:0', dtype=torch.float16) tensor(0.8267, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.1057, device='cuda:0', dtype=torch.float16)
tensor(1.1455, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
tensor(1.4316, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.7969, device='cuda:0', dtype=torch.float16) tensor(1.0762, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.1533, device='cuda:0', dtype=torch.float16)
tensor(2.1875, device='cuda:0', dtype=torch.float16) tensor(0.1560, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1594, device='cuda:0', dtype=torch.float16)
tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.1558, device='cuda:0', dtype=torch.float16)
tensor(0.1530, device='cuda:0')
old_score: tensor(0.1561, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1107, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.906450748443604
Validation after dual ascent:
out_inf: tensor(19.7969, device='cuda:0', dtype=torch.float16) tensor(1.0762, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1087, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.1071, device='cuda:0', dtype=torch.float16)
tensor(1.2832, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(1.3311, device='cuda:0', dtype=torch.float16) tensor(0.1117, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.6543, device='cuda:0', dtype=torch.float16) tensor(0.2045, device='cuda:0', dtype=torch.float16)
tensor(0.6318, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6260, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0097, device='cuda:0')
tensor(0.0501, device='cuda:0')
old_score: tensor(0.0786, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0612, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1844193935394287
Validation after dual ascent:
out_inf: tensor(2.6543, device='cuda:0', dtype=torch.float16) tensor(0.2045, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.4912, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(0.5337, device='cuda:0', dtype=torch.float16) tensor(0.0617, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.1484, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.3691, device='cuda:0', dtype=torch.float16) tensor(0.0084, device='cuda:0', dtype=torch.float16)
tensor(0.4248, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.3306, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.0466, device='cuda:0')
old_score: tensor(0.0088, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0065, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.896271467208862
Validation after dual ascent:
out_inf: tensor(3.1484, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.3010, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.2389, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2323, device='cuda:0', dtype=torch.float16) tensor(0.0066, device='cuda:0', dtype=torch.float16)
tensor(0.2563, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.6855, device='cuda:0', dtype=torch.float16) tensor(0.2169, device='cuda:0', dtype=torch.float16)
tensor(1.2246, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(1.4160, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0084, device='cuda:0')
tensor(0.0395, device='cuda:0')
old_score: tensor(0.0772, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0588, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.097067356109619
Validation after dual ascent:
out_inf: tensor(3.6855, device='cuda:0', dtype=torch.float16) tensor(0.2169, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.8691, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.7646, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.8818, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1172, device='cuda:0', dtype=torch.float16) tensor(0.1606, device='cuda:0', dtype=torch.float16)
tensor(0.8418, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(1.0332, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(1.0371, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0686, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0037, device='cuda:0')
tensor(0.0330, device='cuda:0')
old_score: tensor(0.0680, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0525, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.105833292007446
Validation after dual ascent:
out_inf: tensor(4.1172, device='cuda:0', dtype=torch.float16) tensor(0.1606, device='cuda:0', dtype=torch.float16)
tensor(0.8799, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.6006, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.9814, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.3213, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
tensor(0.3174, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.2788, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.2769, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0112, device='cuda:0')
tensor(0.0230, device='cuda:0')
old_score: tensor(0.0181, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0159, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 41.03180241584778
Validation after dual ascent:
out_inf: tensor(1.9814, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.2139, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.2169, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
tensor(0.2203, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.1957, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.0078, device='cuda:0', dtype=torch.float16) tensor(0.8389, device='cuda:0', dtype=torch.float16)
tensor(2.7070, device='cuda:0', dtype=torch.float16) tensor(0.1794, device='cuda:0', dtype=torch.float16)
tensor(2.7344, device='cuda:0', dtype=torch.float16) tensor(0.1830, device='cuda:0', dtype=torch.float16)
tensor(3.4062, device='cuda:0', dtype=torch.float16) tensor(0.1837, device='cuda:0', dtype=torch.float16)
tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.1829, device='cuda:0', dtype=torch.float16)
tensor(0.0816, device='cuda:0')
old_score: tensor(0.1821, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1254, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.857516527175903
Validation after dual ascent:
out_inf: tensor(15.0078, device='cuda:0', dtype=torch.float16) tensor(0.8389, device='cuda:0', dtype=torch.float16)
tensor(1.8086, device='cuda:0', dtype=torch.float16) tensor(0.1265, device='cuda:0', dtype=torch.float16)
tensor(1.8291, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(1.9180, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1285, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.7969, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.1853, device='cuda:0', dtype=torch.float16)
tensor(3.0703, device='cuda:0', dtype=torch.float16) tensor(0.1882, device='cuda:0', dtype=torch.float16)
tensor(2.9297, device='cuda:0', dtype=torch.float16) tensor(0.1892, device='cuda:0', dtype=torch.float16)
tensor(2.7656, device='cuda:0', dtype=torch.float16) tensor(0.1873, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0151, device='cuda:0')
tensor(0.0624, device='cuda:0')
old_score: tensor(0.1875, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1267, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.725316286087036
Validation after dual ascent:
out_inf: tensor(16.7969, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.5840, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
tensor(1.7598, device='cuda:0', dtype=torch.float16) tensor(0.1272, device='cuda:0', dtype=torch.float16)
tensor(1.8271, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.9414, device='cuda:0', dtype=torch.float16) tensor(0.2559, device='cuda:0', dtype=torch.float16)
tensor(0.7695, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0942, device='cuda:0', dtype=torch.float16)
tensor(0.8252, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(0.7900, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.0887, device='cuda:0')
old_score: tensor(0.0946, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0705, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4564085006713867
Validation after dual ascent:
out_inf: tensor(3.9414, device='cuda:0', dtype=torch.float16) tensor(0.2559, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(0.5679, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.3789, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(0.4707, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0163, device='cuda:0', dtype=torch.float16)
tensor(0.5449, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0199, device='cuda:0')
tensor(0.0393, device='cuda:0')
old_score: tensor(0.0155, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0111, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.156680345535278
Validation after dual ascent:
out_inf: tensor(5.3789, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(0.3438, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.3379, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
tensor(0.3672, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.3154, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.3750, device='cuda:0', dtype=torch.float16) tensor(0.2942, device='cuda:0', dtype=torch.float16)
tensor(1.2676, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
tensor(1.4150, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
tensor(1.4629, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0063, device='cuda:0')
tensor(0.0336, device='cuda:0')
old_score: tensor(0.0854, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0600, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.094831228256226
Validation after dual ascent:
out_inf: tensor(4.3750, device='cuda:0', dtype=torch.float16) tensor(0.2942, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.7520, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(0.8965, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.8418, device='cuda:0', dtype=torch.float16) tensor(0.1782, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0724, device='cuda:0', dtype=torch.float16)
tensor(0.8926, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0042, device='cuda:0')
tensor(0.0287, device='cuda:0')
old_score: tensor(0.0721, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0524, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.096989393234253
Validation after dual ascent:
out_inf: tensor(2.8418, device='cuda:0', dtype=torch.float16) tensor(0.1782, device='cuda:0', dtype=torch.float16)
tensor(0.5684, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.4951, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.4561, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.3789, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(0.3779, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0135, device='cuda:0')
tensor(0.0258, device='cuda:0')
old_score: tensor(0.0214, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0173, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 40.88741183280945
Validation after dual ascent:
out_inf: tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(0.2981, device='cuda:0', dtype=torch.float16) tensor(0.0185, device='cuda:0', dtype=torch.float16)
tensor(0.2178, device='cuda:0', dtype=torch.float16) tensor(0.0168, device='cuda:0', dtype=torch.float16)
tensor(0.2456, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.2314, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(0.8418, device='cuda:0', dtype=torch.float16)
tensor(3.0391, device='cuda:0', dtype=torch.float16) tensor(0.1895, device='cuda:0', dtype=torch.float16)
tensor(3.3203, device='cuda:0', dtype=torch.float16) tensor(0.1936, device='cuda:0', dtype=torch.float16)
tensor(3.4141, device='cuda:0', dtype=torch.float16) tensor(0.1951, device='cuda:0', dtype=torch.float16)
tensor(3.0234, device='cuda:0', dtype=torch.float16) tensor(0.1923, device='cuda:0', dtype=torch.float16)
tensor(0.0808, device='cuda:0')
old_score: tensor(0.1926, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.887070894241333
Validation after dual ascent:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(0.8418, device='cuda:0', dtype=torch.float16)
tensor(2.1641, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1261, device='cuda:0', dtype=torch.float16)
tensor(1.6445, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.0781, device='cuda:0', dtype=torch.float16) tensor(0.9917, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.1918, device='cuda:0', dtype=torch.float16)
tensor(3.1641, device='cuda:0', dtype=torch.float16) tensor(0.1947, device='cuda:0', dtype=torch.float16)
tensor(3.3438, device='cuda:0', dtype=torch.float16) tensor(0.1958, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1930, device='cuda:0', dtype=torch.float16)
tensor(0.0773, device='cuda:0')
old_score: tensor(0.1937, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1239, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.9235360622406
Validation after dual ascent:
out_inf: tensor(16.0781, device='cuda:0', dtype=torch.float16) tensor(0.9917, device='cuda:0', dtype=torch.float16)
tensor(1.5996, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(2.0332, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.1260, device='cuda:0', dtype=torch.float16)
tensor(1.6748, device='cuda:0', dtype=torch.float16) tensor(0.1247, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.1172, device='cuda:0', dtype=torch.float16) tensor(0.2642, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.1005, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0163, device='cuda:0')
tensor(0.0693, device='cuda:0')
old_score: tensor(0.1005, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0705, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1899054050445557
Validation after dual ascent:
out_inf: tensor(4.1172, device='cuda:0', dtype=torch.float16) tensor(0.2642, device='cuda:0', dtype=torch.float16)
tensor(0.7090, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.6538, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.0039, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.6860, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0202, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
tensor(0.0199, device='cuda:0')
old_score: tensor(0.0193, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0130, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.881861209869385
Validation after dual ascent:
out_inf: tensor(4.0039, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.3423, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.3184, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.3008, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.5781, device='cuda:0', dtype=torch.float16) tensor(0.3389, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(2.1152, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
tensor(1.9570, device='cuda:0', dtype=torch.float16) tensor(0.0926, device='cuda:0', dtype=torch.float16)
tensor(1.8398, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0071, device='cuda:0')
tensor(0.0383, device='cuda:0')
old_score: tensor(0.0923, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0627, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.107540607452393
Validation after dual ascent:
out_inf: tensor(4.5781, device='cuda:0', dtype=torch.float16) tensor(0.3389, device='cuda:0', dtype=torch.float16)
tensor(1.0332, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.9443, device='cuda:0', dtype=torch.float16) tensor(0.0610, device='cuda:0', dtype=torch.float16)
tensor(0.9824, device='cuda:0', dtype=torch.float16) tensor(0.0639, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4336, device='cuda:0', dtype=torch.float16) tensor(0.1919, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.9453, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0036, device='cuda:0')
tensor(0.0328, device='cuda:0')
old_score: tensor(0.0785, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0551, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.107014179229736
Validation after dual ascent:
out_inf: tensor(4.4336, device='cuda:0', dtype=torch.float16) tensor(0.1919, device='cuda:0', dtype=torch.float16)
tensor(0.6006, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.4980, device='cuda:0', dtype=torch.float16) tensor(0.0536, device='cuda:0', dtype=torch.float16)
tensor(0.5713, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0555, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5332, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0252, device='cuda:0', dtype=torch.float16)
tensor(0.4551, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.5098, device='cuda:0', dtype=torch.float16) tensor(0.0237, device='cuda:0', dtype=torch.float16)
tensor(0.4541, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0198, device='cuda:0')
tensor(0.0201, device='cuda:0')
old_score: tensor(0.0245, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0190, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 36.16462278366089
Validation after dual ascent:
out_inf: tensor(1.5332, device='cuda:0', dtype=torch.float16) tensor(0.0645, device='cuda:0', dtype=torch.float16)
tensor(0.2500, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
tensor(0.2710, device='cuda:0', dtype=torch.float16) tensor(0.0190, device='cuda:0', dtype=torch.float16)
tensor(0.3276, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2031, device='cuda:0', dtype=torch.float16) tensor(0.7969, device='cuda:0', dtype=torch.float16)
tensor(3.4219, device='cuda:0', dtype=torch.float16) tensor(0.1842, device='cuda:0', dtype=torch.float16)
tensor(4.0703, device='cuda:0', dtype=torch.float16) tensor(0.1912, device='cuda:0', dtype=torch.float16)
tensor(3.5938, device='cuda:0', dtype=torch.float16) tensor(0.1920, device='cuda:0', dtype=torch.float16)
tensor(3.5625, device='cuda:0', dtype=torch.float16) tensor(0.1864, device='cuda:0', dtype=torch.float16)
tensor(0.1052, device='cuda:0')
old_score: tensor(0.1885, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.8822500705719
Validation after dual ascent:
out_inf: tensor(17.2031, device='cuda:0', dtype=torch.float16) tensor(0.7969, device='cuda:0', dtype=torch.float16)
tensor(1.8223, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.8652, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(2.4531, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.9707, device='cuda:0', dtype=torch.float16) tensor(0.1250, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.1719, device='cuda:0', dtype=torch.float16) tensor(1.0195, device='cuda:0', dtype=torch.float16)
tensor(2.5801, device='cuda:0', dtype=torch.float16) tensor(0.1871, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.1923, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.1913, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.1888, device='cuda:0', dtype=torch.float16)
tensor(0.1164, device='cuda:0')
old_score: tensor(0.1899, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1245, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.912582874298096
Validation after dual ascent:
out_inf: tensor(19.1719, device='cuda:0', dtype=torch.float16) tensor(1.0195, device='cuda:0', dtype=torch.float16)
tensor(1.4814, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(1.8320, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8164, device='cuda:0', dtype=torch.float16) tensor(0.2725, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.1023, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(0.7998, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.0518, device='cuda:0')
old_score: tensor(0.1033, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0723, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.873680114746094
Validation after dual ascent:
out_inf: tensor(4.8164, device='cuda:0', dtype=torch.float16) tensor(0.2725, device='cuda:0', dtype=torch.float16)
tensor(0.6201, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.7056, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0738, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0129, device='cuda:0')
tensor(0.0326, device='cuda:0')
old_score: tensor(0.0219, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0150, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.238155126571655
Validation after dual ascent:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.0538, device='cuda:0', dtype=torch.float16)
tensor(0.3984, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
tensor(0.3828, device='cuda:0', dtype=torch.float16) tensor(0.0156, device='cuda:0', dtype=torch.float16)
tensor(0.3711, device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0146, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.7422, device='cuda:0', dtype=torch.float16) tensor(0.3120, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.0937, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.0946, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.0928, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0058, device='cuda:0')
tensor(0.0450, device='cuda:0')
old_score: tensor(0.0934, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0659, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.106090545654297
Validation after dual ascent:
out_inf: tensor(5.7422, device='cuda:0', dtype=torch.float16) tensor(0.3120, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(1.1055, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.up_proj
Validation after prune:
out_inf: tensor(8.0312, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(1.7305, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.0842, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0039, device='cuda:0')
tensor(0.0405, device='cuda:0')
old_score: tensor(0.0833, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0597, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1035449504852295
Validation after dual ascent:
out_inf: tensor(8.0312, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.5161, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.3496, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0174, device='cuda:0')
tensor(0.0386, device='cuda:0')
old_score: tensor(0.0266, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0220, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.80890440940857
Validation after dual ascent:
out_inf: tensor(2.3496, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(0.3660, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.3281, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.3096, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.4688, device='cuda:0', dtype=torch.float16) tensor(0.7993, device='cuda:0', dtype=torch.float16)
tensor(2.5195, device='cuda:0', dtype=torch.float16) tensor(0.1907, device='cuda:0', dtype=torch.float16)
tensor(2.7422, device='cuda:0', dtype=torch.float16) tensor(0.1989, device='cuda:0', dtype=torch.float16)
tensor(2.7578, device='cuda:0', dtype=torch.float16) tensor(0.2025, device='cuda:0', dtype=torch.float16)
tensor(2.5195, device='cuda:0', dtype=torch.float16) tensor(0.1929, device='cuda:0', dtype=torch.float16)
tensor(0.0756, device='cuda:0')
old_score: tensor(0.1963, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1338, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.865315914154053
Validation after dual ascent:
out_inf: tensor(14.4688, device='cuda:0', dtype=torch.float16) tensor(0.7993, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.0410, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.1967, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.2035, device='cuda:0', dtype=torch.float16)
tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.2054, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.1982, device='cuda:0', dtype=torch.float16)
tensor(0.0832, device='cuda:0')
old_score: tensor(0.2009, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1354, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.907262086868286
Validation after dual ascent:
out_inf: tensor(18.8594, device='cuda:0', dtype=torch.float16) tensor(1.0410, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.6055, device='cuda:0', dtype=torch.float16) tensor(0.1334, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.7051, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.8203, device='cuda:0', dtype=torch.float16) tensor(0.2812, device='cuda:0', dtype=torch.float16)
tensor(0.9033, device='cuda:0', dtype=torch.float16) tensor(0.1066, device='cuda:0', dtype=torch.float16)
tensor(0.9619, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.1102, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0137, device='cuda:0')
tensor(0.0615, device='cuda:0')
old_score: tensor(0.1082, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0779, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1848554611206055
Validation after dual ascent:
out_inf: tensor(6.8203, device='cuda:0', dtype=torch.float16) tensor(0.2812, device='cuda:0', dtype=torch.float16)
tensor(0.7026, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.6782, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.6587, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.9141, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0194, device='cuda:0')
tensor(0.0386, device='cuda:0')
old_score: tensor(0.0245, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0175, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.296943664550781
Validation after dual ascent:
out_inf: tensor(3.9141, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.3301, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.3867, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
tensor(0.3594, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.9141, device='cuda:0', dtype=torch.float16) tensor(0.3186, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(1.8613, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(1.7988, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(1.7197, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0059, device='cuda:0')
tensor(0.0511, device='cuda:0')
old_score: tensor(0.0953, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0692, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.101496934890747
Validation after dual ascent:
out_inf: tensor(6.9141, device='cuda:0', dtype=torch.float16) tensor(0.3186, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(1.0879, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.0695, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.8945, device='cuda:0', dtype=torch.float16) tensor(0.2172, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(1.1680, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.0879, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0043, device='cuda:0')
tensor(0.0476, device='cuda:0')
old_score: tensor(0.0867, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0638, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.100745677947998
Validation after dual ascent:
out_inf: tensor(4.8945, device='cuda:0', dtype=torch.float16) tensor(0.2172, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
tensor(0.5850, device='cuda:0', dtype=torch.float16) tensor(0.0623, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
tensor(0.4072, device='cuda:0', dtype=torch.float16) tensor(0.0286, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0292, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0084, device='cuda:0')
tensor(0.0094, device='cuda:0')
old_score: tensor(0.0294, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0248, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.811335563659668
Validation after dual ascent:
out_inf: tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.0745, device='cuda:0', dtype=torch.float16)
tensor(0.3752, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.3462, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.3291, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(0.3813, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.0547, device='cuda:0', dtype=torch.float16) tensor(0.7861, device='cuda:0', dtype=torch.float16)
tensor(2.7578, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(3.2305, device='cuda:0', dtype=torch.float16) tensor(0.1989, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.2031, device='cuda:0', dtype=torch.float16)
tensor(2.9141, device='cuda:0', dtype=torch.float16) tensor(0.1941, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0178, device='cuda:0')
tensor(0.2236, device='cuda:0')
old_score: tensor(0.1975, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1384, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.452645778656006
Validation after dual ascent:
out_inf: tensor(14.0547, device='cuda:0', dtype=torch.float16) tensor(0.7861, device='cuda:0', dtype=torch.float16)
tensor(2.0586, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1350, device='cuda:0', dtype=torch.float16)
tensor(1.6572, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1389, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.5000, device='cuda:0', dtype=torch.float16) tensor(1.0439, device='cuda:0', dtype=torch.float16)
tensor(2.5859, device='cuda:0', dtype=torch.float16) tensor(0.2000, device='cuda:0', dtype=torch.float16)
tensor(2.1523, device='cuda:0', dtype=torch.float16) tensor(0.2030, device='cuda:0', dtype=torch.float16)
tensor(2.3477, device='cuda:0', dtype=torch.float16) tensor(0.2072, device='cuda:0', dtype=torch.float16)
tensor(2.3027, device='cuda:0', dtype=torch.float16) tensor(0.2000, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0198, device='cuda:0')
tensor(0.2260, device='cuda:0')
old_score: tensor(0.2024, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1404, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.456629753112793
Validation after dual ascent:
out_inf: tensor(16.5000, device='cuda:0', dtype=torch.float16) tensor(1.0439, device='cuda:0', dtype=torch.float16)
tensor(1.8037, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(1.6152, device='cuda:0', dtype=torch.float16) tensor(0.1368, device='cuda:0', dtype=torch.float16)
tensor(1.9160, device='cuda:0', dtype=torch.float16) tensor(0.1415, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1409, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.1484, device='cuda:0', dtype=torch.float16) tensor(0.2874, device='cuda:0', dtype=torch.float16)
tensor(0.9639, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(0.9492, device='cuda:0', dtype=torch.float16) tensor(0.1090, device='cuda:0', dtype=torch.float16)
tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0086, device='cuda:0')
tensor(0.1271, device='cuda:0')
old_score: tensor(0.1089, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0804, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4482080936431885
Validation after dual ascent:
out_inf: tensor(7.1484, device='cuda:0', dtype=torch.float16) tensor(0.2874, device='cuda:0', dtype=torch.float16)
tensor(0.6924, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0785, device='cuda:0', dtype=torch.float16)
tensor(0.6846, device='cuda:0', dtype=torch.float16) tensor(0.0811, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0808, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.2852, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
tensor(0.5967, device='cuda:0', dtype=torch.float16) tensor(0.0316, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0161, device='cuda:0')
tensor(0.0174, device='cuda:0')
old_score: tensor(0.0316, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0218, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.180267572402954
Validation after dual ascent:
out_inf: tensor(5.2852, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
tensor(0.3594, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(0.4236, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(0.3818, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.1641, device='cuda:0', dtype=torch.float16) tensor(0.3372, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
tensor(1.9043, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(1.7412, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0063, device='cuda:0')
tensor(0.0534, device='cuda:0')
old_score: tensor(0.0961, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0707, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.088011026382446
Validation after dual ascent:
out_inf: tensor(6.1641, device='cuda:0', dtype=torch.float16) tensor(0.3372, device='cuda:0', dtype=torch.float16)
tensor(1.4785, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(1.3408, device='cuda:0', dtype=torch.float16) tensor(0.0677, device='cuda:0', dtype=torch.float16)
tensor(1.2119, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.5977, device='cuda:0', dtype=torch.float16) tensor(0.2329, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(1.0371, device='cuda:0', dtype=torch.float16) tensor(0.0907, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0879, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0045, device='cuda:0')
tensor(0.0499, device='cuda:0')
old_score: tensor(0.0889, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0663, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.089270114898682
Validation after dual ascent:
out_inf: tensor(3.5977, device='cuda:0', dtype=torch.float16) tensor(0.2329, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(0.5791, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.0918, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0307, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0106, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.0325, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0273, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.95302104949951
Validation after dual ascent:
out_inf: tensor(3.0918, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(0.4893, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.3652, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
tensor(0.3320, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
tensor(0.3896, device='cuda:0', dtype=torch.float16) tensor(0.0280, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.6562, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(4.1953, device='cuda:0', dtype=torch.float16) tensor(0.2037, device='cuda:0', dtype=torch.float16)
tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.2050, device='cuda:0', dtype=torch.float16)
tensor(4.1719, device='cuda:0', dtype=torch.float16) tensor(0.2130, device='cuda:0', dtype=torch.float16)
tensor(3.9297, device='cuda:0', dtype=torch.float16) tensor(0.2004, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0125, device='cuda:0')
tensor(0.0755, device='cuda:0')
old_score: tensor(0.2056, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1450, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1798434257507324
Validation after dual ascent:
out_inf: tensor(19.6562, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(2.3164, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
tensor(2.2070, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
tensor(2.2754, device='cuda:0', dtype=torch.float16) tensor(0.1476, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.3594, device='cuda:0', dtype=torch.float16) tensor(1.0127, device='cuda:0', dtype=torch.float16)
tensor(2.6211, device='cuda:0', dtype=torch.float16) tensor(0.2046, device='cuda:0', dtype=torch.float16)
tensor(2.7148, device='cuda:0', dtype=torch.float16) tensor(0.2057, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.2119, device='cuda:0', dtype=torch.float16)
tensor(2.6602, device='cuda:0', dtype=torch.float16) tensor(0.2031, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0137, device='cuda:0')
tensor(0.0684, device='cuda:0')
old_score: tensor(0.2063, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1440, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1859381198883057
Validation after dual ascent:
out_inf: tensor(16.3594, device='cuda:0', dtype=torch.float16) tensor(1.0127, device='cuda:0', dtype=torch.float16)
tensor(1.7402, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(1.7061, device='cuda:0', dtype=torch.float16) tensor(0.1393, device='cuda:0', dtype=torch.float16)
tensor(2.0137, device='cuda:0', dtype=torch.float16) tensor(0.1461, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.1448, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.2266, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(1.0127, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(0.9482, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0054, device='cuda:0')
tensor(0.0602, device='cuda:0')
old_score: tensor(0.1263, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0943, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1771020889282227
Validation after dual ascent:
out_inf: tensor(8.2266, device='cuda:0', dtype=torch.float16) tensor(0.3264, device='cuda:0', dtype=torch.float16)
tensor(0.7632, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(0.7598, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(0.9004, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(0.8105, device='cuda:0', dtype=torch.float16) tensor(0.0949, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.7070, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0348, device='cuda:0', dtype=torch.float16)
tensor(0.7974, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.7383, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0076, device='cuda:0')
tensor(0.0113, device='cuda:0')
old_score: tensor(0.0362, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0246, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1759891510009766
Validation after dual ascent:
out_inf: tensor(6.7070, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0228, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.0547, device='cuda:0', dtype=torch.float16) tensor(0.3459, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.0996, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.0992, device='cuda:0', dtype=torch.float16)
tensor(2.1191, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.9307, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0071, device='cuda:0')
tensor(0.0601, device='cuda:0')
old_score: tensor(0.1002, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0735, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.085578441619873
Validation after dual ascent:
out_inf: tensor(6.0547, device='cuda:0', dtype=torch.float16) tensor(0.3459, device='cuda:0', dtype=torch.float16)
tensor(1.3789, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(1.2666, device='cuda:0', dtype=torch.float16) tensor(0.0755, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0586, device='cuda:0', dtype=torch.float16) tensor(0.2351, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0925, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0962, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0051, device='cuda:0')
tensor(0.0569, device='cuda:0')
old_score: tensor(0.0935, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0698, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.088381767272949
Validation after dual ascent:
out_inf: tensor(4.0586, device='cuda:0', dtype=torch.float16) tensor(0.2351, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0702, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(0.8071, device='cuda:0', dtype=torch.float16) tensor(0.0342, device='cuda:0', dtype=torch.float16)
tensor(0.7773, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.7842, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0063, device='cuda:0')
tensor(0.0130, device='cuda:0')
old_score: tensor(0.0341, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0283, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.931005001068115
Validation after dual ascent:
out_inf: tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
tensor(0.4658, device='cuda:0', dtype=torch.float16) tensor(0.0286, device='cuda:0', dtype=torch.float16)
tensor(0.3823, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.5156, device='cuda:0', dtype=torch.float16) tensor(0.7852, device='cuda:0', dtype=torch.float16)
tensor(3.1875, device='cuda:0', dtype=torch.float16) tensor(0.2094, device='cuda:0', dtype=torch.float16)
tensor(2.8750, device='cuda:0', dtype=torch.float16) tensor(0.2115, device='cuda:0', dtype=torch.float16)
tensor(3.0898, device='cuda:0', dtype=torch.float16) tensor(0.2208, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.2069, device='cuda:0', dtype=torch.float16)
tensor(0.1500, device='cuda:0')
old_score: tensor(0.2122, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1509, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.81900405883789
Validation after dual ascent:
out_inf: tensor(17.5156, device='cuda:0', dtype=torch.float16) tensor(0.7852, device='cuda:0', dtype=torch.float16)
tensor(2.1035, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(1.9883, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
tensor(1.8799, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1501, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.3594, device='cuda:0', dtype=torch.float16) tensor(1.0225, device='cuda:0', dtype=torch.float16)
tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.2168, device='cuda:0', dtype=torch.float16)
tensor(2.5469, device='cuda:0', dtype=torch.float16) tensor(0.2196, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.2290, device='cuda:0', dtype=torch.float16)
tensor(2.4688, device='cuda:0', dtype=torch.float16) tensor(0.2147, device='cuda:0', dtype=torch.float16)
tensor(0.1674, device='cuda:0')
old_score: tensor(0.2201, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1542, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.866532802581787
Validation after dual ascent:
out_inf: tensor(15.3594, device='cuda:0', dtype=torch.float16) tensor(1.0225, device='cuda:0', dtype=torch.float16)
tensor(1.8369, device='cuda:0', dtype=torch.float16) tensor(0.1548, device='cuda:0', dtype=torch.float16)
tensor(1.5801, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
tensor(1.9004, device='cuda:0', dtype=torch.float16) tensor(0.1587, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.1534, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.2344, device='cuda:0', dtype=torch.float16) tensor(0.3208, device='cuda:0', dtype=torch.float16)
tensor(1.0557, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(1.0693, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(0.9976, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0186, device='cuda:0')
tensor(0.0822, device='cuda:0')
old_score: tensor(0.1250, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0933, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.639312505722046
Validation after dual ascent:
out_inf: tensor(6.2344, device='cuda:0', dtype=torch.float16) tensor(0.3208, device='cuda:0', dtype=torch.float16)
tensor(0.8530, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(0.8887, device='cuda:0', dtype=torch.float16) tensor(0.0905, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0960, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(0.7930, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
tensor(1.5928, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.8877, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0137, device='cuda:0')
tensor(0.0232, device='cuda:0')
old_score: tensor(0.0380, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0260, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.6308434009552
Validation after dual ascent:
out_inf: tensor(6.2227, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.3416, device='cuda:0', dtype=torch.float16)
tensor(1.9648, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1015, device='cuda:0', dtype=torch.float16)
tensor(2.0059, device='cuda:0', dtype=torch.float16) tensor(0.1066, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0072, device='cuda:0')
tensor(0.0656, device='cuda:0')
old_score: tensor(0.1026, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0753, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.093682527542114
Validation after dual ascent:
out_inf: tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.3416, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.0722, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.6211, device='cuda:0', dtype=torch.float16) tensor(0.2424, device='cuda:0', dtype=torch.float16)
tensor(0.9746, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0965, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0055, device='cuda:0')
tensor(0.0633, device='cuda:0')
old_score: tensor(0.0975, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0726, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.096351146697998
Validation after dual ascent:
out_inf: tensor(4.6211, device='cuda:0', dtype=torch.float16) tensor(0.2424, device='cuda:0', dtype=torch.float16)
tensor(0.7139, device='cuda:0', dtype=torch.float16) tensor(0.0730, device='cuda:0', dtype=torch.float16)
tensor(0.6660, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.0879, device='cuda:0', dtype=torch.float16)
tensor(0.5254, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.5879, device='cuda:0', dtype=torch.float16) tensor(0.0367, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0041, device='cuda:0')
tensor(0.0064, device='cuda:0')
old_score: tensor(0.0356, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0298, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.951300382614136
Validation after dual ascent:
out_inf: tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.0879, device='cuda:0', dtype=torch.float16)
tensor(0.3867, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
tensor(0.3726, device='cuda:0', dtype=torch.float16) tensor(0.0281, device='cuda:0', dtype=torch.float16)
tensor(0.3569, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.3906, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(2.8672, device='cuda:0', dtype=torch.float16) tensor(0.2104, device='cuda:0', dtype=torch.float16)
tensor(2.8008, device='cuda:0', dtype=torch.float16) tensor(0.2129, device='cuda:0', dtype=torch.float16)
tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.2209, device='cuda:0', dtype=torch.float16)
tensor(3.0195, device='cuda:0', dtype=torch.float16) tensor(0.2084, device='cuda:0', dtype=torch.float16)
tensor(0.1554, device='cuda:0')
old_score: tensor(0.2133, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1519, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.819318056106567
Validation after dual ascent:
out_inf: tensor(14.3906, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(1.8604, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.6602, device='cuda:0', dtype=torch.float16) tensor(0.1466, device='cuda:0', dtype=torch.float16)
tensor(1.7754, device='cuda:0', dtype=torch.float16) tensor(0.1576, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.2031, device='cuda:0', dtype=torch.float16) tensor(0.9844, device='cuda:0', dtype=torch.float16)
tensor(2.3984, device='cuda:0', dtype=torch.float16) tensor(0.2146, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.2168, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.2258, device='cuda:0', dtype=torch.float16)
tensor(2.2949, device='cuda:0', dtype=torch.float16) tensor(0.2131, device='cuda:0', dtype=torch.float16)
tensor(0.1631, device='cuda:0')
old_score: tensor(0.2175, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1532, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.864412069320679
Validation after dual ascent:
out_inf: tensor(17.2031, device='cuda:0', dtype=torch.float16) tensor(0.9844, device='cuda:0', dtype=torch.float16)
tensor(1.7627, device='cuda:0', dtype=torch.float16) tensor(0.1532, device='cuda:0', dtype=torch.float16)
tensor(1.6357, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
tensor(2.1523, device='cuda:0', dtype=torch.float16) tensor(0.1588, device='cuda:0', dtype=torch.float16)
tensor(1.7148, device='cuda:0', dtype=torch.float16) tensor(0.1525, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.0508, device='cuda:0', dtype=torch.float16) tensor(0.3218, device='cuda:0', dtype=torch.float16)
tensor(1.0723, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
tensor(0.9858, device='cuda:0', dtype=torch.float16) tensor(0.1302, device='cuda:0', dtype=torch.float16)
tensor(1.1855, device='cuda:0', dtype=torch.float16) tensor(0.1335, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0172, device='cuda:0')
tensor(0.0794, device='cuda:0')
old_score: tensor(0.1306, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0980, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.636924028396606
Validation after dual ascent:
out_inf: tensor(5.0508, device='cuda:0', dtype=torch.float16) tensor(0.3218, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(0.8618, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(0.8916, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(0.8018, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.3477, device='cuda:0', dtype=torch.float16) tensor(0.0893, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0387, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.8369, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0157, device='cuda:0')
tensor(0.0358, device='cuda:0')
old_score: tensor(0.0392, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0263, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.545473098754883
Validation after dual ascent:
out_inf: tensor(5.3477, device='cuda:0', dtype=torch.float16) tensor(0.0893, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(0.4443, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.4951, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.3789, device='cuda:0', dtype=torch.float16) tensor(0.3582, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.1053, device='cuda:0', dtype=torch.float16)
tensor(2.1074, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.1098, device='cuda:0', dtype=torch.float16)
tensor(2.3008, device='cuda:0', dtype=torch.float16) tensor(0.1048, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0078, device='cuda:0')
tensor(0.0728, device='cuda:0')
old_score: tensor(0.1059, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0769, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.098246812820435
Validation after dual ascent:
out_inf: tensor(7.3789, device='cuda:0', dtype=torch.float16) tensor(0.3582, device='cuda:0', dtype=torch.float16)
tensor(1.2930, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0800, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.0771, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.8555, device='cuda:0', dtype=torch.float16) tensor(0.2554, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(0.9990, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0062, device='cuda:0')
tensor(0.0715, device='cuda:0')
old_score: tensor(0.1016, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0751, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.094273805618286
Validation after dual ascent:
out_inf: tensor(4.8555, device='cuda:0', dtype=torch.float16) tensor(0.2554, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.1484, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0377, device='cuda:0', dtype=torch.float16)
tensor(0.7329, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.7065, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0063, device='cuda:0')
tensor(0.0390, device='cuda:0')
old_score: tensor(0.0394, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0328, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.153631448745728
Validation after dual ascent:
out_inf: tensor(4.1484, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.4165, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.4707, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.4265, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.4688, device='cuda:0', dtype=torch.float16) tensor(0.7954, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.2189, device='cuda:0', dtype=torch.float16)
tensor(2.6797, device='cuda:0', dtype=torch.float16) tensor(0.2153, device='cuda:0', dtype=torch.float16)
tensor(3.1875, device='cuda:0', dtype=torch.float16) tensor(0.2292, device='cuda:0', dtype=torch.float16)
tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.2152, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0128, device='cuda:0')
tensor(0.0839, device='cuda:0')
old_score: tensor(0.2196, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1539, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.174628973007202
Validation after dual ascent:
out_inf: tensor(15.4688, device='cuda:0', dtype=torch.float16) tensor(0.7954, device='cuda:0', dtype=torch.float16)
tensor(1.8486, device='cuda:0', dtype=torch.float16) tensor(0.1542, device='cuda:0', dtype=torch.float16)
tensor(1.7178, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(1.9404, device='cuda:0', dtype=torch.float16) tensor(0.1600, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.1543, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.4688, device='cuda:0', dtype=torch.float16) tensor(1.0566, device='cuda:0', dtype=torch.float16)
tensor(2.7109, device='cuda:0', dtype=torch.float16) tensor(0.2244, device='cuda:0', dtype=torch.float16)
tensor(2.6230, device='cuda:0', dtype=torch.float16) tensor(0.2238, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.2354, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.2227, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0148, device='cuda:0')
tensor(0.0777, device='cuda:0')
old_score: tensor(0.2266, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1554, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1780776977539062
Validation after dual ascent:
out_inf: tensor(18.4688, device='cuda:0', dtype=torch.float16) tensor(1.0566, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(1.7070, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(1.6709, device='cuda:0', dtype=torch.float16) tensor(0.1559, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.4219, device='cuda:0', dtype=torch.float16) tensor(0.3210, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.1311, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0067, device='cuda:0')
tensor(0.0660, device='cuda:0')
old_score: tensor(0.1313, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0972, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1717066764831543
Validation after dual ascent:
out_inf: tensor(4.4219, device='cuda:0', dtype=torch.float16) tensor(0.3210, device='cuda:0', dtype=torch.float16)
tensor(0.7783, device='cuda:0', dtype=torch.float16) tensor(0.0976, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.0929, device='cuda:0', dtype=torch.float16)
tensor(0.7803, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.o_proj
Validation after prune:
out_inf: tensor(8.2266, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0416, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0122, device='cuda:0')
tensor(0.0118, device='cuda:0')
old_score: tensor(0.0430, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0282, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4440948963165283
Validation after dual ascent:
out_inf: tensor(8.2266, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.3828, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.3203, device='cuda:0', dtype=torch.float16) tensor(0.3679, device='cuda:0', dtype=torch.float16)
tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.1090, device='cuda:0', dtype=torch.float16)
tensor(2.6055, device='cuda:0', dtype=torch.float16) tensor(0.1055, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(2.2773, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0083, device='cuda:0')
tensor(0.0838, device='cuda:0')
old_score: tensor(0.1091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0804, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.077558279037476
Validation after dual ascent:
out_inf: tensor(7.3203, device='cuda:0', dtype=torch.float16) tensor(0.3679, device='cuda:0', dtype=torch.float16)
tensor(1.5723, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
tensor(1.6221, device='cuda:0', dtype=torch.float16) tensor(0.0752, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(1.6191, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.7773, device='cuda:0', dtype=torch.float16) tensor(0.2678, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.1051, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.1992, device='cuda:0', dtype=torch.float16) tensor(0.1040, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0069, device='cuda:0')
tensor(0.0823, device='cuda:0')
old_score: tensor(0.1049, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0788, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0774924755096436
Validation after dual ascent:
out_inf: tensor(4.7773, device='cuda:0', dtype=torch.float16) tensor(0.2678, device='cuda:0', dtype=torch.float16)
tensor(0.7705, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0827, device='cuda:0', dtype=torch.float16)
tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.2910, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0434, device='cuda:0', dtype=torch.float16)
tensor(0.6587, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.6758, device='cuda:0', dtype=torch.float16) tensor(0.0433, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0041, device='cuda:0')
tensor(0.0450, device='cuda:0')
old_score: tensor(0.0422, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0353, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.152455806732178
Validation after dual ascent:
out_inf: tensor(3.2910, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.4741, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.5400, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.4653, device='cuda:0', dtype=torch.float16) tensor(0.0367, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.8125, device='cuda:0', dtype=torch.float16) tensor(0.7827, device='cuda:0', dtype=torch.float16)
tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.2046, device='cuda:0', dtype=torch.float16)
tensor(2.6758, device='cuda:0', dtype=torch.float16) tensor(0.2014, device='cuda:0', dtype=torch.float16)
tensor(2.5898, device='cuda:0', dtype=torch.float16) tensor(0.2163, device='cuda:0', dtype=torch.float16)
tensor(2.9375, device='cuda:0', dtype=torch.float16) tensor(0.2042, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0092, device='cuda:0')
tensor(0.0624, device='cuda:0')
old_score: tensor(0.2065, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1473, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1723263263702393
Validation after dual ascent:
out_inf: tensor(15.8125, device='cuda:0', dtype=torch.float16) tensor(0.7827, device='cuda:0', dtype=torch.float16)
tensor(1.9326, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
tensor(1.6455, device='cuda:0', dtype=torch.float16) tensor(0.1541, device='cuda:0', dtype=torch.float16)
tensor(1.6836, device='cuda:0', dtype=torch.float16) tensor(0.1488, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.3125, device='cuda:0', dtype=torch.float16) tensor(1.0215, device='cuda:0', dtype=torch.float16)
tensor(2.5625, device='cuda:0', dtype=torch.float16) tensor(0.2150, device='cuda:0', dtype=torch.float16)
tensor(2.5684, device='cuda:0', dtype=torch.float16) tensor(0.2125, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.2274, device='cuda:0', dtype=torch.float16)
tensor(2.8516, device='cuda:0', dtype=torch.float16) tensor(0.2153, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0115, device='cuda:0')
tensor(0.0592, device='cuda:0')
old_score: tensor(0.2175, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1514, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.178081750869751
Validation after dual ascent:
out_inf: tensor(15.3125, device='cuda:0', dtype=torch.float16) tensor(1.0215, device='cuda:0', dtype=torch.float16)
tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.1523, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1422, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8945, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.1311, device='cuda:0', dtype=torch.float16)
tensor(1.0342, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(1.0967, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.0205, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0128, device='cuda:0')
tensor(0.2175, device='cuda:0')
old_score: tensor(0.1313, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0984, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4440088272094727
Validation after dual ascent:
out_inf: tensor(4.8945, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(0.8374, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
tensor(0.7681, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
tensor(0.8271, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.8330, device='cuda:0', dtype=torch.float16) tensor(0.0995, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.2734, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(0.7432, device='cuda:0', dtype=torch.float16) tensor(0.0415, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(1.0371, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(1.0918, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0197, device='cuda:0')
tensor(0.0146, device='cuda:0')
old_score: tensor(0.0418, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0287, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4484431743621826
Validation after dual ascent:
out_inf: tensor(6.2734, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0292, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.4297, device='cuda:0', dtype=torch.float16) tensor(0.3875, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(2.0410, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
tensor(1.9336, device='cuda:0', dtype=torch.float16) tensor(0.1183, device='cuda:0', dtype=torch.float16)
tensor(2.1602, device='cuda:0', dtype=torch.float16) tensor(0.1122, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0093, device='cuda:0')
tensor(0.0906, device='cuda:0')
old_score: tensor(0.1135, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0816, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.088576316833496
Validation after dual ascent:
out_inf: tensor(7.4297, device='cuda:0', dtype=torch.float16) tensor(0.3875, device='cuda:0', dtype=torch.float16)
tensor(1.5840, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.0756, device='cuda:0', dtype=torch.float16)
tensor(1.2119, device='cuda:0', dtype=torch.float16) tensor(0.0857, device='cuda:0', dtype=torch.float16)
tensor(1.5020, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.2827, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
tensor(1.4727, device='cuda:0', dtype=torch.float16) tensor(0.1057, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0078, device='cuda:0')
tensor(0.0894, device='cuda:0')
old_score: tensor(0.1093, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.087233781814575
Validation after dual ascent:
out_inf: tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.2827, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(0.8027, device='cuda:0', dtype=torch.float16) tensor(0.0741, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.4648, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(0.8271, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.6792, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0046, device='cuda:0')
tensor(0.0533, device='cuda:0')
old_score: tensor(0.0460, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0379, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.131529808044434
Validation after dual ascent:
out_inf: tensor(5.4648, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(0.4290, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.3745, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.3750, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.6050, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.3750, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(3.7969, device='cuda:0', dtype=torch.float16) tensor(0.2115, device='cuda:0', dtype=torch.float16)
tensor(3.3867, device='cuda:0', dtype=torch.float16) tensor(0.2053, device='cuda:0', dtype=torch.float16)
tensor(3.8672, device='cuda:0', dtype=torch.float16) tensor(0.2195, device='cuda:0', dtype=torch.float16)
tensor(2.8984, device='cuda:0', dtype=torch.float16) tensor(0.2072, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0100, device='cuda:0')
tensor(0.0651, device='cuda:0')
old_score: tensor(0.2109, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1462, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.180558443069458
Validation after dual ascent:
out_inf: tensor(17.3750, device='cuda:0', dtype=torch.float16) tensor(0.7935, device='cuda:0', dtype=torch.float16)
tensor(1.8496, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(2.2266, device='cuda:0', dtype=torch.float16) tensor(0.1531, device='cuda:0', dtype=torch.float16)
tensor(2.1602, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.5625, device='cuda:0', dtype=torch.float16) tensor(1.0508, device='cuda:0', dtype=torch.float16)
tensor(2.4609, device='cuda:0', dtype=torch.float16) tensor(0.2192, device='cuda:0', dtype=torch.float16)
tensor(2.4688, device='cuda:0', dtype=torch.float16) tensor(0.2152, device='cuda:0', dtype=torch.float16)
tensor(2.7969, device='cuda:0', dtype=torch.float16) tensor(0.2300, device='cuda:0', dtype=torch.float16)
tensor(2.5000, device='cuda:0', dtype=torch.float16) tensor(0.2166, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0130, device='cuda:0')
tensor(0.0604, device='cuda:0')
old_score: tensor(0.2202, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1490, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.184685707092285
Validation after dual ascent:
out_inf: tensor(16.5625, device='cuda:0', dtype=torch.float16) tensor(1.0508, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
tensor(1.4619, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(1.7002, device='cuda:0', dtype=torch.float16) tensor(0.1503, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.0195, device='cuda:0', dtype=torch.float16) tensor(0.3352, device='cuda:0', dtype=torch.float16)
tensor(1.0869, device='cuda:0', dtype=torch.float16) tensor(0.1405, device='cuda:0', dtype=torch.float16)
tensor(1.0732, device='cuda:0', dtype=torch.float16) tensor(0.1360, device='cuda:0', dtype=torch.float16)
tensor(1.0830, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0137, device='cuda:0')
tensor(0.2317, device='cuda:0')
old_score: tensor(0.1394, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1023, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.448873281478882
Validation after dual ascent:
out_inf: tensor(5.0195, device='cuda:0', dtype=torch.float16) tensor(0.3352, device='cuda:0', dtype=torch.float16)
tensor(0.8652, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(0.9658, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.9106, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.9805, device='cuda:0', dtype=torch.float16) tensor(0.1318, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(1.1543, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0121, device='cuda:0')
tensor(0.0166, device='cuda:0')
old_score: tensor(0.0503, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0349, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1778032779693604
Validation after dual ascent:
out_inf: tensor(7.9805, device='cuda:0', dtype=torch.float16) tensor(0.1318, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0319, device='cuda:0', dtype=torch.float16)
tensor(0.7549, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.7324, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.3906, device='cuda:0', dtype=torch.float16) tensor(0.4102, device='cuda:0', dtype=torch.float16)
tensor(2.3828, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(2.1953, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(2.3262, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0113, device='cuda:0')
tensor(0.1100, device='cuda:0')
old_score: tensor(0.1234, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0858, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.088815212249756
Validation after dual ascent:
out_inf: tensor(8.3906, device='cuda:0', dtype=torch.float16) tensor(0.4102, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0792, device='cuda:0', dtype=torch.float16)
tensor(1.3994, device='cuda:0', dtype=torch.float16) tensor(0.0901, device='cuda:0', dtype=torch.float16)
tensor(1.7988, device='cuda:0', dtype=torch.float16) tensor(0.0868, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1131, device='cuda:0', dtype=torch.float16)
tensor(1.5098, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0094, device='cuda:0')
tensor(0.1067, device='cuda:0')
old_score: tensor(0.1171, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0836, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.091598987579346
Validation after dual ascent:
out_inf: tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.7793, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.0845, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.6445, device='cuda:0', dtype=torch.float16) tensor(0.1376, device='cuda:0', dtype=torch.float16)
tensor(0.5859, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.6177, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(0.6982, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0053, device='cuda:0')
tensor(0.0652, device='cuda:0')
old_score: tensor(0.0507, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0413, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.092353343963623
Validation after dual ascent:
out_inf: tensor(5.6445, device='cuda:0', dtype=torch.float16) tensor(0.1376, device='cuda:0', dtype=torch.float16)
tensor(0.4729, device='cuda:0', dtype=torch.float16) tensor(0.0437, device='cuda:0', dtype=torch.float16)
tensor(0.4756, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.4902, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.9453, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(3.2031, device='cuda:0', dtype=torch.float16) tensor(0.2159, device='cuda:0', dtype=torch.float16)
tensor(3.0781, device='cuda:0', dtype=torch.float16) tensor(0.2089, device='cuda:0', dtype=torch.float16)
tensor(3.8203, device='cuda:0', dtype=torch.float16) tensor(0.2257, device='cuda:0', dtype=torch.float16)
tensor(3.1016, device='cuda:0', dtype=torch.float16) tensor(0.2111, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0132, device='cuda:0')
tensor(0.0623, device='cuda:0')
old_score: tensor(0.2153, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1416, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1786186695098877
Validation after dual ascent:
out_inf: tensor(15.9453, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.1438, device='cuda:0', dtype=torch.float16)
tensor(1.5225, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.1488, device='cuda:0', dtype=torch.float16)
tensor(1.4629, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.4844, device='cuda:0', dtype=torch.float16) tensor(1.0068, device='cuda:0', dtype=torch.float16)
tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.2206, device='cuda:0', dtype=torch.float16)
tensor(2.7891, device='cuda:0', dtype=torch.float16) tensor(0.2161, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.2318, device='cuda:0', dtype=torch.float16)
tensor(2.5859, device='cuda:0', dtype=torch.float16) tensor(0.2173, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0165, device='cuda:0')
tensor(0.0601, device='cuda:0')
old_score: tensor(0.2214, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1436, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.182027578353882
Validation after dual ascent:
out_inf: tensor(16.4844, device='cuda:0', dtype=torch.float16) tensor(1.0068, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1459, device='cuda:0', dtype=torch.float16)
tensor(1.5527, device='cuda:0', dtype=torch.float16) tensor(0.1318, device='cuda:0', dtype=torch.float16)
tensor(1.6719, device='cuda:0', dtype=torch.float16) tensor(0.1509, device='cuda:0', dtype=torch.float16)
tensor(1.8506, device='cuda:0', dtype=torch.float16) tensor(0.1453, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.3711, device='cuda:0', dtype=torch.float16) tensor(0.3440, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.1064, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.1459, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0165, device='cuda:0')
tensor(0.2172, device='cuda:0')
old_score: tensor(0.1416, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0996, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4473774433135986
Validation after dual ascent:
out_inf: tensor(4.3711, device='cuda:0', dtype=torch.float16) tensor(0.3440, device='cuda:0', dtype=torch.float16)
tensor(0.8989, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
tensor(0.7725, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.1043, device='cuda:0', dtype=torch.float16)
tensor(0.8193, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.8633, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
tensor(0.9414, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0124, device='cuda:0')
tensor(0.0264, device='cuda:0')
old_score: tensor(0.0409, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0274, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.8978939056396484
Validation after dual ascent:
out_inf: tensor(5.8633, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
tensor(0.6128, device='cuda:0', dtype=torch.float16) tensor(0.0279, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.6660, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.5117, device='cuda:0', dtype=torch.float16) tensor(0.4316, device='cuda:0', dtype=torch.float16)
tensor(1.9961, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
tensor(1.9336, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.1355, device='cuda:0', dtype=torch.float16)
tensor(2.1211, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0125, device='cuda:0')
tensor(0.1300, device='cuda:0')
old_score: tensor(0.1299, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0898, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.093727111816406
Validation after dual ascent:
out_inf: tensor(7.5117, device='cuda:0', dtype=torch.float16) tensor(0.4316, device='cuda:0', dtype=torch.float16)
tensor(1.7090, device='cuda:0', dtype=torch.float16) tensor(0.0920, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(1.3223, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.9062, device='cuda:0', dtype=torch.float16) tensor(0.2969, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1220, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
tensor(1.7383, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1197, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0104, device='cuda:0')
tensor(0.1239, device='cuda:0')
old_score: tensor(0.1210, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0862, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0953991413116455
Validation after dual ascent:
out_inf: tensor(5.9062, device='cuda:0', dtype=torch.float16) tensor(0.2969, device='cuda:0', dtype=torch.float16)
tensor(2.5664, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(0.8486, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.6089, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
tensor(0.7329, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0052, device='cuda:0')
tensor(0.0648, device='cuda:0')
old_score: tensor(0.0505, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0407, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.134378671646118
Validation after dual ascent:
out_inf: tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
tensor(0.5967, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.4380, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.5684, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.5884, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.6719, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(2.5234, device='cuda:0', dtype=torch.float16) tensor(0.2178, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.2107, device='cuda:0', dtype=torch.float16)
tensor(2.7305, device='cuda:0', dtype=torch.float16) tensor(0.2277, device='cuda:0', dtype=torch.float16)
tensor(2.5625, device='cuda:0', dtype=torch.float16) tensor(0.2118, device='cuda:0', dtype=torch.float16)
tensor(0.0977, device='cuda:0')
old_score: tensor(0.2170, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1438, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.830854892730713
Validation after dual ascent:
out_inf: tensor(13.6719, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(1.4238, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.1517, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.0781, device='cuda:0', dtype=torch.float16) tensor(0.9712, device='cuda:0', dtype=torch.float16)
tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.2242, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.2179, device='cuda:0', dtype=torch.float16)
tensor(3.4609, device='cuda:0', dtype=torch.float16) tensor(0.2356, device='cuda:0', dtype=torch.float16)
tensor(2.9297, device='cuda:0', dtype=torch.float16) tensor(0.2184, device='cuda:0', dtype=torch.float16)
tensor(0.0818, device='cuda:0')
old_score: tensor(0.2240, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1455, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.873956441879272
Validation after dual ascent:
out_inf: tensor(18.0781, device='cuda:0', dtype=torch.float16) tensor(0.9712, device='cuda:0', dtype=torch.float16)
tensor(1.6719, device='cuda:0', dtype=torch.float16) tensor(0.1489, device='cuda:0', dtype=torch.float16)
tensor(1.5410, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(1.5332, device='cuda:0', dtype=torch.float16) tensor(0.1469, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8281, device='cuda:0', dtype=torch.float16) tensor(0.3564, device='cuda:0', dtype=torch.float16)
tensor(1.1943, device='cuda:0', dtype=torch.float16) tensor(0.1523, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(1.3145, device='cuda:0', dtype=torch.float16) tensor(0.1582, device='cuda:0', dtype=torch.float16)
tensor(1.2012, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0139, device='cuda:0')
tensor(0.0858, device='cuda:0')
old_score: tensor(0.1516, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1078, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1792173385620117
Validation after dual ascent:
out_inf: tensor(4.8281, device='cuda:0', dtype=torch.float16) tensor(0.3564, device='cuda:0', dtype=torch.float16)
tensor(0.9756, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(0.8545, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(0.9351, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(0.9175, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.4961, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.0373, device='cuda:0', dtype=torch.float16)
tensor(1.3066, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(1.1504, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(1.4150, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0174, device='cuda:0')
tensor(0.0290, device='cuda:0')
old_score: tensor(0.0380, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0256, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.18097186088562
Validation after dual ascent:
out_inf: tensor(4.4961, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.6367, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.0273, device='cuda:0', dtype=torch.float16)
tensor(0.8848, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.4297, device='cuda:0', dtype=torch.float16) tensor(0.4431, device='cuda:0', dtype=torch.float16)
tensor(2.2617, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1302, device='cuda:0', dtype=torch.float16)
tensor(2.4219, device='cuda:0', dtype=torch.float16) tensor(0.1422, device='cuda:0', dtype=torch.float16)
tensor(2.4609, device='cuda:0', dtype=torch.float16) tensor(0.1326, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0142, device='cuda:0')
tensor(0.1519, device='cuda:0')
old_score: tensor(0.1355, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0925, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.106920957565308
Validation after dual ascent:
out_inf: tensor(8.4297, device='cuda:0', dtype=torch.float16) tensor(0.4431, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(1.8398, device='cuda:0', dtype=torch.float16) tensor(0.0840, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(1.6914, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.5391, device='cuda:0', dtype=torch.float16) tensor(0.2971, device='cuda:0', dtype=torch.float16)
tensor(1.5059, device='cuda:0', dtype=torch.float16) tensor(0.1256, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1204, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.1302, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0119, device='cuda:0')
tensor(0.1427, device='cuda:0')
old_score: tensor(0.1247, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0876, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1002357006073
Validation after dual ascent:
out_inf: tensor(6.5391, device='cuda:0', dtype=torch.float16) tensor(0.2971, device='cuda:0', dtype=torch.float16)
tensor(0.8999, device='cuda:0', dtype=torch.float16) tensor(0.0902, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.0797, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.0923, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.0885, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.3828, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(0.6494, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.6196, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0061, device='cuda:0')
tensor(0.0716, device='cuda:0')
old_score: tensor(0.0520, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0421, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.11622929573059
Validation after dual ascent:
out_inf: tensor(5.3828, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(0.5415, device='cuda:0', dtype=torch.float16) tensor(0.0443, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0366, device='cuda:0', dtype=torch.float16)
tensor(0.5444, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.4561, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.4297, device='cuda:0', dtype=torch.float16) tensor(0.7754, device='cuda:0', dtype=torch.float16)
tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.2128, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.2042, device='cuda:0', dtype=torch.float16)
tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.2222, device='cuda:0', dtype=torch.float16)
tensor(2.5547, device='cuda:0', dtype=torch.float16) tensor(0.2048, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0147, device='cuda:0')
tensor(0.0637, device='cuda:0')
old_score: tensor(0.2109, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1378, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.668238639831543
Validation after dual ascent:
out_inf: tensor(13.4297, device='cuda:0', dtype=torch.float16) tensor(0.7754, device='cuda:0', dtype=torch.float16)
tensor(1.4385, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.1260, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
tensor(1.5605, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.2969, device='cuda:0', dtype=torch.float16) tensor(1.0088, device='cuda:0', dtype=torch.float16)
tensor(2.7344, device='cuda:0', dtype=torch.float16) tensor(0.2170, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.2103, device='cuda:0', dtype=torch.float16)
tensor(3.2656, device='cuda:0', dtype=torch.float16) tensor(0.2290, device='cuda:0', dtype=torch.float16)
tensor(2.9141, device='cuda:0', dtype=torch.float16) tensor(0.2113, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0137, device='cuda:0')
tensor(0.0567, device='cuda:0')
old_score: tensor(0.2169, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1394, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.693434715270996
Validation after dual ascent:
out_inf: tensor(18.2969, device='cuda:0', dtype=torch.float16) tensor(1.0088, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.1641, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.1482, device='cuda:0', dtype=torch.float16)
tensor(1.2842, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1498, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0109, device='cuda:0')
tensor(0.0744, device='cuda:0')
old_score: tensor(0.1527, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1065, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1762685775756836
Validation after dual ascent:
out_inf: tensor(4.1641, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(0.9546, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
tensor(0.8994, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(0.9458, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.2578, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0399, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(0.9590, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0125, device='cuda:0')
tensor(0.0158, device='cuda:0')
old_score: tensor(0.0395, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0272, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.083539962768555
Validation after dual ascent:
out_inf: tensor(7.2578, device='cuda:0', dtype=torch.float16) tensor(0.1157, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.4473, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.5469, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.7373, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.2656, device='cuda:0', dtype=torch.float16) tensor(0.4316, device='cuda:0', dtype=torch.float16)
tensor(2.0742, device='cuda:0', dtype=torch.float16) tensor(0.1396, device='cuda:0', dtype=torch.float16)
tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.1340, device='cuda:0', dtype=torch.float16)
tensor(2.5820, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(2.5039, device='cuda:0', dtype=torch.float16) tensor(0.1353, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0148, device='cuda:0')
tensor(0.1670, device='cuda:0')
old_score: tensor(0.1384, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0949, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0978684425354
Validation after dual ascent:
out_inf: tensor(8.2656, device='cuda:0', dtype=torch.float16) tensor(0.4316, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.0978, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(1.2930, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.5898, device='cuda:0', dtype=torch.float16) tensor(0.3037, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.7148, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
tensor(1.5742, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0128, device='cuda:0')
tensor(0.1567, device='cuda:0')
old_score: tensor(0.1276, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0897, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.098264932632446
Validation after dual ascent:
out_inf: tensor(7.5898, device='cuda:0', dtype=torch.float16) tensor(0.3037, device='cuda:0', dtype=torch.float16)
tensor(1.9883, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0899, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.6797, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(0.7559, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.7510, device='cuda:0', dtype=torch.float16) tensor(0.0492, device='cuda:0', dtype=torch.float16)
tensor(0.8037, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0062, device='cuda:0')
tensor(0.0730, device='cuda:0')
old_score: tensor(0.0528, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0429, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.070642471313477
Validation after dual ascent:
out_inf: tensor(4.6797, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(0.5459, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0452, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.0312, device='cuda:0', dtype=torch.float16) tensor(0.8032, device='cuda:0', dtype=torch.float16)
tensor(3.1953, device='cuda:0', dtype=torch.float16) tensor(0.2152, device='cuda:0', dtype=torch.float16)
tensor(2.4766, device='cuda:0', dtype=torch.float16) tensor(0.2069, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.2238, device='cuda:0', dtype=torch.float16)
tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.2076, device='cuda:0', dtype=torch.float16)
tensor(0.2218, device='cuda:0')
old_score: tensor(0.2134, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1387, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.843931674957275
Validation after dual ascent:
out_inf: tensor(16.0312, device='cuda:0', dtype=torch.float16) tensor(0.8032, device='cuda:0', dtype=torch.float16)
tensor(1.6309, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(1.4404, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.6270, device='cuda:0', dtype=torch.float16) tensor(0.1467, device='cuda:0', dtype=torch.float16)
tensor(1.4277, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18., device='cuda:0', dtype=torch.float16) tensor(1.0156, device='cuda:0', dtype=torch.float16)
tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.2196, device='cuda:0', dtype=torch.float16)
tensor(2.6289, device='cuda:0', dtype=torch.float16) tensor(0.2133, device='cuda:0', dtype=torch.float16)
tensor(2.8359, device='cuda:0', dtype=torch.float16) tensor(0.2281, device='cuda:0', dtype=torch.float16)
tensor(2.9531, device='cuda:0', dtype=torch.float16) tensor(0.2123, device='cuda:0', dtype=torch.float16)
tensor(0.2463, device='cuda:0')
old_score: tensor(0.2184, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1396, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.875049591064453
Validation after dual ascent:
out_inf: tensor(18., device='cuda:0', dtype=torch.float16) tensor(1.0156, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
tensor(1.8008, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.6133, device='cuda:0', dtype=torch.float16) tensor(0.3604, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(1.2666, device='cuda:0', dtype=torch.float16) tensor(0.1500, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.1605, device='cuda:0', dtype=torch.float16)
tensor(1.3545, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
tensor(0.1114, device='cuda:0')
old_score: tensor(0.1544, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1077, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.838461875915527
Validation after dual ascent:
out_inf: tensor(4.6133, device='cuda:0', dtype=torch.float16) tensor(0.3604, device='cuda:0', dtype=torch.float16)
tensor(0.9189, device='cuda:0', dtype=torch.float16) tensor(0.1109, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(0.8945, device='cuda:0', dtype=torch.float16) tensor(0.1079, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.o_proj
Validation after prune:
out_inf: tensor(12.8125, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0514, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0080, device='cuda:0')
tensor(0.0154, device='cuda:0')
old_score: tensor(0.0513, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0340, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.907219886779785
Validation after dual ascent:
out_inf: tensor(12.8125, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.5996, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.5391, device='cuda:0', dtype=torch.float16) tensor(0.4351, device='cuda:0', dtype=torch.float16)
tensor(2.8828, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
tensor(2.0762, device='cuda:0', dtype=torch.float16) tensor(0.1479, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0150, device='cuda:0')
tensor(0.1632, device='cuda:0')
old_score: tensor(0.1406, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0945, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.098236322402954
Validation after dual ascent:
out_inf: tensor(10.5391, device='cuda:0', dtype=torch.float16) tensor(0.4351, device='cuda:0', dtype=torch.float16)
tensor(3.9141, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(1.3193, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.3008, device='cuda:0', dtype=torch.float16) tensor(0.3054, device='cuda:0', dtype=torch.float16)
tensor(2.3125, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(1.6406, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0127, device='cuda:0')
tensor(0.1517, device='cuda:0')
old_score: tensor(0.1284, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0886, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.10058331489563
Validation after dual ascent:
out_inf: tensor(5.3008, device='cuda:0', dtype=torch.float16) tensor(0.3054, device='cuda:0', dtype=torch.float16)
tensor(1.3691, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
tensor(0.8091, device='cuda:0', dtype=torch.float16) tensor(0.0949, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.6133, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.7002, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(0.7905, device='cuda:0', dtype=torch.float16) tensor(0.0537, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0062, device='cuda:0')
tensor(0.0731, device='cuda:0')
old_score: tensor(0.0530, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0424, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.01863718032837
Validation after dual ascent:
out_inf: tensor(6.6133, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0367, device='cuda:0', dtype=torch.float16)
tensor(0.5044, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.6392, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.3594, device='cuda:0', dtype=torch.float16) tensor(0.7700, device='cuda:0', dtype=torch.float16)
tensor(3.0547, device='cuda:0', dtype=torch.float16) tensor(0.2100, device='cuda:0', dtype=torch.float16)
tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.2028, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.2222, device='cuda:0', dtype=torch.float16)
tensor(2.6016, device='cuda:0', dtype=torch.float16) tensor(0.2017, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0153, device='cuda:0')
tensor(0.0667, device='cuda:0')
old_score: tensor(0.2091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1345, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1702566146850586
Validation after dual ascent:
out_inf: tensor(17.3594, device='cuda:0', dtype=torch.float16) tensor(0.7700, device='cuda:0', dtype=torch.float16)
tensor(1.5830, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.5410, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.7695, device='cuda:0', dtype=torch.float16) tensor(0.1448, device='cuda:0', dtype=torch.float16)
tensor(1.3770, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.8438, device='cuda:0', dtype=torch.float16) tensor(0.9600, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.2095, device='cuda:0', dtype=torch.float16)
tensor(3.0859, device='cuda:0', dtype=torch.float16) tensor(0.2047, device='cuda:0', dtype=torch.float16)
tensor(3.1562, device='cuda:0', dtype=torch.float16) tensor(0.2230, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.2024, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0184, device='cuda:0')
tensor(0.0662, device='cuda:0')
old_score: tensor(0.2100, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1348, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.175733804702759
Validation after dual ascent:
out_inf: tensor(17.8438, device='cuda:0', dtype=torch.float16) tensor(0.9600, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(1.5957, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.5352, device='cuda:0', dtype=torch.float16) tensor(0.3716, device='cuda:0', dtype=torch.float16)
tensor(1.3223, device='cuda:0', dtype=torch.float16) tensor(0.1619, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(1.3525, device='cuda:0', dtype=torch.float16) tensor(0.1698, device='cuda:0', dtype=torch.float16)
tensor(1.4229, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0068, device='cuda:0')
tensor(0.0638, device='cuda:0')
old_score: tensor(0.1619, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1111, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1705663204193115
Validation after dual ascent:
out_inf: tensor(5.5352, device='cuda:0', dtype=torch.float16) tensor(0.3716, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
tensor(1.0244, device='cuda:0', dtype=torch.float16) tensor(0.1015, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(1.0586, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.o_proj
Validation after prune:
out_inf: tensor(10.3203, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0148, device='cuda:0')
tensor(0.0275, device='cuda:0')
old_score: tensor(0.0436, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0292, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.161559581756592
Validation after dual ascent:
out_inf: tensor(10.3203, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.5742, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(1.0371, device='cuda:0', dtype=torch.float16) tensor(0.0295, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.9453, device='cuda:0', dtype=torch.float16) tensor(0.4238, device='cuda:0', dtype=torch.float16)
tensor(2.5234, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1494, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0155, device='cuda:0')
tensor(0.1730, device='cuda:0')
old_score: tensor(0.1416, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0963, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.089914321899414
Validation after dual ascent:
out_inf: tensor(9.9453, device='cuda:0', dtype=torch.float16) tensor(0.4238, device='cuda:0', dtype=torch.float16)
tensor(1.7285, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(2.4922, device='cuda:0', dtype=torch.float16) tensor(0.0883, device='cuda:0', dtype=torch.float16)
tensor(1.3262, device='cuda:0', dtype=torch.float16) tensor(0.1037, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.0946, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.8711, device='cuda:0', dtype=torch.float16) tensor(0.2969, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1287, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0131, device='cuda:0')
tensor(0.1595, device='cuda:0')
old_score: tensor(0.1287, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0897, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0890233516693115
Validation after dual ascent:
out_inf: tensor(5.8711, device='cuda:0', dtype=torch.float16) tensor(0.2969, device='cuda:0', dtype=torch.float16)
tensor(1.1719, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0821, device='cuda:0', dtype=torch.float16)
tensor(0.8477, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(1.1758, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.8809, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.5732, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.5537, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.7349, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0057, device='cuda:0')
tensor(0.0661, device='cuda:0')
old_score: tensor(0.0501, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0406, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.015893936157227
Validation after dual ascent:
out_inf: tensor(3.8809, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(0.5713, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.3972, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0444, device='cuda:0', dtype=torch.float16)
tensor(0.6826, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.7969, device='cuda:0', dtype=torch.float16) tensor(0.8271, device='cuda:0', dtype=torch.float16)
tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.2151, device='cuda:0', dtype=torch.float16)
tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.2103, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.2303, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.2096, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0142, device='cuda:0')
tensor(0.0636, device='cuda:0')
old_score: tensor(0.2163, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1392, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1707656383514404
Validation after dual ascent:
out_inf: tensor(17.7969, device='cuda:0', dtype=torch.float16) tensor(0.8271, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(1.3789, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.8594, device='cuda:0', dtype=torch.float16) tensor(0.9907, device='cuda:0', dtype=torch.float16)
tensor(3.0703, device='cuda:0', dtype=torch.float16) tensor(0.2177, device='cuda:0', dtype=torch.float16)
tensor(2.4609, device='cuda:0', dtype=torch.float16) tensor(0.2119, device='cuda:0', dtype=torch.float16)
tensor(3.0312, device='cuda:0', dtype=torch.float16) tensor(0.2321, device='cuda:0', dtype=torch.float16)
tensor(3.0625, device='cuda:0', dtype=torch.float16) tensor(0.2122, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0177, device='cuda:0')
tensor(0.0630, device='cuda:0')
old_score: tensor(0.2185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1396, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.171098232269287
Validation after dual ascent:
out_inf: tensor(19.8594, device='cuda:0', dtype=torch.float16) tensor(0.9907, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.5703, device='cuda:0', dtype=torch.float16) tensor(0.1516, device='cuda:0', dtype=torch.float16)
tensor(1.6865, device='cuda:0', dtype=torch.float16) tensor(0.1365, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.9336, device='cuda:0', dtype=torch.float16) tensor(0.3870, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1636, device='cuda:0', dtype=torch.float16)
tensor(1.6445, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1722, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0171, device='cuda:0')
tensor(0.2787, device='cuda:0')
old_score: tensor(0.1637, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1127, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4412343502044678
Validation after dual ascent:
out_inf: tensor(7.9336, device='cuda:0', dtype=torch.float16) tensor(0.3870, device='cuda:0', dtype=torch.float16)
tensor(1.0225, device='cuda:0', dtype=torch.float16) tensor(0.1151, device='cuda:0', dtype=torch.float16)
tensor(0.9365, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.3672, device='cuda:0', dtype=torch.float16) tensor(0.1505, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.0211, device='cuda:0')
old_score: tensor(0.0430, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0301, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.780003786087036
Validation after dual ascent:
out_inf: tensor(11.3672, device='cuda:0', dtype=torch.float16) tensor(0.1505, device='cuda:0', dtype=torch.float16)
tensor(0.6797, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.6396, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.9219, device='cuda:0', dtype=torch.float16) tensor(0.4202, device='cuda:0', dtype=torch.float16)
tensor(2.8359, device='cuda:0', dtype=torch.float16) tensor(0.1444, device='cuda:0', dtype=torch.float16)
tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(3.0645, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0154, device='cuda:0')
tensor(0.1712, device='cuda:0')
old_score: tensor(0.1436, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0967, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.095319747924805
Validation after dual ascent:
out_inf: tensor(9.9219, device='cuda:0', dtype=torch.float16) tensor(0.4202, device='cuda:0', dtype=torch.float16)
tensor(1.6172, device='cuda:0', dtype=torch.float16) tensor(0.0984, device='cuda:0', dtype=torch.float16)
tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.0891, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.0781, device='cuda:0', dtype=torch.float16) tensor(0.3047, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1265, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0131, device='cuda:0')
tensor(0.1564, device='cuda:0')
old_score: tensor(0.1294, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0892, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.093981027603149
Validation after dual ascent:
out_inf: tensor(6.0781, device='cuda:0', dtype=torch.float16) tensor(0.3047, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(0.9414, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(0.8867, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(0.9043, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.2227, device='cuda:0', dtype=torch.float16) tensor(0.1472, device='cuda:0', dtype=torch.float16)
tensor(0.6069, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
tensor(0.4873, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.6904, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.5303, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0060, device='cuda:0')
tensor(0.0702, device='cuda:0')
old_score: tensor(0.0518, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0419, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.058128118515015
Validation after dual ascent:
out_inf: tensor(3.2227, device='cuda:0', dtype=torch.float16) tensor(0.1472, device='cuda:0', dtype=torch.float16)
tensor(0.5649, device='cuda:0', dtype=torch.float16) tensor(0.0436, device='cuda:0', dtype=torch.float16)
tensor(0.4985, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.5557, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.5781, device='cuda:0', dtype=torch.float16) tensor(0.7837, device='cuda:0', dtype=torch.float16)
tensor(2.8359, device='cuda:0', dtype=torch.float16) tensor(0.2172, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.2102, device='cuda:0', dtype=torch.float16)
tensor(2.8125, device='cuda:0', dtype=torch.float16) tensor(0.2288, device='cuda:0', dtype=torch.float16)
tensor(2.4609, device='cuda:0', dtype=torch.float16) tensor(0.2098, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0148, device='cuda:0')
tensor(0.0636, device='cuda:0')
old_score: tensor(0.2166, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1410, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.175184488296509
Validation after dual ascent:
out_inf: tensor(16.5781, device='cuda:0', dtype=torch.float16) tensor(0.7837, device='cuda:0', dtype=torch.float16)
tensor(1.5264, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(1.4854, device='cuda:0', dtype=torch.float16) tensor(0.1302, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1543, device='cuda:0', dtype=torch.float16)
tensor(1.6348, device='cuda:0', dtype=torch.float16) tensor(0.1365, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.4219, device='cuda:0', dtype=torch.float16) tensor(0.9229, device='cuda:0', dtype=torch.float16)
tensor(3.2422, device='cuda:0', dtype=torch.float16) tensor(0.2184, device='cuda:0', dtype=torch.float16)
tensor(2.8359, device='cuda:0', dtype=torch.float16) tensor(0.2130, device='cuda:0', dtype=torch.float16)
tensor(2.8203, device='cuda:0', dtype=torch.float16) tensor(0.2310, device='cuda:0', dtype=torch.float16)
tensor(2.7578, device='cuda:0', dtype=torch.float16) tensor(0.2123, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0183, device='cuda:0')
tensor(0.0633, device='cuda:0')
old_score: tensor(0.2186, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1414, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.178276538848877
Validation after dual ascent:
out_inf: tensor(18.4219, device='cuda:0', dtype=torch.float16) tensor(0.9229, device='cuda:0', dtype=torch.float16)
tensor(1.6797, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1548, device='cuda:0', dtype=torch.float16)
tensor(1.4727, device='cuda:0', dtype=torch.float16) tensor(0.1367, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.4805, device='cuda:0', dtype=torch.float16) tensor(0.4094, device='cuda:0', dtype=torch.float16)
tensor(1.5566, device='cuda:0', dtype=torch.float16) tensor(0.1758, device='cuda:0', dtype=torch.float16)
tensor(1.4629, device='cuda:0', dtype=torch.float16) tensor(0.1708, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1844, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1721, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0188, device='cuda:0')
tensor(0.3069, device='cuda:0')
old_score: tensor(0.1758, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1204, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4454903602600098
Validation after dual ascent:
out_inf: tensor(5.4805, device='cuda:0', dtype=torch.float16) tensor(0.4094, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(1.1182, device='cuda:0', dtype=torch.float16) tensor(0.1112, device='cuda:0', dtype=torch.float16)
tensor(1.0889, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.1169, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.o_proj
Validation after prune:
out_inf: tensor(15.6719, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
tensor(0.9775, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(1.2500, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
tensor(0.0312, device='cuda:0')
old_score: tensor(0.0360, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0247, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.788300514221191
Validation after dual ascent:
out_inf: tensor(15.6719, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.9023, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.1562, device='cuda:0', dtype=torch.float16) tensor(0.4153, device='cuda:0', dtype=torch.float16)
tensor(2.5312, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
tensor(2.1797, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(2.2148, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(2.7227, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.1746, device='cuda:0')
old_score: tensor(0.1445, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0973, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.100219488143921
Validation after dual ascent:
out_inf: tensor(9.1562, device='cuda:0', dtype=torch.float16) tensor(0.4153, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
tensor(1.4824, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(1.7930, device='cuda:0', dtype=torch.float16) tensor(0.1066, device='cuda:0', dtype=torch.float16)
tensor(2.1602, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.2734, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(1.8008, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1273, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0133, device='cuda:0')
tensor(0.1604, device='cuda:0')
old_score: tensor(0.1311, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0901, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.102017879486084
Validation after dual ascent:
out_inf: tensor(6.2734, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(0.7544, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(0.8896, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0867, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.7188, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(0.6865, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.6104, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(0.5791, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.5635, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0058, device='cuda:0')
tensor(0.0694, device='cuda:0')
old_score: tensor(0.0516, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.083680391311646
Validation after dual ascent:
out_inf: tensor(5.7188, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.4556, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.5356, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.5317, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.6250, device='cuda:0', dtype=torch.float16) tensor(0.7632, device='cuda:0', dtype=torch.float16)
tensor(2.5898, device='cuda:0', dtype=torch.float16) tensor(0.2057, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1996, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.2189, device='cuda:0', dtype=torch.float16)
tensor(2.5898, device='cuda:0', dtype=torch.float16) tensor(0.1970, device='cuda:0', dtype=torch.float16)
tensor(0.3664, device='cuda:0')
old_score: tensor(0.2053, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1327, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.840927362442017
Validation after dual ascent:
out_inf: tensor(16.6250, device='cuda:0', dtype=torch.float16) tensor(0.7632, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.1460, device='cuda:0', dtype=torch.float16)
tensor(1.5049, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.3594, device='cuda:0', dtype=torch.float16) tensor(0.9570, device='cuda:0', dtype=torch.float16)
tensor(2.5312, device='cuda:0', dtype=torch.float16) tensor(0.2054, device='cuda:0', dtype=torch.float16)
tensor(2.5547, device='cuda:0', dtype=torch.float16) tensor(0.2010, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.2194, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.1980, device='cuda:0', dtype=torch.float16)
tensor(0.3410, device='cuda:0')
old_score: tensor(0.2061, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1323, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.873795986175537
Validation after dual ascent:
out_inf: tensor(17.3594, device='cuda:0', dtype=torch.float16) tensor(0.9570, device='cuda:0', dtype=torch.float16)
tensor(1.6348, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.1265, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.2539, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.1705, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1660, device='cuda:0', dtype=torch.float16)
tensor(1.4600, device='cuda:0', dtype=torch.float16) tensor(0.1793, device='cuda:0', dtype=torch.float16)
tensor(1.3760, device='cuda:0', dtype=torch.float16) tensor(0.1644, device='cuda:0', dtype=torch.float16)
tensor(0.1096, device='cuda:0')
old_score: tensor(0.1700, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1166, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.855249881744385
Validation after dual ascent:
out_inf: tensor(5.2539, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1183, device='cuda:0', dtype=torch.float16)
tensor(1.1475, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1283, device='cuda:0', dtype=torch.float16)
tensor(0.9971, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.o_proj
Validation after prune:
out_inf: tensor(12.0859, device='cuda:0', dtype=torch.float16) tensor(0.1730, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
tensor(0.0385, device='cuda:0')
old_score: tensor(0.0459, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0303, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.813583612442017
Validation after dual ascent:
out_inf: tensor(12.0859, device='cuda:0', dtype=torch.float16) tensor(0.1730, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.5718, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(0.6177, device='cuda:0', dtype=torch.float16) tensor(0.0292, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.6406, device='cuda:0', dtype=torch.float16) tensor(0.4182, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1449, device='cuda:0', dtype=torch.float16)
tensor(2.4727, device='cuda:0', dtype=torch.float16) tensor(0.1543, device='cuda:0', dtype=torch.float16)
tensor(2.4453, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0164, device='cuda:0')
tensor(0.1857, device='cuda:0')
old_score: tensor(0.1477, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0994, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.113637208938599
Validation after dual ascent:
out_inf: tensor(10.6406, device='cuda:0', dtype=torch.float16) tensor(0.4182, device='cuda:0', dtype=torch.float16)
tensor(2.1719, device='cuda:0', dtype=torch.float16) tensor(0.1008, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0928, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1086, device='cuda:0', dtype=torch.float16)
tensor(2.1758, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.0625, device='cuda:0', dtype=torch.float16) tensor(0.3074, device='cuda:0', dtype=torch.float16)
tensor(1.5449, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.1318, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0140, device='cuda:0')
tensor(0.1707, device='cuda:0')
old_score: tensor(0.1343, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0923, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.112288951873779
Validation after dual ascent:
out_inf: tensor(6.0625, device='cuda:0', dtype=torch.float16) tensor(0.3074, device='cuda:0', dtype=torch.float16)
tensor(0.8828, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(0.8232, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(0.9023, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(1.0029, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5479, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0063, device='cuda:0')
tensor(0.0749, device='cuda:0')
old_score: tensor(0.0532, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0434, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.045207262039185
Validation after dual ascent:
out_inf: tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(0.5581, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.4712, device='cuda:0', dtype=torch.float16) tensor(0.0391, device='cuda:0', dtype=torch.float16)
tensor(0.5620, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.4966, device='cuda:0', dtype=torch.float16) tensor(0.0417, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.q_proj
Validation after prune:
out_inf: tensor(11.9766, device='cuda:0', dtype=torch.float16) tensor(0.7656, device='cuda:0', dtype=torch.float16)
tensor(2.5195, device='cuda:0', dtype=torch.float16) tensor(0.2195, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.2150, device='cuda:0', dtype=torch.float16)
tensor(2.6953, device='cuda:0', dtype=torch.float16) tensor(0.2324, device='cuda:0', dtype=torch.float16)
tensor(2.5469, device='cuda:0', dtype=torch.float16) tensor(0.2117, device='cuda:0', dtype=torch.float16)
tensor(0.1828, device='cuda:0')
old_score: tensor(0.2197, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1436, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.852459907531738
Validation after dual ascent:
out_inf: tensor(11.9766, device='cuda:0', dtype=torch.float16) tensor(0.7656, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1450, device='cuda:0', dtype=torch.float16)
tensor(1.5195, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.1580, device='cuda:0', dtype=torch.float16)
tensor(1.5195, device='cuda:0', dtype=torch.float16) tensor(0.1368, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.9531, device='cuda:0', dtype=torch.float16) tensor(0.8979, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.2190, device='cuda:0', dtype=torch.float16)
tensor(2.6719, device='cuda:0', dtype=torch.float16) tensor(0.2166, device='cuda:0', dtype=torch.float16)
tensor(2.7969, device='cuda:0', dtype=torch.float16) tensor(0.2338, device='cuda:0', dtype=torch.float16)
tensor(2.3906, device='cuda:0', dtype=torch.float16) tensor(0.2115, device='cuda:0', dtype=torch.float16)
tensor(0.1605, device='cuda:0')
old_score: tensor(0.2202, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1436, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.884407043457031
Validation after dual ascent:
out_inf: tensor(16.9531, device='cuda:0', dtype=torch.float16) tensor(0.8979, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1453, device='cuda:0', dtype=torch.float16)
tensor(1.4629, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.1580, device='cuda:0', dtype=torch.float16)
tensor(1.4355, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.2578, device='cuda:0', dtype=torch.float16) tensor(0.4292, device='cuda:0', dtype=torch.float16)
tensor(1.5986, device='cuda:0', dtype=torch.float16) tensor(0.1879, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.1842, device='cuda:0', dtype=torch.float16)
tensor(1.5254, device='cuda:0', dtype=torch.float16) tensor(0.1975, device='cuda:0', dtype=torch.float16)
tensor(1.4971, device='cuda:0', dtype=torch.float16) tensor(0.1804, device='cuda:0', dtype=torch.float16)
tensor(0.0581, device='cuda:0')
old_score: tensor(0.1875, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1288, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.872063636779785
Validation after dual ascent:
out_inf: tensor(5.2578, device='cuda:0', dtype=torch.float16) tensor(0.4292, device='cuda:0', dtype=torch.float16)
tensor(1.2529, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
tensor(1.1436, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(1.1475, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.9844, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.0166, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(1.0869, device='cuda:0', dtype=torch.float16) tensor(0.0318, device='cuda:0', dtype=torch.float16)
tensor(1.0244, device='cuda:0', dtype=torch.float16) tensor(0.0312, device='cuda:0', dtype=torch.float16)
tensor(0.0475, device='cuda:0')
old_score: tensor(0.0319, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0202, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.828919410705566
Validation after dual ascent:
out_inf: tensor(4.9844, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(0.6577, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.6484, device='cuda:0', dtype=torch.float16) tensor(0.4421, device='cuda:0', dtype=torch.float16)
tensor(2.5117, device='cuda:0', dtype=torch.float16) tensor(0.1532, device='cuda:0', dtype=torch.float16)
tensor(2.5195, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(2.5820, device='cuda:0', dtype=torch.float16) tensor(0.1594, device='cuda:0', dtype=torch.float16)
tensor(2.4121, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.2070, device='cuda:0')
old_score: tensor(0.1527, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1019, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115850210189819
Validation after dual ascent:
out_inf: tensor(9.6484, device='cuda:0', dtype=torch.float16) tensor(0.4421, device='cuda:0', dtype=torch.float16)
tensor(1.8477, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(1.6055, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(1.7383, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.7578, device='cuda:0', dtype=torch.float16) tensor(0.3206, device='cuda:0', dtype=torch.float16)
tensor(1.6055, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.6172, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.6914, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
tensor(1.7930, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0156, device='cuda:0')
tensor(0.1909, device='cuda:0')
old_score: tensor(0.1395, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0949, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1149742603302
Validation after dual ascent:
out_inf: tensor(7.7578, device='cuda:0', dtype=torch.float16) tensor(0.3206, device='cuda:0', dtype=torch.float16)
tensor(0.9092, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0906, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.9492, device='cuda:0', dtype=torch.float16) tensor(0.1693, device='cuda:0', dtype=torch.float16)
tensor(0.6064, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5776, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.6636, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0076, device='cuda:0')
tensor(0.0844, device='cuda:0')
old_score: tensor(0.0563, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0454, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.942875623703003
Validation after dual ascent:
out_inf: tensor(4.9492, device='cuda:0', dtype=torch.float16) tensor(0.1693, device='cuda:0', dtype=torch.float16)
tensor(0.6650, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.5591, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.5635, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.7188, device='cuda:0', dtype=torch.float16) tensor(0.8237, device='cuda:0', dtype=torch.float16)
tensor(3.1094, device='cuda:0', dtype=torch.float16) tensor(0.2240, device='cuda:0', dtype=torch.float16)
tensor(2.3906, device='cuda:0', dtype=torch.float16) tensor(0.2225, device='cuda:0', dtype=torch.float16)
tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.2346, device='cuda:0', dtype=torch.float16)
tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.2157, device='cuda:0', dtype=torch.float16)
tensor(0.1205, device='cuda:0')
old_score: tensor(0.2242, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1427, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.851627111434937
Validation after dual ascent:
out_inf: tensor(14.7188, device='cuda:0', dtype=torch.float16) tensor(0.8237, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1438, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1353, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.7812, device='cuda:0', dtype=torch.float16) tensor(1., device='cuda:0', dtype=torch.float16)
tensor(2.8203, device='cuda:0', dtype=torch.float16) tensor(0.2253, device='cuda:0', dtype=torch.float16)
tensor(2.7812, device='cuda:0', dtype=torch.float16) tensor(0.2247, device='cuda:0', dtype=torch.float16)
tensor(3.1094, device='cuda:0', dtype=torch.float16) tensor(0.2367, device='cuda:0', dtype=torch.float16)
tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.2177, device='cuda:0', dtype=torch.float16)
tensor(0.1064, device='cuda:0')
old_score: tensor(0.2262, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1427, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.891801357269287
Validation after dual ascent:
out_inf: tensor(17.7812, device='cuda:0', dtype=torch.float16) tensor(1., device='cuda:0', dtype=torch.float16)
tensor(1.7402, device='cuda:0', dtype=torch.float16) tensor(0.1438, device='cuda:0', dtype=torch.float16)
tensor(1.4951, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.7871, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.0156, device='cuda:0', dtype=torch.float16) tensor(0.4456, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1920, device='cuda:0', dtype=torch.float16)
tensor(1.6611, device='cuda:0', dtype=torch.float16) tensor(0.1929, device='cuda:0', dtype=torch.float16)
tensor(1.7148, device='cuda:0', dtype=torch.float16) tensor(0.2006, device='cuda:0', dtype=torch.float16)
tensor(1.8838, device='cuda:0', dtype=torch.float16) tensor(0.1859, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0150, device='cuda:0')
tensor(0.0960, device='cuda:0')
old_score: tensor(0.1929, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1317, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.183420181274414
Validation after dual ascent:
out_inf: tensor(8.0156, device='cuda:0', dtype=torch.float16) tensor(0.4456, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
tensor(1.1943, device='cuda:0', dtype=torch.float16) tensor(0.1249, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.o_proj
Validation after prune:
out_inf: tensor(24.6406, device='cuda:0', dtype=torch.float16) tensor(0.1930, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.0444, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(1.6328, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(0.0485, device='cuda:0')
old_score: tensor(0.0484, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0323, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.811165809631348
Validation after dual ascent:
out_inf: tensor(24.6406, device='cuda:0', dtype=torch.float16) tensor(0.1930, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(1.0684, device='cuda:0', dtype=torch.float16) tensor(0.0319, device='cuda:0', dtype=torch.float16)
tensor(1.0391, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.7188, device='cuda:0', dtype=torch.float16) tensor(0.4663, device='cuda:0', dtype=torch.float16)
tensor(2.5195, device='cuda:0', dtype=torch.float16) tensor(0.1576, device='cuda:0', dtype=torch.float16)
tensor(3.2500, device='cuda:0', dtype=torch.float16) tensor(0.1570, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.1636, device='cuda:0', dtype=torch.float16)
tensor(2.0898, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0196, device='cuda:0')
tensor(0.2197, device='cuda:0')
old_score: tensor(0.1575, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.119091749191284
Validation after dual ascent:
out_inf: tensor(8.7188, device='cuda:0', dtype=torch.float16) tensor(0.4663, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.0979, device='cuda:0', dtype=torch.float16)
tensor(2.0508, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.5234, device='cuda:0', dtype=torch.float16) tensor(0.3413, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1442, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.1493, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0167, device='cuda:0')
tensor(0.2028, device='cuda:0')
old_score: tensor(0.1438, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0968, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115894794464111
Validation after dual ascent:
out_inf: tensor(6.5234, device='cuda:0', dtype=torch.float16) tensor(0.3413, device='cuda:0', dtype=torch.float16)
tensor(0.9595, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(1.0586, device='cuda:0', dtype=torch.float16) tensor(0.0913, device='cuda:0', dtype=torch.float16)
tensor(0.9146, device='cuda:0', dtype=torch.float16) tensor(0.1059, device='cuda:0', dtype=torch.float16)
tensor(0.8535, device='cuda:0', dtype=torch.float16) tensor(0.0924, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.1815, device='cuda:0', dtype=torch.float16)
tensor(0.6704, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.7412, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.6494, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.6821, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0089, device='cuda:0')
tensor(0.0991, device='cuda:0')
old_score: tensor(0.0606, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0484, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.99465537071228
Validation after dual ascent:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.1815, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
tensor(0.6147, device='cuda:0', dtype=torch.float16) tensor(0.0447, device='cuda:0', dtype=torch.float16)
tensor(0.6509, device='cuda:0', dtype=torch.float16) tensor(0.0530, device='cuda:0', dtype=torch.float16)
tensor(0.5483, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1484, device='cuda:0', dtype=torch.float16) tensor(0.7944, device='cuda:0', dtype=torch.float16)
tensor(3.5469, device='cuda:0', dtype=torch.float16) tensor(0.2311, device='cuda:0', dtype=torch.float16)
tensor(3.0625, device='cuda:0', dtype=torch.float16) tensor(0.2281, device='cuda:0', dtype=torch.float16)
tensor(3.1953, device='cuda:0', dtype=torch.float16) tensor(0.2438, device='cuda:0', dtype=torch.float16)
tensor(3.2266, device='cuda:0', dtype=torch.float16) tensor(0.2234, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0156, device='cuda:0')
tensor(0.0415, device='cuda:0')
old_score: tensor(0.2317, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1449, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0987937450408936
Validation after dual ascent:
out_inf: tensor(15.1484, device='cuda:0', dtype=torch.float16) tensor(0.7944, device='cuda:0', dtype=torch.float16)
tensor(2.3125, device='cuda:0', dtype=torch.float16) tensor(0.1459, device='cuda:0', dtype=torch.float16)
tensor(1.4092, device='cuda:0', dtype=torch.float16) tensor(0.1368, device='cuda:0', dtype=torch.float16)
tensor(1.6172, device='cuda:0', dtype=torch.float16) tensor(0.1595, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.9375, device='cuda:0', dtype=torch.float16) tensor(0.9277, device='cuda:0', dtype=torch.float16)
tensor(3.8672, device='cuda:0', dtype=torch.float16) tensor(0.2363, device='cuda:0', dtype=torch.float16)
tensor(3.2891, device='cuda:0', dtype=torch.float16) tensor(0.2363, device='cuda:0', dtype=torch.float16)
tensor(3.8516, device='cuda:0', dtype=torch.float16) tensor(0.2505, device='cuda:0', dtype=torch.float16)
tensor(3.5078, device='cuda:0', dtype=torch.float16) tensor(0.2280, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0171, device='cuda:0')
tensor(0.0441, device='cuda:0')
old_score: tensor(0.2378, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1462, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.106856346130371
Validation after dual ascent:
out_inf: tensor(17.9375, device='cuda:0', dtype=torch.float16) tensor(0.9277, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1610, device='cuda:0', dtype=torch.float16)
tensor(1.6328, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.9453, device='cuda:0', dtype=torch.float16) tensor(0.4321, device='cuda:0', dtype=torch.float16)
tensor(1.9023, device='cuda:0', dtype=torch.float16) tensor(0.1897, device='cuda:0', dtype=torch.float16)
tensor(1.6797, device='cuda:0', dtype=torch.float16) tensor(0.1892, device='cuda:0', dtype=torch.float16)
tensor(2.1680, device='cuda:0', dtype=torch.float16) tensor(0.1989, device='cuda:0', dtype=torch.float16)
tensor(1.5098, device='cuda:0', dtype=torch.float16) tensor(0.1832, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0087, device='cuda:0')
tensor(0.0624, device='cuda:0')
old_score: tensor(0.1902, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1283, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1783413887023926
Validation after dual ascent:
out_inf: tensor(8.9453, device='cuda:0', dtype=torch.float16) tensor(0.4321, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(1.2588, device='cuda:0', dtype=torch.float16) tensor(0.1214, device='cuda:0', dtype=torch.float16)
tensor(1.3301, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.6953, device='cuda:0', dtype=torch.float16) tensor(0.1040, device='cuda:0', dtype=torch.float16)
tensor(1.0264, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(0.9238, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(1.1416, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.0570, device='cuda:0')
old_score: tensor(0.0247, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0155, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.785937070846558
Validation after dual ascent:
out_inf: tensor(5.6953, device='cuda:0', dtype=torch.float16) tensor(0.1040, device='cuda:0', dtype=torch.float16)
tensor(0.6865, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0140, device='cuda:0', dtype=torch.float16)
tensor(0.7422, device='cuda:0', dtype=torch.float16) tensor(0.0185, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0142, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.2500, device='cuda:0', dtype=torch.float16) tensor(0.4919, device='cuda:0', dtype=torch.float16)
tensor(2.4648, device='cuda:0', dtype=torch.float16) tensor(0.1636, device='cuda:0', dtype=torch.float16)
tensor(2.5039, device='cuda:0', dtype=torch.float16) tensor(0.1632, device='cuda:0', dtype=torch.float16)
tensor(3.0234, device='cuda:0', dtype=torch.float16) tensor(0.1699, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.1576, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0105, device='cuda:0')
tensor(0.0256, device='cuda:0')
old_score: tensor(0.1636, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1052, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.03696870803833
Validation after dual ascent:
out_inf: tensor(10.2500, device='cuda:0', dtype=torch.float16) tensor(0.4919, device='cuda:0', dtype=torch.float16)
tensor(1.7646, device='cuda:0', dtype=torch.float16) tensor(0.1063, device='cuda:0', dtype=torch.float16)
tensor(1.6602, device='cuda:0', dtype=torch.float16) tensor(0.0991, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.7285, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.4180, device='cuda:0', dtype=torch.float16) tensor(0.3665, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1505, device='cuda:0', dtype=torch.float16)
tensor(2.2148, device='cuda:0', dtype=torch.float16) tensor(0.1500, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(2.2305, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0185, device='cuda:0')
tensor(0.2242, device='cuda:0')
old_score: tensor(0.1504, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0989, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110268831253052
Validation after dual ascent:
out_inf: tensor(7.4180, device='cuda:0', dtype=torch.float16) tensor(0.3665, device='cuda:0', dtype=torch.float16)
tensor(0.9858, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(1.0742, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.1086, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.7949, device='cuda:0', dtype=torch.float16) tensor(0.2019, device='cuda:0', dtype=torch.float16)
tensor(0.7832, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.7222, device='cuda:0', dtype=torch.float16) tensor(0.0677, device='cuda:0', dtype=torch.float16)
tensor(0.8145, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0108, device='cuda:0')
tensor(0.1188, device='cuda:0')
old_score: tensor(0.0664, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0521, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.973048210144043
Validation after dual ascent:
out_inf: tensor(2.7949, device='cuda:0', dtype=torch.float16) tensor(0.2019, device='cuda:0', dtype=torch.float16)
tensor(0.8096, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.5469, device='cuda:0', dtype=torch.float16) tensor(0.8232, device='cuda:0', dtype=torch.float16)
tensor(3.2812, device='cuda:0', dtype=torch.float16) tensor(0.2384, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.2372, device='cuda:0', dtype=torch.float16)
tensor(3.5234, device='cuda:0', dtype=torch.float16) tensor(0.2479, device='cuda:0', dtype=torch.float16)
tensor(3.3906, device='cuda:0', dtype=torch.float16) tensor(0.2294, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0132, device='cuda:0')
tensor(0.0549, device='cuda:0')
old_score: tensor(0.2383, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1455, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.678377151489258
Validation after dual ascent:
out_inf: tensor(15.5469, device='cuda:0', dtype=torch.float16) tensor(0.8232, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1464, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
tensor(1.6680, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(2.1328, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.6875, device='cuda:0', dtype=torch.float16) tensor(0.9780, device='cuda:0', dtype=torch.float16)
tensor(4.6016, device='cuda:0', dtype=torch.float16) tensor(0.2438, device='cuda:0', dtype=torch.float16)
tensor(3.4844, device='cuda:0', dtype=torch.float16) tensor(0.2424, device='cuda:0', dtype=torch.float16)
tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.2576, device='cuda:0', dtype=torch.float16)
tensor(3.9609, device='cuda:0', dtype=torch.float16) tensor(0.2350, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0160, device='cuda:0')
tensor(0.0660, device='cuda:0')
old_score: tensor(0.2448, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1466, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.703622102737427
Validation after dual ascent:
out_inf: tensor(19.6875, device='cuda:0', dtype=torch.float16) tensor(0.9780, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
tensor(1.6406, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(2.5156, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.2305, device='cuda:0', dtype=torch.float16) tensor(0.4817, device='cuda:0', dtype=torch.float16)
tensor(1.8936, device='cuda:0', dtype=torch.float16) tensor(0.2048, device='cuda:0', dtype=torch.float16)
tensor(1.9160, device='cuda:0', dtype=torch.float16) tensor(0.2074, device='cuda:0', dtype=torch.float16)
tensor(1.7246, device='cuda:0', dtype=torch.float16) tensor(0.2133, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.2007, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0159, device='cuda:0')
tensor(0.0931, device='cuda:0')
old_score: tensor(0.2065, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1367, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1854264736175537
Validation after dual ascent:
out_inf: tensor(7.2305, device='cuda:0', dtype=torch.float16) tensor(0.4817, device='cuda:0', dtype=torch.float16)
tensor(1.3105, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1298, device='cuda:0', dtype=torch.float16)
tensor(1.5225, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(1.3848, device='cuda:0', dtype=torch.float16) tensor(0.1296, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.o_proj
Validation after prune:
out_inf: tensor(10.1250, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(1.3984, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
tensor(0.0733, device='cuda:0')
old_score: tensor(0.0355, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0210, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.803798913955688
Validation after dual ascent:
out_inf: tensor(10.1250, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(0.5044, device='cuda:0', dtype=torch.float16) tensor(0.0191, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
tensor(1.0488, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0207, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.3203, device='cuda:0', dtype=torch.float16) tensor(0.5181, device='cuda:0', dtype=torch.float16)
tensor(2.8203, device='cuda:0', dtype=torch.float16) tensor(0.1694, device='cuda:0', dtype=torch.float16)
tensor(2.8984, device='cuda:0', dtype=torch.float16) tensor(0.1721, device='cuda:0', dtype=torch.float16)
tensor(3.2500, device='cuda:0', dtype=torch.float16) tensor(0.1769, device='cuda:0', dtype=torch.float16)
tensor(3.0312, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0110, device='cuda:0')
tensor(0.0329, device='cuda:0')
old_score: tensor(0.1708, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1085, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.051948547363281
Validation after dual ascent:
out_inf: tensor(10.3203, device='cuda:0', dtype=torch.float16) tensor(0.5181, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1095, device='cuda:0', dtype=torch.float16)
tensor(2.3555, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.1188, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.1031, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.up_proj
Validation after prune:
out_inf: tensor(12.0625, device='cuda:0', dtype=torch.float16) tensor(0.4089, device='cuda:0', dtype=torch.float16)
tensor(2.8359, device='cuda:0', dtype=torch.float16) tensor(0.1598, device='cuda:0', dtype=torch.float16)
tensor(2.8672, device='cuda:0', dtype=torch.float16) tensor(0.1617, device='cuda:0', dtype=torch.float16)
tensor(2.9648, device='cuda:0', dtype=torch.float16) tensor(0.1670, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.1561, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0084, device='cuda:0')
tensor(0.0306, device='cuda:0')
old_score: tensor(0.1611, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1035, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.05057168006897
Validation after dual ascent:
out_inf: tensor(12.0625, device='cuda:0', dtype=torch.float16) tensor(0.4089, device='cuda:0', dtype=torch.float16)
tensor(1.2109, device='cuda:0', dtype=torch.float16) tensor(0.1045, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0978, device='cuda:0', dtype=torch.float16)
tensor(1.2070, device='cuda:0', dtype=torch.float16) tensor(0.1132, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.0985, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.down_proj
Validation after prune:
out_inf: tensor(7.7109, device='cuda:0', dtype=torch.float16) tensor(0.2369, device='cuda:0', dtype=torch.float16)
tensor(0.9590, device='cuda:0', dtype=torch.float16) tensor(0.0774, device='cuda:0', dtype=torch.float16)
tensor(0.9038, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(0.8667, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(1.1045, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0148, device='cuda:0')
tensor(0.1673, device='cuda:0')
old_score: tensor(0.0773, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0602, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.978259563446045
Validation after dual ascent:
out_inf: tensor(7.7109, device='cuda:0', dtype=torch.float16) tensor(0.2369, device='cuda:0', dtype=torch.float16)
tensor(0.7783, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0564, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.0078, device='cuda:0', dtype=torch.float16) tensor(0.8057, device='cuda:0', dtype=torch.float16)
tensor(3.3828, device='cuda:0', dtype=torch.float16) tensor(0.2275, device='cuda:0', dtype=torch.float16)
tensor(2.9766, device='cuda:0', dtype=torch.float16) tensor(0.2310, device='cuda:0', dtype=torch.float16)
tensor(3.5625, device='cuda:0', dtype=torch.float16) tensor(0.2419, device='cuda:0', dtype=torch.float16)
tensor(3.2812, device='cuda:0', dtype=torch.float16) tensor(0.2216, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0126, device='cuda:0')
tensor(0.0462, device='cuda:0')
old_score: tensor(0.2305, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1371, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.393780708312988
Validation after dual ascent:
out_inf: tensor(13.0078, device='cuda:0', dtype=torch.float16) tensor(0.8057, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1301, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
tensor(1.6406, device='cuda:0', dtype=torch.float16) tensor(0.1295, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20., device='cuda:0', dtype=torch.float16) tensor(1.0156, device='cuda:0', dtype=torch.float16)
tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.2350, device='cuda:0', dtype=torch.float16)
tensor(3.4297, device='cuda:0', dtype=torch.float16) tensor(0.2374, device='cuda:0', dtype=torch.float16)
tensor(3.5547, device='cuda:0', dtype=torch.float16) tensor(0.2491, device='cuda:0', dtype=torch.float16)
tensor(3.6562, device='cuda:0', dtype=torch.float16) tensor(0.2264, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0187, device='cuda:0')
tensor(0.0253, device='cuda:0')
old_score: tensor(0.2371, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1382, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.129263877868652
Validation after dual ascent:
out_inf: tensor(20., device='cuda:0', dtype=torch.float16) tensor(1.0156, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1520, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1302, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.2734, device='cuda:0', dtype=torch.float16) tensor(0.4602, device='cuda:0', dtype=torch.float16)
tensor(1.9570, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.2062, device='cuda:0', dtype=torch.float16)
tensor(1.9766, device='cuda:0', dtype=torch.float16) tensor(0.2117, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.1980, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0077, device='cuda:0')
tensor(0.0699, device='cuda:0')
old_score: tensor(0.2046, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1344, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1934010982513428
Validation after dual ascent:
out_inf: tensor(7.2734, device='cuda:0', dtype=torch.float16) tensor(0.4602, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.1353, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(1.2627, device='cuda:0', dtype=torch.float16) tensor(0.1478, device='cuda:0', dtype=torch.float16)
tensor(1.1416, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.o_proj
Validation after prune:
out_inf: tensor(19.7344, device='cuda:0', dtype=torch.float16) tensor(0.1903, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(2.5312, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(3.0859, device='cuda:0', dtype=torch.float16) tensor(0.0554, device='cuda:0', dtype=torch.float16)
tensor(2.9766, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(0.0610, device='cuda:0')
old_score: tensor(0.0497, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0313, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.882942199707031
Validation after dual ascent:
out_inf: tensor(19.7344, device='cuda:0', dtype=torch.float16) tensor(0.1903, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0304, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(1.1094, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.gate_proj
Validation after prune:
out_inf: tensor(12.7656, device='cuda:0', dtype=torch.float16) tensor(0.5283, device='cuda:0', dtype=torch.float16)
tensor(3.4062, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.1753, device='cuda:0', dtype=torch.float16)
tensor(3.3594, device='cuda:0', dtype=torch.float16) tensor(0.1792, device='cuda:0', dtype=torch.float16)
tensor(3.1836, device='cuda:0', dtype=torch.float16) tensor(0.1688, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0120, device='cuda:0')
tensor(0.0350, device='cuda:0')
old_score: tensor(0.1741, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1095, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.053226232528687
Validation after dual ascent:
out_inf: tensor(12.7656, device='cuda:0', dtype=torch.float16) tensor(0.5283, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1040, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1194, device='cuda:0', dtype=torch.float16)
tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.up_proj
Validation after prune:
out_inf: tensor(9.3750, device='cuda:0', dtype=torch.float16) tensor(0.4561, device='cuda:0', dtype=torch.float16)
tensor(4.1953, device='cuda:0', dtype=torch.float16) tensor(0.1669, device='cuda:0', dtype=torch.float16)
tensor(5.2266, device='cuda:0', dtype=torch.float16) tensor(0.1688, device='cuda:0', dtype=torch.float16)
tensor(3.4961, device='cuda:0', dtype=torch.float16) tensor(0.1738, device='cuda:0', dtype=torch.float16)
tensor(4.5859, device='cuda:0', dtype=torch.float16) tensor(0.1633, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0111, device='cuda:0')
tensor(0.0334, device='cuda:0')
old_score: tensor(0.1682, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1053, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.053697109222412
Validation after dual ascent:
out_inf: tensor(9.3750, device='cuda:0', dtype=torch.float16) tensor(0.4561, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
tensor(2.9531, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(3.0859, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(3.4688, device='cuda:0', dtype=torch.float16) tensor(0.1004, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.down_proj
Validation after prune:
out_inf: tensor(21.5312, device='cuda:0', dtype=torch.float16) tensor(0.2920, device='cuda:0', dtype=torch.float16)
tensor(1.0889, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
tensor(0.9443, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(1.3105, device='cuda:0', dtype=torch.float16) tensor(0.0855, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0189, device='cuda:0')
tensor(0.2156, device='cuda:0')
old_score: tensor(0.0865, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0662, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.981783151626587
Validation after dual ascent:
out_inf: tensor(21.5312, device='cuda:0', dtype=torch.float16) tensor(0.2920, device='cuda:0', dtype=torch.float16)
tensor(0.9199, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(0.8779, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.7427, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.4844, device='cuda:0', dtype=torch.float16) tensor(0.8320, device='cuda:0', dtype=torch.float16)
tensor(3.8984, device='cuda:0', dtype=torch.float16) tensor(0.2413, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.2434, device='cuda:0', dtype=torch.float16)
tensor(3.5469, device='cuda:0', dtype=torch.float16) tensor(0.2539, device='cuda:0', dtype=torch.float16)
tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.2368, device='cuda:0', dtype=torch.float16)
tensor(0.0356, device='cuda:0')
old_score: tensor(0.2439, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1409, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.934672832489014
Validation after dual ascent:
out_inf: tensor(14.4844, device='cuda:0', dtype=torch.float16) tensor(0.8320, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
tensor(1.6328, device='cuda:0', dtype=torch.float16) tensor(0.1544, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.7344, device='cuda:0', dtype=torch.float16) tensor(0.9731, device='cuda:0', dtype=torch.float16)
tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.2517, device='cuda:0', dtype=torch.float16)
tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.2551, device='cuda:0', dtype=torch.float16)
tensor(4.1016, device='cuda:0', dtype=torch.float16) tensor(0.2666, device='cuda:0', dtype=torch.float16)
tensor(3.9062, device='cuda:0', dtype=torch.float16) tensor(0.2480, device='cuda:0', dtype=torch.float16)
tensor(0.0368, device='cuda:0')
old_score: tensor(0.2554, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1433, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.960596084594727
Validation after dual ascent:
out_inf: tensor(17.7344, device='cuda:0', dtype=torch.float16) tensor(0.9731, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1442, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1570, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.v_proj
Validation after prune:
out_inf: tensor(9.2109, device='cuda:0', dtype=torch.float16) tensor(0.5083, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.2167, device='cuda:0', dtype=torch.float16)
tensor(1.7520, device='cuda:0', dtype=torch.float16) tensor(0.2207, device='cuda:0', dtype=torch.float16)
tensor(1.9570, device='cuda:0', dtype=torch.float16) tensor(0.2271, device='cuda:0', dtype=torch.float16)
tensor(1.6855, device='cuda:0', dtype=torch.float16) tensor(0.2128, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0164, device='cuda:0')
tensor(0.1045, device='cuda:0')
old_score: tensor(0.2194, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1395, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.2033841609954834
Validation after dual ascent:
out_inf: tensor(9.2109, device='cuda:0', dtype=torch.float16) tensor(0.5083, device='cuda:0', dtype=torch.float16)
tensor(1.4590, device='cuda:0', dtype=torch.float16) tensor(0.1405, device='cuda:0', dtype=torch.float16)
tensor(1.3740, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
tensor(1.2412, device='cuda:0', dtype=torch.float16) tensor(0.1525, device='cuda:0', dtype=torch.float16)
tensor(1.2676, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.o_proj
Validation after prune:
out_inf: tensor(17.6562, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(2.0742, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(1.5312, device='cuda:0', dtype=torch.float16) tensor(0.0367, device='cuda:0', dtype=torch.float16)
tensor(1.4727, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.0684, device='cuda:0')
old_score: tensor(0.0365, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0215, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.895573854446411
Validation after dual ascent:
out_inf: tensor(17.6562, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.gate_proj
Validation after prune:
out_inf: tensor(34.4688, device='cuda:0', dtype=torch.float16) tensor(0.5815, device='cuda:0', dtype=torch.float16)
tensor(19.4531, device='cuda:0', dtype=torch.float16) tensor(0.1830, device='cuda:0', dtype=torch.float16)
tensor(21.0469, device='cuda:0', dtype=torch.float16) tensor(0.1865, device='cuda:0', dtype=torch.float16)
tensor(20.5312, device='cuda:0', dtype=torch.float16) tensor(0.1913, device='cuda:0', dtype=torch.float16)
tensor(15.8906, device='cuda:0', dtype=torch.float16) tensor(0.1807, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0185, device='cuda:0')
tensor(0.0366, device='cuda:0')
old_score: tensor(0.1854, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1098, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.067371368408203
Validation after dual ascent:
out_inf: tensor(34.4688, device='cuda:0', dtype=torch.float16) tensor(0.5815, device='cuda:0', dtype=torch.float16)
tensor(8.1250, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(7.4688, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(9.0938, device='cuda:0', dtype=torch.float16) tensor(0.1204, device='cuda:0', dtype=torch.float16)
tensor(7.7188, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.up_proj
Validation after prune:
out_inf: tensor(35.0312, device='cuda:0', dtype=torch.float16) tensor(0.5439, device='cuda:0', dtype=torch.float16)
tensor(19.6875, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(17.5312, device='cuda:0', dtype=torch.float16) tensor(0.1815, device='cuda:0', dtype=torch.float16)
tensor(19.8906, device='cuda:0', dtype=torch.float16) tensor(0.1880, device='cuda:0', dtype=torch.float16)
tensor(16.2969, device='cuda:0', dtype=torch.float16) tensor(0.1759, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0186, device='cuda:0')
tensor(0.0351, device='cuda:0')
old_score: tensor(0.1809, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1050, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.070471286773682
Validation after dual ascent:
out_inf: tensor(35.0312, device='cuda:0', dtype=torch.float16) tensor(0.5439, device='cuda:0', dtype=torch.float16)
tensor(9.3438, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(7.8594, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(10.2812, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(7.9375, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.down_proj
Validation after prune:
out_inf: tensor(1472., device='cuda:0', dtype=torch.float16) tensor(0.4968, device='cuda:0', dtype=torch.float16)
tensor(1.6934, device='cuda:0', dtype=torch.float16) tensor(0.1001, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
tensor(1.2588, device='cuda:0', dtype=torch.float16) tensor(0.1045, device='cuda:0', dtype=torch.float16)
tensor(1.6973, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0160, device='cuda:0')
tensor(0.0389, device='cuda:0')
old_score: tensor(0.1017, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0744, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.757472276687622
Validation after dual ascent:
out_inf: tensor(1472., device='cuda:0', dtype=torch.float16) tensor(0.4968, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.0744, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.9482, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(1.0400, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.6562, device='cuda:0', dtype=torch.float16) tensor(0.8545, device='cuda:0', dtype=torch.float16)
tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.2334, device='cuda:0', dtype=torch.float16)
tensor(4.0938, device='cuda:0', dtype=torch.float16) tensor(0.2377, device='cuda:0', dtype=torch.float16)
tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.2465, device='cuda:0', dtype=torch.float16)
tensor(4.2578, device='cuda:0', dtype=torch.float16) tensor(0.2339, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0192, device='cuda:0')
tensor(0.0290, device='cuda:0')
old_score: tensor(0.2379, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1166, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1961560249328613
Validation after dual ascent:
out_inf: tensor(13.6562, device='cuda:0', dtype=torch.float16) tensor(0.8545, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(1.4531, device='cuda:0', dtype=torch.float16) tensor(0.1106, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.1293, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.k_proj
Validation after prune:
out_inf: tensor(21.9375, device='cuda:0', dtype=torch.float16) tensor(1.0781, device='cuda:0', dtype=torch.float16)
tensor(4.8750, device='cuda:0', dtype=torch.float16) tensor(0.2524, device='cuda:0', dtype=torch.float16)
tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.2532, device='cuda:0', dtype=torch.float16)
tensor(5.3594, device='cuda:0', dtype=torch.float16) tensor(0.2659, device='cuda:0', dtype=torch.float16)
tensor(5.1641, device='cuda:0', dtype=torch.float16) tensor(0.2544, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0127, device='cuda:0')
tensor(0.0144, device='cuda:0')
old_score: tensor(0.2563, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1201, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.670062780380249
Validation after dual ascent:
out_inf: tensor(21.9375, device='cuda:0', dtype=torch.float16) tensor(1.0781, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(1.6328, device='cuda:0', dtype=torch.float16) tensor(0.1137, device='cuda:0', dtype=torch.float16)
tensor(2.1641, device='cuda:0', dtype=torch.float16) tensor(0.1332, device='cuda:0', dtype=torch.float16)
tensor(1.5879, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.3125, device='cuda:0', dtype=torch.float16) tensor(0.3984, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.1702, device='cuda:0', dtype=torch.float16)
tensor(1.4629, device='cuda:0', dtype=torch.float16) tensor(0.1746, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.1770, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1694, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.1780, device='cuda:0')
old_score: tensor(0.1727, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1036, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.463550090789795
Validation after dual ascent:
out_inf: tensor(7.3125, device='cuda:0', dtype=torch.float16) tensor(0.3984, device='cuda:0', dtype=torch.float16)
tensor(1.1953, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(1.0596, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(1.0986, device='cuda:0', dtype=torch.float16) tensor(0.1143, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.o_proj
Validation after prune:
out_inf: tensor(115.7500, device='cuda:0', dtype=torch.float16) tensor(0.3213, device='cuda:0', dtype=torch.float16)
tensor(4., device='cuda:0', dtype=torch.float16) tensor(0.0876, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
tensor(3.0547, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0160, device='cuda:0')
tensor(0.0146, device='cuda:0')
old_score: tensor(0.0894, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0347, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1699445247650146
Validation after dual ascent:
out_inf: tensor(115.7500, device='cuda:0', dtype=torch.float16) tensor(0.3213, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0362, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.gate_proj
Validation after prune:
out_inf: tensor(29.6562, device='cuda:0', dtype=torch.float16) tensor(0.6323, device='cuda:0', dtype=torch.float16)
tensor(8.5781, device='cuda:0', dtype=torch.float16) tensor(0.1935, device='cuda:0', dtype=torch.float16)
tensor(8.2734, device='cuda:0', dtype=torch.float16) tensor(0.2003, device='cuda:0', dtype=torch.float16)
tensor(8.5781, device='cuda:0', dtype=torch.float16) tensor(0.2008, device='cuda:0', dtype=torch.float16)
tensor(9.0469, device='cuda:0', dtype=torch.float16) tensor(0.1965, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0152, device='cuda:0')
tensor(0.0165, device='cuda:0')
old_score: tensor(0.1978, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0996, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.923602104187012
Validation after dual ascent:
out_inf: tensor(29.6562, device='cuda:0', dtype=torch.float16) tensor(0.6323, device='cuda:0', dtype=torch.float16)
tensor(2.6484, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(2.1875, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.up_proj
Validation after prune:
out_inf: tensor(32.4062, device='cuda:0', dtype=torch.float16) tensor(0.6577, device='cuda:0', dtype=torch.float16)
tensor(12.7812, device='cuda:0', dtype=torch.float16) tensor(0.1899, device='cuda:0', dtype=torch.float16)
tensor(13.0625, device='cuda:0', dtype=torch.float16) tensor(0.1949, device='cuda:0', dtype=torch.float16)
tensor(13.4062, device='cuda:0', dtype=torch.float16) tensor(0.1985, device='cuda:0', dtype=torch.float16)
tensor(13.0938, device='cuda:0', dtype=torch.float16) tensor(0.1907, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0149, device='cuda:0')
tensor(0.0163, device='cuda:0')
old_score: tensor(0.1934, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0945, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.934790134429932
Validation after dual ascent:
out_inf: tensor(32.4062, device='cuda:0', dtype=torch.float16) tensor(0.6577, device='cuda:0', dtype=torch.float16)
tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(2.9570, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(3.4062, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.down_proj
Validation after prune:
out_inf: tensor(143.3750, device='cuda:0', dtype=torch.float16) tensor(1.6016, device='cuda:0', dtype=torch.float16)
tensor(4.8125, device='cuda:0', dtype=torch.float16) tensor(0.1244, device='cuda:0', dtype=torch.float16)
tensor(4.3125, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
tensor(4.5625, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(3.9844, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.17it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.18it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.99it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25': 0, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.699950
layer 1 sparsity 0.699950
layer 2 sparsity 0.699950
layer 3 sparsity 0.699950
layer 4 sparsity 0.699950
layer 5 sparsity 0.699950
layer 6 sparsity 0.699950
layer 7 sparsity 0.699950
layer 8 sparsity 0.699950
layer 9 sparsity 0.699950
layer 10 sparsity 0.699950
layer 11 sparsity 0.699950
layer 12 sparsity 0.699950
layer 13 sparsity 0.699950
layer 14 sparsity 0.699950
layer 15 sparsity 0.699950
layer 16 sparsity 0.699950
layer 17 sparsity 0.699950
layer 18 sparsity 0.699950
layer 19 sparsity 0.699950
layer 20 sparsity 0.699950
layer 21 sparsity 0.699950
layer 22 sparsity 0.699950
layer 23 sparsity 0.699950
layer 24 sparsity 0.699950
layer 25 sparsity 0.699950
layer 26 sparsity 0.699950
layer 27 sparsity 0.699950
layer 28 sparsity 0.699950
layer 29 sparsity 0.699950
layer 30 sparsity 0.699950
layer 31 sparsity 0.699950
sparsity sanity check 0.6999
******************************
evaluating on wikitext2
nsamples 83
sample 0
sample 50
wikitext perplexity 22.998395919799805
wanda_dual_3	0.6999	22.9984	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.7, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='wanda_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
2025-04-24 02:34:52.603261: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 02:34:52.804095: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 02:34:52.809478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 02:34:52.810945: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 02:34:56.436428: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 02:34:56.436974: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 02:34:56.436993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.60it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.79it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.76it/s]
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
model.embed_tokens.weight torch.Size([32000, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([32000, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:00<03:22,  1.26it/s]  1%|          | 2/256 [00:01<03:13,  1.31it/s]  2%|▏         | 4/256 [00:01<01:37,  2.58it/s]  2%|▏         | 5/256 [00:02<01:54,  2.19it/s]  2%|▏         | 6/256 [00:02<01:32,  2.70it/s]  3%|▎         | 7/256 [00:03<02:17,  1.81it/s]  3%|▎         | 8/256 [00:03<01:44,  2.37it/s]  4%|▎         | 9/256 [00:03<01:20,  3.07it/s]  4%|▍         | 11/256 [00:04<00:52,  4.67it/s]  5%|▍         | 12/256 [00:04<00:46,  5.19it/s]  5%|▌         | 13/256 [00:05<01:33,  2.60it/s]  5%|▌         | 14/256 [00:05<01:31,  2.65it/s]  6%|▌         | 15/256 [00:05<01:17,  3.13it/s]  6%|▋         | 16/256 [00:05<01:06,  3.60it/s]  7%|▋         | 18/256 [00:06<01:08,  3.45it/s]  8%|▊         | 20/256 [00:06<00:51,  4.58it/s]  8%|▊         | 21/256 [00:06<00:45,  5.19it/s]  9%|▊         | 22/256 [00:06<00:48,  4.85it/s]  9%|▉         | 24/256 [00:07<00:42,  5.50it/s] 10%|▉         | 25/256 [00:07<00:40,  5.76it/s] 10%|█         | 26/256 [00:07<00:52,  4.35it/s] 11%|█         | 28/256 [00:08<00:44,  5.18it/s] 11%|█▏        | 29/256 [00:08<00:45,  4.98it/s] 12%|█▏        | 31/256 [00:08<00:38,  5.89it/s] 12%|█▎        | 32/256 [00:08<00:46,  4.86it/s] 13%|█▎        | 33/256 [00:09<00:57,  3.87it/s] 13%|█▎        | 34/256 [00:09<01:01,  3.60it/s] 14%|█▎        | 35/256 [00:10<01:08,  3.23it/s] 14%|█▍        | 36/256 [00:10<01:19,  2.78it/s] 14%|█▍        | 37/256 [00:10<01:13,  2.97it/s] 15%|█▍        | 38/256 [00:11<01:08,  3.17it/s] 16%|█▌        | 40/256 [00:11<01:03,  3.39it/s] 16%|█▋        | 42/256 [00:11<00:44,  4.82it/s] 17%|█▋        | 43/256 [00:11<00:39,  5.40it/s] 17%|█▋        | 44/256 [00:12<00:38,  5.45it/s] 18%|█▊        | 45/256 [00:12<00:34,  6.15it/s] 18%|█▊        | 46/256 [00:12<00:32,  6.39it/s] 18%|█▊        | 47/256 [00:12<00:34,  6.14it/s] 19%|█▉        | 48/256 [00:12<00:38,  5.45it/s] 19%|█▉        | 49/256 [00:12<00:34,  5.96it/s] 20%|█▉        | 50/256 [00:13<00:51,  4.01it/s] 21%|██        | 53/256 [00:13<00:49,  4.12it/s] 21%|██        | 54/256 [00:14<00:48,  4.17it/s] 21%|██▏       | 55/256 [00:14<00:41,  4.79it/s] 22%|██▏       | 56/256 [00:14<00:48,  4.11it/s] 22%|██▏       | 57/256 [00:14<00:44,  4.46it/s] 23%|██▎       | 58/256 [00:15<00:49,  3.97it/s] 23%|██▎       | 59/256 [00:15<00:43,  4.51it/s] 23%|██▎       | 60/256 [00:15<00:46,  4.18it/s] 24%|██▍       | 61/256 [00:15<00:55,  3.53it/s] 24%|██▍       | 62/256 [00:16<00:59,  3.25it/s] 25%|██▍       | 63/256 [00:16<00:51,  3.73it/s] 25%|██▌       | 64/256 [00:16<00:42,  4.51it/s] 25%|██▌       | 65/256 [00:17<01:09,  2.76it/s] 26%|██▌       | 67/256 [00:17<00:44,  4.29it/s] 27%|██▋       | 68/256 [00:17<00:42,  4.39it/s] 27%|██▋       | 69/256 [00:17<00:43,  4.28it/s] 28%|██▊       | 71/256 [00:18<00:33,  5.50it/s] 29%|██▊       | 73/256 [00:18<00:26,  6.81it/s] 29%|██▉       | 74/256 [00:18<00:26,  6.88it/s] 29%|██▉       | 75/256 [00:18<00:31,  5.73it/s] 30%|██▉       | 76/256 [00:19<00:44,  4.06it/s] 30%|███       | 78/256 [00:19<00:30,  5.84it/s] 31%|███       | 79/256 [00:19<00:38,  4.66it/s] 31%|███▏      | 80/256 [00:20<00:48,  3.60it/s] 32%|███▏      | 81/256 [00:20<00:54,  3.22it/s] 32%|███▏      | 82/256 [00:20<00:44,  3.88it/s] 32%|███▏      | 83/256 [00:21<00:55,  3.10it/s] 33%|███▎      | 84/256 [00:21<00:52,  3.27it/s] 33%|███▎      | 85/256 [00:21<00:47,  3.57it/s] 34%|███▎      | 86/256 [00:21<00:43,  3.90it/s] 34%|███▍      | 87/256 [00:22<01:00,  2.77it/s] 34%|███▍      | 88/256 [00:22<01:03,  2.66it/s] 35%|███▍      | 89/256 [00:23<00:58,  2.84it/s] 35%|███▌      | 90/256 [00:23<01:00,  2.76it/s] 36%|███▌      | 91/256 [00:23<00:58,  2.83it/s] 36%|███▌      | 92/256 [00:24<00:53,  3.06it/s] 36%|███▋      | 93/256 [00:24<00:50,  3.23it/s] 37%|███▋      | 94/256 [00:25<01:06,  2.42it/s] 37%|███▋      | 95/256 [00:25<01:17,  2.07it/s] 38%|███▊      | 96/256 [00:25<01:00,  2.63it/s] 38%|███▊      | 97/256 [00:26<01:02,  2.56it/s] 38%|███▊      | 98/256 [00:26<00:51,  3.09it/s] 39%|███▊      | 99/256 [00:26<00:48,  3.27it/s] 39%|███▉      | 100/256 [00:26<00:45,  3.44it/s] 39%|███▉      | 101/256 [00:27<01:17,  2.01it/s] 40%|███▉      | 102/256 [00:28<01:05,  2.34it/s] 41%|████      | 104/256 [00:28<00:42,  3.62it/s] 41%|████▏     | 106/256 [00:28<00:34,  4.38it/s] 42%|████▏     | 107/256 [00:28<00:33,  4.39it/s] 42%|████▏     | 108/256 [00:29<00:48,  3.05it/s] 43%|████▎     | 111/256 [00:29<00:30,  4.73it/s] 44%|████▍     | 112/256 [00:30<00:32,  4.48it/s] 44%|████▍     | 113/256 [00:30<00:31,  4.47it/s] 45%|████▍     | 114/256 [00:30<00:29,  4.88it/s] 45%|████▍     | 115/256 [00:30<00:27,  5.12it/s] 45%|████▌     | 116/256 [00:31<00:38,  3.65it/s] 46%|████▌     | 117/256 [00:31<00:32,  4.22it/s] 46%|████▌     | 118/256 [00:31<00:34,  4.05it/s] 47%|████▋     | 120/256 [00:31<00:25,  5.29it/s] 47%|████▋     | 121/256 [00:32<00:25,  5.33it/s] 48%|████▊     | 122/256 [00:32<00:51,  2.62it/s] 48%|████▊     | 123/256 [00:33<00:50,  2.62it/s] 48%|████▊     | 124/256 [00:34<01:00,  2.19it/s] 49%|████▉     | 125/256 [00:35<01:28,  1.48it/s] 49%|████▉     | 126/256 [00:35<01:13,  1.76it/s] 50%|████▉     | 127/256 [00:36<01:18,  1.64it/s] 50%|█████     | 129/256 [00:36<00:47,  2.69it/s] 51%|█████     | 130/256 [00:36<00:42,  2.95it/s] 51%|█████     | 131/256 [00:36<00:39,  3.15it/s] 52%|█████▏    | 132/256 [00:37<00:39,  3.17it/s] 52%|█████▏    | 133/256 [00:37<00:54,  2.27it/s] 52%|█████▏    | 134/256 [00:38<00:57,  2.12it/s] 53%|█████▎    | 135/256 [00:38<00:47,  2.55it/s] 53%|█████▎    | 136/256 [00:39<00:48,  2.46it/s] 54%|█████▎    | 137/256 [00:39<00:39,  3.04it/s] 54%|█████▍    | 138/256 [00:39<00:33,  3.56it/s] 54%|█████▍    | 139/256 [00:39<00:28,  4.08it/s] 55%|█████▍    | 140/256 [00:39<00:25,  4.58it/s] 55%|█████▌    | 142/256 [00:40<00:18,  6.14it/s] 56%|█████▌    | 143/256 [00:40<00:17,  6.43it/s] 57%|█████▋    | 145/256 [00:41<00:35,  3.10it/s] 57%|█████▋    | 146/256 [00:41<00:39,  2.81it/s] 57%|█████▋    | 147/256 [00:41<00:36,  3.01it/s] 58%|█████▊    | 148/256 [00:42<00:36,  2.93it/s] 59%|█████▊    | 150/256 [00:42<00:29,  3.62it/s] 59%|█████▉    | 151/256 [00:42<00:25,  4.18it/s] 59%|█████▉    | 152/256 [00:43<00:28,  3.61it/s] 60%|█████▉    | 153/256 [00:43<00:25,  3.99it/s] 60%|██████    | 154/256 [00:43<00:29,  3.43it/s] 61%|██████    | 155/256 [00:44<00:26,  3.75it/s] 61%|██████    | 156/256 [00:44<00:22,  4.43it/s] 61%|██████▏   | 157/256 [00:44<00:28,  3.52it/s] 62%|██████▏   | 158/256 [00:44<00:24,  4.02it/s] 62%|██████▏   | 159/256 [00:45<00:43,  2.24it/s] 62%|██████▎   | 160/256 [00:45<00:33,  2.88it/s] 63%|██████▎   | 162/256 [00:46<00:37,  2.53it/s] 64%|██████▎   | 163/256 [00:46<00:32,  2.84it/s] 64%|██████▍   | 164/256 [00:47<00:27,  3.36it/s] 65%|██████▍   | 166/256 [00:47<00:23,  3.89it/s] 65%|██████▌   | 167/256 [00:47<00:25,  3.51it/s] 66%|██████▌   | 168/256 [00:48<00:28,  3.10it/s] 66%|██████▌   | 169/256 [00:48<00:31,  2.74it/s] 66%|██████▋   | 170/256 [00:49<00:31,  2.75it/s] 67%|██████▋   | 171/256 [00:49<00:24,  3.45it/s] 67%|██████▋   | 172/256 [00:49<00:21,  3.93it/s] 68%|██████▊   | 173/256 [00:49<00:20,  4.05it/s] 68%|██████▊   | 174/256 [00:50<00:29,  2.79it/s] 68%|██████▊   | 175/256 [00:51<00:42,  1.91it/s] 69%|██████▉   | 176/256 [00:51<00:36,  2.21it/s] 69%|██████▉   | 177/256 [00:51<00:29,  2.69it/s] 70%|██████▉   | 179/256 [00:51<00:19,  3.95it/s] 70%|███████   | 180/256 [00:53<00:37,  2.04it/s] 71%|███████   | 181/256 [00:53<00:29,  2.53it/s] 71%|███████   | 182/256 [00:53<00:38,  1.95it/s] 72%|███████▏  | 184/256 [00:54<00:35,  2.05it/s] 73%|███████▎  | 186/256 [00:55<00:23,  2.96it/s] 73%|███████▎  | 187/256 [00:55<00:27,  2.54it/s] 73%|███████▎  | 188/256 [00:55<00:23,  2.90it/s] 74%|███████▍  | 189/256 [00:56<00:23,  2.88it/s] 74%|███████▍  | 190/256 [00:56<00:21,  3.10it/s] 75%|███████▍  | 191/256 [00:56<00:19,  3.41it/s] 75%|███████▌  | 192/256 [00:57<00:22,  2.89it/s] 75%|███████▌  | 193/256 [00:57<00:20,  3.01it/s] 77%|███████▋  | 196/256 [00:57<00:13,  4.52it/s] 77%|███████▋  | 197/256 [00:58<00:15,  3.89it/s] 78%|███████▊  | 199/256 [00:58<00:11,  4.94it/s] 79%|███████▊  | 201/256 [00:58<00:09,  5.58it/s] 79%|███████▉  | 202/256 [00:59<00:11,  4.59it/s] 80%|███████▉  | 204/256 [00:59<00:08,  5.79it/s] 80%|████████  | 206/256 [00:59<00:06,  7.16it/s] 81%|████████  | 207/256 [00:59<00:06,  7.49it/s] 81%|████████▏ | 208/256 [00:59<00:07,  6.58it/s] 82%|████████▏ | 210/256 [00:59<00:05,  8.64it/s] 83%|████████▎ | 212/256 [01:00<00:05,  8.34it/s] 83%|████████▎ | 213/256 [01:00<00:05,  7.44it/s] 84%|████████▎ | 214/256 [01:00<00:07,  5.72it/s] 84%|████████▍ | 215/256 [01:01<00:08,  4.56it/s] 84%|████████▍ | 216/256 [01:01<00:08,  4.47it/s] 85%|████████▌ | 218/256 [01:01<00:07,  5.32it/s] 86%|████████▌ | 219/256 [01:02<00:14,  2.55it/s] 86%|████████▌ | 220/256 [01:02<00:11,  3.00it/s] 86%|████████▋ | 221/256 [01:03<00:12,  2.90it/s] 87%|████████▋ | 222/256 [01:03<00:11,  2.86it/s] 87%|████████▋ | 223/256 [01:03<00:12,  2.75it/s] 88%|████████▊ | 224/256 [01:05<00:23,  1.34it/s] 88%|████████▊ | 225/256 [01:06<00:22,  1.38it/s] 88%|████████▊ | 226/256 [01:06<00:16,  1.78it/s] 89%|████████▊ | 227/256 [01:06<00:13,  2.13it/s] 89%|████████▉ | 228/256 [01:07<00:12,  2.28it/s] 89%|████████▉ | 229/256 [01:08<00:18,  1.45it/s] 90%|████████▉ | 230/256 [01:08<00:13,  1.92it/s] 90%|█████████ | 231/256 [01:08<00:12,  1.97it/s] 91%|█████████ | 232/256 [01:09<00:10,  2.25it/s] 91%|█████████ | 233/256 [01:09<00:08,  2.70it/s] 92%|█████████▏| 235/256 [01:09<00:05,  3.72it/s] 92%|█████████▏| 236/256 [01:10<00:05,  3.61it/s] 93%|█████████▎| 237/256 [01:10<00:04,  4.00it/s] 93%|█████████▎| 238/256 [01:10<00:03,  4.67it/s] 93%|█████████▎| 239/256 [01:10<00:03,  4.60it/s] 94%|█████████▍| 241/256 [01:10<00:02,  5.78it/s] 95%|█████████▍| 242/256 [01:11<00:04,  2.80it/s] 95%|█████████▌| 244/256 [01:11<00:02,  4.28it/s] 96%|█████████▌| 245/256 [01:12<00:02,  4.23it/s] 96%|█████████▌| 246/256 [01:12<00:02,  4.70it/s] 97%|█████████▋| 248/256 [01:12<00:01,  6.34it/s] 97%|█████████▋| 249/256 [01:12<00:01,  3.90it/s] 98%|█████████▊| 251/256 [01:13<00:00,  5.45it/s] 98%|█████████▊| 252/256 [01:13<00:01,  3.42it/s] 99%|█████████▉| 253/256 [01:14<00:01,  2.77it/s]100%|█████████▉| 255/256 [01:14<00:00,  2.95it/s]100%|██████████| 256/256 [01:15<00:00,  3.05it/s]100%|██████████| 256/256 [01:15<00:00,  3.40it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
pruning layer 0 name self_attn.q_proj
Validation after prune:
out_inf: tensor(7.8555, device='cuda:0', dtype=torch.float16) tensor(0.6099, device='cuda:0', dtype=torch.float16)
tensor(0.2070, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.2344, device='cuda:0', dtype=torch.float16) tensor(0.0044, device='cuda:0', dtype=torch.float16)
tensor(0.2070, device='cuda:0', dtype=torch.float16) tensor(0.0045, device='cuda:0', dtype=torch.float16)
tensor(0.2344, device='cuda:0', dtype=torch.float16) tensor(0.0043, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.k_proj
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.1895, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.2031, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.v_proj
Validation after prune:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1277, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.1250, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.0572, device='cuda:0')
old_score: tensor(0.0036, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0019, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.721197366714478
Validation after dual ascent:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.0735, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0718, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0718, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.0605, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0124, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
tensor(0.0074, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0158, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0130, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
tensor(0.8955, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.9346, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.8877, device='cuda:0', dtype=torch.float16) tensor(0.0193, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0183, device='cuda:0')
tensor(0.0178, device='cuda:0')
old_score: tensor(0.0200, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0124, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 28.996588230133057
Validation after dual ascent:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.6465, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
tensor(0.6348, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.7080, device='cuda:0', dtype=torch.float16) tensor(0.0135, device='cuda:0', dtype=torch.float16)
tensor(0.6279, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.up_proj
Validation after prune:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.4209, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.4385, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.4629, device='cuda:0', dtype=torch.float16) tensor(0.0208, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0185, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0193, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.0193, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 27.279409408569336
Validation after dual ascent:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.3076, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.3237, device='cuda:0', dtype=torch.float16) tensor(0.0117, device='cuda:0', dtype=torch.float16)
tensor(0.3584, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.2939, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.1113, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.1152, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.0947, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
tensor(0.1221, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.1215, device='cuda:0')
old_score: tensor(0.0024, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0018, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.43929123878479
Validation after dual ascent:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.0557, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0457, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0483, device='cuda:0', dtype=torch.float16) tensor(0.0020, device='cuda:0', dtype=torch.float16)
tensor(0.0649, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.q_proj
Validation after prune:
out_inf: tensor(9.3984, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(1.6738, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(1.7461, device='cuda:0', dtype=torch.float16) tensor(0.0427, device='cuda:0', dtype=torch.float16)
tensor(1.7119, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.0422, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.k_proj
Validation after prune:
out_inf: tensor(7.9297, device='cuda:0', dtype=torch.float16) tensor(0.8110, device='cuda:0', dtype=torch.float16)
tensor(1.6064, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(1.6338, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.6050, device='cuda:0', dtype=torch.float16) tensor(0.0122, device='cuda:0', dtype=torch.float16)
tensor(0.6206, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.6665, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.0195, device='cuda:0')
old_score: tensor(0.0124, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0076, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.743943691253662
Validation after dual ascent:
out_inf: tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.5176, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.5288, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.5679, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.5220, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0462, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0928, device='cuda:0', dtype=torch.float16) tensor(0.0018, device='cuda:0', dtype=torch.float16)
tensor(0.0684, device='cuda:0', dtype=torch.float16) tensor(0.0017, device='cuda:0', dtype=torch.float16)
tensor(0.0471, device='cuda:0', dtype=torch.float16) tensor(0.0016, device='cuda:0', dtype=torch.float16)
tensor(0.0263, device='cuda:0')
old_score: tensor(0.0017, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0012, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.812286138534546
Validation after dual ascent:
out_inf: tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.0375, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0393, device='cuda:0', dtype=torch.float16) tensor(0.0013, device='cuda:0', dtype=torch.float16)
tensor(0.0402, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
tensor(0.0369, device='cuda:0', dtype=torch.float16) tensor(0.0012, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.gate_proj
Validation after prune:
out_inf: tensor(42.9062, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(13.9062, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(13.2188, device='cuda:0', dtype=torch.float16) tensor(0.0458, device='cuda:0', dtype=torch.float16)
tensor(14.4531, device='cuda:0', dtype=torch.float16) tensor(0.0405, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0189, device='cuda:0')
tensor(0.0209, device='cuda:0')
old_score: tensor(0.0420, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0284, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 15.718479871749878
Validation after dual ascent:
out_inf: tensor(42.9062, device='cuda:0', dtype=torch.float16) tensor(0.0945, device='cuda:0', dtype=torch.float16)
tensor(4.1875, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(4.0625, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(3.6406, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(5.1250, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.up_proj
Validation after prune:
out_inf: tensor(37.4688, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(10.0469, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(9.9219, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(9.2031, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(10.3281, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0187, device='cuda:0')
tensor(0.0291, device='cuda:0')
old_score: tensor(0.0366, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0262, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.824942827224731
Validation after dual ascent:
out_inf: tensor(37.4688, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(2.8125, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(2.7500, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.0279, device='cuda:0', dtype=torch.float16)
tensor(3.5000, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.down_proj
Validation after prune:
out_inf: tensor(2612., device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.1719, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
tensor(1.9491, device='cuda:0')
old_score: tensor(0.0065, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0086, device='cuda:0', dtype=torch.float16)
Not converged!
Dual ascent finished!
Time: 98.196053981781
Validation after dual ascent:
out_inf: tensor(2612., device='cuda:0', dtype=torch.float16) tensor(0.0158, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.1719, device='cuda:0', dtype=torch.float16) tensor(0.0059, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0061, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.4609, device='cuda:0', dtype=torch.float16) tensor(0.9609, device='cuda:0', dtype=torch.float16)
tensor(2.8867, device='cuda:0', dtype=torch.float16) tensor(0.1208, device='cuda:0', dtype=torch.float16)
tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(2.6758, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(3.0703, device='cuda:0', dtype=torch.float16) tensor(0.1210, device='cuda:0', dtype=torch.float16)
tensor(0.0531, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0669, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.783235311508179
Validation after dual ascent:
out_inf: tensor(13.4609, device='cuda:0', dtype=torch.float16) tensor(0.9609, device='cuda:0', dtype=torch.float16)
tensor(2.0352, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.0647, device='cuda:0', dtype=torch.float16)
tensor(1.5215, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.k_proj
Validation after prune:
out_inf: tensor(14.5859, device='cuda:0', dtype=torch.float16) tensor(1.1406, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.1278, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1279, device='cuda:0', dtype=torch.float16)
tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(0.0584, device='cuda:0')
old_score: tensor(0.1267, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0684, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.833831310272217
Validation after dual ascent:
out_inf: tensor(14.5859, device='cuda:0', dtype=torch.float16) tensor(1.1406, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.0667, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(1.6211, device='cuda:0', dtype=torch.float16) tensor(0.0736, device='cuda:0', dtype=torch.float16)
tensor(1.5723, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
tensor(0.8271, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(1.0273, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0552, device='cuda:0', dtype=torch.float16)
tensor(1.0303, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0043, device='cuda:0')
tensor(0.0485, device='cuda:0')
old_score: tensor(0.0546, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0378, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1667537689208984
Validation after dual ascent:
out_inf: tensor(2.6250, device='cuda:0', dtype=torch.float16) tensor(0.1207, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
tensor(0.4553, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1783, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.1445, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1146, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.1615, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0662, device='cuda:0')
old_score: tensor(0.0026, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0020, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.896512031555176
Validation after dual ascent:
out_inf: tensor(1.0801, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1461, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.2646, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
tensor(0.1301, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.2208, device='cuda:0', dtype=torch.float16) tensor(0.0021, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(1.5234, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(1.5332, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(1.4893, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.0533, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0153, device='cuda:0')
tensor(0.0241, device='cuda:0')
old_score: tensor(0.0543, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0413, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.795584440231323
Validation after dual ascent:
out_inf: tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.6504, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(0.8193, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.6528, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.2715, device='cuda:0', dtype=torch.float16) tensor(0.0895, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.6963, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0488, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0197, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.0496, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0381, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.88417100906372
Validation after dual ascent:
out_inf: tensor(2.2715, device='cuda:0', dtype=torch.float16) tensor(0.0895, device='cuda:0', dtype=torch.float16)
tensor(0.5986, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
tensor(0.5029, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(0.4802, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0375, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.1161, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1650, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.2080, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.1481, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.1266, device='cuda:0')
old_score: tensor(0.0077, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0066, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.57223653793335
Validation after dual ascent:
out_inf: tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.0848, device='cuda:0', dtype=torch.float16) tensor(0.0062, device='cuda:0', dtype=torch.float16)
tensor(0.0973, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.1208, device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
tensor(0.1018, device='cuda:0', dtype=torch.float16) tensor(0.0064, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.2656, device='cuda:0', dtype=torch.float16) tensor(0.8584, device='cuda:0', dtype=torch.float16)
tensor(3.1133, device='cuda:0', dtype=torch.float16) tensor(0.1738, device='cuda:0', dtype=torch.float16)
tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.1741, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.1855, device='cuda:0', dtype=torch.float16)
tensor(3.0508, device='cuda:0', dtype=torch.float16) tensor(0.1755, device='cuda:0', dtype=torch.float16)
tensor(0.1685, device='cuda:0')
old_score: tensor(0.1772, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1194, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.80254054069519
Validation after dual ascent:
out_inf: tensor(17.2656, device='cuda:0', dtype=torch.float16) tensor(0.8584, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(1.7773, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(2.2520, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.1804, device='cuda:0', dtype=torch.float16)
tensor(2.8418, device='cuda:0', dtype=torch.float16) tensor(0.1803, device='cuda:0', dtype=torch.float16)
tensor(3.2266, device='cuda:0', dtype=torch.float16) tensor(0.1906, device='cuda:0', dtype=torch.float16)
tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.1814, device='cuda:0', dtype=torch.float16)
tensor(0.1599, device='cuda:0')
old_score: tensor(0.1831, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1227, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.885438680648804
Validation after dual ascent:
out_inf: tensor(15.6875, device='cuda:0', dtype=torch.float16) tensor(1.0264, device='cuda:0', dtype=torch.float16)
tensor(1.8018, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1180, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1333, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.1203, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1835, device='cuda:0', dtype=torch.float16)
tensor(0.9355, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0871, device='cuda:0', dtype=torch.float16)
tensor(0.8408, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0162, device='cuda:0')
tensor(0.0705, device='cuda:0')
old_score: tensor(0.0879, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0660, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.698488712310791
Validation after dual ascent:
out_inf: tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1835, device='cuda:0', dtype=torch.float16)
tensor(0.6299, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(0.6362, device='cuda:0', dtype=torch.float16) tensor(0.0635, device='cuda:0', dtype=torch.float16)
tensor(0.6704, device='cuda:0', dtype=torch.float16) tensor(0.0716, device='cuda:0', dtype=torch.float16)
tensor(0.7329, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.2493, device='cuda:0', dtype=torch.float16) tensor(0.0037, device='cuda:0', dtype=torch.float16)
tensor(0.2046, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.2456, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.2754, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0637, device='cuda:0')
old_score: tensor(0.0038, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0028, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.906495332717896
Validation after dual ascent:
out_inf: tensor(1.0645, device='cuda:0', dtype=torch.float16) tensor(0.0103, device='cuda:0', dtype=torch.float16)
tensor(0.1543, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.1182, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.1428, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1362, device='cuda:0', dtype=torch.float16) tensor(0.0029, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.4258, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(3., device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0679, device='cuda:0', dtype=torch.float16)
tensor(2.5859, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(3.2031, device='cuda:0', dtype=torch.float16) tensor(0.0690, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.0335, device='cuda:0')
old_score: tensor(0.0696, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0542, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.109663963317871
Validation after dual ascent:
out_inf: tensor(4.4258, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0527, device='cuda:0', dtype=torch.float16)
tensor(1.0898, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
tensor(1.0898, device='cuda:0', dtype=torch.float16) tensor(0.0534, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.4941, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.0771, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(1.2119, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(1.0684, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0087, device='cuda:0')
tensor(0.0281, device='cuda:0')
old_score: tensor(0.0632, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0500, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.109667062759399
Validation after dual ascent:
out_inf: tensor(2.4941, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0478, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0542, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0492, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.2231, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
tensor(0.1774, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.2307, device='cuda:0', dtype=torch.float16) tensor(0.0115, device='cuda:0', dtype=torch.float16)
tensor(0.1245, device='cuda:0')
old_score: tensor(0.0116, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.62899947166443
Validation after dual ascent:
out_inf: tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.1353, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.1371, device='cuda:0', dtype=torch.float16) tensor(0.0093, device='cuda:0', dtype=torch.float16)
tensor(0.1482, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.1630, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.5547, device='cuda:0', dtype=torch.float16) tensor(0.8447, device='cuda:0', dtype=torch.float16)
tensor(2.6016, device='cuda:0', dtype=torch.float16) tensor(0.1801, device='cuda:0', dtype=torch.float16)
tensor(2.4316, device='cuda:0', dtype=torch.float16) tensor(0.1813, device='cuda:0', dtype=torch.float16)
tensor(2.5332, device='cuda:0', dtype=torch.float16) tensor(0.1885, device='cuda:0', dtype=torch.float16)
tensor(2.5723, device='cuda:0', dtype=torch.float16) tensor(0.1833, device='cuda:0', dtype=torch.float16)
tensor(0.1028, device='cuda:0')
old_score: tensor(0.1833, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.814309120178223
Validation after dual ascent:
out_inf: tensor(14.5547, device='cuda:0', dtype=torch.float16) tensor(0.8447, device='cuda:0', dtype=torch.float16)
tensor(1.6025, device='cuda:0', dtype=torch.float16) tensor(0.1192, device='cuda:0', dtype=torch.float16)
tensor(1.5381, device='cuda:0', dtype=torch.float16) tensor(0.1198, device='cuda:0', dtype=torch.float16)
tensor(1.7568, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.8594, device='cuda:0', dtype=torch.float16) tensor(1.0791, device='cuda:0', dtype=torch.float16)
tensor(2.4102, device='cuda:0', dtype=torch.float16) tensor(0.1848, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1847, device='cuda:0', dtype=torch.float16)
tensor(2.5156, device='cuda:0', dtype=torch.float16) tensor(0.1919, device='cuda:0', dtype=torch.float16)
tensor(2.8086, device='cuda:0', dtype=torch.float16) tensor(0.1866, device='cuda:0', dtype=torch.float16)
tensor(0.1051, device='cuda:0')
old_score: tensor(0.1870, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1240, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.923558712005615
Validation after dual ascent:
out_inf: tensor(19.8594, device='cuda:0', dtype=torch.float16) tensor(1.0791, device='cuda:0', dtype=torch.float16)
tensor(1.7881, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(1.6416, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.1331, device='cuda:0', dtype=torch.float16)
tensor(1.9502, device='cuda:0', dtype=torch.float16) tensor(0.1224, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.5586, device='cuda:0', dtype=torch.float16) tensor(0.1958, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(1.2861, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(1.3027, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0184, device='cuda:0')
tensor(0.0873, device='cuda:0')
old_score: tensor(0.0940, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0685, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.181831121444702
Validation after dual ascent:
out_inf: tensor(4.5586, device='cuda:0', dtype=torch.float16) tensor(0.1958, device='cuda:0', dtype=torch.float16)
tensor(0.6060, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.6201, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(0.6147, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(0.6743, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.0039, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.4639, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
tensor(0.5156, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.3506, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.4165, device='cuda:0', dtype=torch.float16) tensor(0.0094, device='cuda:0', dtype=torch.float16)
tensor(0.0542, device='cuda:0')
old_score: tensor(0.0091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0067, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.914055347442627
Validation after dual ascent:
out_inf: tensor(4.0039, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.2041, device='cuda:0', dtype=torch.float16) tensor(0.0065, device='cuda:0', dtype=torch.float16)
tensor(0.2734, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.2705, device='cuda:0', dtype=torch.float16) tensor(0.0060, device='cuda:0', dtype=torch.float16)
tensor(0.2368, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(2.2441, device='cuda:0', dtype=torch.float16) tensor(0.0878, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
tensor(1.7266, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0117, device='cuda:0')
tensor(0.0365, device='cuda:0')
old_score: tensor(0.0886, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0667, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110349655151367
Validation after dual ascent:
out_inf: tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.1783, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0652, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.0647, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(0.9102, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.1582, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(1.4570, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(1.2461, device='cuda:0', dtype=torch.float16) tensor(0.0763, device='cuda:0', dtype=torch.float16)
tensor(1.1738, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0775, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0077, device='cuda:0')
tensor(0.0326, device='cuda:0')
old_score: tensor(0.0772, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0596, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.110961675643921
Validation after dual ascent:
out_inf: tensor(3.1582, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(0.7031, device='cuda:0', dtype=torch.float16) tensor(0.0578, device='cuda:0', dtype=torch.float16)
tensor(0.5576, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.9658, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.down_proj
Validation after prune:
out_inf: tensor(9.1875, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.4502, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.4565, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
tensor(0.4785, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0189, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0102, device='cuda:0')
tensor(0.0250, device='cuda:0')
old_score: tensor(0.0185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0159, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 84.25284099578857
Validation after dual ascent:
out_inf: tensor(9.1875, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.2046, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.2627, device='cuda:0', dtype=torch.float16) tensor(0.0155, device='cuda:0', dtype=torch.float16)
tensor(0.2195, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.2505, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16., device='cuda:0', dtype=torch.float16) tensor(0.8628, device='cuda:0', dtype=torch.float16)
tensor(2.5977, device='cuda:0', dtype=torch.float16) tensor(0.1980, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.2034, device='cuda:0', dtype=torch.float16)
tensor(3.1055, device='cuda:0', dtype=torch.float16) tensor(0.2039, device='cuda:0', dtype=torch.float16)
tensor(2.5977, device='cuda:0', dtype=torch.float16) tensor(0.2014, device='cuda:0', dtype=torch.float16)
tensor(0.0521, device='cuda:0')
old_score: tensor(0.2017, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1289, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.835981607437134
Validation after dual ascent:
out_inf: tensor(16., device='cuda:0', dtype=torch.float16) tensor(0.8628, device='cuda:0', dtype=torch.float16)
tensor(1.4482, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.4404, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(1.6846, device='cuda:0', dtype=torch.float16) tensor(0.1326, device='cuda:0', dtype=torch.float16)
tensor(1.6152, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.6719, device='cuda:0', dtype=torch.float16) tensor(1.1162, device='cuda:0', dtype=torch.float16)
tensor(2.9766, device='cuda:0', dtype=torch.float16) tensor(0.2103, device='cuda:0', dtype=torch.float16)
tensor(2.8750, device='cuda:0', dtype=torch.float16) tensor(0.2151, device='cuda:0', dtype=torch.float16)
tensor(2.7656, device='cuda:0', dtype=torch.float16) tensor(0.2150, device='cuda:0', dtype=torch.float16)
tensor(2.9531, device='cuda:0', dtype=torch.float16) tensor(0.2128, device='cuda:0', dtype=torch.float16)
tensor(0.0563, device='cuda:0')
old_score: tensor(0.2133, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1323, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.931797504425049
Validation after dual ascent:
out_inf: tensor(18.6719, device='cuda:0', dtype=torch.float16) tensor(1.1162, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1299, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1360, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.6309, device='cuda:0', dtype=torch.float16) tensor(0.2068, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.1002, device='cuda:0', dtype=torch.float16)
tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.1023, device='cuda:0', dtype=torch.float16)
tensor(0.8970, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.0098, device='cuda:0', dtype=torch.float16) tensor(0.1014, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0088, device='cuda:0')
tensor(0.0380, device='cuda:0')
old_score: tensor(0.1014, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0719, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.182368516921997
Validation after dual ascent:
out_inf: tensor(2.6309, device='cuda:0', dtype=torch.float16) tensor(0.2068, device='cuda:0', dtype=torch.float16)
tensor(0.6675, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(0.5845, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.9902, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.3574, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.4409, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.0573, device='cuda:0')
old_score: tensor(0.0121, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0083, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.895846366882324
Validation after dual ascent:
out_inf: tensor(3.9902, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.2842, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.2568, device='cuda:0', dtype=torch.float16) tensor(0.0086, device='cuda:0', dtype=torch.float16)
tensor(0.3354, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
tensor(0.2661, device='cuda:0', dtype=torch.float16) tensor(0.0082, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.1641, device='cuda:0', dtype=torch.float16) tensor(0.2098, device='cuda:0', dtype=torch.float16)
tensor(1.8965, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
tensor(2.0098, device='cuda:0', dtype=torch.float16) tensor(0.0985, device='cuda:0', dtype=torch.float16)
tensor(1.6963, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0116, device='cuda:0')
tensor(0.0515, device='cuda:0')
old_score: tensor(0.0986, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0670, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.108670711517334
Validation after dual ascent:
out_inf: tensor(4.1641, device='cuda:0', dtype=torch.float16) tensor(0.2098, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0673, device='cuda:0', dtype=torch.float16)
tensor(1.3574, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(0.7949, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0856, device='cuda:0', dtype=torch.float16)
tensor(1.6621, device='cuda:0', dtype=torch.float16) tensor(0.0855, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.0843, device='cuda:0', dtype=torch.float16)
tensor(1.3691, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0091, device='cuda:0')
tensor(0.0400, device='cuda:0')
old_score: tensor(0.0854, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0596, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.109299659729004
Validation after dual ascent:
out_inf: tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.8887, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.4417, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.3003, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(0.4307, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0114, device='cuda:0')
tensor(0.0267, device='cuda:0')
old_score: tensor(0.0210, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0173, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 84.17368173599243
Validation after dual ascent:
out_inf: tensor(1.8887, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(0.2288, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.3110, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
tensor(0.2197, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.3018, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.8525, device='cuda:0', dtype=torch.float16)
tensor(4.4492, device='cuda:0', dtype=torch.float16) tensor(0.2456, device='cuda:0', dtype=torch.float16)
tensor(4.5547, device='cuda:0', dtype=torch.float16) tensor(0.2496, device='cuda:0', dtype=torch.float16)
tensor(4.9219, device='cuda:0', dtype=torch.float16) tensor(0.2439, device='cuda:0', dtype=torch.float16)
tensor(4.6211, device='cuda:0', dtype=torch.float16) tensor(0.2463, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0176, device='cuda:0')
tensor(0.0388, device='cuda:0')
old_score: tensor(0.2463, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1388, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.683669805526733
Validation after dual ascent:
out_inf: tensor(15.1250, device='cuda:0', dtype=torch.float16) tensor(0.8525, device='cuda:0', dtype=torch.float16)
tensor(2.2227, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(2.5508, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(2.1660, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.9844, device='cuda:0', dtype=torch.float16) tensor(1.0391, device='cuda:0', dtype=torch.float16)
tensor(4.5781, device='cuda:0', dtype=torch.float16) tensor(0.2544, device='cuda:0', dtype=torch.float16)
tensor(5.1562, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.2527, device='cuda:0', dtype=torch.float16)
tensor(4.4062, device='cuda:0', dtype=torch.float16) tensor(0.2551, device='cuda:0', dtype=torch.float16)
tensor(0.0342, device='cuda:0')
old_score: tensor(0.2554, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1400, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.941412687301636
Validation after dual ascent:
out_inf: tensor(16.9844, device='cuda:0', dtype=torch.float16) tensor(1.0391, device='cuda:0', dtype=torch.float16)
tensor(2.0879, device='cuda:0', dtype=torch.float16) tensor(0.1415, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(1.9580, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(1.9619, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.2969, device='cuda:0', dtype=torch.float16) tensor(0.2566, device='cuda:0', dtype=torch.float16)
tensor(1.1943, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.1188, device='cuda:0', dtype=torch.float16)
tensor(1.1895, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0065, device='cuda:0')
tensor(0.0285, device='cuda:0')
old_score: tensor(0.1211, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0766, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.187377452850342
Validation after dual ascent:
out_inf: tensor(3.2969, device='cuda:0', dtype=torch.float16) tensor(0.2566, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.6611, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.6567, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.7056, device='cuda:0', dtype=torch.float16) tensor(0.0768, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.o_proj
Validation after prune:
out_inf: tensor(8.1797, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.8784, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.0188, device='cuda:0', dtype=torch.float16)
tensor(0.0431, device='cuda:0')
old_score: tensor(0.0198, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0122, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.87201189994812
Validation after dual ascent:
out_inf: tensor(8.1797, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.4014, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.5361, device='cuda:0', dtype=torch.float16) tensor(0.0131, device='cuda:0', dtype=torch.float16)
tensor(0.3340, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.8906, device='cuda:0', dtype=torch.float16) tensor(0.2788, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
tensor(1.7637, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0163, device='cuda:0')
tensor(0.0329, device='cuda:0')
old_score: tensor(0.1028, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0607, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.104199409484863
Validation after dual ascent:
out_inf: tensor(3.8906, device='cuda:0', dtype=torch.float16) tensor(0.2788, device='cuda:0', dtype=torch.float16)
tensor(1.0020, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.8569, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.8018, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.8662, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.9258, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(1.6758, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(1.8555, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(1.4824, device='cuda:0', dtype=torch.float16) tensor(0.0863, device='cuda:0', dtype=torch.float16)
tensor(1.8613, device='cuda:0', dtype=torch.float16) tensor(0.0846, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.0273, device='cuda:0')
old_score: tensor(0.0854, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0528, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.09963846206665
Validation after dual ascent:
out_inf: tensor(2.9258, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(0.6689, device='cuda:0', dtype=torch.float16) tensor(0.0531, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0541, device='cuda:0', dtype=torch.float16)
tensor(0.7002, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.5869, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.5850, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.0815, device='cuda:0')
old_score: tensor(0.0217, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0148, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.35929584503174
Validation after dual ascent:
out_inf: tensor(1.5869, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
tensor(0.1904, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.1963, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
tensor(0.2129, device='cuda:0', dtype=torch.float16) tensor(0.0145, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.7656, device='cuda:0', dtype=torch.float16) tensor(0.8516, device='cuda:0', dtype=torch.float16)
tensor(4.9297, device='cuda:0', dtype=torch.float16) tensor(0.2600, device='cuda:0', dtype=torch.float16)
tensor(5.7109, device='cuda:0', dtype=torch.float16) tensor(0.2646, device='cuda:0', dtype=torch.float16)
tensor(5.3906, device='cuda:0', dtype=torch.float16) tensor(0.2659, device='cuda:0', dtype=torch.float16)
tensor(6.2500, device='cuda:0', dtype=torch.float16) tensor(0.2607, device='cuda:0', dtype=torch.float16)
tensor(0.1452, device='cuda:0')
old_score: tensor(0.2627, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1343, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.88845157623291
Validation after dual ascent:
out_inf: tensor(18.7656, device='cuda:0', dtype=torch.float16) tensor(0.8516, device='cuda:0', dtype=torch.float16)
tensor(2.3965, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.1348, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
tensor(1.8779, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.4844, device='cuda:0', dtype=torch.float16) tensor(0.9966, device='cuda:0', dtype=torch.float16)
tensor(4.5391, device='cuda:0', dtype=torch.float16) tensor(0.2620, device='cuda:0', dtype=torch.float16)
tensor(5.0312, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
tensor(5.2812, device='cuda:0', dtype=torch.float16) tensor(0.2683, device='cuda:0', dtype=torch.float16)
tensor(5.4609, device='cuda:0', dtype=torch.float16) tensor(0.2627, device='cuda:0', dtype=torch.float16)
tensor(0.1446, device='cuda:0')
old_score: tensor(0.2651, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1335, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.946462631225586
Validation after dual ascent:
out_inf: tensor(16.4844, device='cuda:0', dtype=torch.float16) tensor(0.9966, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.1312, device='cuda:0', dtype=torch.float16)
tensor(1.8242, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(2.1289, device='cuda:0', dtype=torch.float16) tensor(0.1313, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.8125, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(1.3574, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.4316, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(1.4707, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
tensor(1.4121, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(0.0701, device='cuda:0')
old_score: tensor(0.1271, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0745, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.919153213500977
Validation after dual ascent:
out_inf: tensor(3.8125, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(0.7715, device='cuda:0', dtype=torch.float16) tensor(0.0733, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0748, device='cuda:0', dtype=torch.float16)
tensor(0.6924, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.4570, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.6426, device='cuda:0', dtype=torch.float16) tensor(0.0224, device='cuda:0', dtype=torch.float16)
tensor(0.7275, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
tensor(0.0433, device='cuda:0')
old_score: tensor(0.0222, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0126, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.898626327514648
Validation after dual ascent:
out_inf: tensor(3.4570, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.3252, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0143, device='cuda:0', dtype=torch.float16)
tensor(0.3047, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.4062, device='cuda:0', dtype=torch.float16) tensor(0.3027, device='cuda:0', dtype=torch.float16)
tensor(3.1523, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(3.1191, device='cuda:0', dtype=torch.float16) tensor(0.1153, device='cuda:0', dtype=torch.float16)
tensor(3.3516, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(3.0977, device='cuda:0', dtype=torch.float16) tensor(0.1131, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0118, device='cuda:0')
tensor(0.0425, device='cuda:0')
old_score: tensor(0.1141, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0667, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.117231130599976
Validation after dual ascent:
out_inf: tensor(5.4062, device='cuda:0', dtype=torch.float16) tensor(0.3027, device='cuda:0', dtype=torch.float16)
tensor(1.4043, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
tensor(1.0215, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0664, device='cuda:0', dtype=torch.float16) tensor(0.1809, device='cuda:0', dtype=torch.float16)
tensor(1.3262, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(1.4658, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(2.1816, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(1.3135, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0065, device='cuda:0')
tensor(0.0359, device='cuda:0')
old_score: tensor(0.0966, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0585, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1146399974823
Validation after dual ascent:
out_inf: tensor(4.0664, device='cuda:0', dtype=torch.float16) tensor(0.1809, device='cuda:0', dtype=torch.float16)
tensor(0.7012, device='cuda:0', dtype=torch.float16) tensor(0.0574, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.8789, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.6230, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.5938, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(1.0615, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(0.6416, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
Converged at iteration 900
tensor(0.0165, device='cuda:0')
tensor(0.0296, device='cuda:0')
old_score: tensor(0.0255, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0177, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 89.04472541809082
Validation after dual ascent:
out_inf: tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.3130, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.3052, device='cuda:0', dtype=torch.float16) tensor(0.0175, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
tensor(0.2617, device='cuda:0', dtype=torch.float16) tensor(0.0174, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19., device='cuda:0', dtype=torch.float16) tensor(0.8062, device='cuda:0', dtype=torch.float16)
tensor(5.5312, device='cuda:0', dtype=torch.float16) tensor(0.2522, device='cuda:0', dtype=torch.float16)
tensor(5.6016, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(5.2500, device='cuda:0', dtype=torch.float16) tensor(0.2590, device='cuda:0', dtype=torch.float16)
tensor(5.4062, device='cuda:0', dtype=torch.float16) tensor(0.2505, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0170, device='cuda:0')
tensor(0.0240, device='cuda:0')
old_score: tensor(0.2544, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1392, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.098436117172241
Validation after dual ascent:
out_inf: tensor(19., device='cuda:0', dtype=torch.float16) tensor(0.8062, device='cuda:0', dtype=torch.float16)
tensor(3.0234, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(2.3066, device='cuda:0', dtype=torch.float16) tensor(0.1367, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.9062, device='cuda:0', dtype=torch.float16) tensor(1.0293, device='cuda:0', dtype=torch.float16)
tensor(3.9492, device='cuda:0', dtype=torch.float16) tensor(0.2546, device='cuda:0', dtype=torch.float16)
tensor(3.8008, device='cuda:0', dtype=torch.float16) tensor(0.2576, device='cuda:0', dtype=torch.float16)
tensor(3.9727, device='cuda:0', dtype=torch.float16) tensor(0.2568, device='cuda:0', dtype=torch.float16)
tensor(4.0391, device='cuda:0', dtype=torch.float16) tensor(0.2532, device='cuda:0', dtype=torch.float16)
tensor(0.0234, device='cuda:0')
old_score: tensor(0.2556, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1385, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.950822830200195
Validation after dual ascent:
out_inf: tensor(16.9062, device='cuda:0', dtype=torch.float16) tensor(1.0293, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1393, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(1.7393, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.2622, device='cuda:0', dtype=torch.float16)
tensor(1.0947, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.3018, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0138, device='cuda:0')
tensor(0.1252, device='cuda:0')
old_score: tensor(0.1323, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0794, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4538838863372803
Validation after dual ascent:
out_inf: tensor(4.6602, device='cuda:0', dtype=torch.float16) tensor(0.2622, device='cuda:0', dtype=torch.float16)
tensor(0.8374, device='cuda:0', dtype=torch.float16) tensor(0.0785, device='cuda:0', dtype=torch.float16)
tensor(0.7178, device='cuda:0', dtype=torch.float16) tensor(0.0798, device='cuda:0', dtype=torch.float16)
tensor(0.6963, device='cuda:0', dtype=torch.float16) tensor(0.0813, device='cuda:0', dtype=torch.float16)
tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.7461, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.7285, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.6074, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.8628, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.0331, device='cuda:0')
old_score: tensor(0.0263, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0153, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.885694026947021
Validation after dual ascent:
out_inf: tensor(3.7461, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.3760, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
tensor(0.3335, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.4302, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
tensor(0.4341, device='cuda:0', dtype=torch.float16) tensor(0.0147, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.8164, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.1165, device='cuda:0', dtype=torch.float16)
tensor(2.5547, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(5.2891, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(2.0723, device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.0503, device='cuda:0')
old_score: tensor(0.1167, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0703, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1156206130981445
Validation after dual ascent:
out_inf: tensor(7.8164, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(2.8438, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.6055, device='cuda:0', dtype=torch.float16) tensor(0.1937, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1037, device='cuda:0', dtype=torch.float16)
tensor(1.9570, device='cuda:0', dtype=torch.float16) tensor(0.1043, device='cuda:0', dtype=torch.float16)
tensor(2.6602, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0070, device='cuda:0')
tensor(0.0445, device='cuda:0')
old_score: tensor(0.1036, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0635, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.114902973175049
Validation after dual ascent:
out_inf: tensor(5.6055, device='cuda:0', dtype=torch.float16) tensor(0.1937, device='cuda:0', dtype=torch.float16)
tensor(0.6592, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(0.6934, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.2949, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.6558, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0277, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0167, device='cuda:0')
tensor(0.0209, device='cuda:0')
old_score: tensor(0.0277, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0206, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 79.4409408569336
Validation after dual ascent:
out_inf: tensor(2.2949, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.3359, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.2705, device='cuda:0', dtype=torch.float16) tensor(0.0205, device='cuda:0', dtype=torch.float16)
tensor(0.3203, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.2832, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.8140, device='cuda:0', dtype=torch.float16)
tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.2600, device='cuda:0', dtype=torch.float16)
tensor(3.7227, device='cuda:0', dtype=torch.float16) tensor(0.2651, device='cuda:0', dtype=torch.float16)
tensor(4.8750, device='cuda:0', dtype=torch.float16) tensor(0.2727, device='cuda:0', dtype=torch.float16)
tensor(4.0898, device='cuda:0', dtype=torch.float16) tensor(0.2576, device='cuda:0', dtype=torch.float16)
tensor(0.1390, device='cuda:0')
old_score: tensor(0.2639, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1476, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.91592812538147
Validation after dual ascent:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.8140, device='cuda:0', dtype=torch.float16)
tensor(1.8027, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(1.8477, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
tensor(2.4609, device='cuda:0', dtype=torch.float16) tensor(0.1486, device='cuda:0', dtype=torch.float16)
tensor(1.8154, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.3594, device='cuda:0', dtype=torch.float16) tensor(1.0527, device='cuda:0', dtype=torch.float16)
tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
tensor(3.0586, device='cuda:0', dtype=torch.float16) tensor(0.2720, device='cuda:0', dtype=torch.float16)
tensor(3.2559, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.2646, device='cuda:0', dtype=torch.float16)
tensor(0.1357, device='cuda:0')
old_score: tensor(0.2703, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1484, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.957448959350586
Validation after dual ascent:
out_inf: tensor(18.3594, device='cuda:0', dtype=torch.float16) tensor(1.0527, device='cuda:0', dtype=torch.float16)
tensor(1.8994, device='cuda:0', dtype=torch.float16) tensor(0.1482, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1501, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
tensor(1.8574, device='cuda:0', dtype=torch.float16) tensor(0.1460, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.8516, device='cuda:0', dtype=torch.float16) tensor(0.2710, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.1381, device='cuda:0', dtype=torch.float16)
tensor(1.2832, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.1364, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0105, device='cuda:0')
tensor(0.0740, device='cuda:0')
old_score: tensor(0.1389, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0844, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.735926389694214
Validation after dual ascent:
out_inf: tensor(6.8516, device='cuda:0', dtype=torch.float16) tensor(0.2710, device='cuda:0', dtype=torch.float16)
tensor(0.8232, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
tensor(0.7939, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
tensor(0.7427, device='cuda:0', dtype=torch.float16) tensor(0.0830, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.6211, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.8730, device='cuda:0', dtype=torch.float16) tensor(0.0284, device='cuda:0', dtype=torch.float16)
tensor(1.4160, device='cuda:0', dtype=torch.float16) tensor(0.0313, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0199, device='cuda:0')
tensor(0.0436, device='cuda:0')
old_score: tensor(0.0283, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0168, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.18191385269165
Validation after dual ascent:
out_inf: tensor(4.6211, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.4033, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.4062, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.2500, device='cuda:0', dtype=torch.float16) tensor(0.2788, device='cuda:0', dtype=torch.float16)
tensor(3.0039, device='cuda:0', dtype=torch.float16) tensor(0.1171, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(2.4824, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0103, device='cuda:0')
tensor(0.0546, device='cuda:0')
old_score: tensor(0.1170, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0719, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.116163015365601
Validation after dual ascent:
out_inf: tensor(8.2500, device='cuda:0', dtype=torch.float16) tensor(0.2788, device='cuda:0', dtype=torch.float16)
tensor(1.6504, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
tensor(1.4033, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(1.1816, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(1.6162, device='cuda:0', dtype=torch.float16) tensor(0.0708, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.1875, device='cuda:0', dtype=torch.float16) tensor(0.1996, device='cuda:0', dtype=torch.float16)
tensor(2.0605, device='cuda:0', dtype=torch.float16) tensor(0.1062, device='cuda:0', dtype=torch.float16)
tensor(1.7988, device='cuda:0', dtype=torch.float16) tensor(0.1062, device='cuda:0', dtype=torch.float16)
tensor(2.3340, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(1.7441, device='cuda:0', dtype=torch.float16) tensor(0.1043, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0070, device='cuda:0')
tensor(0.0495, device='cuda:0')
old_score: tensor(0.1059, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0661, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115250587463379
Validation after dual ascent:
out_inf: tensor(5.1875, device='cuda:0', dtype=torch.float16) tensor(0.1996, device='cuda:0', dtype=torch.float16)
tensor(0.8291, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0651, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.8008, device='cuda:0', dtype=torch.float16) tensor(0.0653, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.6162, device='cuda:0', dtype=torch.float16) tensor(0.0297, device='cuda:0', dtype=torch.float16)
tensor(0.6816, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0103, device='cuda:0')
tensor(0.0239, device='cuda:0')
old_score: tensor(0.0298, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0224, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 64.92329335212708
Validation after dual ascent:
out_inf: tensor(2.8008, device='cuda:0', dtype=torch.float16) tensor(0.0653, device='cuda:0', dtype=torch.float16)
tensor(0.3843, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.3105, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.3613, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
tensor(0.3455, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(4.2383, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
tensor(4.1953, device='cuda:0', dtype=torch.float16) tensor(0.2612, device='cuda:0', dtype=torch.float16)
tensor(5.5547, device='cuda:0', dtype=torch.float16) tensor(0.2700, device='cuda:0', dtype=torch.float16)
tensor(4.4102, device='cuda:0', dtype=torch.float16) tensor(0.2554, device='cuda:0', dtype=torch.float16)
tensor(0.0918, device='cuda:0')
old_score: tensor(0.2615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1497, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.811928749084473
Validation after dual ascent:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(2.2910, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1492, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0527, device='cuda:0', dtype=torch.float16)
tensor(3.2188, device='cuda:0', dtype=torch.float16) tensor(0.2639, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.2661, device='cuda:0', dtype=torch.float16)
tensor(3.7891, device='cuda:0', dtype=torch.float16) tensor(0.2742, device='cuda:0', dtype=torch.float16)
tensor(3.3652, device='cuda:0', dtype=torch.float16) tensor(0.2607, device='cuda:0', dtype=torch.float16)
tensor(0.0938, device='cuda:0')
old_score: tensor(0.2664, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1504, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.841912508010864
Validation after dual ascent:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0527, device='cuda:0', dtype=torch.float16)
tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.1520, device='cuda:0', dtype=torch.float16)
tensor(1.9014, device='cuda:0', dtype=torch.float16) tensor(0.1500, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.6582, device='cuda:0', dtype=torch.float16) tensor(0.1478, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.0469, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(1.8613, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.4551, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
tensor(1.9648, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(1.3018, device='cuda:0', dtype=torch.float16) tensor(0.1371, device='cuda:0', dtype=torch.float16)
tensor(0.0493, device='cuda:0')
old_score: tensor(0.1393, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0853, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.815752983093262
Validation after dual ascent:
out_inf: tensor(7.0469, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0850, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0860, device='cuda:0', dtype=torch.float16)
tensor(0.7920, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(1.0117, device='cuda:0', dtype=torch.float16) tensor(0.0402, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0174, device='cuda:0')
tensor(0.0333, device='cuda:0')
old_score: tensor(0.0362, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0204, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.212003231048584
Validation after dual ascent:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.0711, device='cuda:0', dtype=torch.float16)
tensor(0.4043, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.4844, device='cuda:0', dtype=torch.float16) tensor(0.0229, device='cuda:0', dtype=torch.float16)
tensor(0.3945, device='cuda:0', dtype=torch.float16) tensor(0.0184, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.5000, device='cuda:0', dtype=torch.float16) tensor(0.2944, device='cuda:0', dtype=torch.float16)
tensor(2.8105, device='cuda:0', dtype=torch.float16) tensor(0.1154, device='cuda:0', dtype=torch.float16)
tensor(3.0332, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(2.8633, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(3.4258, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0108, device='cuda:0')
tensor(0.0545, device='cuda:0')
old_score: tensor(0.1154, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0714, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.097729921340942
Validation after dual ascent:
out_inf: tensor(6.5000, device='cuda:0', dtype=torch.float16) tensor(0.2944, device='cuda:0', dtype=torch.float16)
tensor(1.4922, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(1.5176, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.4844, device='cuda:0', dtype=torch.float16) tensor(0.2086, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0073, device='cuda:0')
tensor(0.0502, device='cuda:0')
old_score: tensor(0.1067, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0669, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.092335939407349
Validation after dual ascent:
out_inf: tensor(3.4844, device='cuda:0', dtype=torch.float16) tensor(0.2086, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0681, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0656, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0691, device='cuda:0', dtype=torch.float16)
tensor(0.7637, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.1201, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(0.7539, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.7324, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0123, device='cuda:0')
tensor(0.0280, device='cuda:0')
old_score: tensor(0.0318, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0236, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 64.65937995910645
Validation after dual ascent:
out_inf: tensor(1.1201, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(0.4053, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.3936, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.3669, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.3633, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.7969, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(6.3281, device='cuda:0', dtype=torch.float16) tensor(0.2729, device='cuda:0', dtype=torch.float16)
tensor(5.9531, device='cuda:0', dtype=torch.float16) tensor(0.2712, device='cuda:0', dtype=torch.float16)
tensor(5.8125, device='cuda:0', dtype=torch.float16) tensor(0.2852, device='cuda:0', dtype=torch.float16)
tensor(5.9414, device='cuda:0', dtype=torch.float16) tensor(0.2632, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0148, device='cuda:0')
tensor(0.0470, device='cuda:0')
old_score: tensor(0.2729, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1565, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.621601343154907
Validation after dual ascent:
out_inf: tensor(19.7969, device='cuda:0', dtype=torch.float16) tensor(0.8052, device='cuda:0', dtype=torch.float16)
tensor(2.7617, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
tensor(2.6035, device='cuda:0', dtype=torch.float16) tensor(0.1548, device='cuda:0', dtype=torch.float16)
tensor(2.7617, device='cuda:0', dtype=torch.float16) tensor(0.1616, device='cuda:0', dtype=torch.float16)
tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0430, device='cuda:0', dtype=torch.float16)
tensor(4.1875, device='cuda:0', dtype=torch.float16) tensor(0.2734, device='cuda:0', dtype=torch.float16)
tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.2715, device='cuda:0', dtype=torch.float16)
tensor(4.7109, device='cuda:0', dtype=torch.float16) tensor(0.2830, device='cuda:0', dtype=torch.float16)
tensor(3.9062, device='cuda:0', dtype=torch.float16) tensor(0.2656, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0174, device='cuda:0')
tensor(0.0481, device='cuda:0')
old_score: tensor(0.2734, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1538, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.646297693252563
Validation after dual ascent:
out_inf: tensor(16.7500, device='cuda:0', dtype=torch.float16) tensor(1.0430, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.1560, device='cuda:0', dtype=torch.float16)
tensor(2.0820, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.1582, device='cuda:0', dtype=torch.float16)
tensor(2.1133, device='cuda:0', dtype=torch.float16) tensor(0.1490, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.9766, device='cuda:0', dtype=torch.float16) tensor(0.3145, device='cuda:0', dtype=torch.float16)
tensor(1.4258, device='cuda:0', dtype=torch.float16) tensor(0.1608, device='cuda:0', dtype=torch.float16)
tensor(1.3027, device='cuda:0', dtype=torch.float16) tensor(0.1586, device='cuda:0', dtype=torch.float16)
tensor(1.5713, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
tensor(1.3350, device='cuda:0', dtype=torch.float16) tensor(0.1569, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0609, device='cuda:0')
old_score: tensor(0.1595, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0994, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1660995483398438
Validation after dual ascent:
out_inf: tensor(7.9766, device='cuda:0', dtype=torch.float16) tensor(0.3145, device='cuda:0', dtype=torch.float16)
tensor(0.9175, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(0.8501, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(0.8691, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6., device='cuda:0', dtype=torch.float16) tensor(0.0901, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(0.9863, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(1.0576, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(0.8340, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0170, device='cuda:0')
tensor(0.0333, device='cuda:0')
old_score: tensor(0.0424, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0237, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.507464408874512
Validation after dual ascent:
out_inf: tensor(6., device='cuda:0', dtype=torch.float16) tensor(0.0901, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(0.5439, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(0.6221, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(0.5278, device='cuda:0', dtype=torch.float16) tensor(0.0200, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(3.4980, device='cuda:0', dtype=torch.float16) tensor(0.1234, device='cuda:0', dtype=torch.float16)
tensor(3.3691, device='cuda:0', dtype=torch.float16) tensor(0.1240, device='cuda:0', dtype=torch.float16)
tensor(3.2012, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
tensor(3.2344, device='cuda:0', dtype=torch.float16) tensor(0.1222, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0128, device='cuda:0')
tensor(0.0701, device='cuda:0')
old_score: tensor(0.1245, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0770, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.089227914810181
Validation after dual ascent:
out_inf: tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(1.6836, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(1.6270, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(1.4785, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
tensor(1.9160, device='cuda:0', dtype=torch.float16) tensor(0.0735, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.2203, device='cuda:0', dtype=torch.float16)
tensor(1.6855, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.6582, device='cuda:0', dtype=torch.float16) tensor(0.1149, device='cuda:0', dtype=torch.float16)
tensor(1.5449, device='cuda:0', dtype=torch.float16) tensor(0.1192, device='cuda:0', dtype=torch.float16)
tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.1131, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0088, device='cuda:0')
tensor(0.0655, device='cuda:0')
old_score: tensor(0.1154, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0729, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.085031032562256
Validation after dual ascent:
out_inf: tensor(4.1523, device='cuda:0', dtype=torch.float16) tensor(0.2203, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0729, device='cuda:0', dtype=torch.float16)
tensor(0.8398, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.0767, device='cuda:0', dtype=torch.float16)
tensor(0.8545, device='cuda:0', dtype=torch.float16) tensor(0.0696, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.0029, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.7969, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.8965, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0191, device='cuda:0')
tensor(0.0444, device='cuda:0')
old_score: tensor(0.0360, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0263, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.490782737731934
Validation after dual ascent:
out_inf: tensor(1.0029, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0262, device='cuda:0', dtype=torch.float16)
tensor(0.4688, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(0.4238, device='cuda:0', dtype=torch.float16) tensor(0.0282, device='cuda:0', dtype=torch.float16)
tensor(0.4785, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.q_proj
Validation after prune:
out_inf: tensor(18.6562, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(4.7734, device='cuda:0', dtype=torch.float16) tensor(0.2783, device='cuda:0', dtype=torch.float16)
tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.2795, device='cuda:0', dtype=torch.float16)
tensor(4.6484, device='cuda:0', dtype=torch.float16) tensor(0.2961, device='cuda:0', dtype=torch.float16)
tensor(4.0820, device='cuda:0', dtype=torch.float16) tensor(0.2712, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0150, device='cuda:0')
tensor(0.0765, device='cuda:0')
old_score: tensor(0.2812, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1654, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.638241291046143
Validation after dual ascent:
out_inf: tensor(18.6562, device='cuda:0', dtype=torch.float16) tensor(0.7964, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1652, device='cuda:0', dtype=torch.float16)
tensor(2.1133, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(2.7109, device='cuda:0', dtype=torch.float16) tensor(0.1752, device='cuda:0', dtype=torch.float16)
tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.1567, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6719, device='cuda:0', dtype=torch.float16) tensor(1.0420, device='cuda:0', dtype=torch.float16)
tensor(3.8945, device='cuda:0', dtype=torch.float16) tensor(0.2888, device='cuda:0', dtype=torch.float16)
tensor(3.5391, device='cuda:0', dtype=torch.float16) tensor(0.2910, device='cuda:0', dtype=torch.float16)
tensor(3.8125, device='cuda:0', dtype=torch.float16) tensor(0.3071, device='cuda:0', dtype=torch.float16)
tensor(3.8867, device='cuda:0', dtype=torch.float16) tensor(0.2817, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0178, device='cuda:0')
tensor(0.0804, device='cuda:0')
old_score: tensor(0.2922, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1681, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.674818992614746
Validation after dual ascent:
out_inf: tensor(15.6719, device='cuda:0', dtype=torch.float16) tensor(1.0420, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1680, device='cuda:0', dtype=torch.float16)
tensor(1.9941, device='cuda:0', dtype=torch.float16) tensor(0.1676, device='cuda:0', dtype=torch.float16)
tensor(1.9697, device='cuda:0', dtype=torch.float16) tensor(0.1776, device='cuda:0', dtype=torch.float16)
tensor(1.8506, device='cuda:0', dtype=torch.float16) tensor(0.1592, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.1602, device='cuda:0', dtype=torch.float16) tensor(0.3081, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1593, device='cuda:0', dtype=torch.float16)
tensor(1.4346, device='cuda:0', dtype=torch.float16) tensor(0.1592, device='cuda:0', dtype=torch.float16)
tensor(1.4678, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(1.2598, device='cuda:0', dtype=torch.float16) tensor(0.1561, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0149, device='cuda:0')
tensor(0.0759, device='cuda:0')
old_score: tensor(0.1597, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.183180332183838
Validation after dual ascent:
out_inf: tensor(6.1602, device='cuda:0', dtype=torch.float16) tensor(0.3081, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(0.9326, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.9521, device='cuda:0', dtype=torch.float16) tensor(0.0955, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.8320, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.0495, device='cuda:0', dtype=torch.float16)
tensor(1.5195, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
Converged at iteration 500
tensor(0.0126, device='cuda:0')
tensor(0.0192, device='cuda:0')
old_score: tensor(0.0434, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0256, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 7.550901412963867
Validation after dual ascent:
out_inf: tensor(6.8320, device='cuda:0', dtype=torch.float16) tensor(0.0936, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.5391, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.3008, device='cuda:0', dtype=torch.float16) tensor(0.3052, device='cuda:0', dtype=torch.float16)
tensor(3.1211, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(3.1133, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(3.2871, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(3.2051, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0124, device='cuda:0')
tensor(0.0748, device='cuda:0')
old_score: tensor(0.1250, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0781, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0944390296936035
Validation after dual ascent:
out_inf: tensor(6.3008, device='cuda:0', dtype=torch.float16) tensor(0.3052, device='cuda:0', dtype=torch.float16)
tensor(1.5664, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(1.4941, device='cuda:0', dtype=torch.float16) tensor(0.0773, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(1.4492, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.7930, device='cuda:0', dtype=torch.float16) tensor(0.2217, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1232, device='cuda:0', dtype=torch.float16)
tensor(1.5430, device='cuda:0', dtype=torch.float16) tensor(0.1161, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0092, device='cuda:0')
tensor(0.0714, device='cuda:0')
old_score: tensor(0.1187, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0753, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.090860366821289
Validation after dual ascent:
out_inf: tensor(4.7930, device='cuda:0', dtype=torch.float16) tensor(0.2217, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.0751, device='cuda:0', dtype=torch.float16)
tensor(0.7979, device='cuda:0', dtype=torch.float16) tensor(0.0744, device='cuda:0', dtype=torch.float16)
tensor(0.7529, device='cuda:0', dtype=torch.float16) tensor(0.0805, device='cuda:0', dtype=torch.float16)
tensor(0.7412, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.8643, device='cuda:0', dtype=torch.float16) tensor(0.0783, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.7461, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.7480, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0158, device='cuda:0')
tensor(0.0327, device='cuda:0')
old_score: tensor(0.0363, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0271, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.52073836326599
Validation after dual ascent:
out_inf: tensor(1.8643, device='cuda:0', dtype=torch.float16) tensor(0.0783, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0269, device='cuda:0', dtype=torch.float16)
tensor(0.3823, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.4165, device='cuda:0', dtype=torch.float16) tensor(0.0296, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0252, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.7969, device='cuda:0', dtype=torch.float16) tensor(0.7876, device='cuda:0', dtype=torch.float16)
tensor(4.2266, device='cuda:0', dtype=torch.float16) tensor(0.2747, device='cuda:0', dtype=torch.float16)
tensor(4.0820, device='cuda:0', dtype=torch.float16) tensor(0.2781, device='cuda:0', dtype=torch.float16)
tensor(4.3984, device='cuda:0', dtype=torch.float16) tensor(0.2927, device='cuda:0', dtype=torch.float16)
tensor(4.4766, device='cuda:0', dtype=torch.float16) tensor(0.2708, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0172, device='cuda:0')
tensor(0.0504, device='cuda:0')
old_score: tensor(0.2791, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1656, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.078439950942993
Validation after dual ascent:
out_inf: tensor(13.7969, device='cuda:0', dtype=torch.float16) tensor(0.7876, device='cuda:0', dtype=torch.float16)
tensor(2.4883, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(2.3574, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(2.2148, device='cuda:0', dtype=torch.float16) tensor(0.1769, device='cuda:0', dtype=torch.float16)
tensor(1.9248, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.5781, device='cuda:0', dtype=torch.float16) tensor(0.9829, device='cuda:0', dtype=torch.float16)
tensor(3.9531, device='cuda:0', dtype=torch.float16) tensor(0.2795, device='cuda:0', dtype=torch.float16)
tensor(3.3281, device='cuda:0', dtype=torch.float16) tensor(0.2820, device='cuda:0', dtype=torch.float16)
tensor(4.0859, device='cuda:0', dtype=torch.float16) tensor(0.2986, device='cuda:0', dtype=torch.float16)
tensor(3.6328, device='cuda:0', dtype=torch.float16) tensor(0.2756, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0198, device='cuda:0')
tensor(0.0535, device='cuda:0')
old_score: tensor(0.2839, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1658, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.082661151885986
Validation after dual ascent:
out_inf: tensor(16.5781, device='cuda:0', dtype=torch.float16) tensor(0.9829, device='cuda:0', dtype=torch.float16)
tensor(1.8350, device='cuda:0', dtype=torch.float16) tensor(0.1650, device='cuda:0', dtype=torch.float16)
tensor(1.9883, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(2.0723, device='cuda:0', dtype=torch.float16) tensor(0.1768, device='cuda:0', dtype=torch.float16)
tensor(2.3945, device='cuda:0', dtype=torch.float16) tensor(0.1562, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.7695, device='cuda:0', dtype=torch.float16) tensor(0.3059, device='cuda:0', dtype=torch.float16)
tensor(1.4180, device='cuda:0', dtype=torch.float16) tensor(0.1639, device='cuda:0', dtype=torch.float16)
tensor(1.5039, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(1.7090, device='cuda:0', dtype=torch.float16) tensor(0.1697, device='cuda:0', dtype=torch.float16)
tensor(1.5029, device='cuda:0', dtype=torch.float16) tensor(0.1616, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0079, device='cuda:0')
tensor(0.0628, device='cuda:0')
old_score: tensor(0.1648, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1048, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1628572940826416
Validation after dual ascent:
out_inf: tensor(4.7695, device='cuda:0', dtype=torch.float16) tensor(0.3059, device='cuda:0', dtype=torch.float16)
tensor(0.9390, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(0.9092, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(0.9146, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
tensor(0.8633, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.5078, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(1.6289, device='cuda:0', dtype=torch.float16) tensor(0.0461, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(1.4707, device='cuda:0', dtype=torch.float16) tensor(0.0395, device='cuda:0', dtype=torch.float16)
tensor(0.0226, device='cuda:0')
old_score: tensor(0.0447, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0257, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.798562288284302
Validation after dual ascent:
out_inf: tensor(6.5078, device='cuda:0', dtype=torch.float16) tensor(0.0841, device='cuda:0', dtype=torch.float16)
tensor(0.7168, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0223, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.4336, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(3.2695, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(2.8672, device='cuda:0', dtype=torch.float16) tensor(0.1262, device='cuda:0', dtype=torch.float16)
tensor(3.1602, device='cuda:0', dtype=torch.float16) tensor(0.1342, device='cuda:0', dtype=torch.float16)
tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0133, device='cuda:0')
tensor(0.0839, device='cuda:0')
old_score: tensor(0.1289, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0801, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.094265460968018
Validation after dual ascent:
out_inf: tensor(7.4336, device='cuda:0', dtype=torch.float16) tensor(0.3215, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.0802, device='cuda:0', dtype=torch.float16)
tensor(1.4707, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
tensor(1.7510, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(1.5000, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9297, device='cuda:0', dtype=torch.float16) tensor(0.2318, device='cuda:0', dtype=torch.float16)
tensor(1.8418, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(1.6309, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
tensor(1.7773, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0101, device='cuda:0')
tensor(0.0811, device='cuda:0')
old_score: tensor(0.1230, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0781, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.093032360076904
Validation after dual ascent:
out_inf: tensor(4.9297, device='cuda:0', dtype=torch.float16) tensor(0.2318, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(0.7646, device='cuda:0', dtype=torch.float16) tensor(0.0760, device='cuda:0', dtype=torch.float16)
tensor(0.9136, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(0.9912, device='cuda:0', dtype=torch.float16) tensor(0.0744, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.8184, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.7070, device='cuda:0', dtype=torch.float16) tensor(0.0424, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0199, device='cuda:0')
tensor(0.0336, device='cuda:0')
old_score: tensor(0.0403, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0298, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 40.713319540023804
Validation after dual ascent:
out_inf: tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0298, device='cuda:0', dtype=torch.float16)
tensor(0.3857, device='cuda:0', dtype=torch.float16) tensor(0.0285, device='cuda:0', dtype=torch.float16)
tensor(0.5122, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.3425, device='cuda:0', dtype=torch.float16) tensor(0.0283, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.7500, device='cuda:0', dtype=torch.float16) tensor(0.7847, device='cuda:0', dtype=torch.float16)
tensor(3.9453, device='cuda:0', dtype=torch.float16) tensor(0.2844, device='cuda:0', dtype=torch.float16)
tensor(4.1055, device='cuda:0', dtype=torch.float16) tensor(0.2830, device='cuda:0', dtype=torch.float16)
tensor(5.0625, device='cuda:0', dtype=torch.float16) tensor(0.3064, device='cuda:0', dtype=torch.float16)
tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.2786, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0162, device='cuda:0')
tensor(0.0357, device='cuda:0')
old_score: tensor(0.2881, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1681, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.732666492462158
Validation after dual ascent:
out_inf: tensor(13.7500, device='cuda:0', dtype=torch.float16) tensor(0.7847, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.1676, device='cuda:0', dtype=torch.float16)
tensor(1.9668, device='cuda:0', dtype=torch.float16) tensor(0.1644, device='cuda:0', dtype=torch.float16)
tensor(2.2266, device='cuda:0', dtype=torch.float16) tensor(0.1816, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1586, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.4219, device='cuda:0', dtype=torch.float16) tensor(1.0586, device='cuda:0', dtype=torch.float16)
tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.2939, device='cuda:0', dtype=torch.float16)
tensor(3.9375, device='cuda:0', dtype=torch.float16) tensor(0.2935, device='cuda:0', dtype=torch.float16)
tensor(4.1445, device='cuda:0', dtype=torch.float16) tensor(0.3145, device='cuda:0', dtype=torch.float16)
tensor(3.5703, device='cuda:0', dtype=torch.float16) tensor(0.2896, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0196, device='cuda:0')
tensor(0.0404, device='cuda:0')
old_score: tensor(0.2979, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1685, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.774722576141357
Validation after dual ascent:
out_inf: tensor(16.4219, device='cuda:0', dtype=torch.float16) tensor(1.0586, device='cuda:0', dtype=torch.float16)
tensor(1.9824, device='cuda:0', dtype=torch.float16) tensor(0.1681, device='cuda:0', dtype=torch.float16)
tensor(1.9258, device='cuda:0', dtype=torch.float16) tensor(0.1650, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1818, device='cuda:0', dtype=torch.float16)
tensor(1.7871, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.4062, device='cuda:0', dtype=torch.float16) tensor(0.3047, device='cuda:0', dtype=torch.float16)
tensor(1.5928, device='cuda:0', dtype=torch.float16) tensor(0.1643, device='cuda:0', dtype=torch.float16)
tensor(1.4893, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
tensor(1.5654, device='cuda:0', dtype=torch.float16) tensor(0.1696, device='cuda:0', dtype=torch.float16)
tensor(1.4404, device='cuda:0', dtype=torch.float16) tensor(0.1620, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0089, device='cuda:0')
tensor(0.0694, device='cuda:0')
old_score: tensor(0.1646, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1037, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.185657501220703
Validation after dual ascent:
out_inf: tensor(4.4062, device='cuda:0', dtype=torch.float16) tensor(0.3047, device='cuda:0', dtype=torch.float16)
tensor(0.8369, device='cuda:0', dtype=torch.float16) tensor(0.1038, device='cuda:0', dtype=torch.float16)
tensor(0.8975, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
tensor(0.9097, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(0.9307, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.o_proj
Validation after prune:
out_inf: tensor(8.4375, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.3242, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(1.7539, device='cuda:0', dtype=torch.float16) tensor(0.0462, device='cuda:0', dtype=torch.float16)
tensor(1.4727, device='cuda:0', dtype=torch.float16) tensor(0.0513, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0113, device='cuda:0')
tensor(0.0148, device='cuda:0')
old_score: tensor(0.0469, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0261, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.095116376876831
Validation after dual ascent:
out_inf: tensor(8.4375, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0260, device='cuda:0', dtype=torch.float16)
tensor(0.5039, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.5586, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1992, device='cuda:0', dtype=torch.float16) tensor(0.3298, device='cuda:0', dtype=torch.float16)
tensor(3.3516, device='cuda:0', dtype=torch.float16) tensor(0.1309, device='cuda:0', dtype=torch.float16)
tensor(3.4219, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(3.5098, device='cuda:0', dtype=torch.float16) tensor(0.1381, device='cuda:0', dtype=torch.float16)
tensor(3.9707, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0141, device='cuda:0')
tensor(0.0954, device='cuda:0')
old_score: tensor(0.1317, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0829, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.099823713302612
Validation after dual ascent:
out_inf: tensor(7.1992, device='cuda:0', dtype=torch.float16) tensor(0.3298, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
tensor(1.6465, device='cuda:0', dtype=torch.float16) tensor(0.0794, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(1.5791, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.2305, device='cuda:0', dtype=torch.float16) tensor(0.2405, device='cuda:0', dtype=torch.float16)
tensor(1.9961, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(1.9434, device='cuda:0', dtype=torch.float16) tensor(0.1224, device='cuda:0', dtype=torch.float16)
tensor(2.0898, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.1243, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0111, device='cuda:0')
tensor(0.0927, device='cuda:0')
old_score: tensor(0.1260, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0811, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.09902286529541
Validation after dual ascent:
out_inf: tensor(5.2305, device='cuda:0', dtype=torch.float16) tensor(0.2405, device='cuda:0', dtype=torch.float16)
tensor(0.9258, device='cuda:0', dtype=torch.float16) tensor(0.0810, device='cuda:0', dtype=torch.float16)
tensor(0.8418, device='cuda:0', dtype=torch.float16) tensor(0.0777, device='cuda:0', dtype=torch.float16)
tensor(0.9150, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
tensor(0.9541, device='cuda:0', dtype=torch.float16) tensor(0.0764, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.2051, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.6846, device='cuda:0', dtype=torch.float16) tensor(0.0430, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.7080, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0429, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0079, device='cuda:0')
tensor(0.0172, device='cuda:0')
old_score: tensor(0.0428, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0317, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 40.77499985694885
Validation after dual ascent:
out_inf: tensor(2.2051, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0319, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0294, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.3569, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.8438, device='cuda:0', dtype=torch.float16) tensor(0.7661, device='cuda:0', dtype=torch.float16)
tensor(4.5742, device='cuda:0', dtype=torch.float16) tensor(0.2603, device='cuda:0', dtype=torch.float16)
tensor(4.3945, device='cuda:0', dtype=torch.float16) tensor(0.2605, device='cuda:0', dtype=torch.float16)
tensor(4.1797, device='cuda:0', dtype=torch.float16) tensor(0.2825, device='cuda:0', dtype=torch.float16)
tensor(4.8164, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0194, device='cuda:0')
tensor(0.0307, device='cuda:0')
old_score: tensor(0.2656, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1580, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.8979392051696777
Validation after dual ascent:
out_inf: tensor(15.8438, device='cuda:0', dtype=torch.float16) tensor(0.7661, device='cuda:0', dtype=torch.float16)
tensor(1.8867, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(1.6699, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
tensor(2.1113, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.k_proj
Validation after prune:
out_inf: tensor(14.8203, device='cuda:0', dtype=torch.float16) tensor(1.0117, device='cuda:0', dtype=torch.float16)
tensor(4.0703, device='cuda:0', dtype=torch.float16) tensor(0.2742, device='cuda:0', dtype=torch.float16)
tensor(4.3594, device='cuda:0', dtype=torch.float16) tensor(0.2737, device='cuda:0', dtype=torch.float16)
tensor(4.1406, device='cuda:0', dtype=torch.float16) tensor(0.2974, device='cuda:0', dtype=torch.float16)
tensor(4.2852, device='cuda:0', dtype=torch.float16) tensor(0.2739, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0157, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.2798, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1610, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.632508993148804
Validation after dual ascent:
out_inf: tensor(14.8203, device='cuda:0', dtype=torch.float16) tensor(1.0117, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1558, device='cuda:0', dtype=torch.float16)
tensor(2.0840, device='cuda:0', dtype=torch.float16) tensor(0.1770, device='cuda:0', dtype=torch.float16)
tensor(1.9492, device='cuda:0', dtype=torch.float16) tensor(0.1517, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.0391, device='cuda:0', dtype=torch.float16) tensor(0.3069, device='cuda:0', dtype=torch.float16)
tensor(1.3799, device='cuda:0', dtype=torch.float16) tensor(0.1615, device='cuda:0', dtype=torch.float16)
tensor(1.3340, device='cuda:0', dtype=torch.float16) tensor(0.1595, device='cuda:0', dtype=torch.float16)
tensor(1.3818, device='cuda:0', dtype=torch.float16) tensor(0.1704, device='cuda:0', dtype=torch.float16)
tensor(1.3730, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0183, device='cuda:0')
tensor(0.2580, device='cuda:0')
old_score: tensor(0.1628, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1035, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4485998153686523
Validation after dual ascent:
out_inf: tensor(5.0391, device='cuda:0', dtype=torch.float16) tensor(0.3069, device='cuda:0', dtype=torch.float16)
tensor(0.8560, device='cuda:0', dtype=torch.float16) tensor(0.1028, device='cuda:0', dtype=torch.float16)
tensor(0.8379, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(0.8950, device='cuda:0', dtype=torch.float16) tensor(0.1135, device='cuda:0', dtype=torch.float16)
tensor(0.8252, device='cuda:0', dtype=torch.float16) tensor(0.0978, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.5781, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(1.1055, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0455, device='cuda:0', dtype=torch.float16)
tensor(1.6680, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
Converged at iteration 750
tensor(0.0139, device='cuda:0')
tensor(0.0281, device='cuda:0')
old_score: tensor(0.0450, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0258, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.208415508270264
Validation after dual ascent:
out_inf: tensor(7.5781, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(0.5371, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
tensor(0.5723, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.3560, device='cuda:0', dtype=torch.float16)
tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(3.0645, device='cuda:0', dtype=torch.float16) tensor(0.1326, device='cuda:0', dtype=torch.float16)
tensor(2.7070, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0157, device='cuda:0')
tensor(0.0994, device='cuda:0')
old_score: tensor(0.1359, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0826, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.104049205780029
Validation after dual ascent:
out_inf: tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.3560, device='cuda:0', dtype=torch.float16)
tensor(2.1758, device='cuda:0', dtype=torch.float16) tensor(0.0820, device='cuda:0', dtype=torch.float16)
tensor(1.6523, device='cuda:0', dtype=torch.float16) tensor(0.0788, device='cuda:0', dtype=torch.float16)
tensor(1.6152, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
tensor(1.6035, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4570, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(2.1465, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(2.0918, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
tensor(2.2617, device='cuda:0', dtype=torch.float16) tensor(0.1288, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0122, device='cuda:0')
tensor(0.0969, device='cuda:0')
old_score: tensor(0.1301, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0809, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.10254693031311
Validation after dual ascent:
out_inf: tensor(4.4570, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0802, device='cuda:0', dtype=torch.float16)
tensor(1.0996, device='cuda:0', dtype=torch.float16) tensor(0.0772, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.6367, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0471, device='cuda:0', dtype=torch.float16)
tensor(0.8496, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(0.8281, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0078, device='cuda:0')
tensor(0.0169, device='cuda:0')
old_score: tensor(0.0471, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0338, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 40.808029651641846
Validation after dual ascent:
out_inf: tensor(3.6367, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
tensor(0.4678, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.4521, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0322, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1172, device='cuda:0', dtype=torch.float16) tensor(0.7568, device='cuda:0', dtype=torch.float16)
tensor(4.5312, device='cuda:0', dtype=torch.float16) tensor(0.2632, device='cuda:0', dtype=torch.float16)
tensor(5.0781, device='cuda:0', dtype=torch.float16) tensor(0.2593, device='cuda:0', dtype=torch.float16)
tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.2842, device='cuda:0', dtype=torch.float16)
tensor(3.8398, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0148, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.2656, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1541, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.633134126663208
Validation after dual ascent:
out_inf: tensor(15.1172, device='cuda:0', dtype=torch.float16) tensor(0.7568, device='cuda:0', dtype=torch.float16)
tensor(2.2637, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
tensor(2.2559, device='cuda:0', dtype=torch.float16) tensor(0.1475, device='cuda:0', dtype=torch.float16)
tensor(2.5762, device='cuda:0', dtype=torch.float16) tensor(0.1718, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1442, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.8516, device='cuda:0', dtype=torch.float16) tensor(1.0273, device='cuda:0', dtype=torch.float16)
tensor(3.7070, device='cuda:0', dtype=torch.float16) tensor(0.2764, device='cuda:0', dtype=torch.float16)
tensor(3.4531, device='cuda:0', dtype=torch.float16) tensor(0.2766, device='cuda:0', dtype=torch.float16)
tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.3010, device='cuda:0', dtype=torch.float16)
tensor(3.1465, device='cuda:0', dtype=torch.float16) tensor(0.2710, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0178, device='cuda:0')
tensor(0.0222, device='cuda:0')
old_score: tensor(0.2812, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1562, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.654078245162964
Validation after dual ascent:
out_inf: tensor(15.8516, device='cuda:0', dtype=torch.float16) tensor(1.0273, device='cuda:0', dtype=torch.float16)
tensor(1.9512, device='cuda:0', dtype=torch.float16) tensor(0.1549, device='cuda:0', dtype=torch.float16)
tensor(1.6934, device='cuda:0', dtype=torch.float16) tensor(0.1500, device='cuda:0', dtype=torch.float16)
tensor(2.0664, device='cuda:0', dtype=torch.float16) tensor(0.1737, device='cuda:0', dtype=torch.float16)
tensor(1.8975, device='cuda:0', dtype=torch.float16) tensor(0.1462, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.2305, device='cuda:0', dtype=torch.float16) tensor(0.3088, device='cuda:0', dtype=torch.float16)
tensor(1.6289, device='cuda:0', dtype=torch.float16) tensor(0.1691, device='cuda:0', dtype=torch.float16)
tensor(1.4980, device='cuda:0', dtype=torch.float16) tensor(0.1660, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(1.4229, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0192, device='cuda:0')
tensor(0.2641, device='cuda:0')
old_score: tensor(0.1694, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1055, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.4525585174560547
Validation after dual ascent:
out_inf: tensor(5.2305, device='cuda:0', dtype=torch.float16) tensor(0.3088, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1050, device='cuda:0', dtype=torch.float16)
tensor(0.9390, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.1164, device='cuda:0', dtype=torch.float16)
tensor(0.8853, device='cuda:0', dtype=torch.float16) tensor(0.0993, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.3438, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.2637, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(1.5352, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(1.5850, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0143, device='cuda:0')
tensor(0.0324, device='cuda:0')
old_score: tensor(0.0535, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0318, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.139490127563477
Validation after dual ascent:
out_inf: tensor(7.3438, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.6572, device='cuda:0', dtype=torch.float16) tensor(0.0300, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.8223, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1562, device='cuda:0', dtype=torch.float16) tensor(0.3669, device='cuda:0', dtype=torch.float16)
tensor(3.4883, device='cuda:0', dtype=torch.float16) tensor(0.1434, device='cuda:0', dtype=torch.float16)
tensor(3.5566, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(3.4570, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(3.6758, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0186, device='cuda:0')
tensor(0.1169, device='cuda:0')
old_score: tensor(0.1451, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0859, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1014790534973145
Validation after dual ascent:
out_inf: tensor(7.1562, device='cuda:0', dtype=torch.float16) tensor(0.3669, device='cuda:0', dtype=torch.float16)
tensor(2.5879, device='cuda:0', dtype=torch.float16) tensor(0.0853, device='cuda:0', dtype=torch.float16)
tensor(2.3652, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(1.6680, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.3242, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1351, device='cuda:0', dtype=torch.float16)
tensor(1.8652, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1436, device='cuda:0', dtype=torch.float16)
tensor(2.0918, device='cuda:0', dtype=torch.float16) tensor(0.1344, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0142, device='cuda:0')
tensor(0.1125, device='cuda:0')
old_score: tensor(0.1365, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0834, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.103478670120239
Validation after dual ascent:
out_inf: tensor(5.3242, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
tensor(1.2949, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0929, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.5938, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
tensor(0.6924, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.7061, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.7705, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.7188, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0066, device='cuda:0')
tensor(0.0130, device='cuda:0')
old_score: tensor(0.0488, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0345, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 40.74195909500122
Validation after dual ascent:
out_inf: tensor(5.5938, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
tensor(0.3799, device='cuda:0', dtype=torch.float16) tensor(0.0344, device='cuda:0', dtype=torch.float16)
tensor(0.3770, device='cuda:0', dtype=torch.float16) tensor(0.0320, device='cuda:0', dtype=torch.float16)
tensor(0.4805, device='cuda:0', dtype=torch.float16) tensor(0.0389, device='cuda:0', dtype=torch.float16)
tensor(0.4282, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.5625, device='cuda:0', dtype=torch.float16) tensor(0.7573, device='cuda:0', dtype=torch.float16)
tensor(4.5977, device='cuda:0', dtype=torch.float16) tensor(0.2651, device='cuda:0', dtype=torch.float16)
tensor(4.3867, device='cuda:0', dtype=torch.float16) tensor(0.2612, device='cuda:0', dtype=torch.float16)
tensor(4.9219, device='cuda:0', dtype=torch.float16) tensor(0.2871, device='cuda:0', dtype=torch.float16)
tensor(3.5879, device='cuda:0', dtype=torch.float16) tensor(0.2576, device='cuda:0', dtype=torch.float16)
tensor(0.0520, device='cuda:0')
old_score: tensor(0.2678, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1433, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.841926097869873
Validation after dual ascent:
out_inf: tensor(15.5625, device='cuda:0', dtype=torch.float16) tensor(0.7573, device='cuda:0', dtype=torch.float16)
tensor(1.7119, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(1.6924, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.8809, device='cuda:0', dtype=torch.float16) tensor(0.1603, device='cuda:0', dtype=torch.float16)
tensor(1.6377, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6094, device='cuda:0', dtype=torch.float16) tensor(0.9790, device='cuda:0', dtype=torch.float16)
tensor(3.5234, device='cuda:0', dtype=torch.float16) tensor(0.2732, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.2722, device='cuda:0', dtype=torch.float16)
tensor(3.9453, device='cuda:0', dtype=torch.float16) tensor(0.2939, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.2673, device='cuda:0', dtype=torch.float16)
tensor(0.0554, device='cuda:0')
old_score: tensor(0.2766, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1447, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.919874906539917
Validation after dual ascent:
out_inf: tensor(15.6094, device='cuda:0', dtype=torch.float16) tensor(0.9790, device='cuda:0', dtype=torch.float16)
tensor(1.7539, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
tensor(2.3340, device='cuda:0', dtype=torch.float16) tensor(0.1616, device='cuda:0', dtype=torch.float16)
tensor(1.6543, device='cuda:0', dtype=torch.float16) tensor(0.1359, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.3145, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1675, device='cuda:0', dtype=torch.float16)
tensor(1.4912, device='cuda:0', dtype=torch.float16) tensor(0.1649, device='cuda:0', dtype=torch.float16)
tensor(1.4736, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(1.6514, device='cuda:0', dtype=torch.float16) tensor(0.1656, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0125, device='cuda:0')
tensor(0.0657, device='cuda:0')
old_score: tensor(0.1686, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0996, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1837425231933594
Validation after dual ascent:
out_inf: tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.3145, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
tensor(0.9463, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(1.0381, device='cuda:0', dtype=torch.float16) tensor(0.1105, device='cuda:0', dtype=torch.float16)
tensor(0.9204, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.9844, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(1.5332, device='cuda:0', dtype=torch.float16) tensor(0.0501, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.0484, device='cuda:0', dtype=torch.float16)
tensor(1.9434, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(1.4395, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
Converged at iteration 700
tensor(0.0159, device='cuda:0')
tensor(0.0340, device='cuda:0')
old_score: tensor(0.0493, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0265, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.479197025299072
Validation after dual ascent:
out_inf: tensor(5.9844, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.5537, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.5210, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.1875, device='cuda:0', dtype=torch.float16) tensor(0.3892, device='cuda:0', dtype=torch.float16)
tensor(3.5508, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(3.2227, device='cuda:0', dtype=torch.float16) tensor(0.1488, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.1606, device='cuda:0', dtype=torch.float16)
tensor(3.0742, device='cuda:0', dtype=torch.float16) tensor(0.1517, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0137, device='cuda:0')
tensor(0.0173, device='cuda:0')
old_score: tensor(0.1533, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0894, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.036234140396118
Validation after dual ascent:
out_inf: tensor(10.1875, device='cuda:0', dtype=torch.float16) tensor(0.3892, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.0849, device='cuda:0', dtype=torch.float16)
tensor(1.8652, device='cuda:0', dtype=torch.float16) tensor(0.0990, device='cuda:0', dtype=torch.float16)
tensor(1.7871, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.2031, device='cuda:0', dtype=torch.float16) tensor(0.2573, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
tensor(2.7695, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
tensor(2.7891, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(2.4102, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0157, device='cuda:0')
tensor(0.1374, device='cuda:0')
old_score: tensor(0.1407, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0859, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.10984206199646
Validation after dual ascent:
out_inf: tensor(7.2031, device='cuda:0', dtype=torch.float16) tensor(0.2573, device='cuda:0', dtype=torch.float16)
tensor(1.5527, device='cuda:0', dtype=torch.float16) tensor(0.0851, device='cuda:0', dtype=torch.float16)
tensor(0.8809, device='cuda:0', dtype=torch.float16) tensor(0.0815, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(0.9448, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.5879, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(0.6445, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0093, device='cuda:0')
tensor(0.0131, device='cuda:0')
old_score: tensor(0.0493, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0348, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 35.97251558303833
Validation after dual ascent:
out_inf: tensor(3.5879, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(0.3877, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.3943, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.3843, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.4590, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.7764, device='cuda:0', dtype=torch.float16)
tensor(3.4180, device='cuda:0', dtype=torch.float16) tensor(0.2666, device='cuda:0', dtype=torch.float16)
tensor(3.6953, device='cuda:0', dtype=torch.float16) tensor(0.2622, device='cuda:0', dtype=torch.float16)
tensor(4.7891, device='cuda:0', dtype=torch.float16) tensor(0.2856, device='cuda:0', dtype=torch.float16)
tensor(3.3828, device='cuda:0', dtype=torch.float16) tensor(0.2615, device='cuda:0', dtype=torch.float16)
tensor(0.0581, device='cuda:0')
old_score: tensor(0.2690, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1472, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.823173761367798
Validation after dual ascent:
out_inf: tensor(14.1719, device='cuda:0', dtype=torch.float16) tensor(0.7764, device='cuda:0', dtype=torch.float16)
tensor(1.8506, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
tensor(1.7363, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(1.5957, device='cuda:0', dtype=torch.float16) tensor(0.1399, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.1719, device='cuda:0', dtype=torch.float16) tensor(0.9575, device='cuda:0', dtype=torch.float16)
tensor(3.6328, device='cuda:0', dtype=torch.float16) tensor(0.2771, device='cuda:0', dtype=torch.float16)
tensor(3.8750, device='cuda:0', dtype=torch.float16) tensor(0.2751, device='cuda:0', dtype=torch.float16)
tensor(3.6094, device='cuda:0', dtype=torch.float16) tensor(0.2969, device='cuda:0', dtype=torch.float16)
tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.2751, device='cuda:0', dtype=torch.float16)
tensor(0.0594, device='cuda:0')
old_score: tensor(0.2810, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1482, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.922420263290405
Validation after dual ascent:
out_inf: tensor(16.1719, device='cuda:0', dtype=torch.float16) tensor(0.9575, device='cuda:0', dtype=torch.float16)
tensor(1.7832, device='cuda:0', dtype=torch.float16) tensor(0.1461, device='cuda:0', dtype=torch.float16)
tensor(1.9209, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(1.9648, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.5078, device='cuda:0', dtype=torch.float16) tensor(0.3271, device='cuda:0', dtype=torch.float16)
tensor(1.7090, device='cuda:0', dtype=torch.float16) tensor(0.1780, device='cuda:0', dtype=torch.float16)
tensor(2.0273, device='cuda:0', dtype=torch.float16) tensor(0.1754, device='cuda:0', dtype=torch.float16)
tensor(1.8721, device='cuda:0', dtype=torch.float16) tensor(0.1890, device='cuda:0', dtype=torch.float16)
tensor(1.6592, device='cuda:0', dtype=torch.float16) tensor(0.1771, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0147, device='cuda:0')
tensor(0.0858, device='cuda:0')
old_score: tensor(0.1799, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1091, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1848957538604736
Validation after dual ascent:
out_inf: tensor(4.5078, device='cuda:0', dtype=torch.float16) tensor(0.3271, device='cuda:0', dtype=torch.float16)
tensor(0.9639, device='cuda:0', dtype=torch.float16) tensor(0.1077, device='cuda:0', dtype=torch.float16)
tensor(1.0449, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.1210, device='cuda:0', dtype=torch.float16)
tensor(0.9805, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.3281, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
tensor(1.4277, device='cuda:0', dtype=torch.float16) tensor(0.0396, device='cuda:0', dtype=torch.float16)
tensor(1.2969, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.0367, device='cuda:0', dtype=torch.float16)
tensor(0.0524, device='cuda:0')
old_score: tensor(0.0393, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0224, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.856931209564209
Validation after dual ascent:
out_inf: tensor(5.3281, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0218, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
tensor(0.8320, device='cuda:0', dtype=torch.float16) tensor(0.0261, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.1953, device='cuda:0', dtype=torch.float16) tensor(0.3879, device='cuda:0', dtype=torch.float16)
tensor(4.1680, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
tensor(4.0859, device='cuda:0', dtype=torch.float16) tensor(0.1537, device='cuda:0', dtype=torch.float16)
tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
tensor(4.2227, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0193, device='cuda:0')
old_score: tensor(0.1577, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0921, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.030342102050781
Validation after dual ascent:
out_inf: tensor(10.1953, device='cuda:0', dtype=torch.float16) tensor(0.3879, device='cuda:0', dtype=torch.float16)
tensor(1.6562, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(1.9004, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
tensor(1.8770, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.5078, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(2.1738, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(2.2285, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0175, device='cuda:0')
tensor(0.1593, device='cuda:0')
old_score: tensor(0.1436, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0874, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.1004321575164795
Validation after dual ascent:
out_inf: tensor(6.5078, device='cuda:0', dtype=torch.float16) tensor(0.2534, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0862, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0832, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.0088, device='cuda:0', dtype=torch.float16) tensor(0.0834, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.8398, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0494, device='cuda:0', dtype=torch.float16)
tensor(0.6533, device='cuda:0', dtype=torch.float16) tensor(0.0485, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(0.6641, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0176, device='cuda:0')
tensor(0.0372, device='cuda:0')
old_score: tensor(0.0502, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0361, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.585445880889893
Validation after dual ascent:
out_inf: tensor(4.8398, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(0.4482, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.5137, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(0.4370, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.0781, device='cuda:0', dtype=torch.float16) tensor(0.7432, device='cuda:0', dtype=torch.float16)
tensor(4.2305, device='cuda:0', dtype=torch.float16) tensor(0.2603, device='cuda:0', dtype=torch.float16)
tensor(4.3594, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(5.2812, device='cuda:0', dtype=torch.float16) tensor(0.2815, device='cuda:0', dtype=torch.float16)
tensor(3.4727, device='cuda:0', dtype=torch.float16) tensor(0.2537, device='cuda:0', dtype=torch.float16)
tensor(0.1408, device='cuda:0')
old_score: tensor(0.2629, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1429, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.810934782028198
Validation after dual ascent:
out_inf: tensor(13.0781, device='cuda:0', dtype=torch.float16) tensor(0.7432, device='cuda:0', dtype=torch.float16)
tensor(1.7246, device='cuda:0', dtype=torch.float16) tensor(0.1409, device='cuda:0', dtype=torch.float16)
tensor(1.5342, device='cuda:0', dtype=torch.float16) tensor(0.1370, device='cuda:0', dtype=torch.float16)
tensor(1.6445, device='cuda:0', dtype=torch.float16) tensor(0.1583, device='cuda:0', dtype=torch.float16)
tensor(1.5654, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.6719, device='cuda:0', dtype=torch.float16) tensor(1.0029, device='cuda:0', dtype=torch.float16)
tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.2708, device='cuda:0', dtype=torch.float16)
tensor(3.6172, device='cuda:0', dtype=torch.float16) tensor(0.2703, device='cuda:0', dtype=torch.float16)
tensor(3.9531, device='cuda:0', dtype=torch.float16) tensor(0.2900, device='cuda:0', dtype=torch.float16)
tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
tensor(0.1442, device='cuda:0')
old_score: tensor(0.2747, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1443, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.899861097335815
Validation after dual ascent:
out_inf: tensor(17.6719, device='cuda:0', dtype=torch.float16) tensor(1.0029, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.1422, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
tensor(1.4551, device='cuda:0', dtype=torch.float16) tensor(0.1372, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.8730, device='cuda:0', dtype=torch.float16) tensor(0.3474, device='cuda:0', dtype=torch.float16)
tensor(1.5352, device='cuda:0', dtype=torch.float16) tensor(0.1829, device='cuda:0', dtype=torch.float16)
tensor(1.5918, device='cuda:0', dtype=torch.float16) tensor(0.1801, device='cuda:0', dtype=torch.float16)
tensor(1.7861, device='cuda:0', dtype=torch.float16) tensor(0.1924, device='cuda:0', dtype=torch.float16)
tensor(1.7275, device='cuda:0', dtype=torch.float16) tensor(0.1825, device='cuda:0', dtype=torch.float16)
tensor(0.1073, device='cuda:0')
old_score: tensor(0.1844, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.891828298568726
Validation after dual ascent:
out_inf: tensor(3.8730, device='cuda:0', dtype=torch.float16) tensor(0.3474, device='cuda:0', dtype=torch.float16)
tensor(1.0371, device='cuda:0', dtype=torch.float16) tensor(0.1088, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(0.9814, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.2852, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(1.5273, device='cuda:0', dtype=torch.float16) tensor(0.0472, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.0457, device='cuda:0', dtype=torch.float16)
tensor(1.6582, device='cuda:0', dtype=torch.float16) tensor(0.0483, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.0384, device='cuda:0')
old_score: tensor(0.0464, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0279, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.867093563079834
Validation after dual ascent:
out_inf: tensor(6.2852, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(0.7227, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.4941, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0317, device='cuda:0', dtype=torch.float16)
tensor(0.5566, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.4297, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(3.7148, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(4.2344, device='cuda:0', dtype=torch.float16) tensor(0.1578, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0120, device='cuda:0')
tensor(0.0210, device='cuda:0')
old_score: tensor(0.1604, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0961, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.037317514419556
Validation after dual ascent:
out_inf: tensor(9.4297, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(1.7227, device='cuda:0', dtype=torch.float16) tensor(0.0920, device='cuda:0', dtype=torch.float16)
tensor(1.7012, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(1.8008, device='cuda:0', dtype=torch.float16) tensor(0.0920, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.6172, device='cuda:0', dtype=torch.float16) tensor(0.2598, device='cuda:0', dtype=torch.float16)
tensor(2.6016, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(2.5234, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(2.2422, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0191, device='cuda:0')
tensor(0.1822, device='cuda:0')
old_score: tensor(0.1472, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0911, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.108626365661621
Validation after dual ascent:
out_inf: tensor(7.6172, device='cuda:0', dtype=torch.float16) tensor(0.2598, device='cuda:0', dtype=torch.float16)
tensor(0.8457, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(0.9678, device='cuda:0', dtype=torch.float16) tensor(0.0872, device='cuda:0', dtype=torch.float16)
tensor(0.9141, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(0.9062, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.5898, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.8066, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.8521, device='cuda:0', dtype=torch.float16) tensor(0.0523, device='cuda:0', dtype=torch.float16)
tensor(0.8350, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0101, device='cuda:0')
tensor(0.0130, device='cuda:0')
old_score: tensor(0.0505, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0372, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.60488724708557
Validation after dual ascent:
out_inf: tensor(4.5898, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
tensor(0.4016, device='cuda:0', dtype=torch.float16) tensor(0.0349, device='cuda:0', dtype=torch.float16)
tensor(0.5068, device='cuda:0', dtype=torch.float16) tensor(0.0412, device='cuda:0', dtype=torch.float16)
tensor(0.5078, device='cuda:0', dtype=torch.float16) tensor(0.0363, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.6250, device='cuda:0', dtype=torch.float16) tensor(0.7617, device='cuda:0', dtype=torch.float16)
tensor(3.5703, device='cuda:0', dtype=torch.float16) tensor(0.2605, device='cuda:0', dtype=torch.float16)
tensor(3.5117, device='cuda:0', dtype=torch.float16) tensor(0.2549, device='cuda:0', dtype=torch.float16)
tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.2786, device='cuda:0', dtype=torch.float16)
tensor(3.3164, device='cuda:0', dtype=torch.float16) tensor(0.2527, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0192, device='cuda:0')
tensor(0.0202, device='cuda:0')
old_score: tensor(0.2617, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1448, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 5.349672794342041
Validation after dual ascent:
out_inf: tensor(14.6250, device='cuda:0', dtype=torch.float16) tensor(0.7617, device='cuda:0', dtype=torch.float16)
tensor(1.6338, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.5293, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1600, device='cuda:0', dtype=torch.float16)
tensor(1.6895, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1406, device='cuda:0', dtype=torch.float16) tensor(0.9980, device='cuda:0', dtype=torch.float16)
tensor(3.4062, device='cuda:0', dtype=torch.float16) tensor(0.2690, device='cuda:0', dtype=torch.float16)
tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
tensor(3.8555, device='cuda:0', dtype=torch.float16) tensor(0.2856, device='cuda:0', dtype=torch.float16)
tensor(3.6016, device='cuda:0', dtype=torch.float16) tensor(0.2642, device='cuda:0', dtype=torch.float16)
Converged at iteration 400
tensor(0.0193, device='cuda:0')
tensor(0.0241, device='cuda:0')
old_score: tensor(0.2715, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1454, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0908215045928955
Validation after dual ascent:
out_inf: tensor(17.1406, device='cuda:0', dtype=torch.float16) tensor(0.9980, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(1.7051, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.6719, device='cuda:0', dtype=torch.float16) tensor(0.1604, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.3325, device='cuda:0', dtype=torch.float16)
tensor(1.6982, device='cuda:0', dtype=torch.float16) tensor(0.1815, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1792, device='cuda:0', dtype=torch.float16)
tensor(1.7754, device='cuda:0', dtype=torch.float16) tensor(0.1895, device='cuda:0', dtype=torch.float16)
tensor(2.1426, device='cuda:0', dtype=torch.float16) tensor(0.1802, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0064, device='cuda:0')
tensor(0.0668, device='cuda:0')
old_score: tensor(0.1826, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1112, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.182079792022705
Validation after dual ascent:
out_inf: tensor(4.2148, device='cuda:0', dtype=torch.float16) tensor(0.3325, device='cuda:0', dtype=torch.float16)
tensor(1.0439, device='cuda:0', dtype=torch.float16) tensor(0.1099, device='cuda:0', dtype=torch.float16)
tensor(0.9438, device='cuda:0', dtype=torch.float16) tensor(0.1066, device='cuda:0', dtype=torch.float16)
tensor(1.0898, device='cuda:0', dtype=torch.float16) tensor(0.1221, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.1063, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.o_proj
Validation after prune:
out_inf: tensor(13.3828, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.0630, device='cuda:0', dtype=torch.float16)
tensor(1.9336, device='cuda:0', dtype=torch.float16) tensor(0.0582, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
Converged at iteration 950
tensor(0.0177, device='cuda:0')
tensor(0.0360, device='cuda:0')
old_score: tensor(0.0615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0358, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.127431392669678
Validation after dual ascent:
out_inf: tensor(13.3828, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
tensor(0.6133, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
tensor(0.6016, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
tensor(0.7485, device='cuda:0', dtype=torch.float16) tensor(0.0351, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.3281, device='cuda:0', dtype=torch.float16) tensor(0.3694, device='cuda:0', dtype=torch.float16)
tensor(2.9609, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(2.9023, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
tensor(3.3750, device='cuda:0', dtype=torch.float16) tensor(0.1680, device='cuda:0', dtype=torch.float16)
tensor(3.2852, device='cuda:0', dtype=torch.float16) tensor(0.1597, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0129, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.1600, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0955, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.02759575843811
Validation after dual ascent:
out_inf: tensor(7.3281, device='cuda:0', dtype=torch.float16) tensor(0.3694, device='cuda:0', dtype=torch.float16)
tensor(1.4570, device='cuda:0', dtype=torch.float16) tensor(0.0933, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(1.6699, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(1.9082, device='cuda:0', dtype=torch.float16) tensor(0.0916, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.0625, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(2.6367, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
tensor(1.8574, device='cuda:0', dtype=torch.float16) tensor(0.1449, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.1689, device='cuda:0')
old_score: tensor(0.1450, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0897, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.102321147918701
Validation after dual ascent:
out_inf: tensor(6.0625, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
tensor(1.0820, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
tensor(1.4102, device='cuda:0', dtype=torch.float16) tensor(0.0994, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0859, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.down_proj
Validation after prune:
out_inf: tensor(7.9961, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(0.6719, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0100, device='cuda:0')
tensor(0.0137, device='cuda:0')
old_score: tensor(0.0489, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0356, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.557995796203613
Validation after dual ascent:
out_inf: tensor(7.9961, device='cuda:0', dtype=torch.float16) tensor(0.1060, device='cuda:0', dtype=torch.float16)
tensor(0.4543, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.4292, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.4648, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4751, device='cuda:0', dtype=torch.float16) tensor(0.0353, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.9062, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.2515, device='cuda:0', dtype=torch.float16)
tensor(3.8438, device='cuda:0', dtype=torch.float16) tensor(0.2473, device='cuda:0', dtype=torch.float16)
tensor(4.8359, device='cuda:0', dtype=torch.float16) tensor(0.2744, device='cuda:0', dtype=torch.float16)
tensor(3.5781, device='cuda:0', dtype=torch.float16) tensor(0.2474, device='cuda:0', dtype=torch.float16)
tensor(0.2569, device='cuda:0')
old_score: tensor(0.2551, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1396, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.846603393554688
Validation after dual ascent:
out_inf: tensor(17.9062, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1345, device='cuda:0', dtype=torch.float16)
tensor(1.5605, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(1.5391, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(0.9414, device='cuda:0', dtype=torch.float16)
tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(3.7891, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(3.7422, device='cuda:0', dtype=torch.float16) tensor(0.2747, device='cuda:0', dtype=torch.float16)
tensor(4.0078, device='cuda:0', dtype=torch.float16) tensor(0.2517, device='cuda:0', dtype=torch.float16)
tensor(0.2525, device='cuda:0')
old_score: tensor(0.2581, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1399, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.916057348251343
Validation after dual ascent:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(0.9414, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1359, device='cuda:0', dtype=torch.float16)
tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.3459, device='cuda:0', dtype=torch.float16)
tensor(1.7842, device='cuda:0', dtype=torch.float16) tensor(0.1881, device='cuda:0', dtype=torch.float16)
tensor(1.9023, device='cuda:0', dtype=torch.float16) tensor(0.1866, device='cuda:0', dtype=torch.float16)
tensor(1.7979, device='cuda:0', dtype=torch.float16) tensor(0.2004, device='cuda:0', dtype=torch.float16)
tensor(2.0273, device='cuda:0', dtype=torch.float16) tensor(0.1899, device='cuda:0', dtype=torch.float16)
tensor(0.1977, device='cuda:0')
old_score: tensor(0.1913, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1152, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.90550422668457
Validation after dual ascent:
out_inf: tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.3459, device='cuda:0', dtype=torch.float16)
tensor(1.1367, device='cuda:0', dtype=torch.float16) tensor(0.1120, device='cuda:0', dtype=torch.float16)
tensor(1.0381, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.1097, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.o_proj
Validation after prune:
out_inf: tensor(8.8672, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(1.6914, device='cuda:0', dtype=torch.float16) tensor(0.0540, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
tensor(1.5859, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.0404, device='cuda:0')
old_score: tensor(0.0533, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0309, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.867784261703491
Validation after dual ascent:
out_inf: tensor(8.8672, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.6250, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.4258, device='cuda:0', dtype=torch.float16) tensor(0.3682, device='cuda:0', dtype=torch.float16)
tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
tensor(2.6680, device='cuda:0', dtype=torch.float16) tensor(0.1600, device='cuda:0', dtype=torch.float16)
tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(2.8906, device='cuda:0', dtype=torch.float16) tensor(0.1614, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0131, device='cuda:0')
tensor(0.0221, device='cuda:0')
old_score: tensor(0.1633, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0985, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.038984298706055
Validation after dual ascent:
out_inf: tensor(7.4258, device='cuda:0', dtype=torch.float16) tensor(0.3682, device='cuda:0', dtype=torch.float16)
tensor(1.3457, device='cuda:0', dtype=torch.float16) tensor(0.0953, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
tensor(1.6641, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.9893, device='cuda:0', dtype=torch.float16) tensor(0.0938, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.0469, device='cuda:0', dtype=torch.float16) tensor(0.2546, device='cuda:0', dtype=torch.float16)
tensor(1.8613, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1444, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1555, device='cuda:0', dtype=torch.float16)
tensor(2.0957, device='cuda:0', dtype=torch.float16) tensor(0.1462, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0192, device='cuda:0')
tensor(0.1853, device='cuda:0')
old_score: tensor(0.1475, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0918, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.111243963241577
Validation after dual ascent:
out_inf: tensor(5.0469, device='cuda:0', dtype=torch.float16) tensor(0.2546, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
tensor(1.1230, device='cuda:0', dtype=torch.float16) tensor(0.0889, device='cuda:0', dtype=torch.float16)
tensor(1.1445, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(1.1436, device='cuda:0', dtype=torch.float16) tensor(0.0874, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.0762, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.6895, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.7778, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.7129, device='cuda:0', dtype=torch.float16) tensor(0.0497, device='cuda:0', dtype=torch.float16)
tensor(0.7334, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0094, device='cuda:0')
tensor(0.0100, device='cuda:0')
old_score: tensor(0.0478, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0352, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.591278791427612
Validation after dual ascent:
out_inf: tensor(3.0762, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(0.4082, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.4199, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.4883, device='cuda:0', dtype=torch.float16) tensor(0.0398, device='cuda:0', dtype=torch.float16)
tensor(0.4055, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.8281, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(3.9141, device='cuda:0', dtype=torch.float16) tensor(0.2600, device='cuda:0', dtype=torch.float16)
tensor(4.1836, device='cuda:0', dtype=torch.float16) tensor(0.2598, device='cuda:0', dtype=torch.float16)
tensor(4.3008, device='cuda:0', dtype=torch.float16) tensor(0.2871, device='cuda:0', dtype=torch.float16)
tensor(3.2910, device='cuda:0', dtype=torch.float16) tensor(0.2593, device='cuda:0', dtype=torch.float16)
tensor(0.2466, device='cuda:0')
old_score: tensor(0.2666, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1472, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.862006425857544
Validation after dual ascent:
out_inf: tensor(16.8281, device='cuda:0', dtype=torch.float16) tensor(0.7900, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1420, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.6777, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.2031, device='cuda:0', dtype=torch.float16) tensor(0.9697, device='cuda:0', dtype=torch.float16)
tensor(3.7383, device='cuda:0', dtype=torch.float16) tensor(0.2627, device='cuda:0', dtype=torch.float16)
tensor(3.7656, device='cuda:0', dtype=torch.float16) tensor(0.2644, device='cuda:0', dtype=torch.float16)
tensor(3.4922, device='cuda:0', dtype=torch.float16) tensor(0.2874, device='cuda:0', dtype=torch.float16)
tensor(3.7734, device='cuda:0', dtype=torch.float16) tensor(0.2639, device='cuda:0', dtype=torch.float16)
tensor(0.2476, device='cuda:0')
old_score: tensor(0.2695, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1472, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.924801588058472
Validation after dual ascent:
out_inf: tensor(20.2031, device='cuda:0', dtype=torch.float16) tensor(0.9697, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(1.6562, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1654, device='cuda:0', dtype=torch.float16)
tensor(1.5098, device='cuda:0', dtype=torch.float16) tensor(0.1388, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.7773, device='cuda:0', dtype=torch.float16) tensor(0.3560, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.1890, device='cuda:0', dtype=torch.float16)
tensor(2.2266, device='cuda:0', dtype=torch.float16) tensor(0.1897, device='cuda:0', dtype=torch.float16)
tensor(1.8477, device='cuda:0', dtype=torch.float16) tensor(0.2046, device='cuda:0', dtype=torch.float16)
tensor(2.1797, device='cuda:0', dtype=torch.float16) tensor(0.1915, device='cuda:0', dtype=torch.float16)
tensor(0.1678, device='cuda:0')
old_score: tensor(0.1936, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1184, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.923921346664429
Validation after dual ascent:
out_inf: tensor(7.7773, device='cuda:0', dtype=torch.float16) tensor(0.3560, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.1144, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.1148, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
tensor(1.1230, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.3438, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0550, device='cuda:0', dtype=torch.float16)
tensor(1.2031, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.0596, device='cuda:0')
old_score: tensor(0.0561, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0342, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.881569147109985
Validation after dual ascent:
out_inf: tensor(11.3438, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0319, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
tensor(0.7588, device='cuda:0', dtype=torch.float16) tensor(0.0387, device='cuda:0', dtype=torch.float16)
tensor(0.5781, device='cuda:0', dtype=torch.float16) tensor(0.0334, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.4141, device='cuda:0', dtype=torch.float16) tensor(0.3640, device='cuda:0', dtype=torch.float16)
tensor(3.9375, device='cuda:0', dtype=torch.float16) tensor(0.1616, device='cuda:0', dtype=torch.float16)
tensor(3.2305, device='cuda:0', dtype=torch.float16) tensor(0.1604, device='cuda:0', dtype=torch.float16)
tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.1731, device='cuda:0', dtype=torch.float16)
tensor(3.8516, device='cuda:0', dtype=torch.float16) tensor(0.1625, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0124, device='cuda:0')
tensor(0.0214, device='cuda:0')
old_score: tensor(0.1644, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1000, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.049824953079224
Validation after dual ascent:
out_inf: tensor(8.4141, device='cuda:0', dtype=torch.float16) tensor(0.3640, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.0959, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.0969, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.1118, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.6250, device='cuda:0', dtype=torch.float16) tensor(0.2588, device='cuda:0', dtype=torch.float16)
tensor(1.8555, device='cuda:0', dtype=torch.float16) tensor(0.1449, device='cuda:0', dtype=torch.float16)
tensor(1.8418, device='cuda:0', dtype=torch.float16) tensor(0.1443, device='cuda:0', dtype=torch.float16)
tensor(2.0449, device='cuda:0', dtype=torch.float16) tensor(0.1556, device='cuda:0', dtype=torch.float16)
tensor(2.0938, device='cuda:0', dtype=torch.float16) tensor(0.1466, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0189, device='cuda:0')
tensor(0.1805, device='cuda:0')
old_score: tensor(0.1478, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0923, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.115644931793213
Validation after dual ascent:
out_inf: tensor(5.6250, device='cuda:0', dtype=torch.float16) tensor(0.2588, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0887, device='cuda:0', dtype=torch.float16)
tensor(1.2910, device='cuda:0', dtype=torch.float16) tensor(0.0895, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.3438, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.5312, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(0.5142, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0146, device='cuda:0')
tensor(0.0263, device='cuda:0')
old_score: tensor(0.0481, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0358, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.811426162719727
Validation after dual ascent:
out_inf: tensor(2.3438, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(0.3953, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.4277, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
tensor(0.4272, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(0.4480, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.3125, device='cuda:0', dtype=torch.float16) tensor(0.7466, device='cuda:0', dtype=torch.float16)
tensor(5.1484, device='cuda:0', dtype=torch.float16) tensor(0.2551, device='cuda:0', dtype=torch.float16)
tensor(3.3438, device='cuda:0', dtype=torch.float16) tensor(0.2515, device='cuda:0', dtype=torch.float16)
tensor(3.9414, device='cuda:0', dtype=torch.float16) tensor(0.2759, device='cuda:0', dtype=torch.float16)
tensor(3.0859, device='cuda:0', dtype=torch.float16) tensor(0.2517, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0191, device='cuda:0')
tensor(0.0507, device='cuda:0')
old_score: tensor(0.2585, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1467, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.66400694847107
Validation after dual ascent:
out_inf: tensor(19.3125, device='cuda:0', dtype=torch.float16) tensor(0.7466, device='cuda:0', dtype=torch.float16)
tensor(1.5420, device='cuda:0', dtype=torch.float16) tensor(0.1405, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.6992, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(1.8584, device='cuda:0', dtype=torch.float16) tensor(0.1382, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.5781, device='cuda:0', dtype=torch.float16) tensor(0.8926, device='cuda:0', dtype=torch.float16)
tensor(3.9219, device='cuda:0', dtype=torch.float16) tensor(0.2563, device='cuda:0', dtype=torch.float16)
tensor(3.8047, device='cuda:0', dtype=torch.float16) tensor(0.2573, device='cuda:0', dtype=torch.float16)
tensor(4.0547, device='cuda:0', dtype=torch.float16) tensor(0.2766, device='cuda:0', dtype=torch.float16)
tensor(4.2891, device='cuda:0', dtype=torch.float16) tensor(0.2559, device='cuda:0', dtype=torch.float16)
tensor(0.0446, device='cuda:0')
old_score: tensor(0.2615, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1470, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.92564058303833
Validation after dual ascent:
out_inf: tensor(16.5781, device='cuda:0', dtype=torch.float16) tensor(0.8926, device='cuda:0', dtype=torch.float16)
tensor(1.5449, device='cuda:0', dtype=torch.float16) tensor(0.1409, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.7598, device='cuda:0', dtype=torch.float16) tensor(0.1658, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.7500, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(1.8369, device='cuda:0', dtype=torch.float16) tensor(0.2014, device='cuda:0', dtype=torch.float16)
tensor(1.9346, device='cuda:0', dtype=torch.float16) tensor(0.2010, device='cuda:0', dtype=torch.float16)
tensor(2.0430, device='cuda:0', dtype=torch.float16) tensor(0.2151, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.2036, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0142, device='cuda:0')
tensor(0.0827, device='cuda:0')
old_score: tensor(0.2052, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1252, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.186298131942749
Validation after dual ascent:
out_inf: tensor(4.7500, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(1.0957, device='cuda:0', dtype=torch.float16) tensor(0.1201, device='cuda:0', dtype=torch.float16)
tensor(1.1270, device='cuda:0', dtype=torch.float16) tensor(0.1218, device='cuda:0', dtype=torch.float16)
tensor(1.1855, device='cuda:0', dtype=torch.float16) tensor(0.1403, device='cuda:0', dtype=torch.float16)
tensor(1.1113, device='cuda:0', dtype=torch.float16) tensor(0.1186, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.o_proj
Validation after prune:
out_inf: tensor(13.6016, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(1.7832, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(1.3633, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.0404, device='cuda:0', dtype=torch.float16)
tensor(0.0530, device='cuda:0')
old_score: tensor(0.0408, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0248, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.870952844619751
Validation after dual ascent:
out_inf: tensor(13.6016, device='cuda:0', dtype=torch.float16) tensor(0.1392, device='cuda:0', dtype=torch.float16)
tensor(0.8750, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0231, device='cuda:0', dtype=torch.float16)
tensor(1.5596, device='cuda:0', dtype=torch.float16) tensor(0.0272, device='cuda:0', dtype=torch.float16)
tensor(0.7754, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.3906, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(3.5781, device='cuda:0', dtype=torch.float16) tensor(0.1613, device='cuda:0', dtype=torch.float16)
tensor(2.8535, device='cuda:0', dtype=torch.float16) tensor(0.1614, device='cuda:0', dtype=torch.float16)
tensor(3.4766, device='cuda:0', dtype=torch.float16) tensor(0.1732, device='cuda:0', dtype=torch.float16)
tensor(2.9121, device='cuda:0', dtype=torch.float16) tensor(0.1610, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0127, device='cuda:0')
tensor(0.0204, device='cuda:0')
old_score: tensor(0.1643, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0989, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.042896270751953
Validation after dual ascent:
out_inf: tensor(8.3906, device='cuda:0', dtype=torch.float16) tensor(0.3616, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(1.9043, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(1.8066, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.3867, device='cuda:0', dtype=torch.float16) tensor(0.2556, device='cuda:0', dtype=torch.float16)
tensor(2.0625, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(2.1055, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
tensor(1.8379, device='cuda:0', dtype=torch.float16) tensor(0.1562, device='cuda:0', dtype=torch.float16)
tensor(2.0566, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0182, device='cuda:0')
tensor(0.1719, device='cuda:0')
old_score: tensor(0.1482, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0919, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.111414670944214
Validation after dual ascent:
out_inf: tensor(5.3867, device='cuda:0', dtype=torch.float16) tensor(0.2556, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0881, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0898, device='cuda:0', dtype=torch.float16)
tensor(0.9199, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0864, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.5547, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.5703, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0465, device='cuda:0', dtype=torch.float16)
tensor(0.6357, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.6450, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0184, device='cuda:0')
tensor(0.0311, device='cuda:0')
old_score: tensor(0.0478, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0354, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.791526317596436
Validation after dual ascent:
out_inf: tensor(4.5547, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(0.4397, device='cuda:0', dtype=torch.float16) tensor(0.0337, device='cuda:0', dtype=torch.float16)
tensor(0.4326, device='cuda:0', dtype=torch.float16) tensor(0.0336, device='cuda:0', dtype=torch.float16)
tensor(0.4790, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.4458, device='cuda:0', dtype=torch.float16) tensor(0.0335, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.7891, device='cuda:0', dtype=torch.float16) tensor(0.7217, device='cuda:0', dtype=torch.float16)
tensor(3.8047, device='cuda:0', dtype=torch.float16) tensor(0.2434, device='cuda:0', dtype=torch.float16)
tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.2423, device='cuda:0', dtype=torch.float16)
tensor(4.8984, device='cuda:0', dtype=torch.float16) tensor(0.2690, device='cuda:0', dtype=torch.float16)
tensor(3.2227, device='cuda:0', dtype=torch.float16) tensor(0.2377, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0174, device='cuda:0')
tensor(0.0390, device='cuda:0')
old_score: tensor(0.2482, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1389, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.65954875946045
Validation after dual ascent:
out_inf: tensor(15.7891, device='cuda:0', dtype=torch.float16) tensor(0.7217, device='cuda:0', dtype=torch.float16)
tensor(1.8633, device='cuda:0', dtype=torch.float16) tensor(0.1327, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(1.6621, device='cuda:0', dtype=torch.float16) tensor(0.1294, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.2031, device='cuda:0', dtype=torch.float16) tensor(0.9282, device='cuda:0', dtype=torch.float16)
tensor(2.9395, device='cuda:0', dtype=torch.float16) tensor(0.2435, device='cuda:0', dtype=torch.float16)
tensor(3.7031, device='cuda:0', dtype=torch.float16) tensor(0.2460, device='cuda:0', dtype=torch.float16)
tensor(4.9453, device='cuda:0', dtype=torch.float16) tensor(0.2671, device='cuda:0', dtype=torch.float16)
tensor(3.1406, device='cuda:0', dtype=torch.float16) tensor(0.2405, device='cuda:0', dtype=torch.float16)
tensor(0.0371, device='cuda:0')
old_score: tensor(0.2493, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1384, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.922088146209717
Validation after dual ascent:
out_inf: tensor(16.2031, device='cuda:0', dtype=torch.float16) tensor(0.9282, device='cuda:0', dtype=torch.float16)
tensor(1.7305, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.1353, device='cuda:0', dtype=torch.float16)
tensor(1.7676, device='cuda:0', dtype=torch.float16) tensor(0.1571, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1289, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.8477, device='cuda:0', dtype=torch.float16) tensor(0.3672, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(1.9004, device='cuda:0', dtype=torch.float16) tensor(0.1951, device='cuda:0', dtype=torch.float16)
tensor(2.2441, device='cuda:0', dtype=torch.float16) tensor(0.2108, device='cuda:0', dtype=torch.float16)
tensor(2.2676, device='cuda:0', dtype=torch.float16) tensor(0.1941, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0113, device='cuda:0')
tensor(0.0726, device='cuda:0')
old_score: tensor(0.1985, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1218, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.186271905899048
Validation after dual ascent:
out_inf: tensor(4.8477, device='cuda:0', dtype=torch.float16) tensor(0.3672, device='cuda:0', dtype=torch.float16)
tensor(1.1338, device='cuda:0', dtype=torch.float16) tensor(0.1166, device='cuda:0', dtype=torch.float16)
tensor(1.1162, device='cuda:0', dtype=torch.float16) tensor(0.1190, device='cuda:0', dtype=torch.float16)
tensor(1.2881, device='cuda:0', dtype=torch.float16) tensor(0.1375, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.1141, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.1406, device='cuda:0', dtype=torch.float16) tensor(0.1736, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(1.1758, device='cuda:0', dtype=torch.float16) tensor(0.0636, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(1.1133, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.0959, device='cuda:0')
old_score: tensor(0.0610, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0355, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.863842964172363
Validation after dual ascent:
out_inf: tensor(11.1406, device='cuda:0', dtype=torch.float16) tensor(0.1736, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.6562, device='cuda:0', dtype=torch.float16) tensor(0.0394, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.1094, device='cuda:0', dtype=torch.float16) tensor(0.3689, device='cuda:0', dtype=torch.float16)
tensor(2.7539, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(3.4766, device='cuda:0', dtype=torch.float16) tensor(0.1687, device='cuda:0', dtype=torch.float16)
tensor(3.1621, device='cuda:0', dtype=torch.float16) tensor(0.1788, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.1675, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0135, device='cuda:0')
tensor(0.0228, device='cuda:0')
old_score: tensor(0.1704, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1027, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.035907506942749
Validation after dual ascent:
out_inf: tensor(8.1094, device='cuda:0', dtype=torch.float16) tensor(0.3689, device='cuda:0', dtype=torch.float16)
tensor(2.0742, device='cuda:0', dtype=torch.float16) tensor(0.0981, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.1010, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1151, device='cuda:0', dtype=torch.float16)
tensor(1.9795, device='cuda:0', dtype=torch.float16) tensor(0.0968, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.2637, device='cuda:0', dtype=torch.float16)
tensor(2.0488, device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(1.7949, device='cuda:0', dtype=torch.float16) tensor(0.1520, device='cuda:0', dtype=torch.float16)
tensor(2.0762, device='cuda:0', dtype=torch.float16) tensor(0.1606, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0196, device='cuda:0')
tensor(0.1891, device='cuda:0')
old_score: tensor(0.1536, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0955, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.109243869781494
Validation after dual ascent:
out_inf: tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.2637, device='cuda:0', dtype=torch.float16)
tensor(0.8608, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(0.8647, device='cuda:0', dtype=torch.float16) tensor(0.0939, device='cuda:0', dtype=torch.float16)
tensor(1.0049, device='cuda:0', dtype=torch.float16) tensor(0.1070, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.0900, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(0.5376, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.5405, device='cuda:0', dtype=torch.float16) tensor(0.0519, device='cuda:0', dtype=torch.float16)
tensor(0.5381, device='cuda:0', dtype=torch.float16) tensor(0.0505, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0094, device='cuda:0')
tensor(0.0200, device='cuda:0')
old_score: tensor(0.0503, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0374, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.804768562316895
Validation after dual ascent:
out_inf: tensor(4.8008, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(0.4275, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.4282, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.q_proj
Validation after prune:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(3.6289, device='cuda:0', dtype=torch.float16) tensor(0.2546, device='cuda:0', dtype=torch.float16)
tensor(3.3086, device='cuda:0', dtype=torch.float16) tensor(0.2583, device='cuda:0', dtype=torch.float16)
tensor(4.0117, device='cuda:0', dtype=torch.float16) tensor(0.2795, device='cuda:0', dtype=torch.float16)
tensor(2.9805, device='cuda:0', dtype=torch.float16) tensor(0.2520, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0188, device='cuda:0')
tensor(0.0524, device='cuda:0')
old_score: tensor(0.2610, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1498, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.651848793029785
Validation after dual ascent:
out_inf: tensor(11.9453, device='cuda:0', dtype=torch.float16) tensor(0.7285, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.1477, device='cuda:0', dtype=torch.float16)
tensor(1.9902, device='cuda:0', dtype=torch.float16) tensor(0.1697, device='cuda:0', dtype=torch.float16)
tensor(1.5762, device='cuda:0', dtype=torch.float16) tensor(0.1394, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1719, device='cuda:0', dtype=torch.float16) tensor(0.8726, device='cuda:0', dtype=torch.float16)
tensor(3.0078, device='cuda:0', dtype=torch.float16) tensor(0.2554, device='cuda:0', dtype=torch.float16)
tensor(3.3906, device='cuda:0', dtype=torch.float16) tensor(0.2627, device='cuda:0', dtype=torch.float16)
tensor(3.3281, device='cuda:0', dtype=torch.float16) tensor(0.2820, device='cuda:0', dtype=torch.float16)
tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.2554, device='cuda:0', dtype=torch.float16)
tensor(0.0455, device='cuda:0')
old_score: tensor(0.2637, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1500, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.919415473937988
Validation after dual ascent:
out_inf: tensor(17.1719, device='cuda:0', dtype=torch.float16) tensor(0.8726, device='cuda:0', dtype=torch.float16)
tensor(1.6699, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(1.7471, device='cuda:0', dtype=torch.float16) tensor(0.1478, device='cuda:0', dtype=torch.float16)
tensor(1.6670, device='cuda:0', dtype=torch.float16) tensor(0.1700, device='cuda:0', dtype=torch.float16)
tensor(1.5459, device='cuda:0', dtype=torch.float16) tensor(0.1396, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.4805, device='cuda:0', dtype=torch.float16) tensor(0.3938, device='cuda:0', dtype=torch.float16)
tensor(2.4434, device='cuda:0', dtype=torch.float16) tensor(0.2142, device='cuda:0', dtype=torch.float16)
tensor(2.2207, device='cuda:0', dtype=torch.float16) tensor(0.2173, device='cuda:0', dtype=torch.float16)
tensor(2.6289, device='cuda:0', dtype=torch.float16) tensor(0.2322, device='cuda:0', dtype=torch.float16)
tensor(2.0840, device='cuda:0', dtype=torch.float16) tensor(0.2137, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0148, device='cuda:0')
tensor(0.0870, device='cuda:0')
old_score: tensor(0.2195, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1350, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.187769889831543
Validation after dual ascent:
out_inf: tensor(5.4805, device='cuda:0', dtype=torch.float16) tensor(0.3938, device='cuda:0', dtype=torch.float16)
tensor(1.4971, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.1963, device='cuda:0', dtype=torch.float16) tensor(0.1332, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
tensor(1.2773, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.0781, device='cuda:0', dtype=torch.float16) tensor(0.1428, device='cuda:0', dtype=torch.float16)
tensor(1.5049, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(1.3350, device='cuda:0', dtype=torch.float16) tensor(0.0406, device='cuda:0', dtype=torch.float16)
tensor(1.7520, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.0927, device='cuda:0')
old_score: tensor(0.0419, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0222, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.857631206512451
Validation after dual ascent:
out_inf: tensor(5.0781, device='cuda:0', dtype=torch.float16) tensor(0.1428, device='cuda:0', dtype=torch.float16)
tensor(1.0869, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.8164, device='cuda:0', dtype=torch.float16) tensor(0.0245, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.6055, device='cuda:0', dtype=torch.float16) tensor(0.3923, device='cuda:0', dtype=torch.float16)
tensor(3.3164, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(3.1523, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(3.2109, device='cuda:0', dtype=torch.float16) tensor(0.1853, device='cuda:0', dtype=torch.float16)
tensor(3.2344, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0156, device='cuda:0')
tensor(0.0264, device='cuda:0')
old_score: tensor(0.1768, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1050, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.039245843887329
Validation after dual ascent:
out_inf: tensor(7.6055, device='cuda:0', dtype=torch.float16) tensor(0.3923, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
tensor(1.8066, device='cuda:0', dtype=torch.float16) tensor(0.1035, device='cuda:0', dtype=torch.float16)
tensor(1.9004, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.5273, device='cuda:0', dtype=torch.float16) tensor(0.2791, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1560, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1588, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1676, device='cuda:0', dtype=torch.float16)
tensor(2.7227, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0091, device='cuda:0')
tensor(0.0224, device='cuda:0')
old_score: tensor(0.1597, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0979, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.037612676620483
Validation after dual ascent:
out_inf: tensor(6.5273, device='cuda:0', dtype=torch.float16) tensor(0.2791, device='cuda:0', dtype=torch.float16)
tensor(1.1602, device='cuda:0', dtype=torch.float16) tensor(0.0930, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1103, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.0917, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(0.5972, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5986, device='cuda:0', dtype=torch.float16) tensor(0.0567, device='cuda:0', dtype=torch.float16)
tensor(0.5815, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0083, device='cuda:0')
tensor(0.0153, device='cuda:0')
old_score: tensor(0.0547, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0400, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.690146923065186
Validation after dual ascent:
out_inf: tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(0.4773, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
tensor(0.4705, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.5024, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0374, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.8906, device='cuda:0', dtype=torch.float16) tensor(0.8042, device='cuda:0', dtype=torch.float16)
tensor(4.2266, device='cuda:0', dtype=torch.float16) tensor(0.2732, device='cuda:0', dtype=torch.float16)
tensor(3.5938, device='cuda:0', dtype=torch.float16) tensor(0.2793, device='cuda:0', dtype=torch.float16)
tensor(3.9141, device='cuda:0', dtype=torch.float16) tensor(0.2949, device='cuda:0', dtype=torch.float16)
tensor(3.5156, device='cuda:0', dtype=torch.float16) tensor(0.2664, device='cuda:0', dtype=torch.float16)
tensor(0.1365, device='cuda:0')
old_score: tensor(0.2786, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1534, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.840601444244385
Validation after dual ascent:
out_inf: tensor(14.8906, device='cuda:0', dtype=torch.float16) tensor(0.8042, device='cuda:0', dtype=torch.float16)
tensor(1.7617, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.1531, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.1731, device='cuda:0', dtype=torch.float16)
tensor(1.6230, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.6719, device='cuda:0', dtype=torch.float16) tensor(0.9990, device='cuda:0', dtype=torch.float16)
tensor(4.0938, device='cuda:0', dtype=torch.float16) tensor(0.2759, device='cuda:0', dtype=torch.float16)
tensor(3.3906, device='cuda:0', dtype=torch.float16) tensor(0.2847, device='cuda:0', dtype=torch.float16)
tensor(3.9297, device='cuda:0', dtype=torch.float16) tensor(0.2964, device='cuda:0', dtype=torch.float16)
tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.2727, device='cuda:0', dtype=torch.float16)
tensor(0.1463, device='cuda:0')
old_score: tensor(0.2825, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1532, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.911016464233398
Validation after dual ascent:
out_inf: tensor(17.6719, device='cuda:0', dtype=torch.float16) tensor(0.9990, device='cuda:0', dtype=torch.float16)
tensor(1.6348, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.7236, device='cuda:0', dtype=torch.float16) tensor(0.1528, device='cuda:0', dtype=torch.float16)
tensor(1.9922, device='cuda:0', dtype=torch.float16) tensor(0.1727, device='cuda:0', dtype=torch.float16)
tensor(1.6484, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.6211, device='cuda:0', dtype=torch.float16) tensor(0.4236, device='cuda:0', dtype=torch.float16)
tensor(2.4004, device='cuda:0', dtype=torch.float16) tensor(0.2272, device='cuda:0', dtype=torch.float16)
tensor(2.1992, device='cuda:0', dtype=torch.float16) tensor(0.2341, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.2426, device='cuda:0', dtype=torch.float16)
tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.2257, device='cuda:0', dtype=torch.float16)
tensor(0.1229, device='cuda:0')
old_score: tensor(0.2324, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1414, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.924495220184326
Validation after dual ascent:
out_inf: tensor(5.6211, device='cuda:0', dtype=torch.float16) tensor(0.4236, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1346, device='cuda:0', dtype=torch.float16)
tensor(1.4209, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(1.4424, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(1.4512, device='cuda:0', dtype=torch.float16) tensor(0.1312, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.o_proj
Validation after prune:
out_inf: tensor(20.2031, device='cuda:0', dtype=torch.float16) tensor(0.2013, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
tensor(2.4766, device='cuda:0', dtype=torch.float16) tensor(0.0655, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.0705, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.0616, device='cuda:0', dtype=torch.float16)
tensor(0.0865, device='cuda:0')
old_score: tensor(0.0650, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0385, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.870903253555298
Validation after dual ascent:
out_inf: tensor(20.2031, device='cuda:0', dtype=torch.float16) tensor(0.2013, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(1.0625, device='cuda:0', dtype=torch.float16) tensor(0.0390, device='cuda:0', dtype=torch.float16)
tensor(0.8872, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(0.9922, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.1367, device='cuda:0', dtype=torch.float16) tensor(0.4241, device='cuda:0', dtype=torch.float16)
tensor(3.0039, device='cuda:0', dtype=torch.float16) tensor(0.1809, device='cuda:0', dtype=torch.float16)
tensor(6.2891, device='cuda:0', dtype=torch.float16) tensor(0.1873, device='cuda:0', dtype=torch.float16)
tensor(4.0117, device='cuda:0', dtype=torch.float16) tensor(0.1938, device='cuda:0', dtype=torch.float16)
tensor(3.0840, device='cuda:0', dtype=torch.float16) tensor(0.1796, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0184, device='cuda:0')
tensor(0.0306, device='cuda:0')
old_score: tensor(0.1854, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1080, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.046619653701782
Validation after dual ascent:
out_inf: tensor(7.1367, device='cuda:0', dtype=torch.float16) tensor(0.4241, device='cuda:0', dtype=torch.float16)
tensor(2.2012, device='cuda:0', dtype=torch.float16) tensor(0.1022, device='cuda:0', dtype=torch.float16)
tensor(1.9336, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.5898, device='cuda:0', dtype=torch.float16) tensor(0.3032, device='cuda:0', dtype=torch.float16)
tensor(2.0605, device='cuda:0', dtype=torch.float16) tensor(0.1641, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.1752, device='cuda:0', dtype=torch.float16)
tensor(2.4473, device='cuda:0', dtype=torch.float16) tensor(0.1631, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0110, device='cuda:0')
tensor(0.0259, device='cuda:0')
old_score: tensor(0.1674, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1010, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.042848348617554
Validation after dual ascent:
out_inf: tensor(5.5898, device='cuda:0', dtype=torch.float16) tensor(0.3032, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0957, device='cuda:0', dtype=torch.float16)
tensor(1.4609, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(1.4639, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.8770, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(0.7041, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.7686, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.6333, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0061, device='cuda:0')
tensor(0.0114, device='cuda:0')
old_score: tensor(0.0610, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0438, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.764649152755737
Validation after dual ascent:
out_inf: tensor(2.8770, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(0.5347, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.4854, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
tensor(0.5195, device='cuda:0', dtype=torch.float16) tensor(0.0503, device='cuda:0', dtype=torch.float16)
tensor(0.5059, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.7700, device='cuda:0', dtype=torch.float16)
tensor(3.8672, device='cuda:0', dtype=torch.float16) tensor(0.2769, device='cuda:0', dtype=torch.float16)
tensor(4.0781, device='cuda:0', dtype=torch.float16) tensor(0.2827, device='cuda:0', dtype=torch.float16)
tensor(4.0078, device='cuda:0', dtype=torch.float16) tensor(0.2996, device='cuda:0', dtype=torch.float16)
tensor(3.8359, device='cuda:0', dtype=torch.float16) tensor(0.2744, device='cuda:0', dtype=torch.float16)
tensor(0.2226, device='cuda:0')
old_score: tensor(0.2834, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1528, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.851752042770386
Validation after dual ascent:
out_inf: tensor(14.1484, device='cuda:0', dtype=torch.float16) tensor(0.7700, device='cuda:0', dtype=torch.float16)
tensor(1.4170, device='cuda:0', dtype=torch.float16) tensor(0.1449, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1516, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1731, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.5312, device='cuda:0', dtype=torch.float16) tensor(0.9033, device='cuda:0', dtype=torch.float16)
tensor(5.1797, device='cuda:0', dtype=torch.float16) tensor(0.2820, device='cuda:0', dtype=torch.float16)
tensor(4.4297, device='cuda:0', dtype=torch.float16) tensor(0.2937, device='cuda:0', dtype=torch.float16)
tensor(4.8672, device='cuda:0', dtype=torch.float16) tensor(0.3074, device='cuda:0', dtype=torch.float16)
tensor(4.2109, device='cuda:0', dtype=torch.float16) tensor(0.2812, device='cuda:0', dtype=torch.float16)
tensor(0.2253, device='cuda:0')
old_score: tensor(0.2910, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1538, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.920877933502197
Validation after dual ascent:
out_inf: tensor(16.5312, device='cuda:0', dtype=torch.float16) tensor(0.9033, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.1454, device='cuda:0', dtype=torch.float16)
tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.1530, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1741, device='cuda:0', dtype=torch.float16)
tensor(1.5518, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.9062, device='cuda:0', dtype=torch.float16) tensor(0.4021, device='cuda:0', dtype=torch.float16)
tensor(2.3633, device='cuda:0', dtype=torch.float16) tensor(0.2196, device='cuda:0', dtype=torch.float16)
tensor(2.6133, device='cuda:0', dtype=torch.float16) tensor(0.2268, device='cuda:0', dtype=torch.float16)
tensor(1.9805, device='cuda:0', dtype=torch.float16) tensor(0.2361, device='cuda:0', dtype=torch.float16)
tensor(2.0117, device='cuda:0', dtype=torch.float16) tensor(0.2185, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0143, device='cuda:0')
tensor(0.1961, device='cuda:0')
old_score: tensor(0.2253, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1344, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.74176025390625
Validation after dual ascent:
out_inf: tensor(6.9062, device='cuda:0', dtype=torch.float16) tensor(0.4021, device='cuda:0', dtype=torch.float16)
tensor(1.3018, device='cuda:0', dtype=torch.float16) tensor(0.1271, device='cuda:0', dtype=torch.float16)
tensor(1.3232, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
tensor(1.3232, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.1084, device='cuda:0', dtype=torch.float16)
tensor(1.2051, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
tensor(1.5117, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(1.2480, device='cuda:0', dtype=torch.float16) tensor(0.0290, device='cuda:0', dtype=torch.float16)
tensor(0.1049, device='cuda:0')
old_score: tensor(0.0307, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0163, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.862569332122803
Validation after dual ascent:
out_inf: tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.1084, device='cuda:0', dtype=torch.float16)
tensor(0.5117, device='cuda:0', dtype=torch.float16) tensor(0.0159, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.6211, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
tensor(0.8125, device='cuda:0', dtype=torch.float16) tensor(0.0144, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.5312, device='cuda:0', dtype=torch.float16) tensor(0.4543, device='cuda:0', dtype=torch.float16)
tensor(3.8711, device='cuda:0', dtype=torch.float16) tensor(0.1893, device='cuda:0', dtype=torch.float16)
tensor(3.3164, device='cuda:0', dtype=torch.float16) tensor(0.1969, device='cuda:0', dtype=torch.float16)
tensor(5.3398, device='cuda:0', dtype=torch.float16) tensor(0.2035, device='cuda:0', dtype=torch.float16)
tensor(3.7266, device='cuda:0', dtype=torch.float16) tensor(0.1876, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0186, device='cuda:0')
tensor(0.0176, device='cuda:0')
old_score: tensor(0.1943, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1092, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.979317426681519
Validation after dual ascent:
out_inf: tensor(9.5312, device='cuda:0', dtype=torch.float16) tensor(0.4543, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(2.5605, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(2.5215, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
tensor(2.3770, device='cuda:0', dtype=torch.float16) tensor(0.1013, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.4219, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(2.4336, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(2.5430, device='cuda:0', dtype=torch.float16) tensor(0.1775, device='cuda:0', dtype=torch.float16)
tensor(2.3496, device='cuda:0', dtype=torch.float16) tensor(0.1842, device='cuda:0', dtype=torch.float16)
tensor(2.7461, device='cuda:0', dtype=torch.float16) tensor(0.1716, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0132, device='cuda:0')
tensor(0.0293, device='cuda:0')
old_score: tensor(0.1765, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1026, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.051249742507935
Validation after dual ascent:
out_inf: tensor(7.4219, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0974, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.0762, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(1.3555, device='cuda:0', dtype=torch.float16) tensor(0.0952, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(0.8096, device='cuda:0', dtype=torch.float16) tensor(0.0657, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0694, device='cuda:0', dtype=torch.float16)
tensor(0.8516, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0665, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0069, device='cuda:0')
tensor(0.0112, device='cuda:0')
old_score: tensor(0.0679, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0473, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.737462997436523
Validation after dual ascent:
out_inf: tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0446, device='cuda:0', dtype=torch.float16)
tensor(0.5366, device='cuda:0', dtype=torch.float16) tensor(0.0463, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0545, device='cuda:0', dtype=torch.float16)
tensor(0.5581, device='cuda:0', dtype=torch.float16) tensor(0.0438, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.2656, device='cuda:0', dtype=torch.float16) tensor(0.7979, device='cuda:0', dtype=torch.float16)
tensor(4.0234, device='cuda:0', dtype=torch.float16) tensor(0.2878, device='cuda:0', dtype=torch.float16)
tensor(4.1797, device='cuda:0', dtype=torch.float16) tensor(0.2969, device='cuda:0', dtype=torch.float16)
tensor(4.4375, device='cuda:0', dtype=torch.float16) tensor(0.3098, device='cuda:0', dtype=torch.float16)
tensor(4.0703, device='cuda:0', dtype=torch.float16) tensor(0.2844, device='cuda:0', dtype=torch.float16)
tensor(0.1817, device='cuda:0')
old_score: tensor(0.2947, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1550, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.874952793121338
Validation after dual ascent:
out_inf: tensor(14.2656, device='cuda:0', dtype=torch.float16) tensor(0.7979, device='cuda:0', dtype=torch.float16)
tensor(1.6680, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(1.7021, device='cuda:0', dtype=torch.float16) tensor(0.1539, device='cuda:0', dtype=torch.float16)
tensor(1.7188, device='cuda:0', dtype=torch.float16) tensor(0.1760, device='cuda:0', dtype=torch.float16)
tensor(1.3887, device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.5312, device='cuda:0', dtype=torch.float16) tensor(0.9600, device='cuda:0', dtype=torch.float16)
tensor(4.7734, device='cuda:0', dtype=torch.float16) tensor(0.2947, device='cuda:0', dtype=torch.float16)
tensor(4.7031, device='cuda:0', dtype=torch.float16) tensor(0.3066, device='cuda:0', dtype=torch.float16)
tensor(5.1875, device='cuda:0', dtype=torch.float16) tensor(0.3220, device='cuda:0', dtype=torch.float16)
tensor(4.9141, device='cuda:0', dtype=torch.float16) tensor(0.2922, device='cuda:0', dtype=torch.float16)
tensor(0.1991, device='cuda:0')
old_score: tensor(0.3040, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1556, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.9194016456604
Validation after dual ascent:
out_inf: tensor(18.5312, device='cuda:0', dtype=torch.float16) tensor(0.9600, device='cuda:0', dtype=torch.float16)
tensor(2.1406, device='cuda:0', dtype=torch.float16) tensor(0.1473, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1550, device='cuda:0', dtype=torch.float16)
tensor(2.0820, device='cuda:0', dtype=torch.float16) tensor(0.1765, device='cuda:0', dtype=torch.float16)
tensor(1.5781, device='cuda:0', dtype=torch.float16) tensor(0.1438, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.1133, device='cuda:0', dtype=torch.float16) tensor(0.4536, device='cuda:0', dtype=torch.float16)
tensor(2.5059, device='cuda:0', dtype=torch.float16) tensor(0.2427, device='cuda:0', dtype=torch.float16)
tensor(2.4727, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.2598, device='cuda:0', dtype=torch.float16)
tensor(2.4961, device='cuda:0', dtype=torch.float16) tensor(0.2424, device='cuda:0', dtype=torch.float16)
tensor(0.1476, device='cuda:0')
old_score: tensor(0.2495, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1448, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.940786361694336
Validation after dual ascent:
out_inf: tensor(7.1133, device='cuda:0', dtype=torch.float16) tensor(0.4536, device='cuda:0', dtype=torch.float16)
tensor(1.4668, device='cuda:0', dtype=torch.float16) tensor(0.1371, device='cuda:0', dtype=torch.float16)
tensor(1.4629, device='cuda:0', dtype=torch.float16) tensor(0.1440, device='cuda:0', dtype=torch.float16)
tensor(1.5889, device='cuda:0', dtype=torch.float16) tensor(0.1638, device='cuda:0', dtype=torch.float16)
tensor(1.4287, device='cuda:0', dtype=torch.float16) tensor(0.1338, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.o_proj
Validation after prune:
out_inf: tensor(9.9141, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(2.5293, device='cuda:0', dtype=torch.float16) tensor(0.0440, device='cuda:0', dtype=torch.float16)
tensor(2.7480, device='cuda:0', dtype=torch.float16) tensor(0.0479, device='cuda:0', dtype=torch.float16)
tensor(3.0938, device='cuda:0', dtype=torch.float16) tensor(0.0490, device='cuda:0', dtype=torch.float16)
tensor(2.4121, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.1160, device='cuda:0')
old_score: tensor(0.0460, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0230, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.865668058395386
Validation after dual ascent:
out_inf: tensor(9.9141, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(2.0352, device='cuda:0', dtype=torch.float16) tensor(0.0209, device='cuda:0', dtype=torch.float16)
tensor(0.7500, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.1250, device='cuda:0', dtype=torch.float16) tensor(0.4688, device='cuda:0', dtype=torch.float16)
tensor(4.1836, device='cuda:0', dtype=torch.float16) tensor(0.1995, device='cuda:0', dtype=torch.float16)
tensor(5.3086, device='cuda:0', dtype=torch.float16) tensor(0.2084, device='cuda:0', dtype=torch.float16)
tensor(5.0391, device='cuda:0', dtype=torch.float16) tensor(0.2137, device='cuda:0', dtype=torch.float16)
tensor(4.7852, device='cuda:0', dtype=torch.float16) tensor(0.1976, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0197, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.2048, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1131, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.988441228866577
Validation after dual ascent:
out_inf: tensor(10.1250, device='cuda:0', dtype=torch.float16) tensor(0.4688, device='cuda:0', dtype=torch.float16)
tensor(2.2148, device='cuda:0', dtype=torch.float16) tensor(0.1072, device='cuda:0', dtype=torch.float16)
tensor(2.4629, device='cuda:0', dtype=torch.float16) tensor(0.1125, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(2.5293, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.2148, device='cuda:0', dtype=torch.float16) tensor(0.3687, device='cuda:0', dtype=torch.float16)
tensor(3.4961, device='cuda:0', dtype=torch.float16) tensor(0.1865, device='cuda:0', dtype=torch.float16)
tensor(2.9023, device='cuda:0', dtype=torch.float16) tensor(0.1946, device='cuda:0', dtype=torch.float16)
tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.2000, device='cuda:0', dtype=torch.float16)
tensor(2.8008, device='cuda:0', dtype=torch.float16) tensor(0.1859, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0167, device='cuda:0')
tensor(0.0406, device='cuda:0')
old_score: tensor(0.1918, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1080, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.054808616638184
Validation after dual ascent:
out_inf: tensor(7.2148, device='cuda:0', dtype=torch.float16) tensor(0.3687, device='cuda:0', dtype=torch.float16)
tensor(1.4648, device='cuda:0', dtype=torch.float16) tensor(0.1025, device='cuda:0', dtype=torch.float16)
tensor(1.3477, device='cuda:0', dtype=torch.float16) tensor(0.1074, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1216, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.7988, device='cuda:0', dtype=torch.float16) tensor(0.1888, device='cuda:0', dtype=torch.float16)
tensor(0.8916, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(0.8530, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(0.9712, device='cuda:0', dtype=torch.float16) tensor(0.0781, device='cuda:0', dtype=torch.float16)
Converged at iteration 100
tensor(0.0160, device='cuda:0')
tensor(0.1254, device='cuda:0')
old_score: tensor(0.0795, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0556, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.945148944854736
Validation after dual ascent:
out_inf: tensor(3.7988, device='cuda:0', dtype=torch.float16) tensor(0.1888, device='cuda:0', dtype=torch.float16)
tensor(0.9004, device='cuda:0', dtype=torch.float16) tensor(0.0522, device='cuda:0', dtype=torch.float16)
tensor(0.7676, device='cuda:0', dtype=torch.float16) tensor(0.0549, device='cuda:0', dtype=torch.float16)
tensor(0.7236, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(0.7485, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.9922, device='cuda:0', dtype=torch.float16) tensor(0.7969, device='cuda:0', dtype=torch.float16)
tensor(4.6328, device='cuda:0', dtype=torch.float16) tensor(0.2832, device='cuda:0', dtype=torch.float16)
tensor(3.9961, device='cuda:0', dtype=torch.float16) tensor(0.2961, device='cuda:0', dtype=torch.float16)
tensor(4.4219, device='cuda:0', dtype=torch.float16) tensor(0.3113, device='cuda:0', dtype=torch.float16)
tensor(3.8594, device='cuda:0', dtype=torch.float16) tensor(0.2786, device='cuda:0', dtype=torch.float16)
tensor(0.0241, device='cuda:0')
old_score: tensor(0.2922, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1471, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.90806531906128
Validation after dual ascent:
out_inf: tensor(12.9922, device='cuda:0', dtype=torch.float16) tensor(0.7969, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(1.5527, device='cuda:0', dtype=torch.float16) tensor(0.1465, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.1677, device='cuda:0', dtype=torch.float16)
tensor(1.7344, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.4219, device='cuda:0', dtype=torch.float16) tensor(1.0166, device='cuda:0', dtype=torch.float16)
tensor(4.9922, device='cuda:0', dtype=torch.float16) tensor(0.2920, device='cuda:0', dtype=torch.float16)
tensor(4.7578, device='cuda:0', dtype=torch.float16) tensor(0.3064, device='cuda:0', dtype=torch.float16)
tensor(5.0312, device='cuda:0', dtype=torch.float16) tensor(0.3218, device='cuda:0', dtype=torch.float16)
tensor(4.4297, device='cuda:0', dtype=torch.float16) tensor(0.2866, device='cuda:0', dtype=torch.float16)
tensor(0.0264, device='cuda:0')
old_score: tensor(0.3018, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1483, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.933574914932251
Validation after dual ascent:
out_inf: tensor(18.4219, device='cuda:0', dtype=torch.float16) tensor(1.0166, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1476, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1689, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1366, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.2500, device='cuda:0', dtype=torch.float16) tensor(0.4434, device='cuda:0', dtype=torch.float16)
tensor(3.0312, device='cuda:0', dtype=torch.float16) tensor(0.2429, device='cuda:0', dtype=torch.float16)
tensor(2.3867, device='cuda:0', dtype=torch.float16) tensor(0.2522, device='cuda:0', dtype=torch.float16)
tensor(2.9902, device='cuda:0', dtype=torch.float16) tensor(0.2620, device='cuda:0', dtype=torch.float16)
tensor(2.7695, device='cuda:0', dtype=torch.float16) tensor(0.2413, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0108, device='cuda:0')
tensor(0.0825, device='cuda:0')
old_score: tensor(0.2495, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1436, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1921911239624023
Validation after dual ascent:
out_inf: tensor(6.2500, device='cuda:0', dtype=torch.float16) tensor(0.4434, device='cuda:0', dtype=torch.float16)
tensor(1.3369, device='cuda:0', dtype=torch.float16) tensor(0.1356, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1432, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(1.3213, device='cuda:0', dtype=torch.float16) tensor(0.1324, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.o_proj
Validation after prune:
out_inf: tensor(18.1250, device='cuda:0', dtype=torch.float16) tensor(0.2019, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(3.7344, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(4.9297, device='cuda:0', dtype=torch.float16) tensor(0.0572, device='cuda:0', dtype=torch.float16)
tensor(0.1092, device='cuda:0')
old_score: tensor(0.0633, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0342, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.881356954574585
Validation after dual ascent:
out_inf: tensor(18.1250, device='cuda:0', dtype=torch.float16) tensor(0.2019, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.0338, device='cuda:0', dtype=torch.float16)
tensor(1.7578, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.8750, device='cuda:0', dtype=torch.float16) tensor(0.4880, device='cuda:0', dtype=torch.float16)
tensor(4.5312, device='cuda:0', dtype=torch.float16) tensor(0.2063, device='cuda:0', dtype=torch.float16)
tensor(4.0391, device='cuda:0', dtype=torch.float16) tensor(0.2162, device='cuda:0', dtype=torch.float16)
tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.2195, device='cuda:0', dtype=torch.float16)
tensor(3.9102, device='cuda:0', dtype=torch.float16) tensor(0.2048, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0156, device='cuda:0')
tensor(0.0161, device='cuda:0')
old_score: tensor(0.2117, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1151, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.927116632461548
Validation after dual ascent:
out_inf: tensor(10.8750, device='cuda:0', dtype=torch.float16) tensor(0.4880, device='cuda:0', dtype=torch.float16)
tensor(2.1484, device='cuda:0', dtype=torch.float16) tensor(0.1086, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(2.6367, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
tensor(2.3262, device='cuda:0', dtype=torch.float16) tensor(0.1076, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.up_proj
Validation after prune:
out_inf: tensor(8.9141, device='cuda:0', dtype=torch.float16) tensor(0.4167, device='cuda:0', dtype=torch.float16)
tensor(5.8203, device='cuda:0', dtype=torch.float16) tensor(0.1976, device='cuda:0', dtype=torch.float16)
tensor(6.6406, device='cuda:0', dtype=torch.float16) tensor(0.2065, device='cuda:0', dtype=torch.float16)
tensor(5.9531, device='cuda:0', dtype=torch.float16) tensor(0.2126, device='cuda:0', dtype=torch.float16)
tensor(5.6680, device='cuda:0', dtype=torch.float16) tensor(0.1965, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0192, device='cuda:0')
tensor(0.0187, device='cuda:0')
old_score: tensor(0.2034, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1108, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 10.001043558120728
Validation after dual ascent:
out_inf: tensor(8.9141, device='cuda:0', dtype=torch.float16) tensor(0.4167, device='cuda:0', dtype=torch.float16)
tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(3.1250, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(4.3516, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(3.3086, device='cuda:0', dtype=torch.float16) tensor(0.1034, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.down_proj
Validation after prune:
out_inf: tensor(19.1250, device='cuda:0', dtype=torch.float16) tensor(0.2389, device='cuda:0', dtype=torch.float16)
tensor(0.9844, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0084, device='cuda:0')
tensor(0.0184, device='cuda:0')
old_score: tensor(0.0923, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0630, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 16.752650499343872
Validation after dual ascent:
out_inf: tensor(19.1250, device='cuda:0', dtype=torch.float16) tensor(0.2389, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.8994, device='cuda:0', dtype=torch.float16) tensor(0.0624, device='cuda:0', dtype=torch.float16)
tensor(0.8604, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.8213, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.3906, device='cuda:0', dtype=torch.float16) tensor(0.8213, device='cuda:0', dtype=torch.float16)
tensor(4.7070, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.3118, device='cuda:0', dtype=torch.float16)
tensor(4.7266, device='cuda:0', dtype=torch.float16) tensor(0.3254, device='cuda:0', dtype=torch.float16)
tensor(4.6406, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(0.2649, device='cuda:0')
old_score: tensor(0.3086, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1505, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.907778024673462
Validation after dual ascent:
out_inf: tensor(14.3906, device='cuda:0', dtype=torch.float16) tensor(0.8213, device='cuda:0', dtype=torch.float16)
tensor(2.2969, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1500, device='cuda:0', dtype=torch.float16)
tensor(1.8828, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(1.4463, device='cuda:0', dtype=torch.float16) tensor(0.1400, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1094, device='cuda:0', dtype=torch.float16) tensor(0.9673, device='cuda:0', dtype=torch.float16)
tensor(5.7656, device='cuda:0', dtype=torch.float16) tensor(0.3123, device='cuda:0', dtype=torch.float16)
tensor(5.0938, device='cuda:0', dtype=torch.float16) tensor(0.3284, device='cuda:0', dtype=torch.float16)
tensor(5.5781, device='cuda:0', dtype=torch.float16) tensor(0.3413, device='cuda:0', dtype=torch.float16)
tensor(4.9844, device='cuda:0', dtype=torch.float16) tensor(0.3142, device='cuda:0', dtype=torch.float16)
tensor(0.2867, device='cuda:0')
old_score: tensor(0.3240, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1531, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.93644666671753
Validation after dual ascent:
out_inf: tensor(17.1094, device='cuda:0', dtype=torch.float16) tensor(0.9673, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1442, device='cuda:0', dtype=torch.float16)
tensor(1.7031, device='cuda:0', dtype=torch.float16) tensor(0.1521, device='cuda:0', dtype=torch.float16)
tensor(1.9375, device='cuda:0', dtype=torch.float16) tensor(0.1732, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.v_proj
Validation after prune:
out_inf: tensor(8.7500, device='cuda:0', dtype=torch.float16) tensor(0.4841, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.2590, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.2708, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.2778, device='cuda:0', dtype=torch.float16)
tensor(2.0918, device='cuda:0', dtype=torch.float16) tensor(0.2593, device='cuda:0', dtype=torch.float16)
tensor(0.2451, device='cuda:0')
old_score: tensor(0.2666, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1479, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.950133323669434
Validation after dual ascent:
out_inf: tensor(8.7500, device='cuda:0', dtype=torch.float16) tensor(0.4841, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1396, device='cuda:0', dtype=torch.float16)
tensor(1.3809, device='cuda:0', dtype=torch.float16) tensor(0.1477, device='cuda:0', dtype=torch.float16)
tensor(1.4385, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
tensor(1.3457, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.o_proj
Validation after prune:
out_inf: tensor(20.3750, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
tensor(2.8789, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(3.5859, device='cuda:0', dtype=torch.float16) tensor(0.0408, device='cuda:0', dtype=torch.float16)
tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.0489, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.1305, device='cuda:0')
old_score: tensor(0.0450, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0224, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.868889093399048
Validation after dual ascent:
out_inf: tensor(20.3750, device='cuda:0', dtype=torch.float16) tensor(0.1665, device='cuda:0', dtype=torch.float16)
tensor(0.8594, device='cuda:0', dtype=torch.float16) tensor(0.0226, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.0279, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.gate_proj
Validation after prune:
out_inf: tensor(35.9688, device='cuda:0', dtype=torch.float16) tensor(0.5342, device='cuda:0', dtype=torch.float16)
tensor(27.5938, device='cuda:0', dtype=torch.float16) tensor(0.2219, device='cuda:0', dtype=torch.float16)
tensor(27.5625, device='cuda:0', dtype=torch.float16) tensor(0.2313, device='cuda:0', dtype=torch.float16)
tensor(26.6250, device='cuda:0', dtype=torch.float16) tensor(0.2380, device='cuda:0', dtype=torch.float16)
tensor(26.7812, device='cuda:0', dtype=torch.float16) tensor(0.2220, device='cuda:0', dtype=torch.float16)
tensor(0.0257, device='cuda:0')
old_score: tensor(0.2284, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1156, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.979777336120605
Validation after dual ascent:
out_inf: tensor(35.9688, device='cuda:0', dtype=torch.float16) tensor(0.5342, device='cuda:0', dtype=torch.float16)
tensor(7.6875, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(10.2812, device='cuda:0', dtype=torch.float16) tensor(0.1147, device='cuda:0', dtype=torch.float16)
tensor(10.1406, device='cuda:0', dtype=torch.float16) tensor(0.1306, device='cuda:0', dtype=torch.float16)
tensor(7.8125, device='cuda:0', dtype=torch.float16) tensor(0.1076, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.up_proj
Validation after prune:
out_inf: tensor(36.6562, device='cuda:0', dtype=torch.float16) tensor(0.5015, device='cuda:0', dtype=torch.float16)
tensor(25.4688, device='cuda:0', dtype=torch.float16) tensor(0.2153, device='cuda:0', dtype=torch.float16)
tensor(25.2344, device='cuda:0', dtype=torch.float16) tensor(0.2256, device='cuda:0', dtype=torch.float16)
tensor(25.6250, device='cuda:0', dtype=torch.float16) tensor(0.2340, device='cuda:0', dtype=torch.float16)
tensor(21.0469, device='cuda:0', dtype=torch.float16) tensor(0.2150, device='cuda:0', dtype=torch.float16)
tensor(0.0251, device='cuda:0')
old_score: tensor(0.2224, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1107, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.992459774017334
Validation after dual ascent:
out_inf: tensor(36.6562, device='cuda:0', dtype=torch.float16) tensor(0.5015, device='cuda:0', dtype=torch.float16)
tensor(8.7188, device='cuda:0', dtype=torch.float16) tensor(0.1046, device='cuda:0', dtype=torch.float16)
tensor(10.2500, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(10.1406, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(8.2812, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.down_proj
Validation after prune:
out_inf: tensor(1588., device='cuda:0', dtype=torch.float16) tensor(0.4314, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1056, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.5078, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(1.6094, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(0.0243, device='cuda:0')
old_score: tensor(0.1119, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0721, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.35791063308716
Validation after dual ascent:
out_inf: tensor(1588., device='cuda:0', dtype=torch.float16) tensor(0.4314, device='cuda:0', dtype=torch.float16)
tensor(0.9751, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(1.0518, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.1484, device='cuda:0', dtype=torch.float16) tensor(0.8633, device='cuda:0', dtype=torch.float16)
tensor(5.3164, device='cuda:0', dtype=torch.float16) tensor(0.2981, device='cuda:0', dtype=torch.float16)
tensor(6.0039, device='cuda:0', dtype=torch.float16) tensor(0.3101, device='cuda:0', dtype=torch.float16)
tensor(5.8164, device='cuda:0', dtype=torch.float16) tensor(0.3296, device='cuda:0', dtype=torch.float16)
tensor(4.8828, device='cuda:0', dtype=torch.float16) tensor(0.3003, device='cuda:0', dtype=torch.float16)
tensor(0.0271, device='cuda:0')
old_score: tensor(0.3096, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1262, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.862729549407959
Validation after dual ascent:
out_inf: tensor(13.1484, device='cuda:0', dtype=torch.float16) tensor(0.8633, device='cuda:0', dtype=torch.float16)
tensor(1.7812, device='cuda:0', dtype=torch.float16) tensor(0.1189, device='cuda:0', dtype=torch.float16)
tensor(3.5703, device='cuda:0', dtype=torch.float16) tensor(0.1254, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1447, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.1159, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.7812, device='cuda:0', dtype=torch.float16) tensor(1.0889, device='cuda:0', dtype=torch.float16)
tensor(6.5469, device='cuda:0', dtype=torch.float16) tensor(0.3242, device='cuda:0', dtype=torch.float16)
tensor(6.9922, device='cuda:0', dtype=torch.float16) tensor(0.3359, device='cuda:0', dtype=torch.float16)
tensor(7.1875, device='cuda:0', dtype=torch.float16) tensor(0.3540, device='cuda:0', dtype=torch.float16)
tensor(5.7969, device='cuda:0', dtype=torch.float16) tensor(0.3271, device='cuda:0', dtype=torch.float16)
tensor(0.0346, device='cuda:0')
old_score: tensor(0.3352, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1299, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.915423154830933
Validation after dual ascent:
out_inf: tensor(18.7812, device='cuda:0', dtype=torch.float16) tensor(1.0889, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1223, device='cuda:0', dtype=torch.float16)
tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1292, device='cuda:0', dtype=torch.float16)
tensor(2.4219, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.9570, device='cuda:0', dtype=torch.float16) tensor(0.3879, device='cuda:0', dtype=torch.float16)
tensor(2.6445, device='cuda:0', dtype=torch.float16) tensor(0.2104, device='cuda:0', dtype=torch.float16)
tensor(4.2344, device='cuda:0', dtype=torch.float16) tensor(0.2178, device='cuda:0', dtype=torch.float16)
tensor(2.4570, device='cuda:0', dtype=torch.float16) tensor(0.2227, device='cuda:0', dtype=torch.float16)
tensor(2.5117, device='cuda:0', dtype=torch.float16) tensor(0.2107, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0100, device='cuda:0')
tensor(0.0315, device='cuda:0')
old_score: tensor(0.2153, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1115, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1881494522094727
Validation after dual ascent:
out_inf: tensor(7.9570, device='cuda:0', dtype=torch.float16) tensor(0.3879, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(2.7812, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.6367, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(1.1289, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.o_proj
Validation after prune:
out_inf: tensor(258.7500, device='cuda:0', dtype=torch.float16) tensor(0.3191, device='cuda:0', dtype=torch.float16)
tensor(4.5156, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(10.9375, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
tensor(10.0938, device='cuda:0', dtype=torch.float16) tensor(0.1354, device='cuda:0', dtype=torch.float16)
tensor(3.6406, device='cuda:0', dtype=torch.float16) tensor(0.1295, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0158, device='cuda:0')
tensor(0.0380, device='cuda:0')
old_score: tensor(0.1350, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0584, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 2.44399094581604
Validation after dual ascent:
out_inf: tensor(258.7500, device='cuda:0', dtype=torch.float16) tensor(0.3191, device='cuda:0', dtype=torch.float16)
tensor(1.3652, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
tensor(1.3750, device='cuda:0', dtype=torch.float16) tensor(0.0563, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.gate_proj
Validation after prune:
out_inf: tensor(30.0781, device='cuda:0', dtype=torch.float16) tensor(0.6016, device='cuda:0', dtype=torch.float16)
tensor(12.6406, device='cuda:0', dtype=torch.float16) tensor(0.2427, device='cuda:0', dtype=torch.float16)
tensor(14.0469, device='cuda:0', dtype=torch.float16) tensor(0.2566, device='cuda:0', dtype=torch.float16)
tensor(13.6250, device='cuda:0', dtype=torch.float16) tensor(0.2646, device='cuda:0', dtype=torch.float16)
tensor(14.0312, device='cuda:0', dtype=torch.float16) tensor(0.2499, device='cuda:0', dtype=torch.float16)
tensor(0.0407, device='cuda:0')
old_score: tensor(0.2534, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1073, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.956480503082275
Validation after dual ascent:
out_inf: tensor(30.0781, device='cuda:0', dtype=torch.float16) tensor(0.6016, device='cuda:0', dtype=torch.float16)
tensor(2.4199, device='cuda:0', dtype=torch.float16) tensor(0.1009, device='cuda:0', dtype=torch.float16)
tensor(3.5742, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(2.6367, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(3.0527, device='cuda:0', dtype=torch.float16) tensor(0.0990, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.up_proj
Validation after prune:
out_inf: tensor(33.8125, device='cuda:0', dtype=torch.float16) tensor(0.6318, device='cuda:0', dtype=torch.float16)
tensor(17.2812, device='cuda:0', dtype=torch.float16) tensor(0.2400, device='cuda:0', dtype=torch.float16)
tensor(21.7031, device='cuda:0', dtype=torch.float16) tensor(0.2546, device='cuda:0', dtype=torch.float16)
tensor(18.4219, device='cuda:0', dtype=torch.float16) tensor(0.2646, device='cuda:0', dtype=torch.float16)
tensor(18.2188, device='cuda:0', dtype=torch.float16) tensor(0.2435, device='cuda:0', dtype=torch.float16)
tensor(0.0377, device='cuda:0')
old_score: tensor(0.2507, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1019, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.99706220626831
Validation after dual ascent:
out_inf: tensor(33.8125, device='cuda:0', dtype=torch.float16) tensor(0.6318, device='cuda:0', dtype=torch.float16)
tensor(4.6953, device='cuda:0', dtype=torch.float16) tensor(0.0959, device='cuda:0', dtype=torch.float16)
tensor(2.9219, device='cuda:0', dtype=torch.float16) tensor(0.1015, device='cuda:0', dtype=torch.float16)
tensor(3.9766, device='cuda:0', dtype=torch.float16) tensor(0.1164, device='cuda:0', dtype=torch.float16)
tensor(6.4531, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.down_proj
Validation after prune:
out_inf: tensor(153.6250, device='cuda:0', dtype=torch.float16) tensor(1.6084, device='cuda:0', dtype=torch.float16)
tensor(5., device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(5.9688, device='cuda:0', dtype=torch.float16) tensor(0.1710, device='cuda:0', dtype=torch.float16)
tensor(6.2500, device='cuda:0', dtype=torch.float16) tensor(0.1808, device='cuda:0', dtype=torch.float16)
tensor(5.0625, device='cuda:0', dtype=torch.float16) tensor(0.1691, device='cuda:0', dtype=torch.float16)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.06it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.09it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.90it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25': 0, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.799840
layer 1 sparsity 0.799840
layer 2 sparsity 0.799840
layer 3 sparsity 0.799840
layer 4 sparsity 0.799840
layer 5 sparsity 0.799840
layer 6 sparsity 0.799840
layer 7 sparsity 0.799840
layer 8 sparsity 0.799840
layer 9 sparsity 0.799840
layer 10 sparsity 0.799840
layer 11 sparsity 0.799840
layer 12 sparsity 0.799840
layer 13 sparsity 0.799840
layer 14 sparsity 0.799840
layer 15 sparsity 0.799840
layer 16 sparsity 0.799840
layer 17 sparsity 0.799840
layer 18 sparsity 0.799840
layer 19 sparsity 0.799840
layer 20 sparsity 0.799840
layer 21 sparsity 0.799840
layer 22 sparsity 0.799840
layer 23 sparsity 0.799840
layer 24 sparsity 0.799840
layer 25 sparsity 0.799840
layer 26 sparsity 0.799840
layer 27 sparsity 0.799840
layer 28 sparsity 0.799840
layer 29 sparsity 0.799840
layer 30 sparsity 0.799840
layer 31 sparsity 0.799840
sparsity sanity check 0.7998
******************************
evaluating on wikitext2
nsamples 83
sample 0
sample 50
wikitext perplexity 87.20243072509766
wanda_dual_3	0.7998	87.2024	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.8, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='wanda_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
2025-04-24 04:21:04.593838: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-24 04:21:04.796509: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-24 04:21:04.801942: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 04:21:04.801965: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2025-04-24 04:21:08.434788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 04:21:08.435298: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2025-04-24 04:21:08.435315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
torch 2.3.1+cu121
transformers 4.47.1
accelerate 0.29.1
# of gpus:  2
loading llm model /h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.27it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.00it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.87it/s]
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
model.embed_tokens.weight torch.Size([32000, 4096])
model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.0.input_layernorm.weight torch.Size([4096])
model.layers.0.post_attention_layernorm.weight torch.Size([4096])
model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.1.input_layernorm.weight torch.Size([4096])
model.layers.1.post_attention_layernorm.weight torch.Size([4096])
model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.2.input_layernorm.weight torch.Size([4096])
model.layers.2.post_attention_layernorm.weight torch.Size([4096])
model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.3.input_layernorm.weight torch.Size([4096])
model.layers.3.post_attention_layernorm.weight torch.Size([4096])
model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.4.input_layernorm.weight torch.Size([4096])
model.layers.4.post_attention_layernorm.weight torch.Size([4096])
model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.5.input_layernorm.weight torch.Size([4096])
model.layers.5.post_attention_layernorm.weight torch.Size([4096])
model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.6.input_layernorm.weight torch.Size([4096])
model.layers.6.post_attention_layernorm.weight torch.Size([4096])
model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.7.input_layernorm.weight torch.Size([4096])
model.layers.7.post_attention_layernorm.weight torch.Size([4096])
model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.8.input_layernorm.weight torch.Size([4096])
model.layers.8.post_attention_layernorm.weight torch.Size([4096])
model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.9.input_layernorm.weight torch.Size([4096])
model.layers.9.post_attention_layernorm.weight torch.Size([4096])
model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.10.input_layernorm.weight torch.Size([4096])
model.layers.10.post_attention_layernorm.weight torch.Size([4096])
model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.11.input_layernorm.weight torch.Size([4096])
model.layers.11.post_attention_layernorm.weight torch.Size([4096])
model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.12.input_layernorm.weight torch.Size([4096])
model.layers.12.post_attention_layernorm.weight torch.Size([4096])
model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.13.input_layernorm.weight torch.Size([4096])
model.layers.13.post_attention_layernorm.weight torch.Size([4096])
model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.14.input_layernorm.weight torch.Size([4096])
model.layers.14.post_attention_layernorm.weight torch.Size([4096])
model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.15.input_layernorm.weight torch.Size([4096])
model.layers.15.post_attention_layernorm.weight torch.Size([4096])
model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.16.input_layernorm.weight torch.Size([4096])
model.layers.16.post_attention_layernorm.weight torch.Size([4096])
model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.17.input_layernorm.weight torch.Size([4096])
model.layers.17.post_attention_layernorm.weight torch.Size([4096])
model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.18.input_layernorm.weight torch.Size([4096])
model.layers.18.post_attention_layernorm.weight torch.Size([4096])
model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.19.input_layernorm.weight torch.Size([4096])
model.layers.19.post_attention_layernorm.weight torch.Size([4096])
model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.20.input_layernorm.weight torch.Size([4096])
model.layers.20.post_attention_layernorm.weight torch.Size([4096])
model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.21.input_layernorm.weight torch.Size([4096])
model.layers.21.post_attention_layernorm.weight torch.Size([4096])
model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.22.input_layernorm.weight torch.Size([4096])
model.layers.22.post_attention_layernorm.weight torch.Size([4096])
model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.23.input_layernorm.weight torch.Size([4096])
model.layers.23.post_attention_layernorm.weight torch.Size([4096])
model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.24.input_layernorm.weight torch.Size([4096])
model.layers.24.post_attention_layernorm.weight torch.Size([4096])
model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.25.input_layernorm.weight torch.Size([4096])
model.layers.25.post_attention_layernorm.weight torch.Size([4096])
model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.26.input_layernorm.weight torch.Size([4096])
model.layers.26.post_attention_layernorm.weight torch.Size([4096])
model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.27.input_layernorm.weight torch.Size([4096])
model.layers.27.post_attention_layernorm.weight torch.Size([4096])
model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.28.input_layernorm.weight torch.Size([4096])
model.layers.28.post_attention_layernorm.weight torch.Size([4096])
model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.29.input_layernorm.weight torch.Size([4096])
model.layers.29.post_attention_layernorm.weight torch.Size([4096])
model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.30.input_layernorm.weight torch.Size([4096])
model.layers.30.post_attention_layernorm.weight torch.Size([4096])
model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])
model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])
model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])
model.layers.31.input_layernorm.weight torch.Size([4096])
model.layers.31.post_attention_layernorm.weight torch.Size([4096])
model.norm.weight torch.Size([4096])
lm_head.weight torch.Size([32000, 4096])
use device  cpu
loading calibdation data
  0%|          | 0/256 [00:00<?, ?it/s]  0%|          | 1/256 [00:00<03:25,  1.24it/s]  1%|          | 2/256 [00:01<03:16,  1.29it/s]  2%|▏         | 4/256 [00:01<01:39,  2.55it/s]  2%|▏         | 5/256 [00:02<01:48,  2.32it/s]  2%|▏         | 6/256 [00:02<01:24,  2.96it/s]  3%|▎         | 7/256 [00:03<01:57,  2.11it/s]  3%|▎         | 8/256 [00:03<01:30,  2.73it/s]  4%|▎         | 9/256 [00:03<01:10,  3.49it/s]  4%|▍         | 11/256 [00:03<00:47,  5.14it/s]  5%|▍         | 12/256 [00:03<00:43,  5.60it/s]  5%|▌         | 13/256 [00:04<01:30,  2.69it/s]  5%|▌         | 14/256 [00:05<01:28,  2.74it/s]  6%|▌         | 15/256 [00:05<01:14,  3.22it/s]  6%|▋         | 16/256 [00:05<01:05,  3.65it/s]  7%|▋         | 18/256 [00:06<01:08,  3.46it/s]  8%|▊         | 20/256 [00:06<00:51,  4.57it/s]  8%|▊         | 21/256 [00:06<00:45,  5.18it/s]  9%|▊         | 22/256 [00:06<00:48,  4.83it/s]  9%|▉         | 24/256 [00:06<00:42,  5.50it/s] 10%|▉         | 25/256 [00:07<00:40,  5.77it/s] 10%|█         | 26/256 [00:07<00:53,  4.32it/s] 11%|█         | 28/256 [00:07<00:44,  5.17it/s] 11%|█▏        | 29/256 [00:08<00:46,  4.90it/s] 12%|█▏        | 31/256 [00:08<00:38,  5.82it/s] 12%|█▎        | 32/256 [00:08<00:46,  4.77it/s] 13%|█▎        | 33/256 [00:09<00:58,  3.81it/s] 13%|█▎        | 34/256 [00:09<01:02,  3.56it/s] 14%|█▎        | 35/256 [00:09<01:09,  3.17it/s] 14%|█▍        | 36/256 [00:10<01:20,  2.73it/s] 14%|█▍        | 37/256 [00:10<01:14,  2.94it/s] 15%|█▍        | 38/256 [00:10<01:09,  3.16it/s] 16%|█▌        | 40/256 [00:11<01:04,  3.34it/s] 16%|█▋        | 42/256 [00:11<00:45,  4.68it/s] 17%|█▋        | 43/256 [00:11<00:40,  5.28it/s] 17%|█▋        | 44/256 [00:11<00:39,  5.38it/s] 18%|█▊        | 46/256 [00:12<00:33,  6.22it/s] 18%|█▊        | 47/256 [00:12<00:34,  6.05it/s] 19%|█▉        | 48/256 [00:12<00:37,  5.53it/s] 19%|█▉        | 49/256 [00:12<00:34,  5.96it/s] 20%|█▉        | 50/256 [00:13<00:49,  4.18it/s] 21%|██        | 53/256 [00:13<00:48,  4.21it/s] 21%|██        | 54/256 [00:13<00:47,  4.25it/s] 21%|██▏       | 55/256 [00:14<00:41,  4.86it/s] 22%|██▏       | 56/256 [00:14<00:48,  4.12it/s] 22%|██▏       | 57/256 [00:14<00:44,  4.43it/s] 23%|██▎       | 58/256 [00:14<00:49,  4.01it/s] 23%|██▎       | 59/256 [00:15<00:43,  4.50it/s] 23%|██▎       | 60/256 [00:15<00:46,  4.21it/s] 24%|██▍       | 61/256 [00:15<00:54,  3.59it/s] 24%|██▍       | 62/256 [00:16<00:58,  3.29it/s] 25%|██▍       | 63/256 [00:16<00:51,  3.74it/s] 25%|██▌       | 64/256 [00:16<00:42,  4.52it/s] 25%|██▌       | 65/256 [00:17<01:08,  2.79it/s] 26%|██▌       | 67/256 [00:17<00:43,  4.32it/s] 27%|██▋       | 68/256 [00:17<00:42,  4.38it/s] 27%|██▋       | 69/256 [00:17<00:43,  4.33it/s] 28%|██▊       | 71/256 [00:17<00:33,  5.53it/s] 29%|██▊       | 73/256 [00:18<00:26,  6.81it/s] 29%|██▉       | 74/256 [00:18<00:26,  6.85it/s] 29%|██▉       | 75/256 [00:18<00:31,  5.73it/s] 30%|██▉       | 76/256 [00:18<00:43,  4.11it/s] 30%|███       | 78/256 [00:19<00:30,  5.93it/s] 31%|███       | 79/256 [00:19<00:37,  4.72it/s] 31%|███▏      | 80/256 [00:19<00:47,  3.68it/s] 32%|███▏      | 81/256 [00:20<00:53,  3.28it/s] 32%|███▏      | 82/256 [00:20<00:44,  3.94it/s] 32%|███▏      | 83/256 [00:20<00:53,  3.22it/s] 33%|███▎      | 84/256 [00:21<00:50,  3.37it/s] 33%|███▎      | 85/256 [00:21<00:46,  3.66it/s] 34%|███▎      | 86/256 [00:21<00:42,  4.00it/s] 34%|███▍      | 87/256 [00:22<01:00,  2.80it/s] 34%|███▍      | 88/256 [00:22<01:02,  2.69it/s] 35%|███▍      | 89/256 [00:22<00:57,  2.91it/s] 35%|███▌      | 90/256 [00:23<00:58,  2.86it/s] 36%|███▌      | 91/256 [00:23<00:56,  2.92it/s] 36%|███▌      | 92/256 [00:23<00:47,  3.43it/s] 36%|███▋      | 93/256 [00:23<00:41,  3.88it/s] 37%|███▋      | 94/256 [00:24<00:50,  3.24it/s] 37%|███▋      | 95/256 [00:24<01:03,  2.54it/s] 38%|███▊      | 96/256 [00:25<00:50,  3.17it/s] 38%|███▊      | 97/256 [00:25<00:54,  2.94it/s] 38%|███▊      | 98/256 [00:25<00:45,  3.45it/s] 39%|███▊      | 99/256 [00:25<00:44,  3.55it/s] 39%|███▉      | 100/256 [00:26<00:42,  3.71it/s] 39%|███▉      | 101/256 [00:27<01:14,  2.08it/s] 40%|███▉      | 102/256 [00:27<01:04,  2.40it/s] 41%|████      | 104/256 [00:27<00:41,  3.69it/s] 41%|████▏     | 106/256 [00:27<00:33,  4.46it/s] 42%|████▏     | 107/256 [00:28<00:33,  4.47it/s] 42%|████▏     | 108/256 [00:28<00:47,  3.11it/s] 43%|████▎     | 111/256 [00:28<00:30,  4.83it/s] 44%|████▍     | 112/256 [00:29<00:31,  4.53it/s] 44%|████▍     | 113/256 [00:29<00:31,  4.51it/s] 45%|████▍     | 114/256 [00:29<00:28,  4.93it/s] 45%|████▍     | 115/256 [00:29<00:27,  5.17it/s] 45%|████▌     | 116/256 [00:30<00:43,  3.22it/s] 46%|████▌     | 117/256 [00:30<00:37,  3.75it/s] 46%|████▌     | 118/256 [00:30<00:36,  3.74it/s] 47%|████▋     | 120/256 [00:31<00:27,  4.97it/s] 47%|████▋     | 121/256 [00:31<00:26,  5.10it/s] 48%|████▊     | 122/256 [00:31<00:41,  3.21it/s] 48%|████▊     | 123/256 [00:32<00:43,  3.03it/s] 48%|████▊     | 124/256 [00:32<00:55,  2.38it/s] 49%|████▉     | 125/256 [00:34<01:24,  1.55it/s] 49%|████▉     | 126/256 [00:34<01:10,  1.84it/s] 50%|████▉     | 127/256 [00:35<01:15,  1.70it/s] 50%|█████     | 129/256 [00:35<00:45,  2.78it/s] 51%|█████     | 130/256 [00:35<00:41,  3.03it/s] 51%|█████     | 131/256 [00:35<00:38,  3.21it/s] 52%|█████▏    | 132/256 [00:36<00:37,  3.33it/s] 52%|█████▏    | 133/256 [00:36<00:45,  2.70it/s] 52%|█████▏    | 134/256 [00:37<00:44,  2.72it/s] 53%|█████▎    | 135/256 [00:37<00:35,  3.36it/s] 53%|█████▎    | 136/256 [00:37<00:35,  3.34it/s] 54%|█████▎    | 137/256 [00:37<00:29,  3.97it/s] 54%|█████▍    | 138/256 [00:37<00:26,  4.47it/s] 54%|█████▍    | 139/256 [00:37<00:24,  4.86it/s] 55%|█████▍    | 140/256 [00:38<00:22,  5.25it/s] 55%|█████▌    | 141/256 [00:38<00:18,  6.08it/s] 55%|█████▌    | 142/256 [00:38<00:16,  6.82it/s] 56%|█████▌    | 143/256 [00:38<00:16,  7.03it/s] 57%|█████▋    | 145/256 [00:39<00:37,  3.00it/s] 57%|█████▋    | 146/256 [00:39<00:40,  2.71it/s] 57%|█████▋    | 147/256 [00:40<00:36,  2.97it/s] 58%|█████▊    | 148/256 [00:40<00:37,  2.91it/s] 59%|█████▊    | 150/256 [00:40<00:29,  3.63it/s] 59%|█████▉    | 151/256 [00:41<00:24,  4.21it/s] 59%|█████▉    | 152/256 [00:41<00:28,  3.69it/s] 60%|█████▉    | 153/256 [00:41<00:25,  4.10it/s] 60%|██████    | 154/256 [00:42<00:29,  3.48it/s] 61%|██████    | 155/256 [00:42<00:26,  3.80it/s] 61%|██████    | 156/256 [00:42<00:22,  4.50it/s] 61%|██████▏   | 157/256 [00:42<00:27,  3.62it/s] 62%|██████▏   | 158/256 [00:42<00:23,  4.14it/s] 62%|██████▏   | 159/256 [00:43<00:42,  2.31it/s] 62%|██████▎   | 160/256 [00:43<00:32,  2.96it/s] 63%|██████▎   | 162/256 [00:44<00:36,  2.56it/s] 64%|██████▎   | 163/256 [00:45<00:32,  2.86it/s] 64%|██████▍   | 164/256 [00:45<00:27,  3.39it/s] 65%|██████▍   | 166/256 [00:45<00:22,  3.96it/s] 65%|██████▌   | 167/256 [00:45<00:25,  3.54it/s] 66%|██████▌   | 168/256 [00:46<00:28,  3.12it/s] 66%|██████▌   | 169/256 [00:46<00:31,  2.76it/s] 66%|██████▋   | 170/256 [00:47<00:31,  2.74it/s] 67%|██████▋   | 172/256 [00:47<00:22,  3.81it/s] 68%|██████▊   | 173/256 [00:47<00:21,  3.95it/s] 68%|██████▊   | 174/256 [00:48<00:29,  2.79it/s] 68%|██████▊   | 175/256 [00:49<00:41,  1.97it/s] 69%|██████▉   | 176/256 [00:49<00:35,  2.24it/s] 69%|██████▉   | 177/256 [00:49<00:29,  2.70it/s] 70%|██████▉   | 179/256 [00:50<00:19,  3.92it/s] 70%|███████   | 180/256 [00:51<00:37,  2.05it/s] 71%|███████   | 181/256 [00:51<00:29,  2.55it/s] 71%|███████   | 182/256 [00:52<00:37,  1.98it/s] 72%|███████▏  | 184/256 [00:53<00:34,  2.07it/s] 73%|███████▎  | 186/256 [00:53<00:23,  2.97it/s] 73%|███████▎  | 187/256 [00:53<00:27,  2.55it/s] 73%|███████▎  | 188/256 [00:54<00:23,  2.91it/s] 74%|███████▍  | 189/256 [00:54<00:23,  2.89it/s] 74%|███████▍  | 190/256 [00:54<00:21,  3.14it/s] 75%|███████▍  | 191/256 [00:54<00:18,  3.45it/s] 75%|███████▌  | 192/256 [00:55<00:21,  2.92it/s] 75%|███████▌  | 193/256 [00:55<00:20,  3.05it/s] 77%|███████▋  | 196/256 [00:56<00:13,  4.58it/s] 77%|███████▋  | 197/256 [00:56<00:15,  3.89it/s] 78%|███████▊  | 199/256 [00:56<00:11,  4.90it/s] 79%|███████▊  | 201/256 [00:56<00:09,  5.57it/s] 79%|███████▉  | 202/256 [00:57<00:11,  4.61it/s] 80%|███████▉  | 204/256 [00:57<00:08,  5.86it/s] 80%|████████  | 206/256 [00:57<00:06,  7.24it/s] 81%|████████  | 207/256 [00:57<00:06,  7.57it/s] 81%|████████▏ | 208/256 [00:57<00:07,  6.54it/s] 82%|████████▏ | 210/256 [00:58<00:05,  8.68it/s] 83%|████████▎ | 212/256 [00:58<00:05,  8.43it/s] 83%|████████▎ | 213/256 [00:58<00:05,  7.50it/s] 84%|████████▎ | 214/256 [00:58<00:07,  5.75it/s] 84%|████████▍ | 215/256 [00:59<00:08,  4.58it/s] 84%|████████▍ | 216/256 [00:59<00:08,  4.47it/s] 85%|████████▌ | 218/256 [00:59<00:07,  5.24it/s] 86%|████████▌ | 219/256 [01:00<00:14,  2.57it/s] 86%|████████▌ | 220/256 [01:00<00:11,  3.01it/s] 86%|████████▋ | 221/256 [01:01<00:11,  2.95it/s] 87%|████████▋ | 222/256 [01:01<00:11,  2.90it/s] 87%|████████▋ | 223/256 [01:02<00:11,  2.76it/s] 88%|████████▊ | 224/256 [01:03<00:24,  1.32it/s] 88%|████████▊ | 225/256 [01:04<00:22,  1.37it/s] 88%|████████▊ | 226/256 [01:04<00:16,  1.77it/s] 89%|████████▊ | 227/256 [01:04<00:13,  2.12it/s] 89%|████████▉ | 228/256 [01:05<00:12,  2.26it/s] 89%|████████▉ | 229/256 [01:06<00:18,  1.45it/s] 90%|████████▉ | 230/256 [01:06<00:13,  1.91it/s] 90%|█████████ | 231/256 [01:07<00:12,  1.96it/s] 91%|█████████ | 232/256 [01:07<00:10,  2.24it/s] 91%|█████████ | 233/256 [01:07<00:08,  2.72it/s] 92%|█████████▏| 235/256 [01:07<00:05,  3.78it/s] 92%|█████████▏| 236/256 [01:08<00:05,  3.67it/s] 93%|█████████▎| 237/256 [01:08<00:04,  4.00it/s] 93%|█████████▎| 238/256 [01:08<00:03,  4.62it/s] 93%|█████████▎| 239/256 [01:08<00:03,  4.43it/s] 94%|█████████▍| 241/256 [01:08<00:02,  5.69it/s] 95%|█████████▍| 242/256 [01:09<00:04,  2.87it/s] 95%|█████████▌| 244/256 [01:09<00:02,  4.39it/s] 96%|█████████▌| 245/256 [01:10<00:02,  4.34it/s] 96%|█████████▌| 246/256 [01:10<00:02,  4.82it/s] 97%|█████████▋| 248/256 [01:10<00:01,  6.44it/s] 97%|█████████▋| 249/256 [01:11<00:01,  3.94it/s] 98%|█████████▊| 251/256 [01:11<00:00,  5.49it/s] 98%|█████████▊| 252/256 [01:11<00:01,  3.50it/s] 99%|█████████▉| 253/256 [01:12<00:01,  2.92it/s]100%|█████████▉| 255/256 [01:13<00:00,  3.08it/s]100%|██████████| 256/256 [01:13<00:00,  3.16it/s]100%|██████████| 256/256 [01:13<00:00,  3.49it/s]
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
dataset loading complete
pruning layer 0 name self_attn.q_proj
Validation after prune:
out_inf: tensor(7.8555, device='cuda:0', dtype=torch.float16) tensor(0.6099, device='cuda:0', dtype=torch.float16)
tensor(0.3477, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0073, device='cuda:0', dtype=torch.float16)
tensor(0.3477, device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.4336, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.k_proj
Validation after prune:
out_inf: tensor(6.1211, device='cuda:0', dtype=torch.float16) tensor(0.4609, device='cuda:0', dtype=torch.float16)
tensor(0.3359, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.3672, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.3809, device='cuda:0', dtype=torch.float16) tensor(0.0116, device='cuda:0', dtype=torch.float16)
tensor(0.3672, device='cuda:0', dtype=torch.float16) tensor(0.0113, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.v_proj
Validation after prune:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.2156, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.1981, device='cuda:0', dtype=torch.float16) tensor(0.0053, device='cuda:0', dtype=torch.float16)
tensor(0.1981, device='cuda:0', dtype=torch.float16) tensor(0.0052, device='cuda:0', dtype=torch.float16)
tensor(0.1981, device='cuda:0', dtype=torch.float16) tensor(0.0051, device='cuda:0', dtype=torch.float16)
tensor(0.0673, device='cuda:0')
old_score: tensor(0.0052, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0031, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.687162399291992
Validation after dual ascent:
out_inf: tensor(0.7524, device='cuda:0', dtype=torch.float16) tensor(0.0114, device='cuda:0', dtype=torch.float16)
tensor(0.1543, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.1543, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
tensor(0.1543, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.1150, device='cuda:0', dtype=torch.float16) tensor(0.0030, device='cuda:0', dtype=torch.float16)
pruning layer 0 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0276, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
tensor(0.0189, device='cuda:0', dtype=torch.float16) tensor(0.0006, device='cuda:0', dtype=torch.float16)
tensor(0.0205, device='cuda:0', dtype=torch.float16) tensor(0.0005, device='cuda:0', dtype=torch.float16)
tensor(0.0305, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0180, device='cuda:0')
tensor(0.0666, device='cuda:0')
old_score: tensor(0.0005, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0003, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1243441104888916
Validation after dual ascent:
out_inf: tensor(0.9517, device='cuda:0', dtype=torch.float16) tensor(0.0039, device='cuda:0', dtype=torch.float16)
tensor(0.0269, device='cuda:0', dtype=torch.float16) tensor(0.0002, device='cuda:0', dtype=torch.float16)
tensor(0.0156, device='cuda:0', dtype=torch.float16) tensor(0.0004, device='cuda:0', dtype=torch.float16)
tensor(0.0182, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
tensor(0.0282, device='cuda:0', dtype=torch.float16) tensor(0.0003, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(1.3965, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.0278, device='cuda:0', dtype=torch.float16)
tensor(1.5059, device='cuda:0', dtype=torch.float16) tensor(0.0308, device='cuda:0', dtype=torch.float16)
tensor(1.4746, device='cuda:0', dtype=torch.float16) tensor(0.0268, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0191, device='cuda:0')
tensor(0.0202, device='cuda:0')
old_score: tensor(0.0280, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0188, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 32.830127477645874
Validation after dual ascent:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(1.2930, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
tensor(1.4189, device='cuda:0', dtype=torch.float16) tensor(0.0203, device='cuda:0', dtype=torch.float16)
tensor(1.2363, device='cuda:0', dtype=torch.float16) tensor(0.0183, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.up_proj
Validation after prune:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0256, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0265, device='cuda:0', dtype=torch.float16)
tensor(0.7202, device='cuda:0', dtype=torch.float16) tensor(0.0293, device='cuda:0', dtype=torch.float16)
tensor(0.6738, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0186, device='cuda:0')
tensor(0.0199, device='cuda:0')
old_score: tensor(0.0267, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0184, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 32.99217939376831
Validation after dual ascent:
out_inf: tensor(1.6016, device='cuda:0', dtype=torch.float16) tensor(0.0439, device='cuda:0', dtype=torch.float16)
tensor(0.5503, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
tensor(0.5508, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
tensor(0.5957, device='cuda:0', dtype=torch.float16) tensor(0.0199, device='cuda:0', dtype=torch.float16)
tensor(0.5186, device='cuda:0', dtype=torch.float16) tensor(0.0179, device='cuda:0', dtype=torch.float16)
pruning layer 0 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.2227, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.2266, device='cuda:0', dtype=torch.float16) tensor(0.0033, device='cuda:0', dtype=torch.float16)
tensor(0.1992, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.1549, device='cuda:0')
old_score: tensor(0.0035, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0026, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.07098340988159
Validation after dual ascent:
out_inf: tensor(1.7217, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
tensor(0.1475, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.0635, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
tensor(0.0752, device='cuda:0', dtype=torch.float16) tensor(0.0031, device='cuda:0', dtype=torch.float16)
tensor(0.1670, device='cuda:0', dtype=torch.float16) tensor(0.0025, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.q_proj
Validation after prune:
out_inf: tensor(9.4219, device='cuda:0', dtype=torch.float16) tensor(0.8154, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(1.8047, device='cuda:0', dtype=torch.float16) tensor(0.0709, device='cuda:0', dtype=torch.float16)
tensor(1.7422, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.k_proj
Validation after prune:
out_inf: tensor(8.1953, device='cuda:0', dtype=torch.float16) tensor(0.8384, device='cuda:0', dtype=torch.float16)
tensor(2.5918, device='cuda:0', dtype=torch.float16) tensor(0.0730, device='cuda:0', dtype=torch.float16)
tensor(2.5293, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(2.5410, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(2.5488, device='cuda:0', dtype=torch.float16) tensor(0.0734, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.v_proj
Validation after prune:
out_inf: tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0166, device='cuda:0', dtype=torch.float16)
tensor(0.6621, device='cuda:0', dtype=torch.float16) tensor(0.0172, device='cuda:0', dtype=torch.float16)
tensor(0.8008, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.7925, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.0240, device='cuda:0')
old_score: tensor(0.0168, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0114, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.747394323348999
Validation after dual ascent:
out_inf: tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.0321, device='cuda:0', dtype=torch.float16)
tensor(0.6670, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
tensor(0.6929, device='cuda:0', dtype=torch.float16) tensor(0.0112, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0121, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0111, device='cuda:0', dtype=torch.float16)
pruning layer 1 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.4607, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1143, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.2285, device='cuda:0', dtype=torch.float16) tensor(0.0036, device='cuda:0', dtype=torch.float16)
tensor(0.1523, device='cuda:0', dtype=torch.float16) tensor(0.0035, device='cuda:0', dtype=torch.float16)
tensor(0.1289, device='cuda:0', dtype=torch.float16) tensor(0.0034, device='cuda:0', dtype=torch.float16)
tensor(0.0320, device='cuda:0')
old_score: tensor(0.0035, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0027, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.78008770942688
Validation after dual ascent:
out_inf: tensor(0.4607, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.0924, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.0938, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.0836, device='cuda:0', dtype=torch.float16) tensor(0.0027, device='cuda:0', dtype=torch.float16)
tensor(0.1094, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.gate_proj
Validation after prune:
out_inf: tensor(35.9062, device='cuda:0', dtype=torch.float16) tensor(0.0937, device='cuda:0', dtype=torch.float16)
tensor(22.6875, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(22.1562, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(22.6562, device='cuda:0', dtype=torch.float16) tensor(0.0646, device='cuda:0', dtype=torch.float16)
tensor(22.3125, device='cuda:0', dtype=torch.float16) tensor(0.0556, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0159, device='cuda:0')
tensor(0.0232, device='cuda:0')
old_score: tensor(0.0580, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.446024894714355
Validation after dual ascent:
out_inf: tensor(35.9062, device='cuda:0', dtype=torch.float16) tensor(0.0937, device='cuda:0', dtype=torch.float16)
tensor(11.7188, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(11.4688, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(11.1250, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(12.2812, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.up_proj
Validation after prune:
out_inf: tensor(32.9375, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(17.4531, device='cuda:0', dtype=torch.float16) tensor(0.0475, device='cuda:0', dtype=torch.float16)
tensor(17.3750, device='cuda:0', dtype=torch.float16) tensor(0.0480, device='cuda:0', dtype=torch.float16)
tensor(16.8281, device='cuda:0', dtype=torch.float16) tensor(0.0520, device='cuda:0', dtype=torch.float16)
tensor(17.4531, device='cuda:0', dtype=torch.float16) tensor(0.0473, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0130, device='cuda:0')
tensor(0.0212, device='cuda:0')
old_score: tensor(0.0487, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0377, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 21.50334930419922
Validation after dual ascent:
out_inf: tensor(32.9375, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(7.6562, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(7.8594, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(6.6406, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(8.2188, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
pruning layer 1 name mlp.down_proj
Validation after prune:
out_inf: tensor(1921., device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(0.3438, device='cuda:0', dtype=torch.float16) tensor(0.0083, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.5625, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.4625, device='cuda:0')
old_score: tensor(0.0085, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0080, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.92604875564575
Validation after dual ascent:
out_inf: tensor(1921., device='cuda:0', dtype=torch.float16) tensor(0.0154, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.0078, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.0074, device='cuda:0', dtype=torch.float16)
tensor(0.5000, device='cuda:0', dtype=torch.float16) tensor(0.0092, device='cuda:0', dtype=torch.float16)
tensor(1., device='cuda:0', dtype=torch.float16) tensor(0.0077, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.5859, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(4.1719, device='cuda:0', dtype=torch.float16) tensor(0.1796, device='cuda:0', dtype=torch.float16)
tensor(4.4688, device='cuda:0', dtype=torch.float16) tensor(0.1848, device='cuda:0', dtype=torch.float16)
tensor(4.0703, device='cuda:0', dtype=torch.float16) tensor(0.1897, device='cuda:0', dtype=torch.float16)
tensor(4.3828, device='cuda:0', dtype=torch.float16) tensor(0.1812, device='cuda:0', dtype=torch.float16)
tensor(0.0864, device='cuda:0')
old_score: tensor(0.1837, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0911, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.823737382888794
Validation after dual ascent:
out_inf: tensor(14.5859, device='cuda:0', dtype=torch.float16) tensor(1.0137, device='cuda:0', dtype=torch.float16)
tensor(2.6094, device='cuda:0', dtype=torch.float16) tensor(0.0888, device='cuda:0', dtype=torch.float16)
tensor(1.5693, device='cuda:0', dtype=torch.float16) tensor(0.0900, device='cuda:0', dtype=torch.float16)
tensor(1.7754, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.0893, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.3203, device='cuda:0', dtype=torch.float16) tensor(1.2148, device='cuda:0', dtype=torch.float16)
tensor(2.7754, device='cuda:0', dtype=torch.float16) tensor(0.1840, device='cuda:0', dtype=torch.float16)
tensor(3.1797, device='cuda:0', dtype=torch.float16) tensor(0.1886, device='cuda:0', dtype=torch.float16)
tensor(3.0469, device='cuda:0', dtype=torch.float16) tensor(0.1881, device='cuda:0', dtype=torch.float16)
tensor(2.8809, device='cuda:0', dtype=torch.float16) tensor(0.1859, device='cuda:0', dtype=torch.float16)
tensor(0.0970, device='cuda:0')
old_score: tensor(0.1866, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0922, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.864015340805054
Validation after dual ascent:
out_inf: tensor(15.3203, device='cuda:0', dtype=torch.float16) tensor(1.2148, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.0897, device='cuda:0', dtype=torch.float16)
tensor(2.6758, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(2.3652, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.5840, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0685, device='cuda:0', dtype=torch.float16)
tensor(1.4170, device='cuda:0', dtype=torch.float16) tensor(0.0701, device='cuda:0', dtype=torch.float16)
tensor(1.0859, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(1.4082, device='cuda:0', dtype=torch.float16) tensor(0.0687, device='cuda:0', dtype=torch.float16)
tensor(0.0244, device='cuda:0')
old_score: tensor(0.0691, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0487, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.827072858810425
Validation after dual ascent:
out_inf: tensor(2.5840, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(0.7339, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(0.8057, device='cuda:0', dtype=torch.float16) tensor(0.0481, device='cuda:0', dtype=torch.float16)
tensor(0.6309, device='cuda:0', dtype=torch.float16) tensor(0.0512, device='cuda:0', dtype=torch.float16)
tensor(0.9121, device='cuda:0', dtype=torch.float16) tensor(0.0477, device='cuda:0', dtype=torch.float16)
pruning layer 2 name self_attn.o_proj
Validation after prune:
out_inf: tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.2214, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.2434, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.1799, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.2356, device='cuda:0', dtype=torch.float16) tensor(0.0032, device='cuda:0', dtype=torch.float16)
tensor(0.0771, device='cuda:0')
old_score: tensor(0.0031, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0022, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.864013910293579
Validation after dual ascent:
out_inf: tensor(1.2402, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
tensor(0.1501, device='cuda:0', dtype=torch.float16) tensor(0.0022, device='cuda:0', dtype=torch.float16)
tensor(0.2068, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
tensor(0.1819, device='cuda:0', dtype=torch.float16) tensor(0.0019, device='cuda:0', dtype=torch.float16)
tensor(0.2888, device='cuda:0', dtype=torch.float16) tensor(0.0023, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.gate_proj
Validation after prune:
out_inf: tensor(2.2559, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(2.5195, device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(2.4727, device='cuda:0', dtype=torch.float16) tensor(0.0660, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0184, device='cuda:0')
tensor(0.0347, device='cuda:0')
old_score: tensor(0.0671, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0521, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.809631824493408
Validation after dual ascent:
out_inf: tensor(2.2559, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(0.8950, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.0506, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0557, device='cuda:0', dtype=torch.float16)
tensor(0.9092, device='cuda:0', dtype=torch.float16) tensor(0.0511, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
tensor(1.1631, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0604, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
tensor(1.1699, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0130, device='cuda:0')
tensor(0.0259, device='cuda:0')
old_score: tensor(0.0612, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0479, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.81597113609314
Validation after dual ascent:
out_inf: tensor(2.2656, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.0470, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0466, device='cuda:0', dtype=torch.float16)
tensor(0.8115, device='cuda:0', dtype=torch.float16) tensor(0.0510, device='cuda:0', dtype=torch.float16)
tensor(0.9023, device='cuda:0', dtype=torch.float16) tensor(0.0469, device='cuda:0', dtype=torch.float16)
pruning layer 2 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.1719, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.1448, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1865, device='cuda:0', dtype=torch.float16) tensor(0.0079, device='cuda:0', dtype=torch.float16)
tensor(0.1664, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.1719, device='cuda:0', dtype=torch.float16) tensor(0.0081, device='cuda:0', dtype=torch.float16)
tensor(0.1653, device='cuda:0')
old_score: tensor(0.0083, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0071, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.45817375183105
Validation after dual ascent:
out_inf: tensor(4.1719, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.1045, device='cuda:0', dtype=torch.float16) tensor(0.0068, device='cuda:0', dtype=torch.float16)
tensor(0.1350, device='cuda:0', dtype=torch.float16) tensor(0.0067, device='cuda:0', dtype=torch.float16)
tensor(0.1043, device='cuda:0', dtype=torch.float16) tensor(0.0080, device='cuda:0', dtype=torch.float16)
tensor(0.1152, device='cuda:0', dtype=torch.float16) tensor(0.0069, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.1406, device='cuda:0', dtype=torch.float16) tensor(0.8975, device='cuda:0', dtype=torch.float16)
tensor(4.1406, device='cuda:0', dtype=torch.float16) tensor(0.2290, device='cuda:0', dtype=torch.float16)
tensor(3.5664, device='cuda:0', dtype=torch.float16) tensor(0.2308, device='cuda:0', dtype=torch.float16)
tensor(4.2305, device='cuda:0', dtype=torch.float16) tensor(0.2428, device='cuda:0', dtype=torch.float16)
tensor(3.8477, device='cuda:0', dtype=torch.float16) tensor(0.2306, device='cuda:0', dtype=torch.float16)
tensor(0.1047, device='cuda:0')
old_score: tensor(0.2333, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1448, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.808048009872437
Validation after dual ascent:
out_inf: tensor(19.1406, device='cuda:0', dtype=torch.float16) tensor(0.8975, device='cuda:0', dtype=torch.float16)
tensor(2.7012, device='cuda:0', dtype=torch.float16) tensor(0.1407, device='cuda:0', dtype=torch.float16)
tensor(2.5527, device='cuda:0', dtype=torch.float16) tensor(0.1421, device='cuda:0', dtype=torch.float16)
tensor(2.5938, device='cuda:0', dtype=torch.float16) tensor(0.1539, device='cuda:0', dtype=torch.float16)
tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.8906, device='cuda:0', dtype=torch.float16) tensor(1.0703, device='cuda:0', dtype=torch.float16)
tensor(3.5957, device='cuda:0', dtype=torch.float16) tensor(0.2345, device='cuda:0', dtype=torch.float16)
tensor(3.7656, device='cuda:0', dtype=torch.float16) tensor(0.2361, device='cuda:0', dtype=torch.float16)
tensor(3.6191, device='cuda:0', dtype=torch.float16) tensor(0.2449, device='cuda:0', dtype=torch.float16)
tensor(4.2188, device='cuda:0', dtype=torch.float16) tensor(0.2356, device='cuda:0', dtype=torch.float16)
tensor(0.1042, device='cuda:0')
old_score: tensor(0.2378, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1479, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.846197128295898
Validation after dual ascent:
out_inf: tensor(16.8906, device='cuda:0', dtype=torch.float16) tensor(1.0703, device='cuda:0', dtype=torch.float16)
tensor(2.4863, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
tensor(2.3730, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
tensor(2.3926, device='cuda:0', dtype=torch.float16) tensor(0.1572, device='cuda:0', dtype=torch.float16)
tensor(2.5918, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.5859, device='cuda:0', dtype=torch.float16) tensor(0.1732, device='cuda:0', dtype=torch.float16)
tensor(1.3379, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.1067, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1096, device='cuda:0', dtype=torch.float16)
tensor(1.3828, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0171, device='cuda:0')
tensor(0.1055, device='cuda:0')
old_score: tensor(0.1070, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0773, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.155792713165283
Validation after dual ascent:
out_inf: tensor(2.5859, device='cuda:0', dtype=torch.float16) tensor(0.1732, device='cuda:0', dtype=torch.float16)
tensor(0.8711, device='cuda:0', dtype=torch.float16) tensor(0.0753, device='cuda:0', dtype=torch.float16)
tensor(0.7432, device='cuda:0', dtype=torch.float16) tensor(0.0762, device='cuda:0', dtype=torch.float16)
tensor(0.7861, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(0.7861, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
pruning layer 3 name self_attn.o_proj
Validation after prune:
out_inf: tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.3206, device='cuda:0', dtype=torch.float16) tensor(0.0040, device='cuda:0', dtype=torch.float16)
tensor(0.2712, device='cuda:0', dtype=torch.float16) tensor(0.0041, device='cuda:0', dtype=torch.float16)
tensor(0.3062, device='cuda:0', dtype=torch.float16) tensor(0.0038, device='cuda:0', dtype=torch.float16)
tensor(0.5278, device='cuda:0', dtype=torch.float16) tensor(0.0042, device='cuda:0', dtype=torch.float16)
tensor(0.0782, device='cuda:0')
old_score: tensor(0.0040, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0027, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.80118465423584
Validation after dual ascent:
out_inf: tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0097, device='cuda:0', dtype=torch.float16)
tensor(0.1433, device='cuda:0', dtype=torch.float16) tensor(0.0026, device='cuda:0', dtype=torch.float16)
tensor(0.1765, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
tensor(0.1636, device='cuda:0', dtype=torch.float16) tensor(0.0024, device='cuda:0', dtype=torch.float16)
tensor(0.2910, device='cuda:0', dtype=torch.float16) tensor(0.0028, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.gate_proj
Validation after prune:
out_inf: tensor(3.4121, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(3.4512, device='cuda:0', dtype=torch.float16) tensor(0.0854, device='cuda:0', dtype=torch.float16)
tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.0852, device='cuda:0', dtype=torch.float16)
tensor(4.5625, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(3.0918, device='cuda:0', dtype=torch.float16) tensor(0.0861, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0181, device='cuda:0')
tensor(0.0449, device='cuda:0')
old_score: tensor(0.0863, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0623, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.090433120727539
Validation after dual ascent:
out_inf: tensor(3.4121, device='cuda:0', dtype=torch.float16) tensor(0.1185, device='cuda:0', dtype=torch.float16)
tensor(1.4980, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(1.8164, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.0662, device='cuda:0', dtype=torch.float16)
tensor(1.4697, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.3789, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(1.5400, device='cuda:0', dtype=torch.float16) tensor(0.0750, device='cuda:0', dtype=torch.float16)
tensor(1.8789, device='cuda:0', dtype=torch.float16) tensor(0.0754, device='cuda:0', dtype=torch.float16)
tensor(1.5576, device='cuda:0', dtype=torch.float16) tensor(0.0782, device='cuda:0', dtype=torch.float16)
tensor(1.6895, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0144, device='cuda:0')
tensor(0.0375, device='cuda:0')
old_score: tensor(0.0760, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0572, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0874412059783936
Validation after dual ascent:
out_inf: tensor(2.3789, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
tensor(1.1045, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(0.7871, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.7617, device='cuda:0', dtype=torch.float16) tensor(0.0606, device='cuda:0', dtype=torch.float16)
tensor(0.9033, device='cuda:0', dtype=torch.float16) tensor(0.0562, device='cuda:0', dtype=torch.float16)
pruning layer 3 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.9092, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.2469, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.2133, device='cuda:0', dtype=torch.float16) tensor(0.0123, device='cuda:0', dtype=torch.float16)
tensor(0.2534, device='cuda:0', dtype=torch.float16) tensor(0.0126, device='cuda:0', dtype=torch.float16)
tensor(0.2419, device='cuda:0', dtype=torch.float16) tensor(0.0125, device='cuda:0', dtype=torch.float16)
tensor(0.1555, device='cuda:0')
old_score: tensor(0.0125, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0102, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.09062314033508
Validation after dual ascent:
out_inf: tensor(0.9092, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
tensor(0.1525, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.1333, device='cuda:0', dtype=torch.float16) tensor(0.0098, device='cuda:0', dtype=torch.float16)
tensor(0.1663, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.1465, device='cuda:0', dtype=torch.float16) tensor(0.0101, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.7109, device='cuda:0', dtype=torch.float16) tensor(0.8989, device='cuda:0', dtype=torch.float16)
tensor(3.5430, device='cuda:0', dtype=torch.float16) tensor(0.2544, device='cuda:0', dtype=torch.float16)
tensor(3.4102, device='cuda:0', dtype=torch.float16) tensor(0.2544, device='cuda:0', dtype=torch.float16)
tensor(3.2578, device='cuda:0', dtype=torch.float16) tensor(0.2622, device='cuda:0', dtype=torch.float16)
tensor(3.3145, device='cuda:0', dtype=torch.float16) tensor(0.2571, device='cuda:0', dtype=torch.float16)
tensor(0.1023, device='cuda:0')
old_score: tensor(0.2571, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1417, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.826946020126343
Validation after dual ascent:
out_inf: tensor(15.7109, device='cuda:0', dtype=torch.float16) tensor(0.8989, device='cuda:0', dtype=torch.float16)
tensor(2.0293, device='cuda:0', dtype=torch.float16) tensor(0.1373, device='cuda:0', dtype=torch.float16)
tensor(1.8379, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
tensor(1.9609, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
tensor(1.7900, device='cuda:0', dtype=torch.float16) tensor(0.1396, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.4844, device='cuda:0', dtype=torch.float16) tensor(1.1475, device='cuda:0', dtype=torch.float16)
tensor(3.8945, device='cuda:0', dtype=torch.float16) tensor(0.2568, device='cuda:0', dtype=torch.float16)
tensor(3.4297, device='cuda:0', dtype=torch.float16) tensor(0.2556, device='cuda:0', dtype=torch.float16)
tensor(3.2578, device='cuda:0', dtype=torch.float16) tensor(0.2593, device='cuda:0', dtype=torch.float16)
tensor(3.7793, device='cuda:0', dtype=torch.float16) tensor(0.2588, device='cuda:0', dtype=torch.float16)
tensor(0.1076, device='cuda:0')
old_score: tensor(0.2578, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.856858730316162
Validation after dual ascent:
out_inf: tensor(20.4844, device='cuda:0', dtype=torch.float16) tensor(1.1475, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.1376, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1420, device='cuda:0', dtype=torch.float16)
tensor(1.8877, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
tensor(1.9150, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.1948, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1188, device='cuda:0', dtype=torch.float16)
tensor(2.1055, device='cuda:0', dtype=torch.float16) tensor(0.1196, device='cuda:0', dtype=torch.float16)
tensor(3.0059, device='cuda:0', dtype=torch.float16) tensor(0.1209, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1197, device='cuda:0', dtype=torch.float16)
tensor(0.0467, device='cuda:0')
old_score: tensor(0.1197, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0758, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.800065040588379
Validation after dual ascent:
out_inf: tensor(3.6641, device='cuda:0', dtype=torch.float16) tensor(0.1948, device='cuda:0', dtype=torch.float16)
tensor(0.7002, device='cuda:0', dtype=torch.float16) tensor(0.0737, device='cuda:0', dtype=torch.float16)
tensor(0.7729, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(0.7051, device='cuda:0', dtype=torch.float16) tensor(0.0790, device='cuda:0', dtype=torch.float16)
tensor(0.7295, device='cuda:0', dtype=torch.float16) tensor(0.0746, device='cuda:0', dtype=torch.float16)
pruning layer 4 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.7852, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.6270, device='cuda:0', dtype=torch.float16) tensor(0.0109, device='cuda:0', dtype=torch.float16)
tensor(0.5894, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.5215, device='cuda:0', dtype=torch.float16) tensor(0.0100, device='cuda:0', dtype=torch.float16)
tensor(0.6201, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.0770, device='cuda:0')
old_score: tensor(0.0106, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0070, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.829866647720337
Validation after dual ascent:
out_inf: tensor(4.7852, device='cuda:0', dtype=torch.float16) tensor(0.0221, device='cuda:0', dtype=torch.float16)
tensor(0.2698, device='cuda:0', dtype=torch.float16) tensor(0.0070, device='cuda:0', dtype=torch.float16)
tensor(0.2876, device='cuda:0', dtype=torch.float16) tensor(0.0075, device='cuda:0', dtype=torch.float16)
tensor(0.2344, device='cuda:0', dtype=torch.float16) tensor(0.0063, device='cuda:0', dtype=torch.float16)
tensor(0.2837, device='cuda:0', dtype=torch.float16) tensor(0.0071, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.0625, device='cuda:0', dtype=torch.float16) tensor(0.1749, device='cuda:0', dtype=torch.float16)
tensor(3.1523, device='cuda:0', dtype=torch.float16) tensor(0.1143, device='cuda:0', dtype=torch.float16)
tensor(3.7656, device='cuda:0', dtype=torch.float16) tensor(0.1143, device='cuda:0', dtype=torch.float16)
tensor(3.3379, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(3.4141, device='cuda:0', dtype=torch.float16) tensor(0.1153, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0105, device='cuda:0')
tensor(0.0526, device='cuda:0')
old_score: tensor(0.1150, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0725, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.092919588088989
Validation after dual ascent:
out_inf: tensor(5.0625, device='cuda:0', dtype=torch.float16) tensor(0.1749, device='cuda:0', dtype=torch.float16)
tensor(1.3721, device='cuda:0', dtype=torch.float16) tensor(0.0712, device='cuda:0', dtype=torch.float16)
tensor(1.4121, device='cuda:0', dtype=torch.float16) tensor(0.0731, device='cuda:0', dtype=torch.float16)
tensor(1.3086, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.7695, device='cuda:0', dtype=torch.float16) tensor(0.1389, device='cuda:0', dtype=torch.float16)
tensor(2.6602, device='cuda:0', dtype=torch.float16) tensor(0.0959, device='cuda:0', dtype=torch.float16)
tensor(2.0488, device='cuda:0', dtype=torch.float16) tensor(0.0962, device='cuda:0', dtype=torch.float16)
tensor(2.0273, device='cuda:0', dtype=torch.float16) tensor(0.0972, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0093, device='cuda:0')
tensor(0.0463, device='cuda:0')
old_score: tensor(0.0965, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0643, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.0894317626953125
Validation after dual ascent:
out_inf: tensor(3.7695, device='cuda:0', dtype=torch.float16) tensor(0.1389, device='cuda:0', dtype=torch.float16)
tensor(1.0498, device='cuda:0', dtype=torch.float16) tensor(0.0632, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.8262, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.0639, device='cuda:0', dtype=torch.float16)
pruning layer 4 name mlp.down_proj
Validation after prune:
out_inf: tensor(8.7891, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.9668, device='cuda:0', dtype=torch.float16) tensor(0.0214, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0215, device='cuda:0', dtype=torch.float16)
tensor(0.7549, device='cuda:0', dtype=torch.float16) tensor(0.0210, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(0.1583, device='cuda:0')
old_score: tensor(0.0214, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0162, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.72954893112183
Validation after dual ascent:
out_inf: tensor(8.7891, device='cuda:0', dtype=torch.float16) tensor(0.0435, device='cuda:0', dtype=torch.float16)
tensor(0.5952, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.3071, device='cuda:0', dtype=torch.float16) tensor(0.0165, device='cuda:0', dtype=torch.float16)
tensor(0.4312, device='cuda:0', dtype=torch.float16) tensor(0.0161, device='cuda:0', dtype=torch.float16)
tensor(0.2490, device='cuda:0', dtype=torch.float16) tensor(0.0164, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.9141, device='cuda:0', dtype=torch.float16) tensor(0.8813, device='cuda:0', dtype=torch.float16)
tensor(4.4766, device='cuda:0', dtype=torch.float16) tensor(0.2805, device='cuda:0', dtype=torch.float16)
tensor(3.8887, device='cuda:0', dtype=torch.float16) tensor(0.2832, device='cuda:0', dtype=torch.float16)
tensor(4.5938, device='cuda:0', dtype=torch.float16) tensor(0.2849, device='cuda:0', dtype=torch.float16)
tensor(3.7812, device='cuda:0', dtype=torch.float16) tensor(0.2815, device='cuda:0', dtype=torch.float16)
tensor(0.0788, device='cuda:0')
old_score: tensor(0.2825, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1270, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.830715894699097
Validation after dual ascent:
out_inf: tensor(15.9141, device='cuda:0', dtype=torch.float16) tensor(0.8813, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(1.9023, device='cuda:0', dtype=torch.float16) tensor(0.1305, device='cuda:0', dtype=torch.float16)
tensor(1.6514, device='cuda:0', dtype=torch.float16) tensor(0.1277, device='cuda:0', dtype=torch.float16)
tensor(1.6572, device='cuda:0', dtype=torch.float16) tensor(0.1255, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.7656, device='cuda:0', dtype=torch.float16) tensor(1.1406, device='cuda:0', dtype=torch.float16)
tensor(5.5703, device='cuda:0', dtype=torch.float16) tensor(0.3020, device='cuda:0', dtype=torch.float16)
tensor(5.1641, device='cuda:0', dtype=torch.float16) tensor(0.3040, device='cuda:0', dtype=torch.float16)
tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.3047, device='cuda:0', dtype=torch.float16)
tensor(5.1562, device='cuda:0', dtype=torch.float16) tensor(0.3027, device='cuda:0', dtype=torch.float16)
tensor(0.0946, device='cuda:0')
old_score: tensor(0.3032, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1301, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.854366302490234
Validation after dual ascent:
out_inf: tensor(18.7656, device='cuda:0', dtype=torch.float16) tensor(1.1406, device='cuda:0', dtype=torch.float16)
tensor(1.7061, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
tensor(1.7559, device='cuda:0', dtype=torch.float16) tensor(0.1339, device='cuda:0', dtype=torch.float16)
tensor(1.6797, device='cuda:0', dtype=torch.float16) tensor(0.1310, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.v_proj
Validation after prune:
out_inf: tensor(2.5898, device='cuda:0', dtype=torch.float16) tensor(0.2108, device='cuda:0', dtype=torch.float16)
tensor(1.5684, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
tensor(1.4395, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.1304, device='cuda:0', dtype=torch.float16)
tensor(1.4590, device='cuda:0', dtype=torch.float16) tensor(0.1311, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0137, device='cuda:0')
tensor(0.0671, device='cuda:0')
old_score: tensor(0.1309, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0681, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1606576442718506
Validation after dual ascent:
out_inf: tensor(2.5898, device='cuda:0', dtype=torch.float16) tensor(0.2108, device='cuda:0', dtype=torch.float16)
tensor(0.6372, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(0.6855, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(0.6602, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0674, device='cuda:0', dtype=torch.float16)
pruning layer 5 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.3633, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0176, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.9180, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
tensor(0.0862, device='cuda:0')
old_score: tensor(0.0180, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0090, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.792740821838379
Validation after dual ascent:
out_inf: tensor(5.3633, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
tensor(0.3242, device='cuda:0', dtype=torch.float16) tensor(0.0090, device='cuda:0', dtype=torch.float16)
tensor(0.5771, device='cuda:0', dtype=torch.float16) tensor(0.0096, device='cuda:0', dtype=torch.float16)
tensor(0.3535, device='cuda:0', dtype=torch.float16) tensor(0.0087, device='cuda:0', dtype=torch.float16)
tensor(0.2983, device='cuda:0', dtype=torch.float16) tensor(0.0089, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.2656, device='cuda:0', dtype=torch.float16) tensor(0.2106, device='cuda:0', dtype=torch.float16)
tensor(3.1484, device='cuda:0', dtype=torch.float16) tensor(0.1239, device='cuda:0', dtype=torch.float16)
tensor(3.3379, device='cuda:0', dtype=torch.float16) tensor(0.1222, device='cuda:0', dtype=torch.float16)
tensor(2.8594, device='cuda:0', dtype=torch.float16) tensor(0.1209, device='cuda:0', dtype=torch.float16)
tensor(3.0039, device='cuda:0', dtype=torch.float16) tensor(0.1238, device='cuda:0', dtype=torch.float16)
tensor(0.0234, device='cuda:0')
old_score: tensor(0.1227, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0620, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.7823224067688
Validation after dual ascent:
out_inf: tensor(5.2656, device='cuda:0', dtype=torch.float16) tensor(0.2106, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(1.3340, device='cuda:0', dtype=torch.float16) tensor(0.0637, device='cuda:0', dtype=torch.float16)
tensor(1.1777, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
tensor(1.2793, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.3984, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(2.5312, device='cuda:0', dtype=torch.float16) tensor(0.1037, device='cuda:0', dtype=torch.float16)
tensor(2.4375, device='cuda:0', dtype=torch.float16) tensor(0.1033, device='cuda:0', dtype=torch.float16)
tensor(3.0195, device='cuda:0', dtype=torch.float16) tensor(0.1005, device='cuda:0', dtype=torch.float16)
tensor(2.2891, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0195, device='cuda:0')
tensor(0.0346, device='cuda:0')
old_score: tensor(0.1029, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0546, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.022934913635254
Validation after dual ascent:
out_inf: tensor(4.3984, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(0.7905, device='cuda:0', dtype=torch.float16) tensor(0.0547, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0561, device='cuda:0', dtype=torch.float16)
tensor(0.8047, device='cuda:0', dtype=torch.float16) tensor(0.0524, device='cuda:0', dtype=torch.float16)
tensor(0.9351, device='cuda:0', dtype=torch.float16) tensor(0.0551, device='cuda:0', dtype=torch.float16)
pruning layer 5 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.2910, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.6396, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
tensor(0.1571, device='cuda:0')
old_score: tensor(0.0230, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0146, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.69167923927307
Validation after dual ascent:
out_inf: tensor(2.2910, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(0.2849, device='cuda:0', dtype=torch.float16) tensor(0.0149, device='cuda:0', dtype=torch.float16)
tensor(0.2285, device='cuda:0', dtype=torch.float16) tensor(0.0152, device='cuda:0', dtype=torch.float16)
tensor(0.2222, device='cuda:0', dtype=torch.float16) tensor(0.0133, device='cuda:0', dtype=torch.float16)
tensor(0.2686, device='cuda:0', dtype=torch.float16) tensor(0.0151, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.2891, device='cuda:0', dtype=torch.float16) tensor(0.8667, device='cuda:0', dtype=torch.float16)
tensor(7.8359, device='cuda:0', dtype=torch.float16) tensor(0.3391, device='cuda:0', dtype=torch.float16)
tensor(8.1562, device='cuda:0', dtype=torch.float16) tensor(0.3389, device='cuda:0', dtype=torch.float16)
tensor(6.6836, device='cuda:0', dtype=torch.float16) tensor(0.3303, device='cuda:0', dtype=torch.float16)
tensor(6.4141, device='cuda:0', dtype=torch.float16) tensor(0.3350, device='cuda:0', dtype=torch.float16)
tensor(0.1062, device='cuda:0')
old_score: tensor(0.3357, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1338, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.845668315887451
Validation after dual ascent:
out_inf: tensor(14.2891, device='cuda:0', dtype=torch.float16) tensor(0.8667, device='cuda:0', dtype=torch.float16)
tensor(2.2246, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(2.3867, device='cuda:0', dtype=torch.float16) tensor(0.1377, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.1324, device='cuda:0', dtype=torch.float16)
tensor(2.1133, device='cuda:0', dtype=torch.float16) tensor(0.1328, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(1.0586, device='cuda:0', dtype=torch.float16)
tensor(7.2109, device='cuda:0', dtype=torch.float16) tensor(0.3569, device='cuda:0', dtype=torch.float16)
tensor(7.3203, device='cuda:0', dtype=torch.float16) tensor(0.3577, device='cuda:0', dtype=torch.float16)
tensor(8.1797, device='cuda:0', dtype=torch.float16) tensor(0.3477, device='cuda:0', dtype=torch.float16)
tensor(7.3906, device='cuda:0', dtype=torch.float16) tensor(0.3506, device='cuda:0', dtype=torch.float16)
tensor(0.1248, device='cuda:0')
old_score: tensor(0.3533, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1334, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.863272905349731
Validation after dual ascent:
out_inf: tensor(17.4062, device='cuda:0', dtype=torch.float16) tensor(1.0586, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.1317, device='cuda:0', dtype=torch.float16)
tensor(2.2539, device='cuda:0', dtype=torch.float16) tensor(0.1376, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(2.1934, device='cuda:0', dtype=torch.float16) tensor(0.1324, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.1973, device='cuda:0', dtype=torch.float16) tensor(0.2438, device='cuda:0', dtype=torch.float16)
tensor(1.5684, device='cuda:0', dtype=torch.float16) tensor(0.1526, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1516, device='cuda:0', dtype=torch.float16)
tensor(1.5332, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0159, device='cuda:0')
tensor(0.0504, device='cuda:0')
old_score: tensor(0.1505, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0701, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1599743366241455
Validation after dual ascent:
out_inf: tensor(3.1973, device='cuda:0', dtype=torch.float16) tensor(0.2438, device='cuda:0', dtype=torch.float16)
tensor(0.6807, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.7925, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(0.6934, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(0.6436, device='cuda:0', dtype=torch.float16) tensor(0.0697, device='cuda:0', dtype=torch.float16)
pruning layer 6 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.7852, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(1.2422, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.0241, device='cuda:0', dtype=torch.float16)
tensor(1.0098, device='cuda:0', dtype=torch.float16) tensor(0.0229, device='cuda:0', dtype=torch.float16)
tensor(1.3359, device='cuda:0', dtype=torch.float16) tensor(0.0233, device='cuda:0', dtype=torch.float16)
tensor(0.0831, device='cuda:0')
old_score: tensor(0.0234, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0111, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.789117097854614
Validation after dual ascent:
out_inf: tensor(7.7852, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
tensor(0.4170, device='cuda:0', dtype=torch.float16) tensor(0.0108, device='cuda:0', dtype=torch.float16)
tensor(0.3457, device='cuda:0', dtype=torch.float16) tensor(0.0119, device='cuda:0', dtype=torch.float16)
tensor(0.4814, device='cuda:0', dtype=torch.float16) tensor(0.0106, device='cuda:0', dtype=torch.float16)
tensor(0.3896, device='cuda:0', dtype=torch.float16) tensor(0.0110, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.3125, device='cuda:0', dtype=torch.float16) tensor(0.2544, device='cuda:0', dtype=torch.float16)
tensor(3.2012, device='cuda:0', dtype=torch.float16) tensor(0.1268, device='cuda:0', dtype=torch.float16)
tensor(2.3887, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(2.8828, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
tensor(2.6523, device='cuda:0', dtype=torch.float16) tensor(0.1274, device='cuda:0', dtype=torch.float16)
tensor(0.0345, device='cuda:0')
old_score: tensor(0.1271, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0596, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.80200386047363
Validation after dual ascent:
out_inf: tensor(4.3125, device='cuda:0', dtype=torch.float16) tensor(0.2544, device='cuda:0', dtype=torch.float16)
tensor(1.1621, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.0607, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(0.9111, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.1567, device='cuda:0', dtype=torch.float16)
tensor(2.5684, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(2.5410, device='cuda:0', dtype=torch.float16) tensor(0.1049, device='cuda:0', dtype=torch.float16)
tensor(2.1660, device='cuda:0', dtype=torch.float16) tensor(0.1071, device='cuda:0', dtype=torch.float16)
tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.1055, device='cuda:0', dtype=torch.float16)
Converged at iteration 350
tensor(0.0186, device='cuda:0')
tensor(0.0280, device='cuda:0')
old_score: tensor(0.1056, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0516, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 13.804406642913818
Validation after dual ascent:
out_inf: tensor(3.3359, device='cuda:0', dtype=torch.float16) tensor(0.1567, device='cuda:0', dtype=torch.float16)
tensor(0.9941, device='cuda:0', dtype=torch.float16) tensor(0.0500, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0525, device='cuda:0', dtype=torch.float16)
tensor(0.7246, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(0.7505, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
pruning layer 6 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.0508, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.0248, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0247, device='cuda:0', dtype=torch.float16)
tensor(0.7646, device='cuda:0', dtype=torch.float16) tensor(0.0244, device='cuda:0', dtype=torch.float16)
tensor(0.9219, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.1520, device='cuda:0')
old_score: tensor(0.0248, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0138, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.68775820732117
Validation after dual ascent:
out_inf: tensor(2.0508, device='cuda:0', dtype=torch.float16) tensor(0.0516, device='cuda:0', dtype=torch.float16)
tensor(0.2930, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.2051, device='cuda:0', dtype=torch.float16) tensor(0.0141, device='cuda:0', dtype=torch.float16)
tensor(0.2402, device='cuda:0', dtype=torch.float16) tensor(0.0139, device='cuda:0', dtype=torch.float16)
tensor(0.2324, device='cuda:0', dtype=torch.float16) tensor(0.0137, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.7344, device='cuda:0', dtype=torch.float16) tensor(0.8745, device='cuda:0', dtype=torch.float16)
tensor(8.6328, device='cuda:0', dtype=torch.float16) tensor(0.3589, device='cuda:0', dtype=torch.float16)
tensor(8.3281, device='cuda:0', dtype=torch.float16) tensor(0.3623, device='cuda:0', dtype=torch.float16)
tensor(9.4922, device='cuda:0', dtype=torch.float16) tensor(0.3630, device='cuda:0', dtype=torch.float16)
tensor(10.4688, device='cuda:0', dtype=torch.float16) tensor(0.3623, device='cuda:0', dtype=torch.float16)
tensor(0.4341, device='cuda:0')
old_score: tensor(0.3616, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1453, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.853984117507935
Validation after dual ascent:
out_inf: tensor(17.7344, device='cuda:0', dtype=torch.float16) tensor(0.8745, device='cuda:0', dtype=torch.float16)
tensor(2.5078, device='cuda:0', dtype=torch.float16) tensor(0.1416, device='cuda:0', dtype=torch.float16)
tensor(2.5195, device='cuda:0', dtype=torch.float16) tensor(0.1493, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1461, device='cuda:0', dtype=torch.float16)
tensor(2.4531, device='cuda:0', dtype=torch.float16) tensor(0.1442, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.6719, device='cuda:0', dtype=torch.float16) tensor(1.0342, device='cuda:0', dtype=torch.float16)
tensor(7.2344, device='cuda:0', dtype=torch.float16) tensor(0.3660, device='cuda:0', dtype=torch.float16)
tensor(7.6484, device='cuda:0', dtype=torch.float16) tensor(0.3704, device='cuda:0', dtype=torch.float16)
tensor(9.1016, device='cuda:0', dtype=torch.float16) tensor(0.3743, device='cuda:0', dtype=torch.float16)
tensor(6.9922, device='cuda:0', dtype=torch.float16) tensor(0.3694, device='cuda:0', dtype=torch.float16)
tensor(0.4240, device='cuda:0')
old_score: tensor(0.3699, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1422, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.871440410614014
Validation after dual ascent:
out_inf: tensor(16.6719, device='cuda:0', dtype=torch.float16) tensor(1.0342, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1387, device='cuda:0', dtype=torch.float16)
tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1461, device='cuda:0', dtype=torch.float16)
tensor(2.3887, device='cuda:0', dtype=torch.float16) tensor(0.1431, device='cuda:0', dtype=torch.float16)
tensor(2.3574, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.4277, device='cuda:0', dtype=torch.float16) tensor(0.2413, device='cuda:0', dtype=torch.float16)
tensor(2.3945, device='cuda:0', dtype=torch.float16) tensor(0.1577, device='cuda:0', dtype=torch.float16)
tensor(2.0977, device='cuda:0', dtype=torch.float16) tensor(0.1588, device='cuda:0', dtype=torch.float16)
tensor(2.3730, device='cuda:0', dtype=torch.float16) tensor(0.1580, device='cuda:0', dtype=torch.float16)
tensor(2.4121, device='cuda:0', dtype=torch.float16) tensor(0.1587, device='cuda:0', dtype=torch.float16)
tensor(0.1664, device='cuda:0')
old_score: tensor(0.1582, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0762, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.857830047607422
Validation after dual ascent:
out_inf: tensor(3.4277, device='cuda:0', dtype=torch.float16) tensor(0.2413, device='cuda:0', dtype=torch.float16)
tensor(0.8301, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(0.8247, device='cuda:0', dtype=torch.float16) tensor(0.0784, device='cuda:0', dtype=torch.float16)
tensor(0.8018, device='cuda:0', dtype=torch.float16) tensor(0.0765, device='cuda:0', dtype=torch.float16)
tensor(0.8135, device='cuda:0', dtype=torch.float16) tensor(0.0757, device='cuda:0', dtype=torch.float16)
pruning layer 7 name self_attn.o_proj
Validation after prune:
out_inf: tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.9834, device='cuda:0', dtype=torch.float16) tensor(0.0239, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0262, device='cuda:0', dtype=torch.float16)
tensor(1.4375, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.9229, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.0823, device='cuda:0')
old_score: tensor(0.0248, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0125, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.816294193267822
Validation after dual ascent:
out_inf: tensor(3.1328, device='cuda:0', dtype=torch.float16) tensor(0.0509, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0118, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0134, device='cuda:0', dtype=torch.float16)
tensor(0.5439, device='cuda:0', dtype=torch.float16) tensor(0.0129, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0120, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.0703, device='cuda:0', dtype=torch.float16) tensor(0.2568, device='cuda:0', dtype=torch.float16)
tensor(4.8281, device='cuda:0', dtype=torch.float16) tensor(0.1384, device='cuda:0', dtype=torch.float16)
tensor(4.2305, device='cuda:0', dtype=torch.float16) tensor(0.1379, device='cuda:0', dtype=torch.float16)
tensor(4.5273, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
tensor(5.2695, device='cuda:0', dtype=torch.float16) tensor(0.1383, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0195, device='cuda:0')
tensor(0.0192, device='cuda:0')
old_score: tensor(0.1383, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0690, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.945319175720215
Validation after dual ascent:
out_inf: tensor(5.0703, device='cuda:0', dtype=torch.float16) tensor(0.2568, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0677, device='cuda:0', dtype=torch.float16)
tensor(1.6855, device='cuda:0', dtype=torch.float16) tensor(0.0703, device='cuda:0', dtype=torch.float16)
tensor(1.5332, device='cuda:0', dtype=torch.float16) tensor(0.0699, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.up_proj
Validation after prune:
out_inf: tensor(3.4004, device='cuda:0', dtype=torch.float16) tensor(0.1711, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.1178, device='cuda:0', dtype=torch.float16)
tensor(1.9551, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1187, device='cuda:0', dtype=torch.float16)
tensor(2.2793, device='cuda:0', dtype=torch.float16) tensor(0.1181, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0174, device='cuda:0')
tensor(0.0586, device='cuda:0')
old_score: tensor(0.1180, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0602, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.066169500350952
Validation after dual ascent:
out_inf: tensor(3.4004, device='cuda:0', dtype=torch.float16) tensor(0.1711, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0590, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0612, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(0.8086, device='cuda:0', dtype=torch.float16) tensor(0.0595, device='cuda:0', dtype=torch.float16)
pruning layer 7 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.7568, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0284, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.0284, device='cuda:0', dtype=torch.float16)
tensor(0.9746, device='cuda:0', dtype=torch.float16) tensor(0.0276, device='cuda:0', dtype=torch.float16)
tensor(0.8770, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.1561, device='cuda:0')
old_score: tensor(0.0283, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0173, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.75193953514099
Validation after dual ascent:
out_inf: tensor(0.7568, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.2988, device='cuda:0', dtype=torch.float16) tensor(0.0171, device='cuda:0', dtype=torch.float16)
tensor(0.3083, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.3027, device='cuda:0', dtype=torch.float16) tensor(0.0172, device='cuda:0', dtype=torch.float16)
tensor(0.2539, device='cuda:0', dtype=torch.float16) tensor(0.0173, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.q_proj
Validation after prune:
out_inf: tensor(19.4531, device='cuda:0', dtype=torch.float16) tensor(0.8403, device='cuda:0', dtype=torch.float16)
tensor(9.3281, device='cuda:0', dtype=torch.float16) tensor(0.3557, device='cuda:0', dtype=torch.float16)
tensor(8.8750, device='cuda:0', dtype=torch.float16) tensor(0.3584, device='cuda:0', dtype=torch.float16)
tensor(8.0156, device='cuda:0', dtype=torch.float16) tensor(0.3599, device='cuda:0', dtype=torch.float16)
tensor(8.3984, device='cuda:0', dtype=torch.float16) tensor(0.3550, device='cuda:0', dtype=torch.float16)
tensor(0.1029, device='cuda:0')
old_score: tensor(0.3574, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1531, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.873277187347412
Validation after dual ascent:
out_inf: tensor(19.4531, device='cuda:0', dtype=torch.float16) tensor(0.8403, device='cuda:0', dtype=torch.float16)
tensor(3.0449, device='cuda:0', dtype=torch.float16) tensor(0.1503, device='cuda:0', dtype=torch.float16)
tensor(2.9023, device='cuda:0', dtype=torch.float16) tensor(0.1569, device='cuda:0', dtype=torch.float16)
tensor(3.0898, device='cuda:0', dtype=torch.float16) tensor(0.1541, device='cuda:0', dtype=torch.float16)
tensor(2.7539, device='cuda:0', dtype=torch.float16) tensor(0.1511, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.2031, device='cuda:0', dtype=torch.float16) tensor(1.0674, device='cuda:0', dtype=torch.float16)
tensor(6.2344, device='cuda:0', dtype=torch.float16) tensor(0.3613, device='cuda:0', dtype=torch.float16)
tensor(6.8789, device='cuda:0', dtype=torch.float16) tensor(0.3613, device='cuda:0', dtype=torch.float16)
tensor(6.6250, device='cuda:0', dtype=torch.float16) tensor(0.3652, device='cuda:0', dtype=torch.float16)
tensor(7.4336, device='cuda:0', dtype=torch.float16) tensor(0.3601, device='cuda:0', dtype=torch.float16)
tensor(0.1102, device='cuda:0')
old_score: tensor(0.3621, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1500, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.895458221435547
Validation after dual ascent:
out_inf: tensor(17.2031, device='cuda:0', dtype=torch.float16) tensor(1.0674, device='cuda:0', dtype=torch.float16)
tensor(2.5801, device='cuda:0', dtype=torch.float16) tensor(0.1471, device='cuda:0', dtype=torch.float16)
tensor(2.4258, device='cuda:0', dtype=torch.float16) tensor(0.1541, device='cuda:0', dtype=torch.float16)
tensor(2.3555, device='cuda:0', dtype=torch.float16) tensor(0.1510, device='cuda:0', dtype=torch.float16)
tensor(2.2754, device='cuda:0', dtype=torch.float16) tensor(0.1479, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.7188, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
tensor(1.6133, device='cuda:0', dtype=torch.float16) tensor(0.1724, device='cuda:0', dtype=torch.float16)
tensor(1.7256, device='cuda:0', dtype=torch.float16) tensor(0.1730, device='cuda:0', dtype=torch.float16)
tensor(1.6055, device='cuda:0', dtype=torch.float16) tensor(0.1729, device='cuda:0', dtype=torch.float16)
tensor(1.6357, device='cuda:0', dtype=torch.float16) tensor(0.1720, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0188, device='cuda:0')
tensor(0.0794, device='cuda:0')
old_score: tensor(0.1725, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0844, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.169997453689575
Validation after dual ascent:
out_inf: tensor(4.7188, device='cuda:0', dtype=torch.float16) tensor(0.2676, device='cuda:0', dtype=torch.float16)
tensor(0.8887, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(0.8530, device='cuda:0', dtype=torch.float16) tensor(0.0865, device='cuda:0', dtype=torch.float16)
tensor(0.8667, device='cuda:0', dtype=torch.float16) tensor(0.0849, device='cuda:0', dtype=torch.float16)
tensor(0.7900, device='cuda:0', dtype=torch.float16) tensor(0.0833, device='cuda:0', dtype=torch.float16)
pruning layer 8 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.4492, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.0367, device='cuda:0', dtype=torch.float16)
tensor(1.5547, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(1.4863, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(1.5469, device='cuda:0', dtype=torch.float16) tensor(0.0366, device='cuda:0', dtype=torch.float16)
tensor(0.0885, device='cuda:0')
old_score: tensor(0.0371, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0175, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.809355020523071
Validation after dual ascent:
out_inf: tensor(5.4492, device='cuda:0', dtype=torch.float16) tensor(0.0776, device='cuda:0', dtype=torch.float16)
tensor(0.8906, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
tensor(0.6333, device='cuda:0', dtype=torch.float16) tensor(0.0182, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0177, device='cuda:0', dtype=torch.float16)
tensor(0.6191, device='cuda:0', dtype=torch.float16) tensor(0.0172, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.5742, device='cuda:0', dtype=torch.float16) tensor(0.2803, device='cuda:0', dtype=torch.float16)
tensor(4.2891, device='cuda:0', dtype=torch.float16) tensor(0.1411, device='cuda:0', dtype=torch.float16)
tensor(3.9688, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(4.3398, device='cuda:0', dtype=torch.float16) tensor(0.1429, device='cuda:0', dtype=torch.float16)
tensor(3.4199, device='cuda:0', dtype=torch.float16) tensor(0.1410, device='cuda:0', dtype=torch.float16)
tensor(0.0350, device='cuda:0')
old_score: tensor(0.1421, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0682, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.7241485118866
Validation after dual ascent:
out_inf: tensor(4.5742, device='cuda:0', dtype=torch.float16) tensor(0.2803, device='cuda:0', dtype=torch.float16)
tensor(1.5820, device='cuda:0', dtype=torch.float16) tensor(0.0659, device='cuda:0', dtype=torch.float16)
tensor(1.2979, device='cuda:0', dtype=torch.float16) tensor(0.0704, device='cuda:0', dtype=torch.float16)
tensor(2.7344, device='cuda:0', dtype=torch.float16) tensor(0.0692, device='cuda:0', dtype=torch.float16)
tensor(1.1826, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1094, device='cuda:0', dtype=torch.float16) tensor(0.1897, device='cuda:0', dtype=torch.float16)
tensor(2.1699, device='cuda:0', dtype=torch.float16) tensor(0.1229, device='cuda:0', dtype=torch.float16)
tensor(1.9209, device='cuda:0', dtype=torch.float16) tensor(0.1248, device='cuda:0', dtype=torch.float16)
tensor(4.2656, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0197, device='cuda:0')
tensor(0.0619, device='cuda:0')
old_score: tensor(0.1238, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0612, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.073636054992676
Validation after dual ascent:
out_inf: tensor(4.1094, device='cuda:0', dtype=torch.float16) tensor(0.1897, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.0633, device='cuda:0', dtype=torch.float16)
tensor(1.7734, device='cuda:0', dtype=torch.float16) tensor(0.0622, device='cuda:0', dtype=torch.float16)
tensor(0.9434, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
pruning layer 8 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.8691, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(1.1465, device='cuda:0', dtype=torch.float16) tensor(0.0325, device='cuda:0', dtype=torch.float16)
tensor(1.1387, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
tensor(1.0234, device='cuda:0', dtype=torch.float16) tensor(0.0326, device='cuda:0', dtype=torch.float16)
tensor(1.0703, device='cuda:0', dtype=torch.float16) tensor(0.0324, device='cuda:0', dtype=torch.float16)
tensor(0.1567, device='cuda:0')
old_score: tensor(0.0327, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0184, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.8547010421753
Validation after dual ascent:
out_inf: tensor(3.8691, device='cuda:0', dtype=torch.float16) tensor(0.0669, device='cuda:0', dtype=torch.float16)
tensor(0.3418, device='cuda:0', dtype=torch.float16) tensor(0.0178, device='cuda:0', dtype=torch.float16)
tensor(0.4004, device='cuda:0', dtype=torch.float16) tensor(0.0192, device='cuda:0', dtype=torch.float16)
tensor(0.3516, device='cuda:0', dtype=torch.float16) tensor(0.0186, device='cuda:0', dtype=torch.float16)
tensor(0.3496, device='cuda:0', dtype=torch.float16) tensor(0.0181, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.9375, device='cuda:0', dtype=torch.float16) tensor(0.8291, device='cuda:0', dtype=torch.float16)
tensor(5.4102, device='cuda:0', dtype=torch.float16) tensor(0.3601, device='cuda:0', dtype=torch.float16)
tensor(5.2031, device='cuda:0', dtype=torch.float16) tensor(0.3635, device='cuda:0', dtype=torch.float16)
tensor(5.4297, device='cuda:0', dtype=torch.float16) tensor(0.3689, device='cuda:0', dtype=torch.float16)
tensor(5.2852, device='cuda:0', dtype=torch.float16) tensor(0.3586, device='cuda:0', dtype=torch.float16)
tensor(0.0870, device='cuda:0')
old_score: tensor(0.3628, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1591, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.879529237747192
Validation after dual ascent:
out_inf: tensor(13.9375, device='cuda:0', dtype=torch.float16) tensor(0.8291, device='cuda:0', dtype=torch.float16)
tensor(2.2461, device='cuda:0', dtype=torch.float16) tensor(0.1539, device='cuda:0', dtype=torch.float16)
tensor(2.2305, device='cuda:0', dtype=torch.float16) tensor(0.1647, device='cuda:0', dtype=torch.float16)
tensor(2.1895, device='cuda:0', dtype=torch.float16) tensor(0.1611, device='cuda:0', dtype=torch.float16)
tensor(2.0840, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.5000, device='cuda:0', dtype=torch.float16) tensor(1.0459, device='cuda:0', dtype=torch.float16)
tensor(4.9180, device='cuda:0', dtype=torch.float16) tensor(0.3708, device='cuda:0', dtype=torch.float16)
tensor(4.8164, device='cuda:0', dtype=torch.float16) tensor(0.3735, device='cuda:0', dtype=torch.float16)
tensor(4.9141, device='cuda:0', dtype=torch.float16) tensor(0.3826, device='cuda:0', dtype=torch.float16)
tensor(4.3047, device='cuda:0', dtype=torch.float16) tensor(0.3679, device='cuda:0', dtype=torch.float16)
tensor(0.1022, device='cuda:0')
old_score: tensor(0.3738, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1570, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.901585340499878
Validation after dual ascent:
out_inf: tensor(17.5000, device='cuda:0', dtype=torch.float16) tensor(1.0459, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
tensor(2.5371, device='cuda:0', dtype=torch.float16) tensor(0.1627, device='cuda:0', dtype=torch.float16)
tensor(2.2285, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(2.6582, device='cuda:0', dtype=torch.float16) tensor(0.1542, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.4805, device='cuda:0', dtype=torch.float16) tensor(0.2649, device='cuda:0', dtype=torch.float16)
tensor(1.8574, device='cuda:0', dtype=torch.float16) tensor(0.1769, device='cuda:0', dtype=torch.float16)
tensor(1.8994, device='cuda:0', dtype=torch.float16) tensor(0.1788, device='cuda:0', dtype=torch.float16)
tensor(1.9717, device='cuda:0', dtype=torch.float16) tensor(0.1786, device='cuda:0', dtype=torch.float16)
tensor(1.8271, device='cuda:0', dtype=torch.float16) tensor(0.1765, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0167, device='cuda:0')
tensor(0.0641, device='cuda:0')
old_score: tensor(0.1777, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0875, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.170987844467163
Validation after dual ascent:
out_inf: tensor(6.4805, device='cuda:0', dtype=torch.float16) tensor(0.2649, device='cuda:0', dtype=torch.float16)
tensor(0.9424, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
tensor(0.7998, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
tensor(0.8267, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0860, device='cuda:0', dtype=torch.float16)
pruning layer 9 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.8906, device='cuda:0', dtype=torch.float16) tensor(0.0772, device='cuda:0', dtype=torch.float16)
tensor(1.5879, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(1.5527, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(1.4336, device='cuda:0', dtype=torch.float16) tensor(0.0384, device='cuda:0', dtype=torch.float16)
tensor(0.0628, device='cuda:0')
old_score: tensor(0.0399, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0174, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.78688907623291
Validation after dual ascent:
out_inf: tensor(5.8906, device='cuda:0', dtype=torch.float16) tensor(0.0772, device='cuda:0', dtype=torch.float16)
tensor(0.4766, device='cuda:0', dtype=torch.float16) tensor(0.0167, device='cuda:0', dtype=torch.float16)
tensor(0.5898, device='cuda:0', dtype=torch.float16) tensor(0.0180, device='cuda:0', dtype=torch.float16)
tensor(0.6680, device='cuda:0', dtype=torch.float16) tensor(0.0187, device='cuda:0', dtype=torch.float16)
tensor(0.4922, device='cuda:0', dtype=torch.float16) tensor(0.0162, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.3867, device='cuda:0', dtype=torch.float16) tensor(0.2861, device='cuda:0', dtype=torch.float16)
tensor(4.3438, device='cuda:0', dtype=torch.float16) tensor(0.1438, device='cuda:0', dtype=torch.float16)
tensor(4.1562, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(4.9375, device='cuda:0', dtype=torch.float16) tensor(0.1455, device='cuda:0', dtype=torch.float16)
tensor(4.2109, device='cuda:0', dtype=torch.float16) tensor(0.1436, device='cuda:0', dtype=torch.float16)
tensor(0.0330, device='cuda:0')
old_score: tensor(0.1447, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0695, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.73291635513306
Validation after dual ascent:
out_inf: tensor(6.3867, device='cuda:0', dtype=torch.float16) tensor(0.2861, device='cuda:0', dtype=torch.float16)
tensor(1.6406, device='cuda:0', dtype=torch.float16) tensor(0.0668, device='cuda:0', dtype=torch.float16)
tensor(1.6963, device='cuda:0', dtype=torch.float16) tensor(0.0723, device='cuda:0', dtype=torch.float16)
tensor(1.4766, device='cuda:0', dtype=torch.float16) tensor(0.0706, device='cuda:0', dtype=torch.float16)
tensor(1.8730, device='cuda:0', dtype=torch.float16) tensor(0.0682, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.2266, device='cuda:0', dtype=torch.float16) tensor(0.1971, device='cuda:0', dtype=torch.float16)
tensor(2.7344, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.1302, device='cuda:0', dtype=torch.float16)
tensor(3.3457, device='cuda:0', dtype=torch.float16) tensor(0.1296, device='cuda:0', dtype=torch.float16)
tensor(3.1758, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0190, device='cuda:0')
tensor(0.0696, device='cuda:0')
old_score: tensor(0.1292, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0638, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.078370571136475
Validation after dual ascent:
out_inf: tensor(4.2266, device='cuda:0', dtype=torch.float16) tensor(0.1971, device='cuda:0', dtype=torch.float16)
tensor(0.9780, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(1.0566, device='cuda:0', dtype=torch.float16) tensor(0.0664, device='cuda:0', dtype=torch.float16)
tensor(0.9341, device='cuda:0', dtype=torch.float16) tensor(0.0649, device='cuda:0', dtype=torch.float16)
tensor(0.8740, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
pruning layer 9 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.8916, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(1.1562, device='cuda:0', dtype=torch.float16) tensor(0.0355, device='cuda:0', dtype=torch.float16)
tensor(1.1426, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(1.1934, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.1505, device='cuda:0')
old_score: tensor(0.0354, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0202, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.90859889984131
Validation after dual ascent:
out_inf: tensor(1.8916, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(0.3164, device='cuda:0', dtype=torch.float16) tensor(0.0194, device='cuda:0', dtype=torch.float16)
tensor(0.4399, device='cuda:0', dtype=torch.float16) tensor(0.0211, device='cuda:0', dtype=torch.float16)
tensor(0.2988, device='cuda:0', dtype=torch.float16) tensor(0.0206, device='cuda:0', dtype=torch.float16)
tensor(0.3418, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.3672, device='cuda:0', dtype=torch.float16) tensor(0.8003, device='cuda:0', dtype=torch.float16)
tensor(6.3477, device='cuda:0', dtype=torch.float16) tensor(0.3503, device='cuda:0', dtype=torch.float16)
tensor(7.6172, device='cuda:0', dtype=torch.float16) tensor(0.3567, device='cuda:0', dtype=torch.float16)
tensor(7.2539, device='cuda:0', dtype=torch.float16) tensor(0.3623, device='cuda:0', dtype=torch.float16)
tensor(6.8711, device='cuda:0', dtype=torch.float16) tensor(0.3506, device='cuda:0', dtype=torch.float16)
tensor(0.0873, device='cuda:0')
old_score: tensor(0.3550, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1541, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.880249500274658
Validation after dual ascent:
out_inf: tensor(14.3672, device='cuda:0', dtype=torch.float16) tensor(0.8003, device='cuda:0', dtype=torch.float16)
tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
tensor(2.2305, device='cuda:0', dtype=torch.float16) tensor(0.1584, device='cuda:0', dtype=torch.float16)
tensor(2.2715, device='cuda:0', dtype=torch.float16) tensor(0.1578, device='cuda:0', dtype=torch.float16)
tensor(2.2305, device='cuda:0', dtype=torch.float16) tensor(0.1512, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(5.2500, device='cuda:0', dtype=torch.float16) tensor(0.3613, device='cuda:0', dtype=torch.float16)
tensor(4.9102, device='cuda:0', dtype=torch.float16) tensor(0.3652, device='cuda:0', dtype=torch.float16)
tensor(5.6484, device='cuda:0', dtype=torch.float16) tensor(0.3767, device='cuda:0', dtype=torch.float16)
tensor(4.8906, device='cuda:0', dtype=torch.float16) tensor(0.3601, device='cuda:0', dtype=torch.float16)
tensor(0.0969, device='cuda:0')
old_score: tensor(0.3660, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1515, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.902584075927734
Validation after dual ascent:
out_inf: tensor(17.2344, device='cuda:0', dtype=torch.float16) tensor(1.0596, device='cuda:0', dtype=torch.float16)
tensor(1.9502, device='cuda:0', dtype=torch.float16) tensor(0.1464, device='cuda:0', dtype=torch.float16)
tensor(2.1543, device='cuda:0', dtype=torch.float16) tensor(0.1559, device='cuda:0', dtype=torch.float16)
tensor(1.9180, device='cuda:0', dtype=torch.float16) tensor(0.1553, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1486, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.8008, device='cuda:0', dtype=torch.float16) tensor(0.2620, device='cuda:0', dtype=torch.float16)
tensor(2.0977, device='cuda:0', dtype=torch.float16) tensor(0.1761, device='cuda:0', dtype=torch.float16)
tensor(1.9258, device='cuda:0', dtype=torch.float16) tensor(0.1797, device='cuda:0', dtype=torch.float16)
tensor(2.1523, device='cuda:0', dtype=torch.float16) tensor(0.1808, device='cuda:0', dtype=torch.float16)
tensor(2.3555, device='cuda:0', dtype=torch.float16) tensor(0.1763, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0163, device='cuda:0')
tensor(0.0737, device='cuda:0')
old_score: tensor(0.1782, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0851, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.169273853302002
Validation after dual ascent:
out_inf: tensor(6.8008, device='cuda:0', dtype=torch.float16) tensor(0.2620, device='cuda:0', dtype=torch.float16)
tensor(0.8550, device='cuda:0', dtype=torch.float16) tensor(0.0822, device='cuda:0', dtype=torch.float16)
tensor(0.9990, device='cuda:0', dtype=torch.float16) tensor(0.0877, device='cuda:0', dtype=torch.float16)
tensor(0.9019, device='cuda:0', dtype=torch.float16) tensor(0.0871, device='cuda:0', dtype=torch.float16)
tensor(0.9312, device='cuda:0', dtype=torch.float16) tensor(0.0834, device='cuda:0', dtype=torch.float16)
pruning layer 10 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.8008, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(1.1875, device='cuda:0', dtype=torch.float16) tensor(0.0464, device='cuda:0', dtype=torch.float16)
tensor(0.9648, device='cuda:0', dtype=torch.float16) tensor(0.0492, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(1.1250, device='cuda:0', dtype=torch.float16) tensor(0.0450, device='cuda:0', dtype=torch.float16)
tensor(0.0750, device='cuda:0')
old_score: tensor(0.0480, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0219, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.810284852981567
Validation after dual ascent:
out_inf: tensor(5.8008, device='cuda:0', dtype=torch.float16) tensor(0.0795, device='cuda:0', dtype=torch.float16)
tensor(0.6235, device='cuda:0', dtype=torch.float16) tensor(0.0204, device='cuda:0', dtype=torch.float16)
tensor(0.4492, device='cuda:0', dtype=torch.float16) tensor(0.0227, device='cuda:0', dtype=torch.float16)
tensor(0.4570, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
tensor(0.6318, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.gate_proj
Validation after prune:
out_inf: tensor(5.4492, device='cuda:0', dtype=torch.float16) tensor(0.2778, device='cuda:0', dtype=torch.float16)
tensor(4.1328, device='cuda:0', dtype=torch.float16) tensor(0.1428, device='cuda:0', dtype=torch.float16)
tensor(4.0820, device='cuda:0', dtype=torch.float16) tensor(0.1427, device='cuda:0', dtype=torch.float16)
tensor(4.0625, device='cuda:0', dtype=torch.float16) tensor(0.1466, device='cuda:0', dtype=torch.float16)
tensor(3.9805, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(0.0298, device='cuda:0')
old_score: tensor(0.1433, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0705, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.708664655685425
Validation after dual ascent:
out_inf: tensor(5.4492, device='cuda:0', dtype=torch.float16) tensor(0.2778, device='cuda:0', dtype=torch.float16)
tensor(2.2305, device='cuda:0', dtype=torch.float16) tensor(0.0684, device='cuda:0', dtype=torch.float16)
tensor(2.2129, device='cuda:0', dtype=torch.float16) tensor(0.0721, device='cuda:0', dtype=torch.float16)
tensor(1.9863, device='cuda:0', dtype=torch.float16) tensor(0.0728, device='cuda:0', dtype=torch.float16)
tensor(2.4883, device='cuda:0', dtype=torch.float16) tensor(0.0686, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.up_proj
Validation after prune:
out_inf: tensor(2.9219, device='cuda:0', dtype=torch.float16) tensor(0.2008, device='cuda:0', dtype=torch.float16)
tensor(1.8379, device='cuda:0', dtype=torch.float16) tensor(0.1323, device='cuda:0', dtype=torch.float16)
tensor(1.8818, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
tensor(2.2930, device='cuda:0', dtype=torch.float16) tensor(0.1349, device='cuda:0', dtype=torch.float16)
tensor(1.8369, device='cuda:0', dtype=torch.float16) tensor(0.1311, device='cuda:0', dtype=torch.float16)
Converged at iteration 150
tensor(0.0190, device='cuda:0')
tensor(0.0797, device='cuda:0')
old_score: tensor(0.1326, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0662, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 6.072268724441528
Validation after dual ascent:
out_inf: tensor(2.9219, device='cuda:0', dtype=torch.float16) tensor(0.2008, device='cuda:0', dtype=torch.float16)
tensor(0.7344, device='cuda:0', dtype=torch.float16) tensor(0.0642, device='cuda:0', dtype=torch.float16)
tensor(0.8984, device='cuda:0', dtype=torch.float16) tensor(0.0678, device='cuda:0', dtype=torch.float16)
tensor(0.7021, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
tensor(0.7734, device='cuda:0', dtype=torch.float16) tensor(0.0644, device='cuda:0', dtype=torch.float16)
pruning layer 10 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.5864, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(1.0361, device='cuda:0', dtype=torch.float16) tensor(0.0370, device='cuda:0', dtype=torch.float16)
tensor(1.0039, device='cuda:0', dtype=torch.float16) tensor(0.0364, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(1.0488, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
tensor(0.1403, device='cuda:0')
old_score: tensor(0.0369, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0220, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.6657702922821
Validation after dual ascent:
out_inf: tensor(0.5864, device='cuda:0', dtype=torch.float16) tensor(0.0715, device='cuda:0', dtype=torch.float16)
tensor(0.3174, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
tensor(0.3096, device='cuda:0', dtype=torch.float16) tensor(0.0225, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0230, device='cuda:0', dtype=torch.float16)
tensor(0.2939, device='cuda:0', dtype=torch.float16) tensor(0.0213, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.q_proj
Validation after prune:
out_inf: tensor(21.2188, device='cuda:0', dtype=torch.float16) tensor(0.7798, device='cuda:0', dtype=torch.float16)
tensor(9.0078, device='cuda:0', dtype=torch.float16) tensor(0.3582, device='cuda:0', dtype=torch.float16)
tensor(9.7109, device='cuda:0', dtype=torch.float16) tensor(0.3640, device='cuda:0', dtype=torch.float16)
tensor(10.3672, device='cuda:0', dtype=torch.float16) tensor(0.3774, device='cuda:0', dtype=torch.float16)
tensor(9.5312, device='cuda:0', dtype=torch.float16) tensor(0.3557, device='cuda:0', dtype=torch.float16)
tensor(0.0749, device='cuda:0')
old_score: tensor(0.3638, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1650, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.833607196807861
Validation after dual ascent:
out_inf: tensor(21.2188, device='cuda:0', dtype=torch.float16) tensor(0.7798, device='cuda:0', dtype=torch.float16)
tensor(3.1641, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(3.2617, device='cuda:0', dtype=torch.float16) tensor(0.1691, device='cuda:0', dtype=torch.float16)
tensor(3.2812, device='cuda:0', dtype=torch.float16) tensor(0.1707, device='cuda:0', dtype=torch.float16)
tensor(3.0977, device='cuda:0', dtype=torch.float16) tensor(0.1605, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.2031, device='cuda:0', dtype=torch.float16) tensor(1.0469, device='cuda:0', dtype=torch.float16)
tensor(7.1328, device='cuda:0', dtype=torch.float16) tensor(0.3701, device='cuda:0', dtype=torch.float16)
tensor(6.8516, device='cuda:0', dtype=torch.float16) tensor(0.3708, device='cuda:0', dtype=torch.float16)
tensor(8.9297, device='cuda:0', dtype=torch.float16) tensor(0.3865, device='cuda:0', dtype=torch.float16)
tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.3652, device='cuda:0', dtype=torch.float16)
tensor(0.0869, device='cuda:0')
old_score: tensor(0.3733, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1599, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.858242750167847
Validation after dual ascent:
out_inf: tensor(16.2031, device='cuda:0', dtype=torch.float16) tensor(1.0469, device='cuda:0', dtype=torch.float16)
tensor(2.5898, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.1639, device='cuda:0', dtype=torch.float16)
tensor(2.5664, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(2.5664, device='cuda:0', dtype=torch.float16) tensor(0.1559, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.7070, device='cuda:0', dtype=torch.float16) tensor(0.2898, device='cuda:0', dtype=torch.float16)
tensor(2.0723, device='cuda:0', dtype=torch.float16) tensor(0.1995, device='cuda:0', dtype=torch.float16)
tensor(2.3145, device='cuda:0', dtype=torch.float16) tensor(0.2004, device='cuda:0', dtype=torch.float16)
tensor(2.5137, device='cuda:0', dtype=torch.float16) tensor(0.2034, device='cuda:0', dtype=torch.float16)
tensor(2.1094, device='cuda:0', dtype=torch.float16) tensor(0.1986, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0193, device='cuda:0')
tensor(0.1073, device='cuda:0')
old_score: tensor(0.2006, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1008, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1651864051818848
Validation after dual ascent:
out_inf: tensor(7.7070, device='cuda:0', dtype=torch.float16) tensor(0.2898, device='cuda:0', dtype=torch.float16)
tensor(1.2061, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.1034, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.1034, device='cuda:0', dtype=torch.float16)
tensor(0.9399, device='cuda:0', dtype=torch.float16) tensor(0.0984, device='cuda:0', dtype=torch.float16)
pruning layer 11 name self_attn.o_proj
Validation after prune:
out_inf: tensor(2.9375, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0449, device='cuda:0', dtype=torch.float16)
tensor(1.1582, device='cuda:0', dtype=torch.float16) tensor(0.0491, device='cuda:0', dtype=torch.float16)
tensor(1.2891, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(0.9800, device='cuda:0', dtype=torch.float16) tensor(0.0444, device='cuda:0', dtype=torch.float16)
tensor(0.0640, device='cuda:0')
old_score: tensor(0.0482, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0222, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.782023191452026
Validation after dual ascent:
out_inf: tensor(2.9375, device='cuda:0', dtype=torch.float16) tensor(0.0770, device='cuda:0', dtype=torch.float16)
tensor(0.6035, device='cuda:0', dtype=torch.float16) tensor(0.0201, device='cuda:0', dtype=torch.float16)
tensor(0.5796, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(0.6387, device='cuda:0', dtype=torch.float16) tensor(0.0257, device='cuda:0', dtype=torch.float16)
tensor(0.5820, device='cuda:0', dtype=torch.float16) tensor(0.0198, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.2383, device='cuda:0', dtype=torch.float16) tensor(0.2874, device='cuda:0', dtype=torch.float16)
tensor(5.2266, device='cuda:0', dtype=torch.float16) tensor(0.1528, device='cuda:0', dtype=torch.float16)
tensor(4.2031, device='cuda:0', dtype=torch.float16) tensor(0.1533, device='cuda:0', dtype=torch.float16)
tensor(4.8203, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(5.4570, device='cuda:0', dtype=torch.float16) tensor(0.1519, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0193, device='cuda:0')
tensor(0.0185, device='cuda:0')
old_score: tensor(0.1536, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0804, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.956358194351196
Validation after dual ascent:
out_inf: tensor(7.2383, device='cuda:0', dtype=torch.float16) tensor(0.2874, device='cuda:0', dtype=torch.float16)
tensor(1.8643, device='cuda:0', dtype=torch.float16) tensor(0.0783, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.0824, device='cuda:0', dtype=torch.float16)
tensor(2.1523, device='cuda:0', dtype=torch.float16) tensor(0.0831, device='cuda:0', dtype=torch.float16)
tensor(2.0898, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.3164, device='cuda:0', dtype=torch.float16) tensor(0.2084, device='cuda:0', dtype=torch.float16)
tensor(2.3359, device='cuda:0', dtype=torch.float16) tensor(0.1414, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1417, device='cuda:0', dtype=torch.float16)
tensor(1.9746, device='cuda:0', dtype=torch.float16) tensor(0.1437, device='cuda:0', dtype=torch.float16)
tensor(2.1504, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0124, device='cuda:0')
tensor(0.0175, device='cuda:0')
old_score: tensor(0.1417, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0763, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.02090835571289
Validation after dual ascent:
out_inf: tensor(4.3164, device='cuda:0', dtype=torch.float16) tensor(0.2084, device='cuda:0', dtype=torch.float16)
tensor(0.9160, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(0.8574, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(0.8672, device='cuda:0', dtype=torch.float16) tensor(0.0789, device='cuda:0', dtype=torch.float16)
tensor(0.8193, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
pruning layer 11 name mlp.down_proj
Validation after prune:
out_inf: tensor(0.6528, device='cuda:0', dtype=torch.float16) tensor(0.0705, device='cuda:0', dtype=torch.float16)
tensor(1.2539, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(1.1035, device='cuda:0', dtype=torch.float16) tensor(0.0403, device='cuda:0', dtype=torch.float16)
tensor(1.3926, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(1.0547, device='cuda:0', dtype=torch.float16) tensor(0.0401, device='cuda:0', dtype=torch.float16)
tensor(0.0781, device='cuda:0')
old_score: tensor(0.0405, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0258, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.93206739425659
Validation after dual ascent:
out_inf: tensor(0.6528, device='cuda:0', dtype=torch.float16) tensor(0.0705, device='cuda:0', dtype=torch.float16)
tensor(0.4717, device='cuda:0', dtype=torch.float16) tensor(0.0251, device='cuda:0', dtype=torch.float16)
tensor(0.4453, device='cuda:0', dtype=torch.float16) tensor(0.0263, device='cuda:0', dtype=torch.float16)
tensor(0.4512, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
tensor(0.4326, device='cuda:0', dtype=torch.float16) tensor(0.0249, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.q_proj
Validation after prune:
out_inf: tensor(17.4688, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(7.3633, device='cuda:0', dtype=torch.float16) tensor(0.3699, device='cuda:0', dtype=torch.float16)
tensor(7.9023, device='cuda:0', dtype=torch.float16) tensor(0.3762, device='cuda:0', dtype=torch.float16)
tensor(6.8047, device='cuda:0', dtype=torch.float16) tensor(0.3909, device='cuda:0', dtype=torch.float16)
tensor(7.7969, device='cuda:0', dtype=torch.float16) tensor(0.3687, device='cuda:0', dtype=torch.float16)
tensor(0.0445, device='cuda:0')
old_score: tensor(0.3765, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1846, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.839040040969849
Validation after dual ascent:
out_inf: tensor(17.4688, device='cuda:0', dtype=torch.float16) tensor(0.7930, device='cuda:0', dtype=torch.float16)
tensor(2.7070, device='cuda:0', dtype=torch.float16) tensor(0.1788, device='cuda:0', dtype=torch.float16)
tensor(2.8398, device='cuda:0', dtype=torch.float16) tensor(0.1888, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.1921, device='cuda:0', dtype=torch.float16)
tensor(2.6562, device='cuda:0', dtype=torch.float16) tensor(0.1785, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.1484, device='cuda:0', dtype=torch.float16) tensor(1.0488, device='cuda:0', dtype=torch.float16)
tensor(5.5117, device='cuda:0', dtype=torch.float16) tensor(0.3943, device='cuda:0', dtype=torch.float16)
tensor(6.0352, device='cuda:0', dtype=torch.float16) tensor(0.3970, device='cuda:0', dtype=torch.float16)
tensor(5.7773, device='cuda:0', dtype=torch.float16) tensor(0.4158, device='cuda:0', dtype=torch.float16)
tensor(6.2656, device='cuda:0', dtype=torch.float16) tensor(0.3901, device='cuda:0', dtype=torch.float16)
tensor(0.0540, device='cuda:0')
old_score: tensor(0.3994, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1852, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.859110116958618
Validation after dual ascent:
out_inf: tensor(15.1484, device='cuda:0', dtype=torch.float16) tensor(1.0488, device='cuda:0', dtype=torch.float16)
tensor(2.3848, device='cuda:0', dtype=torch.float16) tensor(0.1798, device='cuda:0', dtype=torch.float16)
tensor(2.3672, device='cuda:0', dtype=torch.float16) tensor(0.1899, device='cuda:0', dtype=torch.float16)
tensor(2.7305, device='cuda:0', dtype=torch.float16) tensor(0.1920, device='cuda:0', dtype=torch.float16)
tensor(3.5156, device='cuda:0', dtype=torch.float16) tensor(0.1792, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.0508, device='cuda:0', dtype=torch.float16) tensor(0.2930, device='cuda:0', dtype=torch.float16)
tensor(2.3164, device='cuda:0', dtype=torch.float16) tensor(0.2002, device='cuda:0', dtype=torch.float16)
tensor(1.9121, device='cuda:0', dtype=torch.float16) tensor(0.2024, device='cuda:0', dtype=torch.float16)
tensor(2.2090, device='cuda:0', dtype=torch.float16) tensor(0.2053, device='cuda:0', dtype=torch.float16)
tensor(1.9336, device='cuda:0', dtype=torch.float16) tensor(0.1993, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0111, device='cuda:0')
tensor(0.0980, device='cuda:0')
old_score: tensor(0.2018, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1096, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.1650662422180176
Validation after dual ascent:
out_inf: tensor(6.0508, device='cuda:0', dtype=torch.float16) tensor(0.2930, device='cuda:0', dtype=torch.float16)
tensor(1.1436, device='cuda:0', dtype=torch.float16) tensor(0.1064, device='cuda:0', dtype=torch.float16)
tensor(1.1436, device='cuda:0', dtype=torch.float16) tensor(0.1124, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.1061, device='cuda:0', dtype=torch.float16)
pruning layer 12 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.8320, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.0476, device='cuda:0', dtype=torch.float16)
tensor(1.8496, device='cuda:0', dtype=torch.float16) tensor(0.0517, device='cuda:0', dtype=torch.float16)
tensor(2.0430, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(1.8223, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.0501, device='cuda:0')
old_score: tensor(0.0506, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0260, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.781676530838013
Validation after dual ascent:
out_inf: tensor(4.8320, device='cuda:0', dtype=torch.float16) tensor(0.0904, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(0.5996, device='cuda:0', dtype=torch.float16) tensor(0.0271, device='cuda:0', dtype=torch.float16)
tensor(0.7324, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(0.7656, device='cuda:0', dtype=torch.float16) tensor(0.0236, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.gate_proj
Validation after prune:
out_inf: tensor(4.8398, device='cuda:0', dtype=torch.float16) tensor(0.2825, device='cuda:0', dtype=torch.float16)
tensor(3.7383, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(3.9141, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(3.9824, device='cuda:0', dtype=torch.float16) tensor(0.1599, device='cuda:0', dtype=torch.float16)
tensor(3.7188, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0194, device='cuda:0')
tensor(0.0239, device='cuda:0')
old_score: tensor(0.1573, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0838, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.020686388015747
Validation after dual ascent:
out_inf: tensor(4.8398, device='cuda:0', dtype=torch.float16) tensor(0.2825, device='cuda:0', dtype=torch.float16)
tensor(2.2598, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.0860, device='cuda:0', dtype=torch.float16)
tensor(2.0820, device='cuda:0', dtype=torch.float16) tensor(0.0869, device='cuda:0', dtype=torch.float16)
tensor(2.3242, device='cuda:0', dtype=torch.float16) tensor(0.0807, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.2031, device='cuda:0', dtype=torch.float16) tensor(0.2169, device='cuda:0', dtype=torch.float16)
tensor(2.1641, device='cuda:0', dtype=torch.float16) tensor(0.1481, device='cuda:0', dtype=torch.float16)
tensor(2.2695, device='cuda:0', dtype=torch.float16) tensor(0.1487, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1504, device='cuda:0', dtype=torch.float16)
tensor(2.0996, device='cuda:0', dtype=torch.float16) tensor(0.1470, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0128, device='cuda:0')
tensor(0.0197, device='cuda:0')
old_score: tensor(0.1486, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0808, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.014064073562622
Validation after dual ascent:
out_inf: tensor(4.2031, device='cuda:0', dtype=torch.float16) tensor(0.2169, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0787, device='cuda:0', dtype=torch.float16)
tensor(1.0430, device='cuda:0', dtype=torch.float16) tensor(0.0829, device='cuda:0', dtype=torch.float16)
tensor(0.9678, device='cuda:0', dtype=torch.float16) tensor(0.0839, device='cuda:0', dtype=torch.float16)
tensor(1.1533, device='cuda:0', dtype=torch.float16) tensor(0.0779, device='cuda:0', dtype=torch.float16)
pruning layer 12 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(1.1328, device='cuda:0', dtype=torch.float16) tensor(0.0425, device='cuda:0', dtype=torch.float16)
tensor(1.2021, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(1.1982, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(1.3174, device='cuda:0', dtype=torch.float16) tensor(0.0423, device='cuda:0', dtype=torch.float16)
tensor(0.0533, device='cuda:0')
old_score: tensor(0.0427, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0278, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.86771631240845
Validation after dual ascent:
out_inf: tensor(2.6816, device='cuda:0', dtype=torch.float16) tensor(0.0743, device='cuda:0', dtype=torch.float16)
tensor(0.4521, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.4575, device='cuda:0', dtype=torch.float16) tensor(0.0285, device='cuda:0', dtype=torch.float16)
tensor(0.4434, device='cuda:0', dtype=torch.float16) tensor(0.0290, device='cuda:0', dtype=torch.float16)
tensor(0.4175, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.3906, device='cuda:0', dtype=torch.float16) tensor(0.8066, device='cuda:0', dtype=torch.float16)
tensor(7.1211, device='cuda:0', dtype=torch.float16) tensor(0.3743, device='cuda:0', dtype=torch.float16)
tensor(6.3594, device='cuda:0', dtype=torch.float16) tensor(0.3818, device='cuda:0', dtype=torch.float16)
tensor(6.7188, device='cuda:0', dtype=torch.float16) tensor(0.3923, device='cuda:0', dtype=torch.float16)
tensor(8.0469, device='cuda:0', dtype=torch.float16) tensor(0.3735, device='cuda:0', dtype=torch.float16)
tensor(0.2530, device='cuda:0')
old_score: tensor(0.3804, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1859, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.829882621765137
Validation after dual ascent:
out_inf: tensor(14.3906, device='cuda:0', dtype=torch.float16) tensor(0.8066, device='cuda:0', dtype=torch.float16)
tensor(2.5664, device='cuda:0', dtype=torch.float16) tensor(0.1796, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.1907, device='cuda:0', dtype=torch.float16)
tensor(2.7129, device='cuda:0', dtype=torch.float16) tensor(0.1945, device='cuda:0', dtype=torch.float16)
tensor(2.6680, device='cuda:0', dtype=torch.float16) tensor(0.1792, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.0156, device='cuda:0', dtype=torch.float16) tensor(1.0068, device='cuda:0', dtype=torch.float16)
tensor(4.8984, device='cuda:0', dtype=torch.float16) tensor(0.3882, device='cuda:0', dtype=torch.float16)
tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.3936, device='cuda:0', dtype=torch.float16)
tensor(5.5312, device='cuda:0', dtype=torch.float16) tensor(0.4089, device='cuda:0', dtype=torch.float16)
tensor(4.6562, device='cuda:0', dtype=torch.float16) tensor(0.3860, device='cuda:0', dtype=torch.float16)
tensor(0.2360, device='cuda:0')
old_score: tensor(0.3940, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1836, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.849665880203247
Validation after dual ascent:
out_inf: tensor(16.0156, device='cuda:0', dtype=torch.float16) tensor(1.0068, device='cuda:0', dtype=torch.float16)
tensor(2.2559, device='cuda:0', dtype=torch.float16) tensor(0.1777, device='cuda:0', dtype=torch.float16)
tensor(2.5547, device='cuda:0', dtype=torch.float16) tensor(0.1882, device='cuda:0', dtype=torch.float16)
tensor(2.5508, device='cuda:0', dtype=torch.float16) tensor(0.1914, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.1769, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.6406, device='cuda:0', dtype=torch.float16) tensor(0.3052, device='cuda:0', dtype=torch.float16)
tensor(2.0703, device='cuda:0', dtype=torch.float16) tensor(0.2106, device='cuda:0', dtype=torch.float16)
tensor(2.0234, device='cuda:0', dtype=torch.float16) tensor(0.2123, device='cuda:0', dtype=torch.float16)
tensor(2.3809, device='cuda:0', dtype=torch.float16) tensor(0.2162, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.2094, device='cuda:0', dtype=torch.float16)
tensor(0.1194, device='cuda:0')
old_score: tensor(0.2122, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1152, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.842906951904297
Validation after dual ascent:
out_inf: tensor(4.6406, device='cuda:0', dtype=torch.float16) tensor(0.3052, device='cuda:0', dtype=torch.float16)
tensor(1.0078, device='cuda:0', dtype=torch.float16) tensor(0.1114, device='cuda:0', dtype=torch.float16)
tensor(1.0293, device='cuda:0', dtype=torch.float16) tensor(0.1181, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1204, device='cuda:0', dtype=torch.float16)
tensor(1.0098, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
pruning layer 13 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.3633, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(1.8867, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(1.9141, device='cuda:0', dtype=torch.float16) tensor(0.0544, device='cuda:0', dtype=torch.float16)
tensor(2.2266, device='cuda:0', dtype=torch.float16) tensor(0.0579, device='cuda:0', dtype=torch.float16)
tensor(2.0195, device='cuda:0', dtype=torch.float16) tensor(0.0504, device='cuda:0', dtype=torch.float16)
tensor(0.0639, device='cuda:0')
old_score: tensor(0.0537, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0263, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.771845817565918
Validation after dual ascent:
out_inf: tensor(5.3633, device='cuda:0', dtype=torch.float16) tensor(0.0816, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0243, device='cuda:0', dtype=torch.float16)
tensor(0.6973, device='cuda:0', dtype=torch.float16) tensor(0.0270, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0299, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.4453, device='cuda:0', dtype=torch.float16) tensor(0.3096, device='cuda:0', dtype=torch.float16)
tensor(5.1055, device='cuda:0', dtype=torch.float16) tensor(0.1646, device='cuda:0', dtype=torch.float16)
tensor(4.8984, device='cuda:0', dtype=torch.float16) tensor(0.1648, device='cuda:0', dtype=torch.float16)
tensor(4.4062, device='cuda:0', dtype=torch.float16) tensor(0.1693, device='cuda:0', dtype=torch.float16)
tensor(4.8828, device='cuda:0', dtype=torch.float16) tensor(0.1631, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0196, device='cuda:0')
tensor(0.0190, device='cuda:0')
old_score: tensor(0.1654, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0861, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.873148918151855
Validation after dual ascent:
out_inf: tensor(6.4453, device='cuda:0', dtype=torch.float16) tensor(0.3096, device='cuda:0', dtype=torch.float16)
tensor(3.2305, device='cuda:0', dtype=torch.float16) tensor(0.0837, device='cuda:0', dtype=torch.float16)
tensor(2.3711, device='cuda:0', dtype=torch.float16) tensor(0.0879, device='cuda:0', dtype=torch.float16)
tensor(2.5215, device='cuda:0', dtype=torch.float16) tensor(0.0900, device='cuda:0', dtype=torch.float16)
tensor(2.3730, device='cuda:0', dtype=torch.float16) tensor(0.0828, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.1445, device='cuda:0', dtype=torch.float16) tensor(0.2324, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
tensor(2.1191, device='cuda:0', dtype=torch.float16) tensor(0.1553, device='cuda:0', dtype=torch.float16)
tensor(2.3945, device='cuda:0', dtype=torch.float16) tensor(0.1581, device='cuda:0', dtype=torch.float16)
tensor(2.3711, device='cuda:0', dtype=torch.float16) tensor(0.1543, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0137, device='cuda:0')
tensor(0.0227, device='cuda:0')
old_score: tensor(0.1558, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0840, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.015056371688843
Validation after dual ascent:
out_inf: tensor(4.1445, device='cuda:0', dtype=torch.float16) tensor(0.2324, device='cuda:0', dtype=torch.float16)
tensor(1.1191, device='cuda:0', dtype=torch.float16) tensor(0.0817, device='cuda:0', dtype=torch.float16)
tensor(0.9609, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
tensor(1.0283, device='cuda:0', dtype=torch.float16) tensor(0.0809, device='cuda:0', dtype=torch.float16)
pruning layer 13 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(1.3008, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.0496, device='cuda:0', dtype=torch.float16)
tensor(0.0408, device='cuda:0')
old_score: tensor(0.0500, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0313, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.8309166431427
Validation after dual ascent:
out_inf: tensor(1.3320, device='cuda:0', dtype=torch.float16) tensor(0.0934, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0305, device='cuda:0', dtype=torch.float16)
tensor(0.5234, device='cuda:0', dtype=torch.float16) tensor(0.0319, device='cuda:0', dtype=torch.float16)
tensor(0.4346, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
tensor(0.3906, device='cuda:0', dtype=torch.float16) tensor(0.0301, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.1875, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(6.9023, device='cuda:0', dtype=torch.float16) tensor(0.3936, device='cuda:0', dtype=torch.float16)
tensor(8.0625, device='cuda:0', dtype=torch.float16) tensor(0.3987, device='cuda:0', dtype=torch.float16)
tensor(7.6328, device='cuda:0', dtype=torch.float16) tensor(0.4199, device='cuda:0', dtype=torch.float16)
tensor(6.5625, device='cuda:0', dtype=torch.float16) tensor(0.3892, device='cuda:0', dtype=torch.float16)
tensor(0.1076, device='cuda:0')
old_score: tensor(0.4004, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1913, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.836245775222778
Validation after dual ascent:
out_inf: tensor(15.1875, device='cuda:0', dtype=torch.float16) tensor(0.8022, device='cuda:0', dtype=torch.float16)
tensor(2.5781, device='cuda:0', dtype=torch.float16) tensor(0.1843, device='cuda:0', dtype=torch.float16)
tensor(2.8926, device='cuda:0', dtype=torch.float16) tensor(0.1954, device='cuda:0', dtype=torch.float16)
tensor(2.7461, device='cuda:0', dtype=torch.float16) tensor(0.2019, device='cuda:0', dtype=torch.float16)
tensor(2.5273, device='cuda:0', dtype=torch.float16) tensor(0.1830, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.6016, device='cuda:0', dtype=torch.float16) tensor(1.0898, device='cuda:0', dtype=torch.float16)
tensor(5.3359, device='cuda:0', dtype=torch.float16) tensor(0.4197, device='cuda:0', dtype=torch.float16)
tensor(5.4258, device='cuda:0', dtype=torch.float16) tensor(0.4214, device='cuda:0', dtype=torch.float16)
tensor(5.7852, device='cuda:0', dtype=torch.float16) tensor(0.4412, device='cuda:0', dtype=torch.float16)
tensor(5.5312, device='cuda:0', dtype=torch.float16) tensor(0.4167, device='cuda:0', dtype=torch.float16)
tensor(0.1013, device='cuda:0')
old_score: tensor(0.4248, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1887, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.861896753311157
Validation after dual ascent:
out_inf: tensor(15.6016, device='cuda:0', dtype=torch.float16) tensor(1.0898, device='cuda:0', dtype=torch.float16)
tensor(2.4922, device='cuda:0', dtype=torch.float16) tensor(0.1825, device='cuda:0', dtype=torch.float16)
tensor(2.4629, device='cuda:0', dtype=torch.float16) tensor(0.1931, device='cuda:0', dtype=torch.float16)
tensor(2.5859, device='cuda:0', dtype=torch.float16) tensor(0.1984, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.1810, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.1055, device='cuda:0', dtype=torch.float16) tensor(0.2996, device='cuda:0', dtype=torch.float16)
tensor(1.9697, device='cuda:0', dtype=torch.float16) tensor(0.2107, device='cuda:0', dtype=torch.float16)
tensor(1.9668, device='cuda:0', dtype=torch.float16) tensor(0.2109, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.2144, device='cuda:0', dtype=torch.float16)
tensor(1.8848, device='cuda:0', dtype=torch.float16) tensor(0.2094, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0182, device='cuda:0')
tensor(0.1139, device='cuda:0')
old_score: tensor(0.2113, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1128, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 3.169269561767578
Validation after dual ascent:
out_inf: tensor(4.1055, device='cuda:0', dtype=torch.float16) tensor(0.2996, device='cuda:0', dtype=torch.float16)
tensor(1.1484, device='cuda:0', dtype=torch.float16) tensor(0.1093, device='cuda:0', dtype=torch.float16)
tensor(1.1172, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(1.0947, device='cuda:0', dtype=torch.float16) tensor(0.1183, device='cuda:0', dtype=torch.float16)
tensor(1.0684, device='cuda:0', dtype=torch.float16) tensor(0.1085, device='cuda:0', dtype=torch.float16)
pruning layer 14 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.0703, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
tensor(1.9414, device='cuda:0', dtype=torch.float16) tensor(0.0528, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.0539, device='cuda:0', dtype=torch.float16)
tensor(2.5156, device='cuda:0', dtype=torch.float16) tensor(0.0577, device='cuda:0', dtype=torch.float16)
tensor(2.0020, device='cuda:0', dtype=torch.float16) tensor(0.0507, device='cuda:0', dtype=torch.float16)
tensor(0.0425, device='cuda:0')
old_score: tensor(0.0538, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0254, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.777445077896118
Validation after dual ascent:
out_inf: tensor(7.0703, device='cuda:0', dtype=torch.float16) tensor(0.0870, device='cuda:0', dtype=torch.float16)
tensor(0.6328, device='cuda:0', dtype=torch.float16) tensor(0.0238, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0259, device='cuda:0', dtype=torch.float16)
tensor(0.8555, device='cuda:0', dtype=torch.float16) tensor(0.0284, device='cuda:0', dtype=torch.float16)
tensor(0.5410, device='cuda:0', dtype=torch.float16) tensor(0.0235, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.6758, device='cuda:0', dtype=torch.float16) tensor(0.3135, device='cuda:0', dtype=torch.float16)
tensor(5.6367, device='cuda:0', dtype=torch.float16) tensor(0.1711, device='cuda:0', dtype=torch.float16)
tensor(5.4141, device='cuda:0', dtype=torch.float16) tensor(0.1708, device='cuda:0', dtype=torch.float16)
tensor(5.6758, device='cuda:0', dtype=torch.float16) tensor(0.1749, device='cuda:0', dtype=torch.float16)
tensor(5.6328, device='cuda:0', dtype=torch.float16) tensor(0.1702, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0194, device='cuda:0')
tensor(0.0187, device='cuda:0')
old_score: tensor(0.1716, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0913, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.957415103912354
Validation after dual ascent:
out_inf: tensor(7.6758, device='cuda:0', dtype=torch.float16) tensor(0.3135, device='cuda:0', dtype=torch.float16)
tensor(2.4297, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
tensor(2.4863, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
tensor(2.2578, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(2.6367, device='cuda:0', dtype=torch.float16) tensor(0.0873, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.0352, device='cuda:0', dtype=torch.float16) tensor(0.2413, device='cuda:0', dtype=torch.float16)
tensor(2.8535, device='cuda:0', dtype=torch.float16) tensor(0.1635, device='cuda:0', dtype=torch.float16)
tensor(3.0137, device='cuda:0', dtype=torch.float16) tensor(0.1625, device='cuda:0', dtype=torch.float16)
tensor(3.0059, device='cuda:0', dtype=torch.float16) tensor(0.1653, device='cuda:0', dtype=torch.float16)
tensor(2.8652, device='cuda:0', dtype=torch.float16) tensor(0.1621, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0135, device='cuda:0')
tensor(0.0289, device='cuda:0')
old_score: tensor(0.1633, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0894, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.022483348846436
Validation after dual ascent:
out_inf: tensor(5.0352, device='cuda:0', dtype=torch.float16) tensor(0.2413, device='cuda:0', dtype=torch.float16)
tensor(1.1553, device='cuda:0', dtype=torch.float16) tensor(0.0868, device='cuda:0', dtype=torch.float16)
tensor(1.1270, device='cuda:0', dtype=torch.float16) tensor(0.0908, device='cuda:0', dtype=torch.float16)
tensor(0.9961, device='cuda:0', dtype=torch.float16) tensor(0.0947, device='cuda:0', dtype=torch.float16)
tensor(1.3564, device='cuda:0', dtype=torch.float16) tensor(0.0855, device='cuda:0', dtype=torch.float16)
pruning layer 14 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.3916, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(1.1309, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(1.1406, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(1.3623, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0529, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0200, device='cuda:0')
tensor(0.0355, device='cuda:0')
old_score: tensor(0.0529, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0340, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 83.54960441589355
Validation after dual ascent:
out_inf: tensor(1.3916, device='cuda:0', dtype=torch.float16) tensor(0.0966, device='cuda:0', dtype=torch.float16)
tensor(0.5342, device='cuda:0', dtype=torch.float16) tensor(0.0333, device='cuda:0', dtype=torch.float16)
tensor(0.4927, device='cuda:0', dtype=torch.float16) tensor(0.0343, device='cuda:0', dtype=torch.float16)
tensor(0.5020, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.4985, device='cuda:0', dtype=torch.float16) tensor(0.0327, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.4531, device='cuda:0', dtype=torch.float16) tensor(0.8115, device='cuda:0', dtype=torch.float16)
tensor(6.3672, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(6.4609, device='cuda:0', dtype=torch.float16) tensor(0.3755, device='cuda:0', dtype=torch.float16)
tensor(7.5938, device='cuda:0', dtype=torch.float16) tensor(0.3909, device='cuda:0', dtype=torch.float16)
tensor(7.3359, device='cuda:0', dtype=torch.float16) tensor(0.3682, device='cuda:0', dtype=torch.float16)
tensor(0.0380, device='cuda:0')
old_score: tensor(0.3767, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1829, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.850746870040894
Validation after dual ascent:
out_inf: tensor(16.4531, device='cuda:0', dtype=torch.float16) tensor(0.8115, device='cuda:0', dtype=torch.float16)
tensor(2.6934, device='cuda:0', dtype=torch.float16) tensor(0.1763, device='cuda:0', dtype=torch.float16)
tensor(2.4648, device='cuda:0', dtype=torch.float16) tensor(0.1854, device='cuda:0', dtype=torch.float16)
tensor(2.6875, device='cuda:0', dtype=torch.float16) tensor(0.1960, device='cuda:0', dtype=torch.float16)
tensor(2.8438, device='cuda:0', dtype=torch.float16) tensor(0.1736, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.2812, device='cuda:0', dtype=torch.float16) tensor(1.0645, device='cuda:0', dtype=torch.float16)
tensor(6.8906, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(6.7266, device='cuda:0', dtype=torch.float16) tensor(0.4016, device='cuda:0', dtype=torch.float16)
tensor(7.0703, device='cuda:0', dtype=torch.float16) tensor(0.4175, device='cuda:0', dtype=torch.float16)
tensor(6.6172, device='cuda:0', dtype=torch.float16) tensor(0.3948, device='cuda:0', dtype=torch.float16)
tensor(0.0477, device='cuda:0')
old_score: tensor(0.4033, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1835, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.87517523765564
Validation after dual ascent:
out_inf: tensor(16.2812, device='cuda:0', dtype=torch.float16) tensor(1.0645, device='cuda:0', dtype=torch.float16)
tensor(2.4805, device='cuda:0', dtype=torch.float16) tensor(0.1772, device='cuda:0', dtype=torch.float16)
tensor(2.5918, device='cuda:0', dtype=torch.float16) tensor(0.1860, device='cuda:0', dtype=torch.float16)
tensor(2.8457, device='cuda:0', dtype=torch.float16) tensor(0.1962, device='cuda:0', dtype=torch.float16)
tensor(2.5703, device='cuda:0', dtype=torch.float16) tensor(0.1742, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.3125, device='cuda:0', dtype=torch.float16)
tensor(1.8818, device='cuda:0', dtype=torch.float16) tensor(0.2151, device='cuda:0', dtype=torch.float16)
tensor(2.1113, device='cuda:0', dtype=torch.float16) tensor(0.2142, device='cuda:0', dtype=torch.float16)
tensor(2.0039, device='cuda:0', dtype=torch.float16) tensor(0.2189, device='cuda:0', dtype=torch.float16)
tensor(1.9004, device='cuda:0', dtype=torch.float16) tensor(0.2126, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0098, device='cuda:0')
tensor(0.0410, device='cuda:0')
old_score: tensor(0.2151, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1158, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.6307220458984375
Validation after dual ascent:
out_inf: tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.3125, device='cuda:0', dtype=torch.float16)
tensor(1.0977, device='cuda:0', dtype=torch.float16) tensor(0.1121, device='cuda:0', dtype=torch.float16)
tensor(0.9712, device='cuda:0', dtype=torch.float16) tensor(0.1176, device='cuda:0', dtype=torch.float16)
tensor(1.0664, device='cuda:0', dtype=torch.float16) tensor(0.1235, device='cuda:0', dtype=torch.float16)
tensor(0.9761, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
pruning layer 15 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(2.0977, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(2.1055, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(2.4199, device='cuda:0', dtype=torch.float16) tensor(0.0558, device='cuda:0', dtype=torch.float16)
tensor(2.0996, device='cuda:0', dtype=torch.float16) tensor(0.0502, device='cuda:0', dtype=torch.float16)
tensor(0.0651, device='cuda:0')
old_score: tensor(0.0524, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0268, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.784791469573975
Validation after dual ascent:
out_inf: tensor(6.7695, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0253, device='cuda:0', dtype=torch.float16)
tensor(0.7812, device='cuda:0', dtype=torch.float16) tensor(0.0266, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0306, device='cuda:0', dtype=torch.float16)
tensor(0.5928, device='cuda:0', dtype=torch.float16) tensor(0.0246, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.0586, device='cuda:0', dtype=torch.float16) tensor(0.3350, device='cuda:0', dtype=torch.float16)
tensor(4.3438, device='cuda:0', dtype=torch.float16) tensor(0.1792, device='cuda:0', dtype=torch.float16)
tensor(3.9336, device='cuda:0', dtype=torch.float16) tensor(0.1777, device='cuda:0', dtype=torch.float16)
tensor(3.6309, device='cuda:0', dtype=torch.float16) tensor(0.1821, device='cuda:0', dtype=torch.float16)
tensor(3.9805, device='cuda:0', dtype=torch.float16) tensor(0.1772, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0194, device='cuda:0')
tensor(0.0189, device='cuda:0')
old_score: tensor(0.1791, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0937, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.962053060531616
Validation after dual ascent:
out_inf: tensor(6.0586, device='cuda:0', dtype=torch.float16) tensor(0.3350, device='cuda:0', dtype=torch.float16)
tensor(3.0977, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(2.5020, device='cuda:0', dtype=torch.float16) tensor(0.0944, device='cuda:0', dtype=torch.float16)
tensor(2.0879, device='cuda:0', dtype=torch.float16) tensor(0.0999, device='cuda:0', dtype=torch.float16)
tensor(2.4844, device='cuda:0', dtype=torch.float16) tensor(0.0893, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.4961, device='cuda:0', dtype=torch.float16) tensor(0.2549, device='cuda:0', dtype=torch.float16)
tensor(3.5059, device='cuda:0', dtype=torch.float16) tensor(0.1702, device='cuda:0', dtype=torch.float16)
tensor(3.4258, device='cuda:0', dtype=torch.float16) tensor(0.1686, device='cuda:0', dtype=torch.float16)
tensor(3.2910, device='cuda:0', dtype=torch.float16) tensor(0.1715, device='cuda:0', dtype=torch.float16)
tensor(3.6445, device='cuda:0', dtype=torch.float16) tensor(0.1685, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0136, device='cuda:0')
tensor(0.0350, device='cuda:0')
old_score: tensor(0.1697, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0918, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.02892255783081
Validation after dual ascent:
out_inf: tensor(4.4961, device='cuda:0', dtype=torch.float16) tensor(0.2549, device='cuda:0', dtype=torch.float16)
tensor(1.2383, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(1.2344, device='cuda:0', dtype=torch.float16) tensor(0.0925, device='cuda:0', dtype=torch.float16)
tensor(1.3574, device='cuda:0', dtype=torch.float16) tensor(0.0979, device='cuda:0', dtype=torch.float16)
tensor(1.2324, device='cuda:0', dtype=torch.float16) tensor(0.0875, device='cuda:0', dtype=torch.float16)
pruning layer 15 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.0742, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(1.0127, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(1.0527, device='cuda:0', dtype=torch.float16) tensor(0.0587, device='cuda:0', dtype=torch.float16)
tensor(1.0186, device='cuda:0', dtype=torch.float16) tensor(0.0580, device='cuda:0', dtype=torch.float16)
tensor(0.9351, device='cuda:0', dtype=torch.float16) tensor(0.0588, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0106, device='cuda:0')
tensor(0.0204, device='cuda:0')
old_score: tensor(0.0588, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0378, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 83.7436089515686
Validation after dual ascent:
out_inf: tensor(4.0742, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(0.5947, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.4355, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.4980, device='cuda:0', dtype=torch.float16) tensor(0.0400, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.5000, device='cuda:0', dtype=torch.float16) tensor(0.7808, device='cuda:0', dtype=torch.float16)
tensor(8.1406, device='cuda:0', dtype=torch.float16) tensor(0.3650, device='cuda:0', dtype=torch.float16)
tensor(7.8633, device='cuda:0', dtype=torch.float16) tensor(0.3672, device='cuda:0', dtype=torch.float16)
tensor(9.4531, device='cuda:0', dtype=torch.float16) tensor(0.3862, device='cuda:0', dtype=torch.float16)
tensor(7.0312, device='cuda:0', dtype=torch.float16) tensor(0.3569, device='cuda:0', dtype=torch.float16)
tensor(0.0350, device='cuda:0')
old_score: tensor(0.3691, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1798, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.856841564178467
Validation after dual ascent:
out_inf: tensor(15.5000, device='cuda:0', dtype=torch.float16) tensor(0.7808, device='cuda:0', dtype=torch.float16)
tensor(2.8281, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
tensor(3.1113, device='cuda:0', dtype=torch.float16) tensor(0.1814, device='cuda:0', dtype=torch.float16)
tensor(4.1992, device='cuda:0', dtype=torch.float16) tensor(0.1937, device='cuda:0', dtype=torch.float16)
tensor(2.6445, device='cuda:0', dtype=torch.float16) tensor(0.1698, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.5938, device='cuda:0', dtype=torch.float16) tensor(1.0879, device='cuda:0', dtype=torch.float16)
tensor(5.9922, device='cuda:0', dtype=torch.float16) tensor(0.4004, device='cuda:0', dtype=torch.float16)
tensor(6.4297, device='cuda:0', dtype=torch.float16) tensor(0.4038, device='cuda:0', dtype=torch.float16)
tensor(7.1484, device='cuda:0', dtype=torch.float16) tensor(0.4204, device='cuda:0', dtype=torch.float16)
tensor(5.6758, device='cuda:0', dtype=torch.float16) tensor(0.3931, device='cuda:0', dtype=torch.float16)
tensor(0.0472, device='cuda:0')
old_score: tensor(0.4043, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1804, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.878962755203247
Validation after dual ascent:
out_inf: tensor(16.5938, device='cuda:0', dtype=torch.float16) tensor(1.0879, device='cuda:0', dtype=torch.float16)
tensor(2.2500, device='cuda:0', dtype=torch.float16) tensor(0.1754, device='cuda:0', dtype=torch.float16)
tensor(2.3281, device='cuda:0', dtype=torch.float16) tensor(0.1826, device='cuda:0', dtype=torch.float16)
tensor(2.6055, device='cuda:0', dtype=torch.float16) tensor(0.1935, device='cuda:0', dtype=torch.float16)
tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.1705, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.5625, device='cuda:0', dtype=torch.float16) tensor(0.3062, device='cuda:0', dtype=torch.float16)
tensor(2.1074, device='cuda:0', dtype=torch.float16) tensor(0.2186, device='cuda:0', dtype=torch.float16)
tensor(2.0020, device='cuda:0', dtype=torch.float16) tensor(0.2183, device='cuda:0', dtype=torch.float16)
tensor(2.0137, device='cuda:0', dtype=torch.float16) tensor(0.2211, device='cuda:0', dtype=torch.float16)
tensor(2.1270, device='cuda:0', dtype=torch.float16) tensor(0.2158, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0182, device='cuda:0')
tensor(0.0490, device='cuda:0')
old_score: tensor(0.2185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1177, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 4.6335225105285645
Validation after dual ascent:
out_inf: tensor(4.5625, device='cuda:0', dtype=torch.float16) tensor(0.3062, device='cuda:0', dtype=torch.float16)
tensor(1.0195, device='cuda:0', dtype=torch.float16) tensor(0.1146, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(1.1299, device='cuda:0', dtype=torch.float16) tensor(0.1257, device='cuda:0', dtype=torch.float16)
tensor(1.1182, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
pruning layer 16 name self_attn.o_proj
Validation after prune:
out_inf: tensor(7.3438, device='cuda:0', dtype=torch.float16) tensor(0.1150, device='cuda:0', dtype=torch.float16)
tensor(2.3926, device='cuda:0', dtype=torch.float16) tensor(0.0584, device='cuda:0', dtype=torch.float16)
tensor(2.3086, device='cuda:0', dtype=torch.float16) tensor(0.0576, device='cuda:0', dtype=torch.float16)
tensor(2.3359, device='cuda:0', dtype=torch.float16) tensor(0.0611, device='cuda:0', dtype=torch.float16)
tensor(1.9863, device='cuda:0', dtype=torch.float16) tensor(0.0565, device='cuda:0', dtype=torch.float16)
tensor(0.0689, device='cuda:0')
old_score: tensor(0.0584, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0311, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.804062604904175
Validation after dual ascent:
out_inf: tensor(7.3438, device='cuda:0', dtype=torch.float16) tensor(0.1150, device='cuda:0', dtype=torch.float16)
tensor(0.8418, device='cuda:0', dtype=torch.float16) tensor(0.0302, device='cuda:0', dtype=torch.float16)
tensor(0.9883, device='cuda:0', dtype=torch.float16) tensor(0.0309, device='cuda:0', dtype=torch.float16)
tensor(0.7988, device='cuda:0', dtype=torch.float16) tensor(0.0347, device='cuda:0', dtype=torch.float16)
tensor(0.7266, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.0781, device='cuda:0', dtype=torch.float16) tensor(0.3459, device='cuda:0', dtype=torch.float16)
tensor(5.7109, device='cuda:0', dtype=torch.float16) tensor(0.1871, device='cuda:0', dtype=torch.float16)
tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.1866, device='cuda:0', dtype=torch.float16)
tensor(5.5234, device='cuda:0', dtype=torch.float16) tensor(0.1943, device='cuda:0', dtype=torch.float16)
tensor(5.0781, device='cuda:0', dtype=torch.float16) tensor(0.1852, device='cuda:0', dtype=torch.float16)
tensor(0.0246, device='cuda:0')
old_score: tensor(0.1884, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0969, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.90804481506348
Validation after dual ascent:
out_inf: tensor(8.0781, device='cuda:0', dtype=torch.float16) tensor(0.3459, device='cuda:0', dtype=torch.float16)
tensor(2.6367, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
tensor(2.7051, device='cuda:0', dtype=torch.float16) tensor(0.0977, device='cuda:0', dtype=torch.float16)
tensor(2.4766, device='cuda:0', dtype=torch.float16) tensor(0.1045, device='cuda:0', dtype=torch.float16)
tensor(2.3242, device='cuda:0', dtype=torch.float16) tensor(0.0917, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.7383, device='cuda:0', dtype=torch.float16) tensor(0.2568, device='cuda:0', dtype=torch.float16)
tensor(3.3027, device='cuda:0', dtype=torch.float16) tensor(0.1757, device='cuda:0', dtype=torch.float16)
tensor(3.4590, device='cuda:0', dtype=torch.float16) tensor(0.1748, device='cuda:0', dtype=torch.float16)
tensor(3.4004, device='cuda:0', dtype=torch.float16) tensor(0.1798, device='cuda:0', dtype=torch.float16)
tensor(3.2910, device='cuda:0', dtype=torch.float16) tensor(0.1737, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0153, device='cuda:0')
tensor(0.0434, device='cuda:0')
old_score: tensor(0.1760, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0944, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.042099475860596
Validation after dual ascent:
out_inf: tensor(4.7383, device='cuda:0', dtype=torch.float16) tensor(0.2568, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0915, device='cuda:0', dtype=torch.float16)
tensor(1.2061, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
tensor(1.2715, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(1.2578, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
pruning layer 16 name mlp.down_proj
Validation after prune:
out_inf: tensor(5.3828, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(0.9531, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
tensor(0.9854, device='cuda:0', dtype=torch.float16) tensor(0.0597, device='cuda:0', dtype=torch.float16)
tensor(1.0254, device='cuda:0', dtype=torch.float16) tensor(0.0608, device='cuda:0', dtype=torch.float16)
tensor(1.0352, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0126, device='cuda:0')
tensor(0.0214, device='cuda:0')
old_score: tensor(0.0601, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0380, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 83.52013206481934
Validation after dual ascent:
out_inf: tensor(5.3828, device='cuda:0', dtype=torch.float16) tensor(0.1245, device='cuda:0', dtype=torch.float16)
tensor(0.4395, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.4907, device='cuda:0', dtype=torch.float16) tensor(0.0381, device='cuda:0', dtype=torch.float16)
tensor(0.4221, device='cuda:0', dtype=torch.float16) tensor(0.0410, device='cuda:0', dtype=torch.float16)
tensor(0.4866, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.9297, device='cuda:0', dtype=torch.float16) tensor(0.7769, device='cuda:0', dtype=torch.float16)
tensor(7.2031, device='cuda:0', dtype=torch.float16) tensor(0.3643, device='cuda:0', dtype=torch.float16)
tensor(6.3203, device='cuda:0', dtype=torch.float16) tensor(0.3652, device='cuda:0', dtype=torch.float16)
tensor(6.9297, device='cuda:0', dtype=torch.float16) tensor(0.3865, device='cuda:0', dtype=torch.float16)
tensor(6.1641, device='cuda:0', dtype=torch.float16) tensor(0.3547, device='cuda:0', dtype=torch.float16)
tensor(0.0777, device='cuda:0')
old_score: tensor(0.3677, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1661, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.847062110900879
Validation after dual ascent:
out_inf: tensor(14.9297, device='cuda:0', dtype=torch.float16) tensor(0.7769, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1598, device='cuda:0', dtype=torch.float16)
tensor(2.1680, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
tensor(2.2461, device='cuda:0', dtype=torch.float16) tensor(0.1810, device='cuda:0', dtype=torch.float16)
tensor(2.0371, device='cuda:0', dtype=torch.float16) tensor(0.1559, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.k_proj
Validation after prune:
out_inf: tensor(15.3594, device='cuda:0', dtype=torch.float16) tensor(1.0273, device='cuda:0', dtype=torch.float16)
tensor(5.3359, device='cuda:0', dtype=torch.float16) tensor(0.3843, device='cuda:0', dtype=torch.float16)
tensor(5.7695, device='cuda:0', dtype=torch.float16) tensor(0.3860, device='cuda:0', dtype=torch.float16)
tensor(6.1562, device='cuda:0', dtype=torch.float16) tensor(0.4038, device='cuda:0', dtype=torch.float16)
tensor(5.7227, device='cuda:0', dtype=torch.float16) tensor(0.3782, device='cuda:0', dtype=torch.float16)
tensor(0.0862, device='cuda:0')
old_score: tensor(0.3879, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1661, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.870266914367676
Validation after dual ascent:
out_inf: tensor(15.3594, device='cuda:0', dtype=torch.float16) tensor(1.0273, device='cuda:0', dtype=torch.float16)
tensor(2.1328, device='cuda:0', dtype=torch.float16) tensor(0.1603, device='cuda:0', dtype=torch.float16)
tensor(2.4707, device='cuda:0', dtype=torch.float16) tensor(0.1681, device='cuda:0', dtype=torch.float16)
tensor(2.9336, device='cuda:0', dtype=torch.float16) tensor(0.1799, device='cuda:0', dtype=torch.float16)
tensor(2.4668, device='cuda:0', dtype=torch.float16) tensor(0.1561, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.3137, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.2170, device='cuda:0', dtype=torch.float16)
tensor(2.1973, device='cuda:0', dtype=torch.float16) tensor(0.2166, device='cuda:0', dtype=torch.float16)
tensor(2.0977, device='cuda:0', dtype=torch.float16) tensor(0.2213, device='cuda:0', dtype=torch.float16)
tensor(2.1289, device='cuda:0', dtype=torch.float16) tensor(0.2139, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0152, device='cuda:0')
tensor(0.0526, device='cuda:0')
old_score: tensor(0.2172, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1112, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.685665130615234
Validation after dual ascent:
out_inf: tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.3137, device='cuda:0', dtype=torch.float16)
tensor(1.3643, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(1.1074, device='cuda:0', dtype=torch.float16) tensor(0.1124, device='cuda:0', dtype=torch.float16)
tensor(1.1973, device='cuda:0', dtype=torch.float16) tensor(0.1200, device='cuda:0', dtype=torch.float16)
tensor(1.2998, device='cuda:0', dtype=torch.float16) tensor(0.1051, device='cuda:0', dtype=torch.float16)
pruning layer 17 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.8633, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(2.5410, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(2.3906, device='cuda:0', dtype=torch.float16) tensor(0.0629, device='cuda:0', dtype=torch.float16)
tensor(2.4160, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(2.4062, device='cuda:0', dtype=torch.float16) tensor(0.0618, device='cuda:0', dtype=torch.float16)
tensor(0.0561, device='cuda:0')
old_score: tensor(0.0623, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0289, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.793553352355957
Validation after dual ascent:
out_inf: tensor(4.8633, device='cuda:0', dtype=torch.float16) tensor(0.1227, device='cuda:0', dtype=torch.float16)
tensor(0.8691, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.7275, device='cuda:0', dtype=torch.float16) tensor(0.0287, device='cuda:0', dtype=torch.float16)
tensor(0.7925, device='cuda:0', dtype=torch.float16) tensor(0.0330, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0264, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.3672, device='cuda:0', dtype=torch.float16) tensor(0.3655, device='cuda:0', dtype=torch.float16)
tensor(4.9727, device='cuda:0', dtype=torch.float16) tensor(0.1971, device='cuda:0', dtype=torch.float16)
tensor(5.2031, device='cuda:0', dtype=torch.float16) tensor(0.1958, device='cuda:0', dtype=torch.float16)
tensor(4.5938, device='cuda:0', dtype=torch.float16) tensor(0.2036, device='cuda:0', dtype=torch.float16)
tensor(5.1328, device='cuda:0', dtype=torch.float16) tensor(0.1957, device='cuda:0', dtype=torch.float16)
tensor(0.0262, device='cuda:0')
old_score: tensor(0.1981, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0983, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.94379711151123
Validation after dual ascent:
out_inf: tensor(8.3672, device='cuda:0', dtype=torch.float16) tensor(0.3655, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.0946, device='cuda:0', dtype=torch.float16)
tensor(2.6328, device='cuda:0', dtype=torch.float16) tensor(0.0993, device='cuda:0', dtype=torch.float16)
tensor(1.6973, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.9883, device='cuda:0', dtype=torch.float16) tensor(0.0925, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.6641, device='cuda:0', dtype=torch.float16) tensor(0.2554, device='cuda:0', dtype=torch.float16)
tensor(3.1465, device='cuda:0', dtype=torch.float16) tensor(0.1796, device='cuda:0', dtype=torch.float16)
tensor(3.5098, device='cuda:0', dtype=torch.float16) tensor(0.1802, device='cuda:0', dtype=torch.float16)
tensor(3.4492, device='cuda:0', dtype=torch.float16) tensor(0.1847, device='cuda:0', dtype=torch.float16)
tensor(3.0059, device='cuda:0', dtype=torch.float16) tensor(0.1785, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0153, device='cuda:0')
tensor(0.0467, device='cuda:0')
old_score: tensor(0.1807, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0947, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.036327123641968
Validation after dual ascent:
out_inf: tensor(5.6641, device='cuda:0', dtype=torch.float16) tensor(0.2554, device='cuda:0', dtype=torch.float16)
tensor(1.3896, device='cuda:0', dtype=torch.float16) tensor(0.0911, device='cuda:0', dtype=torch.float16)
tensor(1.4238, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.7754, device='cuda:0', dtype=torch.float16) tensor(0.1030, device='cuda:0', dtype=torch.float16)
tensor(1.2559, device='cuda:0', dtype=torch.float16) tensor(0.0890, device='cuda:0', dtype=torch.float16)
pruning layer 17 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.7520, device='cuda:0', dtype=torch.float16) tensor(0.1123, device='cuda:0', dtype=torch.float16)
tensor(0.8394, device='cuda:0', dtype=torch.float16) tensor(0.0598, device='cuda:0', dtype=torch.float16)
tensor(0.9443, device='cuda:0', dtype=torch.float16) tensor(0.0596, device='cuda:0', dtype=torch.float16)
tensor(0.8955, device='cuda:0', dtype=torch.float16) tensor(0.0602, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
Converged at iteration 800
tensor(0.0188, device='cuda:0')
tensor(0.0214, device='cuda:0')
old_score: tensor(0.0599, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0373, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 78.6815345287323
Validation after dual ascent:
out_inf: tensor(2.7520, device='cuda:0', dtype=torch.float16) tensor(0.1123, device='cuda:0', dtype=torch.float16)
tensor(0.5083, device='cuda:0', dtype=torch.float16) tensor(0.0358, device='cuda:0', dtype=torch.float16)
tensor(0.4448, device='cuda:0', dtype=torch.float16) tensor(0.0376, device='cuda:0', dtype=torch.float16)
tensor(0.4216, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.3853, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.9062, device='cuda:0', dtype=torch.float16) tensor(0.7979, device='cuda:0', dtype=torch.float16)
tensor(5.7266, device='cuda:0', dtype=torch.float16) tensor(0.3682, device='cuda:0', dtype=torch.float16)
tensor(5.4492, device='cuda:0', dtype=torch.float16) tensor(0.3694, device='cuda:0', dtype=torch.float16)
tensor(5.6641, device='cuda:0', dtype=torch.float16) tensor(0.3860, device='cuda:0', dtype=torch.float16)
tensor(5.1797, device='cuda:0', dtype=torch.float16) tensor(0.3606, device='cuda:0', dtype=torch.float16)
tensor(0.0751, device='cuda:0')
old_score: tensor(0.3708, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1697, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.85164999961853
Validation after dual ascent:
out_inf: tensor(14.9062, device='cuda:0', dtype=torch.float16) tensor(0.7979, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1632, device='cuda:0', dtype=torch.float16)
tensor(1.7598, device='cuda:0', dtype=torch.float16) tensor(0.1711, device='cuda:0', dtype=torch.float16)
tensor(2.2402, device='cuda:0', dtype=torch.float16) tensor(0.1852, device='cuda:0', dtype=torch.float16)
tensor(1.9219, device='cuda:0', dtype=torch.float16) tensor(0.1589, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.1094, device='cuda:0', dtype=torch.float16) tensor(1.0029, device='cuda:0', dtype=torch.float16)
tensor(5.2578, device='cuda:0', dtype=torch.float16) tensor(0.3921, device='cuda:0', dtype=torch.float16)
tensor(5.7461, device='cuda:0', dtype=torch.float16) tensor(0.3921, device='cuda:0', dtype=torch.float16)
tensor(5.3438, device='cuda:0', dtype=torch.float16) tensor(0.4094, device='cuda:0', dtype=torch.float16)
tensor(5.2773, device='cuda:0', dtype=torch.float16) tensor(0.3853, device='cuda:0', dtype=torch.float16)
tensor(0.0815, device='cuda:0')
old_score: tensor(0.3945, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1693, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.875532150268555
Validation after dual ascent:
out_inf: tensor(17.1094, device='cuda:0', dtype=torch.float16) tensor(1.0029, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.1632, device='cuda:0', dtype=torch.float16)
tensor(2.2168, device='cuda:0', dtype=torch.float16) tensor(0.1709, device='cuda:0', dtype=torch.float16)
tensor(2.7969, device='cuda:0', dtype=torch.float16) tensor(0.1847, device='cuda:0', dtype=torch.float16)
tensor(2.0840, device='cuda:0', dtype=torch.float16) tensor(0.1588, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.6016, device='cuda:0', dtype=torch.float16) tensor(0.3411, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.2351, device='cuda:0', dtype=torch.float16)
tensor(2.3594, device='cuda:0', dtype=torch.float16) tensor(0.2347, device='cuda:0', dtype=torch.float16)
tensor(2.4805, device='cuda:0', dtype=torch.float16) tensor(0.2424, device='cuda:0', dtype=torch.float16)
tensor(2.4648, device='cuda:0', dtype=torch.float16) tensor(0.2325, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0169, device='cuda:0')
tensor(0.0519, device='cuda:0')
old_score: tensor(0.2361, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1223, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.699373006820679
Validation after dual ascent:
out_inf: tensor(4.6016, device='cuda:0', dtype=torch.float16) tensor(0.3411, device='cuda:0', dtype=torch.float16)
tensor(1.2842, device='cuda:0', dtype=torch.float16) tensor(0.1180, device='cuda:0', dtype=torch.float16)
tensor(1.1914, device='cuda:0', dtype=torch.float16) tensor(0.1230, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1329, device='cuda:0', dtype=torch.float16)
tensor(1.3311, device='cuda:0', dtype=torch.float16) tensor(0.1150, device='cuda:0', dtype=torch.float16)
pruning layer 18 name self_attn.o_proj
Validation after prune:
out_inf: tensor(5.2969, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(2.0332, device='cuda:0', dtype=torch.float16) tensor(0.0493, device='cuda:0', dtype=torch.float16)
tensor(1.9121, device='cuda:0', dtype=torch.float16) tensor(0.0499, device='cuda:0', dtype=torch.float16)
tensor(2.1621, device='cuda:0', dtype=torch.float16) tensor(0.0543, device='cuda:0', dtype=torch.float16)
tensor(2.1016, device='cuda:0', dtype=torch.float16) tensor(0.0482, device='cuda:0', dtype=torch.float16)
tensor(0.1170, device='cuda:0')
old_score: tensor(0.0504, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0238, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.815912961959839
Validation after dual ascent:
out_inf: tensor(5.2969, device='cuda:0', dtype=torch.float16) tensor(0.1104, device='cuda:0', dtype=torch.float16)
tensor(0.6201, device='cuda:0', dtype=torch.float16) tensor(0.0219, device='cuda:0', dtype=torch.float16)
tensor(0.5547, device='cuda:0', dtype=torch.float16) tensor(0.0237, device='cuda:0', dtype=torch.float16)
tensor(0.7168, device='cuda:0', dtype=torch.float16) tensor(0.0285, device='cuda:0', dtype=torch.float16)
tensor(0.7402, device='cuda:0', dtype=torch.float16) tensor(0.0212, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.2109, device='cuda:0', dtype=torch.float16) tensor(0.3855, device='cuda:0', dtype=torch.float16)
tensor(6.7656, device='cuda:0', dtype=torch.float16) tensor(0.2053, device='cuda:0', dtype=torch.float16)
tensor(7.0508, device='cuda:0', dtype=torch.float16) tensor(0.2026, device='cuda:0', dtype=torch.float16)
tensor(6.6797, device='cuda:0', dtype=torch.float16) tensor(0.2130, device='cuda:0', dtype=torch.float16)
tensor(6.1250, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(0.0288, device='cuda:0')
old_score: tensor(0.2058, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1011, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.7830023765564
Validation after dual ascent:
out_inf: tensor(9.2109, device='cuda:0', dtype=torch.float16) tensor(0.3855, device='cuda:0', dtype=torch.float16)
tensor(2.8828, device='cuda:0', dtype=torch.float16) tensor(0.0975, device='cuda:0', dtype=torch.float16)
tensor(3.4648, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(2.7383, device='cuda:0', dtype=torch.float16) tensor(0.1100, device='cuda:0', dtype=torch.float16)
tensor(2.6523, device='cuda:0', dtype=torch.float16) tensor(0.0950, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.0117, device='cuda:0', dtype=torch.float16) tensor(0.2585, device='cuda:0', dtype=torch.float16)
tensor(3.2227, device='cuda:0', dtype=torch.float16) tensor(0.1847, device='cuda:0', dtype=torch.float16)
tensor(2.9082, device='cuda:0', dtype=torch.float16) tensor(0.1838, device='cuda:0', dtype=torch.float16)
tensor(2.9980, device='cuda:0', dtype=torch.float16) tensor(0.1887, device='cuda:0', dtype=torch.float16)
tensor(3.1875, device='cuda:0', dtype=torch.float16) tensor(0.1827, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0158, device='cuda:0')
tensor(0.0540, device='cuda:0')
old_score: tensor(0.1851, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0959, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.010140895843506
Validation after dual ascent:
out_inf: tensor(6.0117, device='cuda:0', dtype=torch.float16) tensor(0.2585, device='cuda:0', dtype=torch.float16)
tensor(1.2871, device='cuda:0', dtype=torch.float16) tensor(0.0925, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.0968, device='cuda:0', dtype=torch.float16)
tensor(1.3154, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(1.3037, device='cuda:0', dtype=torch.float16) tensor(0.0902, device='cuda:0', dtype=torch.float16)
pruning layer 18 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.4785, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(0.9980, device='cuda:0', dtype=torch.float16) tensor(0.0625, device='cuda:0', dtype=torch.float16)
tensor(1.0176, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(0.9551, device='cuda:0', dtype=torch.float16) tensor(0.0627, device='cuda:0', dtype=torch.float16)
tensor(0.9482, device='cuda:0', dtype=torch.float16) tensor(0.0617, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0136, device='cuda:0')
tensor(0.0260, device='cuda:0')
old_score: tensor(0.0621, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0385, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 64.44184374809265
Validation after dual ascent:
out_inf: tensor(3.4785, device='cuda:0', dtype=torch.float16) tensor(0.1136, device='cuda:0', dtype=torch.float16)
tensor(0.4697, device='cuda:0', dtype=torch.float16) tensor(0.0371, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.5205, device='cuda:0', dtype=torch.float16) tensor(0.0421, device='cuda:0', dtype=torch.float16)
tensor(0.4460, device='cuda:0', dtype=torch.float16) tensor(0.0361, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.6250, device='cuda:0', dtype=torch.float16) tensor(0.7764, device='cuda:0', dtype=torch.float16)
tensor(5.8438, device='cuda:0', dtype=torch.float16) tensor(0.3628, device='cuda:0', dtype=torch.float16)
tensor(5.4180, device='cuda:0', dtype=torch.float16) tensor(0.3608, device='cuda:0', dtype=torch.float16)
tensor(6.6328, device='cuda:0', dtype=torch.float16) tensor(0.3845, device='cuda:0', dtype=torch.float16)
tensor(4.9805, device='cuda:0', dtype=torch.float16) tensor(0.3521, device='cuda:0', dtype=torch.float16)
tensor(0.1029, device='cuda:0')
old_score: tensor(0.3652, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1655, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.8759925365448
Validation after dual ascent:
out_inf: tensor(12.6250, device='cuda:0', dtype=torch.float16) tensor(0.7764, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.1591, device='cuda:0', dtype=torch.float16)
tensor(1.9551, device='cuda:0', dtype=torch.float16) tensor(0.1669, device='cuda:0', dtype=torch.float16)
tensor(2.1445, device='cuda:0', dtype=torch.float16) tensor(0.1814, device='cuda:0', dtype=torch.float16)
tensor(2.0566, device='cuda:0', dtype=torch.float16) tensor(0.1545, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.5000, device='cuda:0', dtype=torch.float16) tensor(1.0605, device='cuda:0', dtype=torch.float16)
tensor(6.0625, device='cuda:0', dtype=torch.float16) tensor(0.3911, device='cuda:0', dtype=torch.float16)
tensor(5.5391, device='cuda:0', dtype=torch.float16) tensor(0.3875, device='cuda:0', dtype=torch.float16)
tensor(5.8125, device='cuda:0', dtype=torch.float16) tensor(0.4067, device='cuda:0', dtype=torch.float16)
tensor(6.1484, device='cuda:0', dtype=torch.float16) tensor(0.3831, device='cuda:0', dtype=torch.float16)
tensor(0.1047, device='cuda:0')
old_score: tensor(0.3921, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1665, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.896345138549805
Validation after dual ascent:
out_inf: tensor(17.5000, device='cuda:0', dtype=torch.float16) tensor(1.0605, device='cuda:0', dtype=torch.float16)
tensor(1.9453, device='cuda:0', dtype=torch.float16) tensor(0.1605, device='cuda:0', dtype=torch.float16)
tensor(1.9092, device='cuda:0', dtype=torch.float16) tensor(0.1680, device='cuda:0', dtype=torch.float16)
tensor(2.2539, device='cuda:0', dtype=torch.float16) tensor(0.1815, device='cuda:0', dtype=torch.float16)
tensor(1.9688, device='cuda:0', dtype=torch.float16) tensor(0.1558, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.v_proj
Validation after prune:
out_inf: tensor(3.3848, device='cuda:0', dtype=torch.float16) tensor(0.3618, device='cuda:0', dtype=torch.float16)
tensor(2.1133, device='cuda:0', dtype=torch.float16) tensor(0.2461, device='cuda:0', dtype=torch.float16)
tensor(2.3008, device='cuda:0', dtype=torch.float16) tensor(0.2448, device='cuda:0', dtype=torch.float16)
tensor(2.1875, device='cuda:0', dtype=torch.float16) tensor(0.2502, device='cuda:0', dtype=torch.float16)
tensor(2.2109, device='cuda:0', dtype=torch.float16) tensor(0.2424, device='cuda:0', dtype=torch.float16)
tensor(0.0685, device='cuda:0')
old_score: tensor(0.2458, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1248, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.901672124862671
Validation after dual ascent:
out_inf: tensor(3.3848, device='cuda:0', dtype=torch.float16) tensor(0.3618, device='cuda:0', dtype=torch.float16)
tensor(1.2002, device='cuda:0', dtype=torch.float16) tensor(0.1205, device='cuda:0', dtype=torch.float16)
tensor(1.2695, device='cuda:0', dtype=torch.float16) tensor(0.1259, device='cuda:0', dtype=torch.float16)
tensor(1.2129, device='cuda:0', dtype=torch.float16) tensor(0.1353, device='cuda:0', dtype=torch.float16)
tensor(1.2725, device='cuda:0', dtype=torch.float16) tensor(0.1173, device='cuda:0', dtype=torch.float16)
pruning layer 19 name self_attn.o_proj
Validation after prune:
out_inf: tensor(6.3320, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(2.6660, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(2.7285, device='cuda:0', dtype=torch.float16) tensor(0.0639, device='cuda:0', dtype=torch.float16)
tensor(2.5449, device='cuda:0', dtype=torch.float16) tensor(0.0605, device='cuda:0', dtype=torch.float16)
tensor(2.3496, device='cuda:0', dtype=torch.float16) tensor(0.0568, device='cuda:0', dtype=torch.float16)
tensor(0.1078, device='cuda:0')
old_score: tensor(0.0602, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0301, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.81398606300354
Validation after dual ascent:
out_inf: tensor(6.3320, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(0.6152, device='cuda:0', dtype=torch.float16) tensor(0.0284, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0312, device='cuda:0', dtype=torch.float16)
tensor(0.7305, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.6875, device='cuda:0', dtype=torch.float16) tensor(0.0267, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.2812, device='cuda:0', dtype=torch.float16) tensor(0.3718, device='cuda:0', dtype=torch.float16)
tensor(5.2500, device='cuda:0', dtype=torch.float16) tensor(0.2086, device='cuda:0', dtype=torch.float16)
tensor(5.8359, device='cuda:0', dtype=torch.float16) tensor(0.2064, device='cuda:0', dtype=torch.float16)
tensor(5.4219, device='cuda:0', dtype=torch.float16) tensor(0.2155, device='cuda:0', dtype=torch.float16)
tensor(6.2852, device='cuda:0', dtype=torch.float16) tensor(0.2052, device='cuda:0', dtype=torch.float16)
tensor(0.0260, device='cuda:0')
old_score: tensor(0.2089, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1039, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.82084393501282
Validation after dual ascent:
out_inf: tensor(8.2812, device='cuda:0', dtype=torch.float16) tensor(0.3718, device='cuda:0', dtype=torch.float16)
tensor(2.0996, device='cuda:0', dtype=torch.float16) tensor(0.1003, device='cuda:0', dtype=torch.float16)
tensor(2.8008, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
tensor(1.9980, device='cuda:0', dtype=torch.float16) tensor(0.1130, device='cuda:0', dtype=torch.float16)
tensor(2.4141, device='cuda:0', dtype=torch.float16) tensor(0.0980, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.7031, device='cuda:0', dtype=torch.float16) tensor(0.2644, device='cuda:0', dtype=torch.float16)
tensor(3.4707, device='cuda:0', dtype=torch.float16) tensor(0.1886, device='cuda:0', dtype=torch.float16)
tensor(4.2734, device='cuda:0', dtype=torch.float16) tensor(0.1877, device='cuda:0', dtype=torch.float16)
tensor(4.4336, device='cuda:0', dtype=torch.float16) tensor(0.1919, device='cuda:0', dtype=torch.float16)
tensor(3.5273, device='cuda:0', dtype=torch.float16) tensor(0.1869, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0162, device='cuda:0')
tensor(0.0594, device='cuda:0')
old_score: tensor(0.1888, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0984, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.019811391830444
Validation after dual ascent:
out_inf: tensor(6.7031, device='cuda:0', dtype=torch.float16) tensor(0.2644, device='cuda:0', dtype=torch.float16)
tensor(1.2734, device='cuda:0', dtype=torch.float16) tensor(0.0951, device='cuda:0', dtype=torch.float16)
tensor(1.3467, device='cuda:0', dtype=torch.float16) tensor(0.0990, device='cuda:0', dtype=torch.float16)
tensor(1.2832, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(1.1660, device='cuda:0', dtype=torch.float16) tensor(0.0927, device='cuda:0', dtype=torch.float16)
pruning layer 19 name mlp.down_proj
Validation after prune:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.1091, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(1.2295, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0615, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0144, device='cuda:0')
tensor(0.0213, device='cuda:0')
old_score: tensor(0.0619, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0392, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 59.73200440406799
Validation after dual ascent:
out_inf: tensor(4.2539, device='cuda:0', dtype=torch.float16) tensor(0.1091, device='cuda:0', dtype=torch.float16)
tensor(0.4121, device='cuda:0', dtype=torch.float16) tensor(0.0378, device='cuda:0', dtype=torch.float16)
tensor(0.4160, device='cuda:0', dtype=torch.float16) tensor(0.0392, device='cuda:0', dtype=torch.float16)
tensor(0.5918, device='cuda:0', dtype=torch.float16) tensor(0.0428, device='cuda:0', dtype=torch.float16)
tensor(0.4141, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14., device='cuda:0', dtype=torch.float16) tensor(0.7676, device='cuda:0', dtype=torch.float16)
tensor(5.4922, device='cuda:0', dtype=torch.float16) tensor(0.3518, device='cuda:0', dtype=torch.float16)
tensor(5.9219, device='cuda:0', dtype=torch.float16) tensor(0.3506, device='cuda:0', dtype=torch.float16)
tensor(5.9609, device='cuda:0', dtype=torch.float16) tensor(0.3706, device='cuda:0', dtype=torch.float16)
tensor(4.6016, device='cuda:0', dtype=torch.float16) tensor(0.3418, device='cuda:0', dtype=torch.float16)
tensor(0.5538, device='cuda:0')
old_score: tensor(0.3535, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1624, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.892719030380249
Validation after dual ascent:
out_inf: tensor(14., device='cuda:0', dtype=torch.float16) tensor(0.7676, device='cuda:0', dtype=torch.float16)
tensor(2.0898, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1636, device='cuda:0', dtype=torch.float16)
tensor(2.5137, device='cuda:0', dtype=torch.float16) tensor(0.1775, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1520, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.7812, device='cuda:0', dtype=torch.float16) tensor(1.0322, device='cuda:0', dtype=torch.float16)
tensor(5.1953, device='cuda:0', dtype=torch.float16) tensor(0.3738, device='cuda:0', dtype=torch.float16)
tensor(5.3477, device='cuda:0', dtype=torch.float16) tensor(0.3745, device='cuda:0', dtype=torch.float16)
tensor(4.6328, device='cuda:0', dtype=torch.float16) tensor(0.3875, device='cuda:0', dtype=torch.float16)
tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.3687, device='cuda:0', dtype=torch.float16)
tensor(0.5352, device='cuda:0')
old_score: tensor(0.3760, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1622, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.910417318344116
Validation after dual ascent:
out_inf: tensor(16.7812, device='cuda:0', dtype=torch.float16) tensor(1.0322, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1565, device='cuda:0', dtype=torch.float16)
tensor(1.8066, device='cuda:0', dtype=torch.float16) tensor(0.1636, device='cuda:0', dtype=torch.float16)
tensor(2.0078, device='cuda:0', dtype=torch.float16) tensor(0.1766, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.1522, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.2266, device='cuda:0', dtype=torch.float16) tensor(0.3367, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.2374, device='cuda:0', dtype=torch.float16)
tensor(2.4414, device='cuda:0', dtype=torch.float16) tensor(0.2357, device='cuda:0', dtype=torch.float16)
tensor(2.6797, device='cuda:0', dtype=torch.float16) tensor(0.2394, device='cuda:0', dtype=torch.float16)
tensor(2.4277, device='cuda:0', dtype=torch.float16) tensor(0.2346, device='cuda:0', dtype=torch.float16)
tensor(0.3507, device='cuda:0')
old_score: tensor(0.2368, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1207, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.887853860855103
Validation after dual ascent:
out_inf: tensor(4.2266, device='cuda:0', dtype=torch.float16) tensor(0.3367, device='cuda:0', dtype=torch.float16)
tensor(1.3594, device='cuda:0', dtype=torch.float16) tensor(0.1167, device='cuda:0', dtype=torch.float16)
tensor(1.3682, device='cuda:0', dtype=torch.float16) tensor(0.1215, device='cuda:0', dtype=torch.float16)
tensor(1.2529, device='cuda:0', dtype=torch.float16) tensor(0.1307, device='cuda:0', dtype=torch.float16)
tensor(1.2275, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
pruning layer 20 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.3516, device='cuda:0', dtype=torch.float16) tensor(0.1711, device='cuda:0', dtype=torch.float16)
tensor(2.4727, device='cuda:0', dtype=torch.float16) tensor(0.0818, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(2.3301, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(2.3828, device='cuda:0', dtype=torch.float16) tensor(0.0780, device='cuda:0', dtype=torch.float16)
tensor(0.0932, device='cuda:0')
old_score: tensor(0.0781, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0348, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.828457355499268
Validation after dual ascent:
out_inf: tensor(11.3516, device='cuda:0', dtype=torch.float16) tensor(0.1711, device='cuda:0', dtype=torch.float16)
tensor(0.7578, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.9355, device='cuda:0', dtype=torch.float16) tensor(0.0365, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0331, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.9062, device='cuda:0', dtype=torch.float16) tensor(0.3735, device='cuda:0', dtype=torch.float16)
tensor(4.6875, device='cuda:0', dtype=torch.float16) tensor(0.2086, device='cuda:0', dtype=torch.float16)
tensor(5.3281, device='cuda:0', dtype=torch.float16) tensor(0.2065, device='cuda:0', dtype=torch.float16)
tensor(4.6719, device='cuda:0', dtype=torch.float16) tensor(0.2153, device='cuda:0', dtype=torch.float16)
tensor(4.8594, device='cuda:0', dtype=torch.float16) tensor(0.2068, device='cuda:0', dtype=torch.float16)
tensor(0.0292, device='cuda:0')
old_score: tensor(0.2092, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1013, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.84642934799194
Validation after dual ascent:
out_inf: tensor(7.9062, device='cuda:0', dtype=torch.float16) tensor(0.3735, device='cuda:0', dtype=torch.float16)
tensor(1.6738, device='cuda:0', dtype=torch.float16) tensor(0.0970, device='cuda:0', dtype=torch.float16)
tensor(1.6836, device='cuda:0', dtype=torch.float16) tensor(0.1017, device='cuda:0', dtype=torch.float16)
tensor(1.6348, device='cuda:0', dtype=torch.float16) tensor(0.1119, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.2383, device='cuda:0', dtype=torch.float16) tensor(0.2629, device='cuda:0', dtype=torch.float16)
tensor(3.2949, device='cuda:0', dtype=torch.float16) tensor(0.1869, device='cuda:0', dtype=torch.float16)
tensor(3.0879, device='cuda:0', dtype=torch.float16) tensor(0.1862, device='cuda:0', dtype=torch.float16)
tensor(2.8711, device='cuda:0', dtype=torch.float16) tensor(0.1915, device='cuda:0', dtype=torch.float16)
tensor(2.8555, device='cuda:0', dtype=torch.float16) tensor(0.1859, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0174, device='cuda:0')
tensor(0.0509, device='cuda:0')
old_score: tensor(0.1876, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0953, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.02191686630249
Validation after dual ascent:
out_inf: tensor(4.2383, device='cuda:0', dtype=torch.float16) tensor(0.2629, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.0912, device='cuda:0', dtype=torch.float16)
tensor(1.2266, device='cuda:0', dtype=torch.float16) tensor(0.0956, device='cuda:0', dtype=torch.float16)
tensor(1.3516, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
tensor(1.1641, device='cuda:0', dtype=torch.float16) tensor(0.0892, device='cuda:0', dtype=torch.float16)
pruning layer 20 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.9180, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(0.9395, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(1.0029, device='cuda:0', dtype=torch.float16) tensor(0.0594, device='cuda:0', dtype=torch.float16)
tensor(1.1055, device='cuda:0', dtype=torch.float16) tensor(0.0613, device='cuda:0', dtype=torch.float16)
tensor(0.9570, device='cuda:0', dtype=torch.float16) tensor(0.0601, device='cuda:0', dtype=torch.float16)
Converged at iteration 650
tensor(0.0129, device='cuda:0')
tensor(0.0191, device='cuda:0')
old_score: tensor(0.0602, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0370, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 64.52405977249146
Validation after dual ascent:
out_inf: tensor(3.9180, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(0.4370, device='cuda:0', dtype=torch.float16) tensor(0.0352, device='cuda:0', dtype=torch.float16)
tensor(0.4609, device='cuda:0', dtype=torch.float16) tensor(0.0368, device='cuda:0', dtype=torch.float16)
tensor(0.6055, device='cuda:0', dtype=torch.float16) tensor(0.0413, device='cuda:0', dtype=torch.float16)
tensor(0.4102, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.q_proj
Validation after prune:
out_inf: tensor(15.3828, device='cuda:0', dtype=torch.float16) tensor(0.7661, device='cuda:0', dtype=torch.float16)
tensor(6.8789, device='cuda:0', dtype=torch.float16) tensor(0.3523, device='cuda:0', dtype=torch.float16)
tensor(6.3242, device='cuda:0', dtype=torch.float16) tensor(0.3503, device='cuda:0', dtype=torch.float16)
tensor(6.3555, device='cuda:0', dtype=torch.float16) tensor(0.3733, device='cuda:0', dtype=torch.float16)
tensor(5.5312, device='cuda:0', dtype=torch.float16) tensor(0.3423, device='cuda:0', dtype=torch.float16)
tensor(0.0846, device='cuda:0')
old_score: tensor(0.3545, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1573, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.876349687576294
Validation after dual ascent:
out_inf: tensor(15.3828, device='cuda:0', dtype=torch.float16) tensor(0.7661, device='cuda:0', dtype=torch.float16)
tensor(1.8164, device='cuda:0', dtype=torch.float16) tensor(0.1505, device='cuda:0', dtype=torch.float16)
tensor(1.9932, device='cuda:0', dtype=torch.float16) tensor(0.1572, device='cuda:0', dtype=torch.float16)
tensor(2.2676, device='cuda:0', dtype=torch.float16) tensor(0.1757, device='cuda:0', dtype=torch.float16)
tensor(2.0879, device='cuda:0', dtype=torch.float16) tensor(0.1460, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.4375, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(6.1875, device='cuda:0', dtype=torch.float16) tensor(0.3687, device='cuda:0', dtype=torch.float16)
tensor(5.3438, device='cuda:0', dtype=torch.float16) tensor(0.3640, device='cuda:0', dtype=torch.float16)
tensor(5.6758, device='cuda:0', dtype=torch.float16) tensor(0.3840, device='cuda:0', dtype=torch.float16)
tensor(5.1094, device='cuda:0', dtype=torch.float16) tensor(0.3596, device='cuda:0', dtype=torch.float16)
tensor(0.1009, device='cuda:0')
old_score: tensor(0.3689, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1571, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.903179168701172
Validation after dual ascent:
out_inf: tensor(17.4375, device='cuda:0', dtype=torch.float16) tensor(1.0049, device='cuda:0', dtype=torch.float16)
tensor(1.9707, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
tensor(1.9023, device='cuda:0', dtype=torch.float16) tensor(0.1572, device='cuda:0', dtype=torch.float16)
tensor(2.1953, device='cuda:0', dtype=torch.float16) tensor(0.1743, device='cuda:0', dtype=torch.float16)
tensor(2.0156, device='cuda:0', dtype=torch.float16) tensor(0.1461, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.9336, device='cuda:0', dtype=torch.float16) tensor(0.3687, device='cuda:0', dtype=torch.float16)
tensor(2.7832, device='cuda:0', dtype=torch.float16) tensor(0.2544, device='cuda:0', dtype=torch.float16)
tensor(2.6230, device='cuda:0', dtype=torch.float16) tensor(0.2510, device='cuda:0', dtype=torch.float16)
tensor(2.7363, device='cuda:0', dtype=torch.float16) tensor(0.2593, device='cuda:0', dtype=torch.float16)
tensor(2.9512, device='cuda:0', dtype=torch.float16) tensor(0.2517, device='cuda:0', dtype=torch.float16)
tensor(0.0492, device='cuda:0')
old_score: tensor(0.2542, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1266, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.887491226196289
Validation after dual ascent:
out_inf: tensor(4.9336, device='cuda:0', dtype=torch.float16) tensor(0.3687, device='cuda:0', dtype=torch.float16)
tensor(1.2139, device='cuda:0', dtype=torch.float16) tensor(0.1217, device='cuda:0', dtype=torch.float16)
tensor(1.1650, device='cuda:0', dtype=torch.float16) tensor(0.1266, device='cuda:0', dtype=torch.float16)
tensor(1.2822, device='cuda:0', dtype=torch.float16) tensor(0.1398, device='cuda:0', dtype=torch.float16)
tensor(1.3281, device='cuda:0', dtype=torch.float16) tensor(0.1182, device='cuda:0', dtype=torch.float16)
pruning layer 21 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.7891, device='cuda:0', dtype=torch.float16) tensor(0.1782, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.0718, device='cuda:0', dtype=torch.float16)
tensor(2.1367, device='cuda:0', dtype=torch.float16) tensor(0.0700, device='cuda:0', dtype=torch.float16)
tensor(2.6309, device='cuda:0', dtype=torch.float16) tensor(0.0717, device='cuda:0', dtype=torch.float16)
tensor(2.2012, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
tensor(0.1916, device='cuda:0')
old_score: tensor(0.0714, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0338, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.80851435661316
Validation after dual ascent:
out_inf: tensor(4.7891, device='cuda:0', dtype=torch.float16) tensor(0.1782, device='cuda:0', dtype=torch.float16)
tensor(0.5605, device='cuda:0', dtype=torch.float16) tensor(0.0323, device='cuda:0', dtype=torch.float16)
tensor(0.8320, device='cuda:0', dtype=torch.float16) tensor(0.0332, device='cuda:0', dtype=torch.float16)
tensor(0.6094, device='cuda:0', dtype=torch.float16) tensor(0.0385, device='cuda:0', dtype=torch.float16)
tensor(0.7485, device='cuda:0', dtype=torch.float16) tensor(0.0315, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.2656, device='cuda:0', dtype=torch.float16) tensor(0.3757, device='cuda:0', dtype=torch.float16)
tensor(4.9688, device='cuda:0', dtype=torch.float16) tensor(0.2159, device='cuda:0', dtype=torch.float16)
tensor(3.7910, device='cuda:0', dtype=torch.float16) tensor(0.2135, device='cuda:0', dtype=torch.float16)
tensor(4.8906, device='cuda:0', dtype=torch.float16) tensor(0.2233, device='cuda:0', dtype=torch.float16)
tensor(3.6309, device='cuda:0', dtype=torch.float16) tensor(0.2131, device='cuda:0', dtype=torch.float16)
tensor(0.0309, device='cuda:0')
old_score: tensor(0.2166, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1040, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.829397439956665
Validation after dual ascent:
out_inf: tensor(8.2656, device='cuda:0', dtype=torch.float16) tensor(0.3757, device='cuda:0', dtype=torch.float16)
tensor(1.7500, device='cuda:0', dtype=torch.float16) tensor(0.0993, device='cuda:0', dtype=torch.float16)
tensor(1.9062, device='cuda:0', dtype=torch.float16) tensor(0.1041, device='cuda:0', dtype=torch.float16)
tensor(1.7148, device='cuda:0', dtype=torch.float16) tensor(0.1159, device='cuda:0', dtype=torch.float16)
tensor(2.0547, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.4141, device='cuda:0', dtype=torch.float16) tensor(0.2693, device='cuda:0', dtype=torch.float16)
tensor(2.9492, device='cuda:0', dtype=torch.float16) tensor(0.1929, device='cuda:0', dtype=torch.float16)
tensor(2.7734, device='cuda:0', dtype=torch.float16) tensor(0.1904, device='cuda:0', dtype=torch.float16)
tensor(3.2910, device='cuda:0', dtype=torch.float16) tensor(0.1970, device='cuda:0', dtype=torch.float16)
tensor(3.1719, device='cuda:0', dtype=torch.float16) tensor(0.1910, device='cuda:0', dtype=torch.float16)
Converged at iteration 200
tensor(0.0193, device='cuda:0')
tensor(0.0568, device='cuda:0')
old_score: tensor(0.1927, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0971, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.022935152053833
Validation after dual ascent:
out_inf: tensor(5.4141, device='cuda:0', dtype=torch.float16) tensor(0.2693, device='cuda:0', dtype=torch.float16)
tensor(1.1211, device='cuda:0', dtype=torch.float16) tensor(0.0926, device='cuda:0', dtype=torch.float16)
tensor(1.5889, device='cuda:0', dtype=torch.float16) tensor(0.0973, device='cuda:0', dtype=torch.float16)
tensor(1.3252, device='cuda:0', dtype=torch.float16) tensor(0.1082, device='cuda:0', dtype=torch.float16)
tensor(1.2061, device='cuda:0', dtype=torch.float16) tensor(0.0903, device='cuda:0', dtype=torch.float16)
pruning layer 21 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.9873, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(0.9707, device='cuda:0', dtype=torch.float16) tensor(0.0603, device='cuda:0', dtype=torch.float16)
tensor(0.9082, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(1.0059, device='cuda:0', dtype=torch.float16) tensor(0.0615, device='cuda:0', dtype=torch.float16)
tensor(1.0312, device='cuda:0', dtype=torch.float16) tensor(0.0600, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0166, device='cuda:0')
tensor(0.0226, device='cuda:0')
old_score: tensor(0.0602, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0372, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 59.751176595687866
Validation after dual ascent:
out_inf: tensor(1.9873, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(0.4324, device='cuda:0', dtype=torch.float16) tensor(0.0354, device='cuda:0', dtype=torch.float16)
tensor(0.3716, device='cuda:0', dtype=torch.float16) tensor(0.0369, device='cuda:0', dtype=torch.float16)
tensor(0.4280, device='cuda:0', dtype=torch.float16) tensor(0.0420, device='cuda:0', dtype=torch.float16)
tensor(0.3989, device='cuda:0', dtype=torch.float16) tensor(0.0346, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.q_proj
Validation after prune:
out_inf: tensor(16.8125, device='cuda:0', dtype=torch.float16) tensor(0.8213, device='cuda:0', dtype=torch.float16)
tensor(5.2031, device='cuda:0', dtype=torch.float16) tensor(0.3684, device='cuda:0', dtype=torch.float16)
tensor(5.6992, device='cuda:0', dtype=torch.float16) tensor(0.3691, device='cuda:0', dtype=torch.float16)
tensor(6.1133, device='cuda:0', dtype=torch.float16) tensor(0.3918, device='cuda:0', dtype=torch.float16)
tensor(5.1562, device='cuda:0', dtype=torch.float16) tensor(0.3599, device='cuda:0', dtype=torch.float16)
tensor(0.0739, device='cuda:0')
old_score: tensor(0.3721, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1638, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.879388570785522
Validation after dual ascent:
out_inf: tensor(16.8125, device='cuda:0', dtype=torch.float16) tensor(0.8213, device='cuda:0', dtype=torch.float16)
tensor(1.9883, device='cuda:0', dtype=torch.float16) tensor(0.1560, device='cuda:0', dtype=torch.float16)
tensor(1.9385, device='cuda:0', dtype=torch.float16) tensor(0.1642, device='cuda:0', dtype=torch.float16)
tensor(2.3086, device='cuda:0', dtype=torch.float16) tensor(0.1836, device='cuda:0', dtype=torch.float16)
tensor(2.2617, device='cuda:0', dtype=torch.float16) tensor(0.1514, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.k_proj
Validation after prune:
out_inf: tensor(20.3594, device='cuda:0', dtype=torch.float16) tensor(1.0322, device='cuda:0', dtype=torch.float16)
tensor(5.3438, device='cuda:0', dtype=torch.float16) tensor(0.3823, device='cuda:0', dtype=torch.float16)
tensor(5.1562, device='cuda:0', dtype=torch.float16) tensor(0.3823, device='cuda:0', dtype=torch.float16)
tensor(5.5898, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(5.3672, device='cuda:0', dtype=torch.float16) tensor(0.3757, device='cuda:0', dtype=torch.float16)
tensor(0.0847, device='cuda:0')
old_score: tensor(0.3850, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1627, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.90322208404541
Validation after dual ascent:
out_inf: tensor(20.3594, device='cuda:0', dtype=torch.float16) tensor(1.0322, device='cuda:0', dtype=torch.float16)
tensor(2.0801, device='cuda:0', dtype=torch.float16) tensor(0.1554, device='cuda:0', dtype=torch.float16)
tensor(1.9160, device='cuda:0', dtype=torch.float16) tensor(0.1628, device='cuda:0', dtype=torch.float16)
tensor(2.0586, device='cuda:0', dtype=torch.float16) tensor(0.1816, device='cuda:0', dtype=torch.float16)
tensor(1.9150, device='cuda:0', dtype=torch.float16) tensor(0.1508, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.6055, device='cuda:0', dtype=torch.float16) tensor(0.3809, device='cuda:0', dtype=torch.float16)
tensor(3.1895, device='cuda:0', dtype=torch.float16) tensor(0.2615, device='cuda:0', dtype=torch.float16)
tensor(3.2910, device='cuda:0', dtype=torch.float16) tensor(0.2571, device='cuda:0', dtype=torch.float16)
tensor(2.5195, device='cuda:0', dtype=torch.float16) tensor(0.2678, device='cuda:0', dtype=torch.float16)
tensor(2.9258, device='cuda:0', dtype=torch.float16) tensor(0.2583, device='cuda:0', dtype=torch.float16)
Converged at iteration 850
tensor(0.0172, device='cuda:0')
tensor(0.0489, device='cuda:0')
old_score: tensor(0.2612, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1276, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 12.70152235031128
Validation after dual ascent:
out_inf: tensor(5.6055, device='cuda:0', dtype=torch.float16) tensor(0.3809, device='cuda:0', dtype=torch.float16)
tensor(1.3945, device='cuda:0', dtype=torch.float16) tensor(0.1219, device='cuda:0', dtype=torch.float16)
tensor(1.5938, device='cuda:0', dtype=torch.float16) tensor(0.1281, device='cuda:0', dtype=torch.float16)
tensor(1.3125, device='cuda:0', dtype=torch.float16) tensor(0.1418, device='cuda:0', dtype=torch.float16)
tensor(1.2549, device='cuda:0', dtype=torch.float16) tensor(0.1186, device='cuda:0', dtype=torch.float16)
pruning layer 22 name self_attn.o_proj
Validation after prune:
out_inf: tensor(10.6016, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(1.5625, device='cuda:0', dtype=torch.float16) tensor(0.0710, device='cuda:0', dtype=torch.float16)
tensor(1.4844, device='cuda:0', dtype=torch.float16) tensor(0.0671, device='cuda:0', dtype=torch.float16)
tensor(1.7891, device='cuda:0', dtype=torch.float16) tensor(0.0732, device='cuda:0', dtype=torch.float16)
tensor(1.2812, device='cuda:0', dtype=torch.float16) tensor(0.0720, device='cuda:0', dtype=torch.float16)
tensor(0.1972, device='cuda:0')
old_score: tensor(0.0709, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0351, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.8172447681427
Validation after dual ascent:
out_inf: tensor(10.6016, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(0.6484, device='cuda:0', dtype=torch.float16) tensor(0.0329, device='cuda:0', dtype=torch.float16)
tensor(0.7109, device='cuda:0', dtype=torch.float16) tensor(0.0339, device='cuda:0', dtype=torch.float16)
tensor(0.6172, device='cuda:0', dtype=torch.float16) tensor(0.0407, device='cuda:0', dtype=torch.float16)
tensor(0.9785, device='cuda:0', dtype=torch.float16) tensor(0.0328, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.gate_proj
Validation after prune:
out_inf: tensor(8.7266, device='cuda:0', dtype=torch.float16) tensor(0.3611, device='cuda:0', dtype=torch.float16)
tensor(5.8594, device='cuda:0', dtype=torch.float16) tensor(0.2139, device='cuda:0', dtype=torch.float16)
tensor(4.1953, device='cuda:0', dtype=torch.float16) tensor(0.2106, device='cuda:0', dtype=torch.float16)
tensor(4.4844, device='cuda:0', dtype=torch.float16) tensor(0.2203, device='cuda:0', dtype=torch.float16)
tensor(4.3125, device='cuda:0', dtype=torch.float16) tensor(0.2122, device='cuda:0', dtype=torch.float16)
tensor(0.0299, device='cuda:0')
old_score: tensor(0.2141, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1037, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.81755566596985
Validation after dual ascent:
out_inf: tensor(8.7266, device='cuda:0', dtype=torch.float16) tensor(0.3611, device='cuda:0', dtype=torch.float16)
tensor(2.4336, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(1.7109, device='cuda:0', dtype=torch.float16) tensor(0.1037, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.1158, device='cuda:0', dtype=torch.float16)
tensor(2.3242, device='cuda:0', dtype=torch.float16) tensor(0.0965, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.9453, device='cuda:0', dtype=torch.float16) tensor(0.2678, device='cuda:0', dtype=torch.float16)
tensor(2.6406, device='cuda:0', dtype=torch.float16) tensor(0.1910, device='cuda:0', dtype=torch.float16)
tensor(2.6367, device='cuda:0', dtype=torch.float16) tensor(0.1870, device='cuda:0', dtype=torch.float16)
tensor(3.2227, device='cuda:0', dtype=torch.float16) tensor(0.1958, device='cuda:0', dtype=torch.float16)
tensor(2.4453, device='cuda:0', dtype=torch.float16) tensor(0.1897, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0177, device='cuda:0')
tensor(0.0189, device='cuda:0')
old_score: tensor(0.1909, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0959, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.939817428588867
Validation after dual ascent:
out_inf: tensor(4.9453, device='cuda:0', dtype=torch.float16) tensor(0.2678, device='cuda:0', dtype=torch.float16)
tensor(1.2031, device='cuda:0', dtype=torch.float16) tensor(0.0914, device='cuda:0', dtype=torch.float16)
tensor(1.0508, device='cuda:0', dtype=torch.float16) tensor(0.0958, device='cuda:0', dtype=torch.float16)
tensor(1.3047, device='cuda:0', dtype=torch.float16) tensor(0.1073, device='cuda:0', dtype=torch.float16)
tensor(1.2656, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
pruning layer 22 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(0.7119, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.8096, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.7114, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
tensor(0.7593, device='cuda:0', dtype=torch.float16) tensor(0.0589, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0130, device='cuda:0')
tensor(0.0191, device='cuda:0')
old_score: tensor(0.0587, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0367, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 59.64037370681763
Validation after dual ascent:
out_inf: tensor(1.6816, device='cuda:0', dtype=torch.float16) tensor(0.1007, device='cuda:0', dtype=torch.float16)
tensor(0.4111, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
tensor(0.4404, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(0.4465, device='cuda:0', dtype=torch.float16) tensor(0.0418, device='cuda:0', dtype=torch.float16)
tensor(0.3555, device='cuda:0', dtype=torch.float16) tensor(0.0340, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.2578, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(4.9688, device='cuda:0', dtype=torch.float16) tensor(0.3579, device='cuda:0', dtype=torch.float16)
tensor(4.5742, device='cuda:0', dtype=torch.float16) tensor(0.3589, device='cuda:0', dtype=torch.float16)
tensor(5.2852, device='cuda:0', dtype=torch.float16) tensor(0.3777, device='cuda:0', dtype=torch.float16)
tensor(4.3398, device='cuda:0', dtype=torch.float16) tensor(0.3523, device='cuda:0', dtype=torch.float16)
tensor(0.1221, device='cuda:0')
old_score: tensor(0.3618, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1608, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.835418224334717
Validation after dual ascent:
out_inf: tensor(14.2578, device='cuda:0', dtype=torch.float16) tensor(0.7959, device='cuda:0', dtype=torch.float16)
tensor(2.1953, device='cuda:0', dtype=torch.float16) tensor(0.1523, device='cuda:0', dtype=torch.float16)
tensor(1.8320, device='cuda:0', dtype=torch.float16) tensor(0.1614, device='cuda:0', dtype=torch.float16)
tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1810, device='cuda:0', dtype=torch.float16)
tensor(1.8926, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.0781, device='cuda:0', dtype=torch.float16) tensor(0.9595, device='cuda:0', dtype=torch.float16)
tensor(4.5859, device='cuda:0', dtype=torch.float16) tensor(0.3650, device='cuda:0', dtype=torch.float16)
tensor(5.1602, device='cuda:0', dtype=torch.float16) tensor(0.3672, device='cuda:0', dtype=torch.float16)
tensor(5.3125, device='cuda:0', dtype=torch.float16) tensor(0.3806, device='cuda:0', dtype=torch.float16)
tensor(5.1719, device='cuda:0', dtype=torch.float16) tensor(0.3618, device='cuda:0', dtype=torch.float16)
tensor(0.1291, device='cuda:0')
old_score: tensor(0.3687, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1606, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.856836557388306
Validation after dual ascent:
out_inf: tensor(17.0781, device='cuda:0', dtype=torch.float16) tensor(0.9595, device='cuda:0', dtype=torch.float16)
tensor(1.6865, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
tensor(1.6943, device='cuda:0', dtype=torch.float16) tensor(0.1614, device='cuda:0', dtype=torch.float16)
tensor(2.0352, device='cuda:0', dtype=torch.float16) tensor(0.1799, device='cuda:0', dtype=torch.float16)
tensor(1.6953, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.3555, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(2.7891, device='cuda:0', dtype=torch.float16) tensor(0.2759, device='cuda:0', dtype=torch.float16)
tensor(2.8457, device='cuda:0', dtype=torch.float16) tensor(0.2717, device='cuda:0', dtype=torch.float16)
tensor(2.7520, device='cuda:0', dtype=torch.float16) tensor(0.2817, device='cuda:0', dtype=torch.float16)
tensor(2.9883, device='cuda:0', dtype=torch.float16) tensor(0.2734, device='cuda:0', dtype=torch.float16)
tensor(0.0910, device='cuda:0')
old_score: tensor(0.2759, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1348, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.872545003890991
Validation after dual ascent:
out_inf: tensor(4.3555, device='cuda:0', dtype=torch.float16) tensor(0.3989, device='cuda:0', dtype=torch.float16)
tensor(1.7822, device='cuda:0', dtype=torch.float16) tensor(0.1283, device='cuda:0', dtype=torch.float16)
tensor(1.3467, device='cuda:0', dtype=torch.float16) tensor(0.1353, device='cuda:0', dtype=torch.float16)
tensor(1.4326, device='cuda:0', dtype=torch.float16) tensor(0.1503, device='cuda:0', dtype=torch.float16)
tensor(1.4883, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
pruning layer 23 name self_attn.o_proj
Validation after prune:
out_inf: tensor(8.7266, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.0560, device='cuda:0', dtype=torch.float16)
tensor(2.1328, device='cuda:0', dtype=torch.float16) tensor(0.0518, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.0515, device='cuda:0', dtype=torch.float16)
tensor(2.3398, device='cuda:0', dtype=torch.float16) tensor(0.0521, device='cuda:0', dtype=torch.float16)
tensor(0.2469, device='cuda:0')
old_score: tensor(0.0529, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0275, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.78557825088501
Validation after dual ascent:
out_inf: tensor(8.7266, device='cuda:0', dtype=torch.float16) tensor(0.1622, device='cuda:0', dtype=torch.float16)
tensor(0.9697, device='cuda:0', dtype=torch.float16) tensor(0.0280, device='cuda:0', dtype=torch.float16)
tensor(0.8203, device='cuda:0', dtype=torch.float16) tensor(0.0274, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.0291, device='cuda:0', dtype=torch.float16)
tensor(1.4004, device='cuda:0', dtype=torch.float16) tensor(0.0255, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.8633, device='cuda:0', dtype=torch.float16) tensor(0.3665, device='cuda:0', dtype=torch.float16)
tensor(4.3359, device='cuda:0', dtype=torch.float16) tensor(0.2161, device='cuda:0', dtype=torch.float16)
tensor(3.7188, device='cuda:0', dtype=torch.float16) tensor(0.2125, device='cuda:0', dtype=torch.float16)
tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.2252, device='cuda:0', dtype=torch.float16)
tensor(3.7324, device='cuda:0', dtype=torch.float16) tensor(0.2134, device='cuda:0', dtype=torch.float16)
tensor(0.0314, device='cuda:0')
old_score: tensor(0.2168, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1037, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.922019243240356
Validation after dual ascent:
out_inf: tensor(6.8633, device='cuda:0', dtype=torch.float16) tensor(0.3665, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.0988, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1037, device='cuda:0', dtype=torch.float16)
tensor(2.8926, device='cuda:0', dtype=torch.float16) tensor(0.1167, device='cuda:0', dtype=torch.float16)
tensor(1.7568, device='cuda:0', dtype=torch.float16) tensor(0.0954, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.7188, device='cuda:0', dtype=torch.float16) tensor(0.2712, device='cuda:0', dtype=torch.float16)
tensor(2.5645, device='cuda:0', dtype=torch.float16) tensor(0.1946, device='cuda:0', dtype=torch.float16)
tensor(2.6133, device='cuda:0', dtype=torch.float16) tensor(0.1903, device='cuda:0', dtype=torch.float16)
tensor(2.5508, device='cuda:0', dtype=torch.float16) tensor(0.2009, device='cuda:0', dtype=torch.float16)
tensor(2.6035, device='cuda:0', dtype=torch.float16) tensor(0.1924, device='cuda:0', dtype=torch.float16)
Converged at iteration 250
tensor(0.0184, device='cuda:0')
tensor(0.0191, device='cuda:0')
old_score: tensor(0.1946, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0963, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 9.970580816268921
Validation after dual ascent:
out_inf: tensor(4.7188, device='cuda:0', dtype=torch.float16) tensor(0.2712, device='cuda:0', dtype=torch.float16)
tensor(0.9990, device='cuda:0', dtype=torch.float16) tensor(0.0918, device='cuda:0', dtype=torch.float16)
tensor(1.1016, device='cuda:0', dtype=torch.float16) tensor(0.0964, device='cuda:0', dtype=torch.float16)
tensor(1.3779, device='cuda:0', dtype=torch.float16) tensor(0.1084, device='cuda:0', dtype=torch.float16)
tensor(1.1797, device='cuda:0', dtype=torch.float16) tensor(0.0886, device='cuda:0', dtype=torch.float16)
pruning layer 23 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.3730, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.7441, device='cuda:0', dtype=torch.float16) tensor(0.0609, device='cuda:0', dtype=torch.float16)
tensor(0.7729, device='cuda:0', dtype=torch.float16) tensor(0.0583, device='cuda:0', dtype=torch.float16)
tensor(0.7803, device='cuda:0', dtype=torch.float16) tensor(0.0628, device='cuda:0', dtype=torch.float16)
tensor(0.6543, device='cuda:0', dtype=torch.float16) tensor(0.0599, device='cuda:0', dtype=torch.float16)
Converged at iteration 600
tensor(0.0125, device='cuda:0')
tensor(0.0182, device='cuda:0')
old_score: tensor(0.0605, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0374, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 59.61753249168396
Validation after dual ascent:
out_inf: tensor(2.3730, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(0.4331, device='cuda:0', dtype=torch.float16) tensor(0.0356, device='cuda:0', dtype=torch.float16)
tensor(0.4292, device='cuda:0', dtype=torch.float16) tensor(0.0366, device='cuda:0', dtype=torch.float16)
tensor(0.4727, device='cuda:0', dtype=torch.float16) tensor(0.0432, device='cuda:0', dtype=torch.float16)
tensor(0.4028, device='cuda:0', dtype=torch.float16) tensor(0.0341, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.9922, device='cuda:0', dtype=torch.float16) tensor(0.7607, device='cuda:0', dtype=torch.float16)
tensor(4.6797, device='cuda:0', dtype=torch.float16) tensor(0.3411, device='cuda:0', dtype=torch.float16)
tensor(6.0430, device='cuda:0', dtype=torch.float16) tensor(0.3442, device='cuda:0', dtype=torch.float16)
tensor(6.8906, device='cuda:0', dtype=torch.float16) tensor(0.3721, device='cuda:0', dtype=torch.float16)
tensor(5.4062, device='cuda:0', dtype=torch.float16) tensor(0.3330, device='cuda:0', dtype=torch.float16)
tensor(0.1057, device='cuda:0')
old_score: tensor(0.3477, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1543, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.81989312171936
Validation after dual ascent:
out_inf: tensor(13.9922, device='cuda:0', dtype=torch.float16) tensor(0.7607, device='cuda:0', dtype=torch.float16)
tensor(2.0273, device='cuda:0', dtype=torch.float16) tensor(0.1458, device='cuda:0', dtype=torch.float16)
tensor(2.2148, device='cuda:0', dtype=torch.float16) tensor(0.1547, device='cuda:0', dtype=torch.float16)
tensor(2.2988, device='cuda:0', dtype=torch.float16) tensor(0.1755, device='cuda:0', dtype=torch.float16)
tensor(1.9844, device='cuda:0', dtype=torch.float16) tensor(0.1412, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.1562, device='cuda:0', dtype=torch.float16) tensor(0.9966, device='cuda:0', dtype=torch.float16)
tensor(5.1016, device='cuda:0', dtype=torch.float16) tensor(0.3530, device='cuda:0', dtype=torch.float16)
tensor(5.4297, device='cuda:0', dtype=torch.float16) tensor(0.3545, device='cuda:0', dtype=torch.float16)
tensor(5.8164, device='cuda:0', dtype=torch.float16) tensor(0.3757, device='cuda:0', dtype=torch.float16)
tensor(5.3477, device='cuda:0', dtype=torch.float16) tensor(0.3467, device='cuda:0', dtype=torch.float16)
tensor(0.1056, device='cuda:0')
old_score: tensor(0.3574, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1531, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.836541891098022
Validation after dual ascent:
out_inf: tensor(16.1562, device='cuda:0', dtype=torch.float16) tensor(0.9966, device='cuda:0', dtype=torch.float16)
tensor(1.9199, device='cuda:0', dtype=torch.float16) tensor(0.1451, device='cuda:0', dtype=torch.float16)
tensor(2.1367, device='cuda:0', dtype=torch.float16) tensor(0.1534, device='cuda:0', dtype=torch.float16)
tensor(2.2383, device='cuda:0', dtype=torch.float16) tensor(0.1730, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1404, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.5195, device='cuda:0', dtype=torch.float16) tensor(0.4043, device='cuda:0', dtype=torch.float16)
tensor(2.9688, device='cuda:0', dtype=torch.float16) tensor(0.2712, device='cuda:0', dtype=torch.float16)
tensor(2.9023, device='cuda:0', dtype=torch.float16) tensor(0.2664, device='cuda:0', dtype=torch.float16)
tensor(2.8828, device='cuda:0', dtype=torch.float16) tensor(0.2815, device='cuda:0', dtype=torch.float16)
tensor(3.3945, device='cuda:0', dtype=torch.float16) tensor(0.2683, device='cuda:0', dtype=torch.float16)
tensor(0.0664, device='cuda:0')
old_score: tensor(0.2720, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1316, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.852071762084961
Validation after dual ascent:
out_inf: tensor(4.5195, device='cuda:0', dtype=torch.float16) tensor(0.4043, device='cuda:0', dtype=torch.float16)
tensor(1.3438, device='cuda:0', dtype=torch.float16) tensor(0.1252, device='cuda:0', dtype=torch.float16)
tensor(1.3398, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(1.3506, device='cuda:0', dtype=torch.float16) tensor(0.1479, device='cuda:0', dtype=torch.float16)
tensor(1.2090, device='cuda:0', dtype=torch.float16) tensor(0.1213, device='cuda:0', dtype=torch.float16)
pruning layer 24 name self_attn.o_proj
Validation after prune:
out_inf: tensor(11.7266, device='cuda:0', dtype=torch.float16) tensor(0.1824, device='cuda:0', dtype=torch.float16)
tensor(1.8867, device='cuda:0', dtype=torch.float16) tensor(0.0758, device='cuda:0', dtype=torch.float16)
tensor(2.0664, device='cuda:0', dtype=torch.float16) tensor(0.0739, device='cuda:0', dtype=torch.float16)
tensor(2.0391, device='cuda:0', dtype=torch.float16) tensor(0.0884, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.0786, device='cuda:0', dtype=torch.float16)
tensor(0.2210, device='cuda:0')
old_score: tensor(0.0792, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0387, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.782458305358887
Validation after dual ascent:
out_inf: tensor(11.7266, device='cuda:0', dtype=torch.float16) tensor(0.1824, device='cuda:0', dtype=torch.float16)
tensor(0.6836, device='cuda:0', dtype=torch.float16) tensor(0.0345, device='cuda:0', dtype=torch.float16)
tensor(0.5645, device='cuda:0', dtype=torch.float16) tensor(0.0380, device='cuda:0', dtype=torch.float16)
tensor(0.6953, device='cuda:0', dtype=torch.float16) tensor(0.0474, device='cuda:0', dtype=torch.float16)
tensor(0.6992, device='cuda:0', dtype=torch.float16) tensor(0.0350, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.gate_proj
Validation after prune:
out_inf: tensor(9.0156, device='cuda:0', dtype=torch.float16) tensor(0.3877, device='cuda:0', dtype=torch.float16)
tensor(5.0703, device='cuda:0', dtype=torch.float16) tensor(0.2264, device='cuda:0', dtype=torch.float16)
tensor(4.3203, device='cuda:0', dtype=torch.float16) tensor(0.2219, device='cuda:0', dtype=torch.float16)
tensor(6.2383, device='cuda:0', dtype=torch.float16) tensor(0.2341, device='cuda:0', dtype=torch.float16)
tensor(4.5703, device='cuda:0', dtype=torch.float16) tensor(0.2239, device='cuda:0', dtype=torch.float16)
tensor(0.0357, device='cuda:0')
old_score: tensor(0.2266, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1063, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.846884965896606
Validation after dual ascent:
out_inf: tensor(9.0156, device='cuda:0', dtype=torch.float16) tensor(0.3877, device='cuda:0', dtype=torch.float16)
tensor(2.2754, device='cuda:0', dtype=torch.float16) tensor(0.1004, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.1071, device='cuda:0', dtype=torch.float16)
tensor(2.7773, device='cuda:0', dtype=torch.float16) tensor(0.1202, device='cuda:0', dtype=torch.float16)
tensor(1.6152, device='cuda:0', dtype=torch.float16) tensor(0.0977, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.up_proj
Validation after prune:
out_inf: tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.2849, device='cuda:0', dtype=torch.float16)
tensor(2.9805, device='cuda:0', dtype=torch.float16) tensor(0.2021, device='cuda:0', dtype=torch.float16)
tensor(2.7109, device='cuda:0', dtype=torch.float16) tensor(0.1967, device='cuda:0', dtype=torch.float16)
tensor(3.0664, device='cuda:0', dtype=torch.float16) tensor(0.2075, device='cuda:0', dtype=torch.float16)
tensor(3.1250, device='cuda:0', dtype=torch.float16) tensor(0.1998, device='cuda:0', dtype=torch.float16)
Converged at iteration 300
tensor(0.0193, device='cuda:0')
tensor(0.0188, device='cuda:0')
old_score: tensor(0.2015, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0989, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 11.882542371749878
Validation after dual ascent:
out_inf: tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.2849, device='cuda:0', dtype=torch.float16)
tensor(1.0908, device='cuda:0', dtype=torch.float16) tensor(0.0935, device='cuda:0', dtype=torch.float16)
tensor(1.0518, device='cuda:0', dtype=torch.float16) tensor(0.0996, device='cuda:0', dtype=torch.float16)
tensor(1.4023, device='cuda:0', dtype=torch.float16) tensor(0.1116, device='cuda:0', dtype=torch.float16)
tensor(0.9873, device='cuda:0', dtype=torch.float16) tensor(0.0909, device='cuda:0', dtype=torch.float16)
pruning layer 24 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.4570, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(0.6289, device='cuda:0', dtype=torch.float16) tensor(0.0648, device='cuda:0', dtype=torch.float16)
tensor(0.6113, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.7148, device='cuda:0', dtype=torch.float16) tensor(0.0663, device='cuda:0', dtype=torch.float16)
tensor(0.5718, device='cuda:0', dtype=torch.float16) tensor(0.0638, device='cuda:0', dtype=torch.float16)
Converged at iteration 450
tensor(0.0195, device='cuda:0')
tensor(0.0375, device='cuda:0')
old_score: tensor(0.0642, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0392, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 45.22628092765808
Validation after dual ascent:
out_inf: tensor(3.4570, device='cuda:0', dtype=torch.float16) tensor(0.1107, device='cuda:0', dtype=torch.float16)
tensor(0.4463, device='cuda:0', dtype=torch.float16) tensor(0.0372, device='cuda:0', dtype=torch.float16)
tensor(0.3872, device='cuda:0', dtype=torch.float16) tensor(0.0386, device='cuda:0', dtype=torch.float16)
tensor(0.5200, device='cuda:0', dtype=torch.float16) tensor(0.0453, device='cuda:0', dtype=torch.float16)
tensor(0.3936, device='cuda:0', dtype=torch.float16) tensor(0.0359, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.q_proj
Validation after prune:
out_inf: tensor(12.4297, device='cuda:0', dtype=torch.float16) tensor(0.7676, device='cuda:0', dtype=torch.float16)
tensor(5.0195, device='cuda:0', dtype=torch.float16) tensor(0.3584, device='cuda:0', dtype=torch.float16)
tensor(5.4688, device='cuda:0', dtype=torch.float16) tensor(0.3628, device='cuda:0', dtype=torch.float16)
tensor(5.4414, device='cuda:0', dtype=torch.float16) tensor(0.3804, device='cuda:0', dtype=torch.float16)
tensor(4.9844, device='cuda:0', dtype=torch.float16) tensor(0.3528, device='cuda:0', dtype=torch.float16)
tensor(0.1649, device='cuda:0')
old_score: tensor(0.3635, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1617, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.800824880599976
Validation after dual ascent:
out_inf: tensor(12.4297, device='cuda:0', dtype=torch.float16) tensor(0.7676, device='cuda:0', dtype=torch.float16)
tensor(1.8779, device='cuda:0', dtype=torch.float16) tensor(0.1520, device='cuda:0', dtype=torch.float16)
tensor(2.0781, device='cuda:0', dtype=torch.float16) tensor(0.1635, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.1838, device='cuda:0', dtype=torch.float16)
tensor(1.9590, device='cuda:0', dtype=torch.float16) tensor(0.1476, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.8750, device='cuda:0', dtype=torch.float16) tensor(0.9526, device='cuda:0', dtype=torch.float16)
tensor(4.8906, device='cuda:0', dtype=torch.float16) tensor(0.3657, device='cuda:0', dtype=torch.float16)
tensor(5.3438, device='cuda:0', dtype=torch.float16) tensor(0.3711, device='cuda:0', dtype=torch.float16)
tensor(4.8672, device='cuda:0', dtype=torch.float16) tensor(0.3879, device='cuda:0', dtype=torch.float16)
tensor(5.1406, device='cuda:0', dtype=torch.float16) tensor(0.3633, device='cuda:0', dtype=torch.float16)
tensor(0.1691, device='cuda:0')
old_score: tensor(0.3721, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1619, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.81796383857727
Validation after dual ascent:
out_inf: tensor(16.8750, device='cuda:0', dtype=torch.float16) tensor(0.9526, device='cuda:0', dtype=torch.float16)
tensor(1.9023, device='cuda:0', dtype=torch.float16) tensor(0.1526, device='cuda:0', dtype=torch.float16)
tensor(1.8438, device='cuda:0', dtype=torch.float16) tensor(0.1637, device='cuda:0', dtype=torch.float16)
tensor(1.9180, device='cuda:0', dtype=torch.float16) tensor(0.1832, device='cuda:0', dtype=torch.float16)
tensor(1.8281, device='cuda:0', dtype=torch.float16) tensor(0.1479, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.7812, device='cuda:0', dtype=torch.float16) tensor(0.4368, device='cuda:0', dtype=torch.float16)
tensor(3.5176, device='cuda:0', dtype=torch.float16) tensor(0.2983, device='cuda:0', dtype=torch.float16)
tensor(3.3477, device='cuda:0', dtype=torch.float16) tensor(0.2937, device='cuda:0', dtype=torch.float16)
tensor(3.4648, device='cuda:0', dtype=torch.float16) tensor(0.3098, device='cuda:0', dtype=torch.float16)
tensor(3.5039, device='cuda:0', dtype=torch.float16) tensor(0.2949, device='cuda:0', dtype=torch.float16)
tensor(0.1311, device='cuda:0')
old_score: tensor(0.2991, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1438, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.844061851501465
Validation after dual ascent:
out_inf: tensor(5.7812, device='cuda:0', dtype=torch.float16) tensor(0.4368, device='cuda:0', dtype=torch.float16)
tensor(1.4062, device='cuda:0', dtype=torch.float16) tensor(0.1359, device='cuda:0', dtype=torch.float16)
tensor(1.3965, device='cuda:0', dtype=torch.float16) tensor(0.1456, device='cuda:0', dtype=torch.float16)
tensor(1.4248, device='cuda:0', dtype=torch.float16) tensor(0.1625, device='cuda:0', dtype=torch.float16)
tensor(1.3193, device='cuda:0', dtype=torch.float16) tensor(0.1316, device='cuda:0', dtype=torch.float16)
pruning layer 25 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.9062, device='cuda:0', dtype=torch.float16) tensor(0.1805, device='cuda:0', dtype=torch.float16)
tensor(2.2129, device='cuda:0', dtype=torch.float16) tensor(0.0592, device='cuda:0', dtype=torch.float16)
tensor(2.1699, device='cuda:0', dtype=torch.float16) tensor(0.0726, device='cuda:0', dtype=torch.float16)
tensor(2.0098, device='cuda:0', dtype=torch.float16) tensor(0.0614, device='cuda:0', dtype=torch.float16)
tensor(2.0762, device='cuda:0', dtype=torch.float16) tensor(0.0626, device='cuda:0', dtype=torch.float16)
tensor(0.2495, device='cuda:0')
old_score: tensor(0.0640, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0263, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.767950057983398
Validation after dual ascent:
out_inf: tensor(4.9062, device='cuda:0', dtype=torch.float16) tensor(0.1805, device='cuda:0', dtype=torch.float16)
tensor(0.6084, device='cuda:0', dtype=torch.float16) tensor(0.0232, device='cuda:0', dtype=torch.float16)
tensor(0.8359, device='cuda:0', dtype=torch.float16) tensor(0.0288, device='cuda:0', dtype=torch.float16)
tensor(0.6523, device='cuda:0', dtype=torch.float16) tensor(0.0289, device='cuda:0', dtype=torch.float16)
tensor(0.7905, device='cuda:0', dtype=torch.float16) tensor(0.0242, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.0859, device='cuda:0', dtype=torch.float16) tensor(0.4116, device='cuda:0', dtype=torch.float16)
tensor(5.3164, device='cuda:0', dtype=torch.float16) tensor(0.2333, device='cuda:0', dtype=torch.float16)
tensor(4.1250, device='cuda:0', dtype=torch.float16) tensor(0.2284, device='cuda:0', dtype=torch.float16)
tensor(4.5391, device='cuda:0', dtype=torch.float16) tensor(0.2422, device='cuda:0', dtype=torch.float16)
tensor(4.4141, device='cuda:0', dtype=torch.float16) tensor(0.2305, device='cuda:0', dtype=torch.float16)
tensor(0.0405, device='cuda:0')
old_score: tensor(0.2336, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1081, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.84235501289368
Validation after dual ascent:
out_inf: tensor(7.0859, device='cuda:0', dtype=torch.float16) tensor(0.4116, device='cuda:0', dtype=torch.float16)
tensor(1.9551, device='cuda:0', dtype=torch.float16) tensor(0.1016, device='cuda:0', dtype=torch.float16)
tensor(1.7305, device='cuda:0', dtype=torch.float16) tensor(0.1094, device='cuda:0', dtype=torch.float16)
tensor(1.9590, device='cuda:0', dtype=torch.float16) tensor(0.1224, device='cuda:0', dtype=torch.float16)
tensor(1.9346, device='cuda:0', dtype=torch.float16) tensor(0.0989, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.3477, device='cuda:0', dtype=torch.float16) tensor(0.3000, device='cuda:0', dtype=torch.float16)
tensor(3.2383, device='cuda:0', dtype=torch.float16) tensor(0.2096, device='cuda:0', dtype=torch.float16)
tensor(3.6621, device='cuda:0', dtype=torch.float16) tensor(0.2047, device='cuda:0', dtype=torch.float16)
tensor(3.5234, device='cuda:0', dtype=torch.float16) tensor(0.2163, device='cuda:0', dtype=torch.float16)
tensor(3.3770, device='cuda:0', dtype=torch.float16) tensor(0.2074, device='cuda:0', dtype=torch.float16)
tensor(0.0254, device='cuda:0')
old_score: tensor(0.2096, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1007, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.8576226234436
Validation after dual ascent:
out_inf: tensor(5.3477, device='cuda:0', dtype=torch.float16) tensor(0.3000, device='cuda:0', dtype=torch.float16)
tensor(1.2412, device='cuda:0', dtype=torch.float16) tensor(0.0948, device='cuda:0', dtype=torch.float16)
tensor(1.2002, device='cuda:0', dtype=torch.float16) tensor(0.1021, device='cuda:0', dtype=torch.float16)
tensor(1.7920, device='cuda:0', dtype=torch.float16) tensor(0.1140, device='cuda:0', dtype=torch.float16)
tensor(1.1152, device='cuda:0', dtype=torch.float16) tensor(0.0922, device='cuda:0', dtype=torch.float16)
pruning layer 25 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.2178, device='cuda:0', dtype=torch.float16) tensor(0.1353, device='cuda:0', dtype=torch.float16)
tensor(0.6528, device='cuda:0', dtype=torch.float16) tensor(0.0707, device='cuda:0', dtype=torch.float16)
tensor(0.6406, device='cuda:0', dtype=torch.float16) tensor(0.0683, device='cuda:0', dtype=torch.float16)
tensor(0.8242, device='cuda:0', dtype=torch.float16) tensor(0.0725, device='cuda:0', dtype=torch.float16)
tensor(0.5977, device='cuda:0', dtype=torch.float16) tensor(0.0698, device='cuda:0', dtype=torch.float16)
tensor(0.0270, device='cuda:0')
old_score: tensor(0.0703, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0418, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.472327709198
Validation after dual ascent:
out_inf: tensor(1.2178, device='cuda:0', dtype=torch.float16) tensor(0.1353, device='cuda:0', dtype=torch.float16)
tensor(0.5376, device='cuda:0', dtype=torch.float16) tensor(0.0393, device='cuda:0', dtype=torch.float16)
tensor(0.4746, device='cuda:0', dtype=torch.float16) tensor(0.0414, device='cuda:0', dtype=torch.float16)
tensor(0.4780, device='cuda:0', dtype=torch.float16) tensor(0.0486, device='cuda:0', dtype=torch.float16)
tensor(0.4446, device='cuda:0', dtype=torch.float16) tensor(0.0379, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.8125, device='cuda:0', dtype=torch.float16) tensor(0.8408, device='cuda:0', dtype=torch.float16)
tensor(6.0938, device='cuda:0', dtype=torch.float16) tensor(0.3816, device='cuda:0', dtype=torch.float16)
tensor(5.8398, device='cuda:0', dtype=torch.float16) tensor(0.3911, device='cuda:0', dtype=torch.float16)
tensor(6.0039, device='cuda:0', dtype=torch.float16) tensor(0.4084, device='cuda:0', dtype=torch.float16)
tensor(4.8867, device='cuda:0', dtype=torch.float16) tensor(0.3762, device='cuda:0', dtype=torch.float16)
tensor(0.0598, device='cuda:0')
old_score: tensor(0.3892, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1667, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.797569990158081
Validation after dual ascent:
out_inf: tensor(13.8125, device='cuda:0', dtype=torch.float16) tensor(0.8408, device='cuda:0', dtype=torch.float16)
tensor(1.9180, device='cuda:0', dtype=torch.float16) tensor(0.1558, device='cuda:0', dtype=torch.float16)
tensor(2.1836, device='cuda:0', dtype=torch.float16) tensor(0.1703, device='cuda:0', dtype=torch.float16)
tensor(2.5020, device='cuda:0', dtype=torch.float16) tensor(0.1892, device='cuda:0', dtype=torch.float16)
tensor(1.9336, device='cuda:0', dtype=torch.float16) tensor(0.1515, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.3750, device='cuda:0', dtype=torch.float16) tensor(1.0723, device='cuda:0', dtype=torch.float16)
tensor(4.9766, device='cuda:0', dtype=torch.float16) tensor(0.3921, device='cuda:0', dtype=torch.float16)
tensor(5.3398, device='cuda:0', dtype=torch.float16) tensor(0.4023, device='cuda:0', dtype=torch.float16)
tensor(5.6836, device='cuda:0', dtype=torch.float16) tensor(0.4131, device='cuda:0', dtype=torch.float16)
tensor(4.8633, device='cuda:0', dtype=torch.float16) tensor(0.3892, device='cuda:0', dtype=torch.float16)
tensor(0.0777, device='cuda:0')
old_score: tensor(0.3989, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1653, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.813395261764526
Validation after dual ascent:
out_inf: tensor(17.3750, device='cuda:0', dtype=torch.float16) tensor(1.0723, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1552, device='cuda:0', dtype=torch.float16)
tensor(1.9102, device='cuda:0', dtype=torch.float16) tensor(0.1691, device='cuda:0', dtype=torch.float16)
tensor(2.5527, device='cuda:0', dtype=torch.float16) tensor(0.1868, device='cuda:0', dtype=torch.float16)
tensor(2.0312, device='cuda:0', dtype=torch.float16) tensor(0.1505, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.v_proj
Validation after prune:
out_inf: tensor(4.7891, device='cuda:0', dtype=torch.float16) tensor(0.4624, device='cuda:0', dtype=torch.float16)
tensor(3.4609, device='cuda:0', dtype=torch.float16) tensor(0.3130, device='cuda:0', dtype=torch.float16)
tensor(2.9844, device='cuda:0', dtype=torch.float16) tensor(0.3130, device='cuda:0', dtype=torch.float16)
tensor(3.3848, device='cuda:0', dtype=torch.float16) tensor(0.3240, device='cuda:0', dtype=torch.float16)
tensor(3.3691, device='cuda:0', dtype=torch.float16) tensor(0.3108, device='cuda:0', dtype=torch.float16)
Converged at iteration 550
tensor(0.0184, device='cuda:0')
tensor(0.0267, device='cuda:0')
old_score: tensor(0.3152, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1492, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 8.276010036468506
Validation after dual ascent:
out_inf: tensor(4.7891, device='cuda:0', dtype=torch.float16) tensor(0.4624, device='cuda:0', dtype=torch.float16)
tensor(1.5801, device='cuda:0', dtype=torch.float16) tensor(0.1401, device='cuda:0', dtype=torch.float16)
tensor(1.6250, device='cuda:0', dtype=torch.float16) tensor(0.1523, device='cuda:0', dtype=torch.float16)
tensor(1.6348, device='cuda:0', dtype=torch.float16) tensor(0.1681, device='cuda:0', dtype=torch.float16)
tensor(1.5439, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
pruning layer 26 name self_attn.o_proj
Validation after prune:
out_inf: tensor(18.2656, device='cuda:0', dtype=torch.float16) tensor(0.2146, device='cuda:0', dtype=torch.float16)
tensor(3.5547, device='cuda:0', dtype=torch.float16) tensor(0.0880, device='cuda:0', dtype=torch.float16)
tensor(3.7656, device='cuda:0', dtype=torch.float16) tensor(0.0858, device='cuda:0', dtype=torch.float16)
tensor(3.6035, device='cuda:0', dtype=torch.float16) tensor(0.1000, device='cuda:0', dtype=torch.float16)
tensor(3.4414, device='cuda:0', dtype=torch.float16) tensor(0.0835, device='cuda:0', dtype=torch.float16)
tensor(0.2706, device='cuda:0')
old_score: tensor(0.0894, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0445, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.758606910705566
Validation after dual ascent:
out_inf: tensor(18.2656, device='cuda:0', dtype=torch.float16) tensor(0.2146, device='cuda:0', dtype=torch.float16)
tensor(0.7349, device='cuda:0', dtype=torch.float16) tensor(0.0409, device='cuda:0', dtype=torch.float16)
tensor(0.8965, device='cuda:0', dtype=torch.float16) tensor(0.0445, device='cuda:0', dtype=torch.float16)
tensor(0.9375, device='cuda:0', dtype=torch.float16) tensor(0.0546, device='cuda:0', dtype=torch.float16)
tensor(0.9336, device='cuda:0', dtype=torch.float16) tensor(0.0382, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.gate_proj
Validation after prune:
out_inf: tensor(6.8086, device='cuda:0', dtype=torch.float16) tensor(0.4739, device='cuda:0', dtype=torch.float16)
tensor(4.3125, device='cuda:0', dtype=torch.float16) tensor(0.2556, device='cuda:0', dtype=torch.float16)
tensor(8.6797, device='cuda:0', dtype=torch.float16) tensor(0.2561, device='cuda:0', dtype=torch.float16)
tensor(5.7656, device='cuda:0', dtype=torch.float16) tensor(0.2644, device='cuda:0', dtype=torch.float16)
tensor(5.4375, device='cuda:0', dtype=torch.float16) tensor(0.2529, device='cuda:0', dtype=torch.float16)
tensor(0.0520, device='cuda:0')
old_score: tensor(0.2573, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1140, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.819597005844116
Validation after dual ascent:
out_inf: tensor(6.8086, device='cuda:0', dtype=torch.float16) tensor(0.4739, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1067, device='cuda:0', dtype=torch.float16)
tensor(2.6484, device='cuda:0', dtype=torch.float16) tensor(0.1152, device='cuda:0', dtype=torch.float16)
tensor(3.3320, device='cuda:0', dtype=torch.float16) tensor(0.1300, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1039, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.2578, device='cuda:0', dtype=torch.float16) tensor(0.3440, device='cuda:0', dtype=torch.float16)
tensor(3.1719, device='cuda:0', dtype=torch.float16) tensor(0.2318, device='cuda:0', dtype=torch.float16)
tensor(2.9531, device='cuda:0', dtype=torch.float16) tensor(0.2262, device='cuda:0', dtype=torch.float16)
tensor(3.0898, device='cuda:0', dtype=torch.float16) tensor(0.2362, device='cuda:0', dtype=torch.float16)
tensor(3.1953, device='cuda:0', dtype=torch.float16) tensor(0.2292, device='cuda:0', dtype=torch.float16)
tensor(0.0335, device='cuda:0')
old_score: tensor(0.2310, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1066, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.86460280418396
Validation after dual ascent:
out_inf: tensor(5.2578, device='cuda:0', dtype=torch.float16) tensor(0.3440, device='cuda:0', dtype=torch.float16)
tensor(1.4824, device='cuda:0', dtype=torch.float16) tensor(0.0998, device='cuda:0', dtype=torch.float16)
tensor(1.3643, device='cuda:0', dtype=torch.float16) tensor(0.1079, device='cuda:0', dtype=torch.float16)
tensor(1.5586, device='cuda:0', dtype=torch.float16) tensor(0.1214, device='cuda:0', dtype=torch.float16)
tensor(1.6875, device='cuda:0', dtype=torch.float16) tensor(0.0971, device='cuda:0', dtype=torch.float16)
pruning layer 26 name mlp.down_proj
Validation after prune:
out_inf: tensor(2.4805, device='cuda:0', dtype=torch.float16) tensor(0.1476, device='cuda:0', dtype=torch.float16)
tensor(0.7144, device='cuda:0', dtype=torch.float16) tensor(0.0836, device='cuda:0', dtype=torch.float16)
tensor(0.6914, device='cuda:0', dtype=torch.float16) tensor(0.0814, device='cuda:0', dtype=torch.float16)
tensor(0.7358, device='cuda:0', dtype=torch.float16) tensor(0.0847, device='cuda:0', dtype=torch.float16)
tensor(0.7085, device='cuda:0', dtype=torch.float16) tensor(0.0823, device='cuda:0', dtype=torch.float16)
tensor(0.0233, device='cuda:0')
old_score: tensor(0.0830, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0471, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.54017210006714
Validation after dual ascent:
out_inf: tensor(2.4805, device='cuda:0', dtype=torch.float16) tensor(0.1476, device='cuda:0', dtype=torch.float16)
tensor(0.4873, device='cuda:0', dtype=torch.float16) tensor(0.0442, device='cuda:0', dtype=torch.float16)
tensor(0.4905, device='cuda:0', dtype=torch.float16) tensor(0.0467, device='cuda:0', dtype=torch.float16)
tensor(0.5430, device='cuda:0', dtype=torch.float16) tensor(0.0548, device='cuda:0', dtype=torch.float16)
tensor(0.5142, device='cuda:0', dtype=torch.float16) tensor(0.0426, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.8125, device='cuda:0', dtype=torch.float16) tensor(0.8281, device='cuda:0', dtype=torch.float16)
tensor(5.1641, device='cuda:0', dtype=torch.float16) tensor(0.3940, device='cuda:0', dtype=torch.float16)
tensor(5.6250, device='cuda:0', dtype=torch.float16) tensor(0.3994, device='cuda:0', dtype=torch.float16)
tensor(5.6406, device='cuda:0', dtype=torch.float16) tensor(0.4172, device='cuda:0', dtype=torch.float16)
tensor(5.1484, device='cuda:0', dtype=torch.float16) tensor(0.3892, device='cuda:0', dtype=torch.float16)
tensor(0.2523, device='cuda:0')
old_score: tensor(0.3999, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1633, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.791102409362793
Validation after dual ascent:
out_inf: tensor(14.8125, device='cuda:0', dtype=torch.float16) tensor(0.8281, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.1525, device='cuda:0', dtype=torch.float16)
tensor(1.7695, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.1868, device='cuda:0', dtype=torch.float16)
tensor(2.0625, device='cuda:0', dtype=torch.float16) tensor(0.1483, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.7812, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(6.1406, device='cuda:0', dtype=torch.float16) tensor(0.4092, device='cuda:0', dtype=torch.float16)
tensor(6.7656, device='cuda:0', dtype=torch.float16) tensor(0.4197, device='cuda:0', dtype=torch.float16)
tensor(7.0938, device='cuda:0', dtype=torch.float16) tensor(0.4385, device='cuda:0', dtype=torch.float16)
tensor(6.6797, device='cuda:0', dtype=torch.float16) tensor(0.4062, device='cuda:0', dtype=torch.float16)
tensor(0.2545, device='cuda:0')
old_score: tensor(0.4185, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1636, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.820935010910034
Validation after dual ascent:
out_inf: tensor(17.7812, device='cuda:0', dtype=torch.float16) tensor(0.9893, device='cuda:0', dtype=torch.float16)
tensor(2.1953, device='cuda:0', dtype=torch.float16) tensor(0.1527, device='cuda:0', dtype=torch.float16)
tensor(1.7656, device='cuda:0', dtype=torch.float16) tensor(0.1655, device='cuda:0', dtype=torch.float16)
tensor(2.3047, device='cuda:0', dtype=torch.float16) tensor(0.1873, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.5273, device='cuda:0', dtype=torch.float16) tensor(0.4536, device='cuda:0', dtype=torch.float16)
tensor(2.7148, device='cuda:0', dtype=torch.float16) tensor(0.3071, device='cuda:0', dtype=torch.float16)
tensor(2.8125, device='cuda:0', dtype=torch.float16) tensor(0.3062, device='cuda:0', dtype=torch.float16)
tensor(2.7969, device='cuda:0', dtype=torch.float16) tensor(0.3179, device='cuda:0', dtype=torch.float16)
tensor(2.5625, device='cuda:0', dtype=torch.float16) tensor(0.3049, device='cuda:0', dtype=torch.float16)
tensor(0.1967, device='cuda:0')
old_score: tensor(0.3091, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1404, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.841216087341309
Validation after dual ascent:
out_inf: tensor(5.5273, device='cuda:0', dtype=torch.float16) tensor(0.4536, device='cuda:0', dtype=torch.float16)
tensor(1.2754, device='cuda:0', dtype=torch.float16) tensor(0.1315, device='cuda:0', dtype=torch.float16)
tensor(1.2881, device='cuda:0', dtype=torch.float16) tensor(0.1425, device='cuda:0', dtype=torch.float16)
tensor(1.7461, device='cuda:0', dtype=torch.float16) tensor(0.1599, device='cuda:0', dtype=torch.float16)
tensor(1.3115, device='cuda:0', dtype=torch.float16) tensor(0.1276, device='cuda:0', dtype=torch.float16)
pruning layer 27 name self_attn.o_proj
Validation after prune:
out_inf: tensor(4.4453, device='cuda:0', dtype=torch.float16) tensor(0.1260, device='cuda:0', dtype=torch.float16)
tensor(2.0801, device='cuda:0', dtype=torch.float16) tensor(0.0431, device='cuda:0', dtype=torch.float16)
tensor(2.1172, device='cuda:0', dtype=torch.float16) tensor(0.0441, device='cuda:0', dtype=torch.float16)
tensor(2.0859, device='cuda:0', dtype=torch.float16) tensor(0.0411, device='cuda:0', dtype=torch.float16)
tensor(2.1348, device='cuda:0', dtype=torch.float16) tensor(0.0459, device='cuda:0', dtype=torch.float16)
tensor(0.1953, device='cuda:0')
old_score: tensor(0.0435, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0173, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.754360437393188
Validation after dual ascent:
out_inf: tensor(4.4453, device='cuda:0', dtype=torch.float16) tensor(0.1260, device='cuda:0', dtype=torch.float16)
tensor(0.6631, device='cuda:0', dtype=torch.float16) tensor(0.0160, device='cuda:0', dtype=torch.float16)
tensor(0.9727, device='cuda:0', dtype=torch.float16) tensor(0.0170, device='cuda:0', dtype=torch.float16)
tensor(0.5244, device='cuda:0', dtype=torch.float16) tensor(0.0194, device='cuda:0', dtype=torch.float16)
tensor(0.5684, device='cuda:0', dtype=torch.float16) tensor(0.0169, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.gate_proj
Validation after prune:
out_inf: tensor(10.7344, device='cuda:0', dtype=torch.float16) tensor(0.5063, device='cuda:0', dtype=torch.float16)
tensor(7.0898, device='cuda:0', dtype=torch.float16) tensor(0.2681, device='cuda:0', dtype=torch.float16)
tensor(5.8477, device='cuda:0', dtype=torch.float16) tensor(0.2678, device='cuda:0', dtype=torch.float16)
tensor(6.7812, device='cuda:0', dtype=torch.float16) tensor(0.2776, device='cuda:0', dtype=torch.float16)
tensor(5.9531, device='cuda:0', dtype=torch.float16) tensor(0.2637, device='cuda:0', dtype=torch.float16)
tensor(0.0617, device='cuda:0')
old_score: tensor(0.2693, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1129, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.85000157356262
Validation after dual ascent:
out_inf: tensor(10.7344, device='cuda:0', dtype=torch.float16) tensor(0.5063, device='cuda:0', dtype=torch.float16)
tensor(2.9062, device='cuda:0', dtype=torch.float16) tensor(0.1058, device='cuda:0', dtype=torch.float16)
tensor(2.2617, device='cuda:0', dtype=torch.float16) tensor(0.1138, device='cuda:0', dtype=torch.float16)
tensor(3.5059, device='cuda:0', dtype=torch.float16) tensor(0.1290, device='cuda:0', dtype=torch.float16)
tensor(2.3945, device='cuda:0', dtype=torch.float16) tensor(0.1029, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.up_proj
Validation after prune:
out_inf: tensor(5.4102, device='cuda:0', dtype=torch.float16) tensor(0.3708, device='cuda:0', dtype=torch.float16)
tensor(3.3320, device='cuda:0', dtype=torch.float16) tensor(0.2419, device='cuda:0', dtype=torch.float16)
tensor(3.2422, device='cuda:0', dtype=torch.float16) tensor(0.2382, device='cuda:0', dtype=torch.float16)
tensor(3.7109, device='cuda:0', dtype=torch.float16) tensor(0.2478, device='cuda:0', dtype=torch.float16)
tensor(3.6992, device='cuda:0', dtype=torch.float16) tensor(0.2391, device='cuda:0', dtype=torch.float16)
tensor(0.0411, device='cuda:0')
old_score: tensor(0.2417, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1061, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.9013614654541
Validation after dual ascent:
out_inf: tensor(5.4102, device='cuda:0', dtype=torch.float16) tensor(0.3708, device='cuda:0', dtype=torch.float16)
tensor(1.3496, device='cuda:0', dtype=torch.float16) tensor(0.0995, device='cuda:0', dtype=torch.float16)
tensor(1.2676, device='cuda:0', dtype=torch.float16) tensor(0.1069, device='cuda:0', dtype=torch.float16)
tensor(2.0215, device='cuda:0', dtype=torch.float16) tensor(0.1211, device='cuda:0', dtype=torch.float16)
tensor(1.3906, device='cuda:0', dtype=torch.float16) tensor(0.0967, device='cuda:0', dtype=torch.float16)
pruning layer 27 name mlp.down_proj
Validation after prune:
out_inf: tensor(1.7275, device='cuda:0', dtype=torch.float16) tensor(0.1704, device='cuda:0', dtype=torch.float16)
tensor(1.1523, device='cuda:0', dtype=torch.float16) tensor(0.0931, device='cuda:0', dtype=torch.float16)
tensor(1.4805, device='cuda:0', dtype=torch.float16) tensor(0.0919, device='cuda:0', dtype=torch.float16)
tensor(1.2158, device='cuda:0', dtype=torch.float16) tensor(0.0943, device='cuda:0', dtype=torch.float16)
tensor(1.2852, device='cuda:0', dtype=torch.float16) tensor(0.0920, device='cuda:0', dtype=torch.float16)
tensor(0.0344, device='cuda:0')
old_score: tensor(0.0928, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0501, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.44797325134277
Validation after dual ascent:
out_inf: tensor(1.7275, device='cuda:0', dtype=torch.float16) tensor(0.1704, device='cuda:0', dtype=torch.float16)
tensor(0.5532, device='cuda:0', dtype=torch.float16) tensor(0.0468, device='cuda:0', dtype=torch.float16)
tensor(0.5801, device='cuda:0', dtype=torch.float16) tensor(0.0498, device='cuda:0', dtype=torch.float16)
tensor(0.5981, device='cuda:0', dtype=torch.float16) tensor(0.0586, device='cuda:0', dtype=torch.float16)
tensor(0.5273, device='cuda:0', dtype=torch.float16) tensor(0.0451, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.8516, device='cuda:0', dtype=torch.float16) tensor(0.8306, device='cuda:0', dtype=torch.float16)
tensor(6.0898, device='cuda:0', dtype=torch.float16) tensor(0.4048, device='cuda:0', dtype=torch.float16)
tensor(5.7578, device='cuda:0', dtype=torch.float16) tensor(0.4199, device='cuda:0', dtype=torch.float16)
tensor(6.5430, device='cuda:0', dtype=torch.float16) tensor(0.4336, device='cuda:0', dtype=torch.float16)
tensor(6.2031, device='cuda:0', dtype=torch.float16) tensor(0.4028, device='cuda:0', dtype=torch.float16)
tensor(0.1059, device='cuda:0')
old_score: tensor(0.4150, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1652, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.789652585983276
Validation after dual ascent:
out_inf: tensor(13.8516, device='cuda:0', dtype=torch.float16) tensor(0.8306, device='cuda:0', dtype=torch.float16)
tensor(2.0352, device='cuda:0', dtype=torch.float16) tensor(0.1537, device='cuda:0', dtype=torch.float16)
tensor(1.8477, device='cuda:0', dtype=torch.float16) tensor(0.1678, device='cuda:0', dtype=torch.float16)
tensor(2.2461, device='cuda:0', dtype=torch.float16) tensor(0.1897, device='cuda:0', dtype=torch.float16)
tensor(2.2734, device='cuda:0', dtype=torch.float16) tensor(0.1494, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.k_proj
Validation after prune:
out_inf: tensor(18.0938, device='cuda:0', dtype=torch.float16) tensor(1.0283, device='cuda:0', dtype=torch.float16)
tensor(6.7266, device='cuda:0', dtype=torch.float16) tensor(0.4231, device='cuda:0', dtype=torch.float16)
tensor(6.7578, device='cuda:0', dtype=torch.float16) tensor(0.4392, device='cuda:0', dtype=torch.float16)
tensor(7.6016, device='cuda:0', dtype=torch.float16) tensor(0.4534, device='cuda:0', dtype=torch.float16)
tensor(7.8906, device='cuda:0', dtype=torch.float16) tensor(0.4209, device='cuda:0', dtype=torch.float16)
tensor(0.1202, device='cuda:0')
old_score: tensor(0.4341, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1642, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.805903673171997
Validation after dual ascent:
out_inf: tensor(18.0938, device='cuda:0', dtype=torch.float16) tensor(1.0283, device='cuda:0', dtype=torch.float16)
tensor(2.3750, device='cuda:0', dtype=torch.float16) tensor(0.1526, device='cuda:0', dtype=torch.float16)
tensor(2.4023, device='cuda:0', dtype=torch.float16) tensor(0.1667, device='cuda:0', dtype=torch.float16)
tensor(2.4766, device='cuda:0', dtype=torch.float16) tensor(0.1890, device='cuda:0', dtype=torch.float16)
tensor(2.8047, device='cuda:0', dtype=torch.float16) tensor(0.1486, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.4844, device='cuda:0', dtype=torch.float16) tensor(0.5122, device='cuda:0', dtype=torch.float16)
tensor(3.5117, device='cuda:0', dtype=torch.float16) tensor(0.3411, device='cuda:0', dtype=torch.float16)
tensor(3.6797, device='cuda:0', dtype=torch.float16) tensor(0.3428, device='cuda:0', dtype=torch.float16)
tensor(4.0703, device='cuda:0', dtype=torch.float16) tensor(0.3496, device='cuda:0', dtype=torch.float16)
tensor(3.4551, device='cuda:0', dtype=torch.float16) tensor(0.3381, device='cuda:0', dtype=torch.float16)
tensor(0.0700, device='cuda:0')
old_score: tensor(0.3428, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1499, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.830613136291504
Validation after dual ascent:
out_inf: tensor(5.4844, device='cuda:0', dtype=torch.float16) tensor(0.5122, device='cuda:0', dtype=torch.float16)
tensor(1.7598, device='cuda:0', dtype=torch.float16) tensor(0.1396, device='cuda:0', dtype=torch.float16)
tensor(1.9902, device='cuda:0', dtype=torch.float16) tensor(0.1523, device='cuda:0', dtype=torch.float16)
tensor(1.9209, device='cuda:0', dtype=torch.float16) tensor(0.1720, device='cuda:0', dtype=torch.float16)
tensor(1.6162, device='cuda:0', dtype=torch.float16) tensor(0.1357, device='cuda:0', dtype=torch.float16)
pruning layer 28 name self_attn.o_proj
Validation after prune:
out_inf: tensor(8.3750, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(3.7227, device='cuda:0', dtype=torch.float16) tensor(0.0570, device='cuda:0', dtype=torch.float16)
tensor(3.8945, device='cuda:0', dtype=torch.float16) tensor(0.0661, device='cuda:0', dtype=torch.float16)
tensor(4.2031, device='cuda:0', dtype=torch.float16) tensor(0.0654, device='cuda:0', dtype=torch.float16)
tensor(3.4688, device='cuda:0', dtype=torch.float16) tensor(0.0621, device='cuda:0', dtype=torch.float16)
tensor(0.3025, device='cuda:0')
old_score: tensor(0.0626, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0232, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.751603603363037
Validation after dual ascent:
out_inf: tensor(8.3750, device='cuda:0', dtype=torch.float16) tensor(0.1672, device='cuda:0', dtype=torch.float16)
tensor(1.0156, device='cuda:0', dtype=torch.float16) tensor(0.0195, device='cuda:0', dtype=torch.float16)
tensor(1.5371, device='cuda:0', dtype=torch.float16) tensor(0.0240, device='cuda:0', dtype=torch.float16)
tensor(1.7969, device='cuda:0', dtype=torch.float16) tensor(0.0275, device='cuda:0', dtype=torch.float16)
tensor(1.3057, device='cuda:0', dtype=torch.float16) tensor(0.0217, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.3516, device='cuda:0', dtype=torch.float16) tensor(0.5107, device='cuda:0', dtype=torch.float16)
tensor(4.5664, device='cuda:0', dtype=torch.float16) tensor(0.2766, device='cuda:0', dtype=torch.float16)
tensor(5.8320, device='cuda:0', dtype=torch.float16) tensor(0.2781, device='cuda:0', dtype=torch.float16)
tensor(7.0703, device='cuda:0', dtype=torch.float16) tensor(0.2871, device='cuda:0', dtype=torch.float16)
tensor(4.2461, device='cuda:0', dtype=torch.float16) tensor(0.2725, device='cuda:0', dtype=torch.float16)
tensor(0.0662, device='cuda:0')
old_score: tensor(0.2786, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1152, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.78213024139404
Validation after dual ascent:
out_inf: tensor(7.3516, device='cuda:0', dtype=torch.float16) tensor(0.5107, device='cuda:0', dtype=torch.float16)
tensor(3.3027, device='cuda:0', dtype=torch.float16) tensor(0.1075, device='cuda:0', dtype=torch.float16)
tensor(3.1660, device='cuda:0', dtype=torch.float16) tensor(0.1163, device='cuda:0', dtype=torch.float16)
tensor(3.2754, device='cuda:0', dtype=torch.float16) tensor(0.1324, device='cuda:0', dtype=torch.float16)
tensor(2.4590, device='cuda:0', dtype=torch.float16) tensor(0.1044, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.up_proj
Validation after prune:
out_inf: tensor(6.0430, device='cuda:0', dtype=torch.float16) tensor(0.4109, device='cuda:0', dtype=torch.float16)
tensor(5.0312, device='cuda:0', dtype=torch.float16) tensor(0.2585, device='cuda:0', dtype=torch.float16)
tensor(4.1875, device='cuda:0', dtype=torch.float16) tensor(0.2595, device='cuda:0', dtype=torch.float16)
tensor(5.6875, device='cuda:0', dtype=torch.float16) tensor(0.2678, device='cuda:0', dtype=torch.float16)
tensor(4.3789, device='cuda:0', dtype=torch.float16) tensor(0.2561, device='cuda:0', dtype=torch.float16)
tensor(0.0518, device='cuda:0')
old_score: tensor(0.2605, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1099, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.72881865501404
Validation after dual ascent:
out_inf: tensor(6.0430, device='cuda:0', dtype=torch.float16) tensor(0.4109, device='cuda:0', dtype=torch.float16)
tensor(1.3730, device='cuda:0', dtype=torch.float16) tensor(0.1027, device='cuda:0', dtype=torch.float16)
tensor(1.8242, device='cuda:0', dtype=torch.float16) tensor(0.1110, device='cuda:0', dtype=torch.float16)
tensor(2.5195, device='cuda:0', dtype=torch.float16) tensor(0.1263, device='cuda:0', dtype=torch.float16)
tensor(1.3848, device='cuda:0', dtype=torch.float16) tensor(0.0997, device='cuda:0', dtype=torch.float16)
pruning layer 28 name mlp.down_proj
Validation after prune:
out_inf: tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.1945, device='cuda:0', dtype=torch.float16)
tensor(1.1348, device='cuda:0', dtype=torch.float16) tensor(0.1052, device='cuda:0', dtype=torch.float16)
tensor(0.9688, device='cuda:0', dtype=torch.float16) tensor(0.1051, device='cuda:0', dtype=torch.float16)
tensor(0.9766, device='cuda:0', dtype=torch.float16) tensor(0.1089, device='cuda:0', dtype=torch.float16)
tensor(0.9600, device='cuda:0', dtype=torch.float16) tensor(0.1042, device='cuda:0', dtype=torch.float16)
tensor(0.0360, device='cuda:0')
old_score: tensor(0.1058, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0569, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.51942086219788
Validation after dual ascent:
out_inf: tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.1945, device='cuda:0', dtype=torch.float16)
tensor(0.6777, device='cuda:0', dtype=torch.float16) tensor(0.0526, device='cuda:0', dtype=torch.float16)
tensor(0.6582, device='cuda:0', dtype=torch.float16) tensor(0.0569, device='cuda:0', dtype=torch.float16)
tensor(0.6768, device='cuda:0', dtype=torch.float16) tensor(0.0676, device='cuda:0', dtype=torch.float16)
tensor(0.6465, device='cuda:0', dtype=torch.float16) tensor(0.0508, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.2656, device='cuda:0', dtype=torch.float16) tensor(0.8340, device='cuda:0', dtype=torch.float16)
tensor(5.3672, device='cuda:0', dtype=torch.float16) tensor(0.3945, device='cuda:0', dtype=torch.float16)
tensor(5.1680, device='cuda:0', dtype=torch.float16) tensor(0.4094, device='cuda:0', dtype=torch.float16)
tensor(6.0195, device='cuda:0', dtype=torch.float16) tensor(0.4297, device='cuda:0', dtype=torch.float16)
tensor(5.4453, device='cuda:0', dtype=torch.float16) tensor(0.3894, device='cuda:0', dtype=torch.float16)
tensor(0.4263, device='cuda:0')
old_score: tensor(0.4058, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1541, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.814393758773804
Validation after dual ascent:
out_inf: tensor(13.2656, device='cuda:0', dtype=torch.float16) tensor(0.8340, device='cuda:0', dtype=torch.float16)
tensor(2.0508, device='cuda:0', dtype=torch.float16) tensor(0.1426, device='cuda:0', dtype=torch.float16)
tensor(1.9004, device='cuda:0', dtype=torch.float16) tensor(0.1564, device='cuda:0', dtype=torch.float16)
tensor(2.4492, device='cuda:0', dtype=torch.float16) tensor(0.1788, device='cuda:0', dtype=torch.float16)
tensor(2.6641, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.k_proj
Validation after prune:
out_inf: tensor(19.1094, device='cuda:0', dtype=torch.float16) tensor(1.0723, device='cuda:0', dtype=torch.float16)
tensor(6.6562, device='cuda:0', dtype=torch.float16) tensor(0.4158, device='cuda:0', dtype=torch.float16)
tensor(6.5391, device='cuda:0', dtype=torch.float16) tensor(0.4338, device='cuda:0', dtype=torch.float16)
tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.4475, device='cuda:0', dtype=torch.float16)
tensor(7., device='cuda:0', dtype=torch.float16) tensor(0.4116, device='cuda:0', dtype=torch.float16)
tensor(0.6030, device='cuda:0')
old_score: tensor(0.4272, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1550, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.832947492599487
Validation after dual ascent:
out_inf: tensor(19.1094, device='cuda:0', dtype=torch.float16) tensor(1.0723, device='cuda:0', dtype=torch.float16)
tensor(2.2031, device='cuda:0', dtype=torch.float16) tensor(0.1439, device='cuda:0', dtype=torch.float16)
tensor(2.1562, device='cuda:0', dtype=torch.float16) tensor(0.1572, device='cuda:0', dtype=torch.float16)
tensor(2.1875, device='cuda:0', dtype=torch.float16) tensor(0.1791, device='cuda:0', dtype=torch.float16)
tensor(2.6016, device='cuda:0', dtype=torch.float16) tensor(0.1395, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.v_proj
Validation after prune:
out_inf: tensor(5.5312, device='cuda:0', dtype=torch.float16) tensor(0.4971, device='cuda:0', dtype=torch.float16)
tensor(6.0938, device='cuda:0', dtype=torch.float16) tensor(0.3372, device='cuda:0', dtype=torch.float16)
tensor(3.8066, device='cuda:0', dtype=torch.float16) tensor(0.3369, device='cuda:0', dtype=torch.float16)
tensor(6.2422, device='cuda:0', dtype=torch.float16) tensor(0.3525, device='cuda:0', dtype=torch.float16)
tensor(5.9922, device='cuda:0', dtype=torch.float16) tensor(0.3342, device='cuda:0', dtype=torch.float16)
tensor(0.5968, device='cuda:0')
old_score: tensor(0.3401, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1462, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.853616714477539
Validation after dual ascent:
out_inf: tensor(5.5312, device='cuda:0', dtype=torch.float16) tensor(0.4971, device='cuda:0', dtype=torch.float16)
tensor(1.7207, device='cuda:0', dtype=torch.float16) tensor(0.1362, device='cuda:0', dtype=torch.float16)
tensor(1.3574, device='cuda:0', dtype=torch.float16) tensor(0.1486, device='cuda:0', dtype=torch.float16)
tensor(1.8652, device='cuda:0', dtype=torch.float16) tensor(0.1682, device='cuda:0', dtype=torch.float16)
tensor(1.4453, device='cuda:0', dtype=torch.float16) tensor(0.1322, device='cuda:0', dtype=torch.float16)
pruning layer 29 name self_attn.o_proj
Validation after prune:
out_inf: tensor(17.4844, device='cuda:0', dtype=torch.float16) tensor(0.2429, device='cuda:0', dtype=torch.float16)
tensor(7.8750, device='cuda:0', dtype=torch.float16) tensor(0.0959, device='cuda:0', dtype=torch.float16)
tensor(6.0547, device='cuda:0', dtype=torch.float16) tensor(0.1177, device='cuda:0', dtype=torch.float16)
tensor(7.9375, device='cuda:0', dtype=torch.float16) tensor(0.1134, device='cuda:0', dtype=torch.float16)
tensor(6.5703, device='cuda:0', dtype=torch.float16) tensor(0.1054, device='cuda:0', dtype=torch.float16)
tensor(0.3743, device='cuda:0')
old_score: tensor(0.1082, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0435, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.821275234222412
Validation after dual ascent:
out_inf: tensor(17.4844, device='cuda:0', dtype=torch.float16) tensor(0.2429, device='cuda:0', dtype=torch.float16)
tensor(2.1328, device='cuda:0', dtype=torch.float16) tensor(0.0360, device='cuda:0', dtype=torch.float16)
tensor(1.4219, device='cuda:0', dtype=torch.float16) tensor(0.0460, device='cuda:0', dtype=torch.float16)
tensor(2.0625, device='cuda:0', dtype=torch.float16) tensor(0.0532, device='cuda:0', dtype=torch.float16)
tensor(1.7852, device='cuda:0', dtype=torch.float16) tensor(0.0388, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.gate_proj
Validation after prune:
out_inf: tensor(7.5312, device='cuda:0', dtype=torch.float16) tensor(0.5347, device='cuda:0', dtype=torch.float16)
tensor(6.5625, device='cuda:0', dtype=torch.float16) tensor(0.2886, device='cuda:0', dtype=torch.float16)
tensor(6.3711, device='cuda:0', dtype=torch.float16) tensor(0.2908, device='cuda:0', dtype=torch.float16)
tensor(6.9375, device='cuda:0', dtype=torch.float16) tensor(0.2976, device='cuda:0', dtype=torch.float16)
tensor(6.5000, device='cuda:0', dtype=torch.float16) tensor(0.2861, device='cuda:0', dtype=torch.float16)
tensor(0.0768, device='cuda:0')
old_score: tensor(0.2908, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1158, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.96065354347229
Validation after dual ascent:
out_inf: tensor(7.5312, device='cuda:0', dtype=torch.float16) tensor(0.5347, device='cuda:0', dtype=torch.float16)
tensor(2.9375, device='cuda:0', dtype=torch.float16) tensor(0.1080, device='cuda:0', dtype=torch.float16)
tensor(2.7891, device='cuda:0', dtype=torch.float16) tensor(0.1172, device='cuda:0', dtype=torch.float16)
tensor(3.5137, device='cuda:0', dtype=torch.float16) tensor(0.1332, device='cuda:0', dtype=torch.float16)
tensor(2.5391, device='cuda:0', dtype=torch.float16) tensor(0.1051, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.up_proj
Validation after prune:
out_inf: tensor(7.8359, device='cuda:0', dtype=torch.float16) tensor(0.4695, device='cuda:0', dtype=torch.float16)
tensor(10.3281, device='cuda:0', dtype=torch.float16) tensor(0.2766, device='cuda:0', dtype=torch.float16)
tensor(11.7812, device='cuda:0', dtype=torch.float16) tensor(0.2788, device='cuda:0', dtype=torch.float16)
tensor(10.2188, device='cuda:0', dtype=torch.float16) tensor(0.2866, device='cuda:0', dtype=torch.float16)
tensor(7.7969, device='cuda:0', dtype=torch.float16) tensor(0.2737, device='cuda:0', dtype=torch.float16)
tensor(0.0687, device='cuda:0')
old_score: tensor(0.2791, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1116, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 39.01539206504822
Validation after dual ascent:
out_inf: tensor(7.8359, device='cuda:0', dtype=torch.float16) tensor(0.4695, device='cuda:0', dtype=torch.float16)
tensor(3.7500, device='cuda:0', dtype=torch.float16) tensor(0.1040, device='cuda:0', dtype=torch.float16)
tensor(4.0391, device='cuda:0', dtype=torch.float16) tensor(0.1129, device='cuda:0', dtype=torch.float16)
tensor(4.7070, device='cuda:0', dtype=torch.float16) tensor(0.1282, device='cuda:0', dtype=torch.float16)
tensor(3.8613, device='cuda:0', dtype=torch.float16) tensor(0.1012, device='cuda:0', dtype=torch.float16)
pruning layer 29 name mlp.down_proj
Validation after prune:
out_inf: tensor(6.1172, device='cuda:0', dtype=torch.float16) tensor(0.2524, device='cuda:0', dtype=torch.float16)
tensor(1.7715, device='cuda:0', dtype=torch.float16) tensor(0.1237, device='cuda:0', dtype=torch.float16)
tensor(1.8672, device='cuda:0', dtype=torch.float16) tensor(0.1246, device='cuda:0', dtype=torch.float16)
tensor(1.6055, device='cuda:0', dtype=torch.float16) tensor(0.1284, device='cuda:0', dtype=torch.float16)
tensor(1.8516, device='cuda:0', dtype=torch.float16) tensor(0.1233, device='cuda:0', dtype=torch.float16)
tensor(0.0509, device='cuda:0')
old_score: tensor(0.1250, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0640, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.27015233039856
Validation after dual ascent:
out_inf: tensor(6.1172, device='cuda:0', dtype=torch.float16) tensor(0.2524, device='cuda:0', dtype=torch.float16)
tensor(0.7686, device='cuda:0', dtype=torch.float16) tensor(0.0591, device='cuda:0', dtype=torch.float16)
tensor(0.8525, device='cuda:0', dtype=torch.float16) tensor(0.0639, device='cuda:0', dtype=torch.float16)
tensor(0.8506, device='cuda:0', dtype=torch.float16) tensor(0.0759, device='cuda:0', dtype=torch.float16)
tensor(0.8628, device='cuda:0', dtype=torch.float16) tensor(0.0573, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.q_proj
Validation after prune:
out_inf: tensor(14.9453, device='cuda:0', dtype=torch.float16) tensor(0.8672, device='cuda:0', dtype=torch.float16)
tensor(6.3984, device='cuda:0', dtype=torch.float16) tensor(0.4163, device='cuda:0', dtype=torch.float16)
tensor(6.3789, device='cuda:0', dtype=torch.float16) tensor(0.4324, device='cuda:0', dtype=torch.float16)
tensor(6.5625, device='cuda:0', dtype=torch.float16) tensor(0.4478, device='cuda:0', dtype=torch.float16)
tensor(5.8555, device='cuda:0', dtype=torch.float16) tensor(0.4165, device='cuda:0', dtype=torch.float16)
tensor(0.0958, device='cuda:0')
old_score: tensor(0.4282, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1533, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.793972492218018
Validation after dual ascent:
out_inf: tensor(14.9453, device='cuda:0', dtype=torch.float16) tensor(0.8672, device='cuda:0', dtype=torch.float16)
tensor(1.8750, device='cuda:0', dtype=torch.float16) tensor(0.1423, device='cuda:0', dtype=torch.float16)
tensor(1.8359, device='cuda:0', dtype=torch.float16) tensor(0.1561, device='cuda:0', dtype=torch.float16)
tensor(1.9766, device='cuda:0', dtype=torch.float16) tensor(0.1763, device='cuda:0', dtype=torch.float16)
tensor(2.0469, device='cuda:0', dtype=torch.float16) tensor(0.1385, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.k_proj
Validation after prune:
out_inf: tensor(17.2188, device='cuda:0', dtype=torch.float16) tensor(1.0273, device='cuda:0', dtype=torch.float16)
tensor(7.7656, device='cuda:0', dtype=torch.float16) tensor(0.4404, device='cuda:0', dtype=torch.float16)
tensor(6.9453, device='cuda:0', dtype=torch.float16) tensor(0.4619, device='cuda:0', dtype=torch.float16)
tensor(8.5625, device='cuda:0', dtype=torch.float16) tensor(0.4722, device='cuda:0', dtype=torch.float16)
tensor(8.0625, device='cuda:0', dtype=torch.float16) tensor(0.4399, device='cuda:0', dtype=torch.float16)
tensor(0.1185, device='cuda:0')
old_score: tensor(0.4536, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1549, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.81241774559021
Validation after dual ascent:
out_inf: tensor(17.2188, device='cuda:0', dtype=torch.float16) tensor(1.0273, device='cuda:0', dtype=torch.float16)
tensor(2.3516, device='cuda:0', dtype=torch.float16) tensor(0.1442, device='cuda:0', dtype=torch.float16)
tensor(1.8125, device='cuda:0', dtype=torch.float16) tensor(0.1575, device='cuda:0', dtype=torch.float16)
tensor(1.9531, device='cuda:0', dtype=torch.float16) tensor(0.1780, device='cuda:0', dtype=torch.float16)
tensor(2.2812, device='cuda:0', dtype=torch.float16) tensor(0.1399, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.v_proj
Validation after prune:
out_inf: tensor(6.8320, device='cuda:0', dtype=torch.float16) tensor(0.5459, device='cuda:0', dtype=torch.float16)
tensor(3.2500, device='cuda:0', dtype=torch.float16) tensor(0.3562, device='cuda:0', dtype=torch.float16)
tensor(3.1797, device='cuda:0', dtype=torch.float16) tensor(0.3608, device='cuda:0', dtype=torch.float16)
tensor(3.1348, device='cuda:0', dtype=torch.float16) tensor(0.3682, device='cuda:0', dtype=torch.float16)
tensor(2.9512, device='cuda:0', dtype=torch.float16) tensor(0.3564, device='cuda:0', dtype=torch.float16)
tensor(0.0425, device='cuda:0')
old_score: tensor(0.3604, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1460, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.836065292358398
Validation after dual ascent:
out_inf: tensor(6.8320, device='cuda:0', dtype=torch.float16) tensor(0.5459, device='cuda:0', dtype=torch.float16)
tensor(1.4902, device='cuda:0', dtype=torch.float16) tensor(0.1361, device='cuda:0', dtype=torch.float16)
tensor(1.4688, device='cuda:0', dtype=torch.float16) tensor(0.1484, device='cuda:0', dtype=torch.float16)
tensor(1.5156, device='cuda:0', dtype=torch.float16) tensor(0.1674, device='cuda:0', dtype=torch.float16)
tensor(1.3203, device='cuda:0', dtype=torch.float16) tensor(0.1321, device='cuda:0', dtype=torch.float16)
pruning layer 30 name self_attn.o_proj
Validation after prune:
out_inf: tensor(14.7422, device='cuda:0', dtype=torch.float16) tensor(0.1882, device='cuda:0', dtype=torch.float16)
tensor(4.1406, device='cuda:0', dtype=torch.float16) tensor(0.0758, device='cuda:0', dtype=torch.float16)
tensor(6.5000, device='cuda:0', dtype=torch.float16) tensor(0.0826, device='cuda:0', dtype=torch.float16)
tensor(5.0547, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(4.1953, device='cuda:0', dtype=torch.float16) tensor(0.0742, device='cuda:0', dtype=torch.float16)
tensor(0.2944, device='cuda:0')
old_score: tensor(0.0792, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0243, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.765641689300537
Validation after dual ascent:
out_inf: tensor(14.7422, device='cuda:0', dtype=torch.float16) tensor(0.1882, device='cuda:0', dtype=torch.float16)
tensor(1.5508, device='cuda:0', dtype=torch.float16) tensor(0.0216, device='cuda:0', dtype=torch.float16)
tensor(2.4414, device='cuda:0', dtype=torch.float16) tensor(0.0234, device='cuda:0', dtype=torch.float16)
tensor(1.2305, device='cuda:0', dtype=torch.float16) tensor(0.0303, device='cuda:0', dtype=torch.float16)
tensor(1.3164, device='cuda:0', dtype=torch.float16) tensor(0.0220, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.gate_proj
Validation after prune:
out_inf: tensor(41.2500, device='cuda:0', dtype=torch.float16) tensor(0.5884, device='cuda:0', dtype=torch.float16)
tensor(51.5312, device='cuda:0', dtype=torch.float16) tensor(0.3127, device='cuda:0', dtype=torch.float16)
tensor(55.5000, device='cuda:0', dtype=torch.float16) tensor(0.3198, device='cuda:0', dtype=torch.float16)
tensor(58.4375, device='cuda:0', dtype=torch.float16) tensor(0.3279, device='cuda:0', dtype=torch.float16)
tensor(39.5312, device='cuda:0', dtype=torch.float16) tensor(0.3098, device='cuda:0', dtype=torch.float16)
tensor(0.1378, device='cuda:0')
old_score: tensor(0.3176, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1154, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.89157700538635
Validation after dual ascent:
out_inf: tensor(41.2500, device='cuda:0', dtype=torch.float16) tensor(0.5884, device='cuda:0', dtype=torch.float16)
tensor(12.6875, device='cuda:0', dtype=torch.float16) tensor(0.1083, device='cuda:0', dtype=torch.float16)
tensor(12.1250, device='cuda:0', dtype=torch.float16) tensor(0.1164, device='cuda:0', dtype=torch.float16)
tensor(13.1875, device='cuda:0', dtype=torch.float16) tensor(0.1320, device='cuda:0', dtype=torch.float16)
tensor(14.1875, device='cuda:0', dtype=torch.float16) tensor(0.1047, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.up_proj
Validation after prune:
out_inf: tensor(42.4688, device='cuda:0', dtype=torch.float16) tensor(0.5596, device='cuda:0', dtype=torch.float16)
tensor(50.1875, device='cuda:0', dtype=torch.float16) tensor(0.3052, device='cuda:0', dtype=torch.float16)
tensor(53.0312, device='cuda:0', dtype=torch.float16) tensor(0.3081, device='cuda:0', dtype=torch.float16)
tensor(56.3125, device='cuda:0', dtype=torch.float16) tensor(0.3201, device='cuda:0', dtype=torch.float16)
tensor(38.8125, device='cuda:0', dtype=torch.float16) tensor(0.3000, device='cuda:0', dtype=torch.float16)
tensor(0.1341, device='cuda:0')
old_score: tensor(0.3083, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1104, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.9216582775116
Validation after dual ascent:
out_inf: tensor(42.4688, device='cuda:0', dtype=torch.float16) tensor(0.5596, device='cuda:0', dtype=torch.float16)
tensor(12.4688, device='cuda:0', dtype=torch.float16) tensor(0.1036, device='cuda:0', dtype=torch.float16)
tensor(11.4375, device='cuda:0', dtype=torch.float16) tensor(0.1113, device='cuda:0', dtype=torch.float16)
tensor(12.5625, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(13.3438, device='cuda:0', dtype=torch.float16) tensor(0.1001, device='cuda:0', dtype=torch.float16)
pruning layer 30 name mlp.down_proj
Validation after prune:
out_inf: tensor(2005., device='cuda:0', dtype=torch.float16) tensor(0.4204, device='cuda:0', dtype=torch.float16)
tensor(3.1172, device='cuda:0', dtype=torch.float16) tensor(0.1536, device='cuda:0', dtype=torch.float16)
tensor(3.0703, device='cuda:0', dtype=torch.float16) tensor(0.1573, device='cuda:0', dtype=torch.float16)
tensor(3.4375, device='cuda:0', dtype=torch.float16) tensor(0.1602, device='cuda:0', dtype=torch.float16)
tensor(2.9648, device='cuda:0', dtype=torch.float16) tensor(0.1538, device='cuda:0', dtype=torch.float16)
tensor(0.1173, device='cuda:0')
old_score: tensor(0.1562, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0714, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 98.24696564674377
Validation after dual ascent:
out_inf: tensor(2005., device='cuda:0', dtype=torch.float16) tensor(0.4204, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0658, device='cuda:0', dtype=torch.float16)
tensor(0.9927, device='cuda:0', dtype=torch.float16) tensor(0.0714, device='cuda:0', dtype=torch.float16)
tensor(1.0410, device='cuda:0', dtype=torch.float16) tensor(0.0844, device='cuda:0', dtype=torch.float16)
tensor(2., device='cuda:0', dtype=torch.float16) tensor(0.0641, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.q_proj
Validation after prune:
out_inf: tensor(13.3984, device='cuda:0', dtype=torch.float16) tensor(0.8887, device='cuda:0', dtype=torch.float16)
tensor(7.8398, device='cuda:0', dtype=torch.float16) tensor(0.4138, device='cuda:0', dtype=torch.float16)
tensor(7.0586, device='cuda:0', dtype=torch.float16) tensor(0.4260, device='cuda:0', dtype=torch.float16)
tensor(7.6953, device='cuda:0', dtype=torch.float16) tensor(0.4453, device='cuda:0', dtype=torch.float16)
tensor(6.8477, device='cuda:0', dtype=torch.float16) tensor(0.4087, device='cuda:0', dtype=torch.float16)
tensor(0.1225, device='cuda:0')
old_score: tensor(0.4233, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1284, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.795870304107666
Validation after dual ascent:
out_inf: tensor(13.3984, device='cuda:0', dtype=torch.float16) tensor(0.8887, device='cuda:0', dtype=torch.float16)
tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(0.1191, device='cuda:0', dtype=torch.float16)
tensor(2.4492, device='cuda:0', dtype=torch.float16) tensor(0.1302, device='cuda:0', dtype=torch.float16)
tensor(1.8594, device='cuda:0', dtype=torch.float16) tensor(0.1497, device='cuda:0', dtype=torch.float16)
tensor(2.2344, device='cuda:0', dtype=torch.float16) tensor(0.1148, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.k_proj
Validation after prune:
out_inf: tensor(16.8906, device='cuda:0', dtype=torch.float16) tensor(1.1436, device='cuda:0', dtype=torch.float16)
tensor(8.7656, device='cuda:0', dtype=torch.float16) tensor(0.4592, device='cuda:0', dtype=torch.float16)
tensor(9.0547, device='cuda:0', dtype=torch.float16) tensor(0.4739, device='cuda:0', dtype=torch.float16)
tensor(9.6875, device='cuda:0', dtype=torch.float16) tensor(0.4856, device='cuda:0', dtype=torch.float16)
tensor(8.0938, device='cuda:0', dtype=torch.float16) tensor(0.4521, device='cuda:0', dtype=torch.float16)
tensor(0.1584, device='cuda:0')
old_score: tensor(0.4678, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1318, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.808876514434814
Validation after dual ascent:
out_inf: tensor(16.8906, device='cuda:0', dtype=torch.float16) tensor(1.1436, device='cuda:0', dtype=torch.float16)
tensor(2.7031, device='cuda:0', dtype=torch.float16) tensor(0.1226, device='cuda:0', dtype=torch.float16)
tensor(3.0430, device='cuda:0', dtype=torch.float16) tensor(0.1337, device='cuda:0', dtype=torch.float16)
tensor(2.5625, device='cuda:0', dtype=torch.float16) tensor(0.1532, device='cuda:0', dtype=torch.float16)
tensor(2.3672, device='cuda:0', dtype=torch.float16) tensor(0.1179, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.v_proj
Validation after prune:
out_inf: tensor(7.5391, device='cuda:0', dtype=torch.float16) tensor(0.4375, device='cuda:0', dtype=torch.float16)
tensor(4.1953, device='cuda:0', dtype=torch.float16) tensor(0.2842, device='cuda:0', dtype=torch.float16)
tensor(2.8320, device='cuda:0', dtype=torch.float16) tensor(0.2878, device='cuda:0', dtype=torch.float16)
tensor(4.0469, device='cuda:0', dtype=torch.float16) tensor(0.2949, device='cuda:0', dtype=torch.float16)
tensor(4.3047, device='cuda:0', dtype=torch.float16) tensor(0.2839, device='cuda:0', dtype=torch.float16)
tensor(0.0406, device='cuda:0')
old_score: tensor(0.2878, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1094, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.84543776512146
Validation after dual ascent:
out_inf: tensor(7.5391, device='cuda:0', dtype=torch.float16) tensor(0.4375, device='cuda:0', dtype=torch.float16)
tensor(1.3672, device='cuda:0', dtype=torch.float16) tensor(0.1019, device='cuda:0', dtype=torch.float16)
tensor(1.3145, device='cuda:0', dtype=torch.float16) tensor(0.1108, device='cuda:0', dtype=torch.float16)
tensor(1.3711, device='cuda:0', dtype=torch.float16) tensor(0.1267, device='cuda:0', dtype=torch.float16)
tensor(1.2617, device='cuda:0', dtype=torch.float16) tensor(0.0983, device='cuda:0', dtype=torch.float16)
pruning layer 31 name self_attn.o_proj
Validation after prune:
out_inf: tensor(257.5000, device='cuda:0', dtype=torch.float16) tensor(0.3794, device='cuda:0', dtype=torch.float16)
tensor(13.1094, device='cuda:0', dtype=torch.float16) tensor(0.2158, device='cuda:0', dtype=torch.float16)
tensor(13.4844, device='cuda:0', dtype=torch.float16) tensor(0.2180, device='cuda:0', dtype=torch.float16)
tensor(10.7500, device='cuda:0', dtype=torch.float16) tensor(0.2135, device='cuda:0', dtype=torch.float16)
tensor(13.2500, device='cuda:0', dtype=torch.float16) tensor(0.2140, device='cuda:0', dtype=torch.float16)
tensor(0.0638, device='cuda:0')
old_score: tensor(0.2153, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0704, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 14.823309421539307
Validation after dual ascent:
out_inf: tensor(257.5000, device='cuda:0', dtype=torch.float16) tensor(0.3794, device='cuda:0', dtype=torch.float16)
tensor(1.9912, device='cuda:0', dtype=torch.float16) tensor(0.0666, device='cuda:0', dtype=torch.float16)
tensor(2.4492, device='cuda:0', dtype=torch.float16) tensor(0.0693, device='cuda:0', dtype=torch.float16)
tensor(1.8906, device='cuda:0', dtype=torch.float16) tensor(0.0812, device='cuda:0', dtype=torch.float16)
tensor(2.2812, device='cuda:0', dtype=torch.float16) tensor(0.0643, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.gate_proj
Validation after prune:
out_inf: tensor(24.3750, device='cuda:0', dtype=torch.float16) tensor(0.6460, device='cuda:0', dtype=torch.float16)
tensor(16.7188, device='cuda:0', dtype=torch.float16) tensor(0.3418, device='cuda:0', dtype=torch.float16)
tensor(18.4688, device='cuda:0', dtype=torch.float16) tensor(0.3591, device='cuda:0', dtype=torch.float16)
tensor(22.8438, device='cuda:0', dtype=torch.float16) tensor(0.3572, device='cuda:0', dtype=torch.float16)
tensor(17.8750, device='cuda:0', dtype=torch.float16) tensor(0.3479, device='cuda:0', dtype=torch.float16)
tensor(0.1758, device='cuda:0')
old_score: tensor(0.3516, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1089, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.879669427871704
Validation after dual ascent:
out_inf: tensor(24.3750, device='cuda:0', dtype=torch.float16) tensor(0.6460, device='cuda:0', dtype=torch.float16)
tensor(2.6172, device='cuda:0', dtype=torch.float16) tensor(0.1006, device='cuda:0', dtype=torch.float16)
tensor(2.8438, device='cuda:0', dtype=torch.float16) tensor(0.1111, device='cuda:0', dtype=torch.float16)
tensor(3.7930, device='cuda:0', dtype=torch.float16) tensor(0.1251, device='cuda:0', dtype=torch.float16)
tensor(3.2031, device='cuda:0', dtype=torch.float16) tensor(0.0986, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.up_proj
Validation after prune:
out_inf: tensor(25.2812, device='cuda:0', dtype=torch.float16) tensor(0.6948, device='cuda:0', dtype=torch.float16)
tensor(24.7500, device='cuda:0', dtype=torch.float16) tensor(0.3506, device='cuda:0', dtype=torch.float16)
tensor(25.4375, device='cuda:0', dtype=torch.float16) tensor(0.3711, device='cuda:0', dtype=torch.float16)
tensor(30.4844, device='cuda:0', dtype=torch.float16) tensor(0.3655, device='cuda:0', dtype=torch.float16)
tensor(25.5312, device='cuda:0', dtype=torch.float16) tensor(0.3508, device='cuda:0', dtype=torch.float16)
tensor(0.1653, device='cuda:0')
old_score: tensor(0.3594, device='cuda:0', dtype=torch.float16) new_score: tensor(0.1039, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 38.836092472076416
Validation after dual ascent:
out_inf: tensor(25.2812, device='cuda:0', dtype=torch.float16) tensor(0.6948, device='cuda:0', dtype=torch.float16)
tensor(3.7891, device='cuda:0', dtype=torch.float16) tensor(0.0961, device='cuda:0', dtype=torch.float16)
tensor(3.5469, device='cuda:0', dtype=torch.float16) tensor(0.1062, device='cuda:0', dtype=torch.float16)
tensor(4.4688, device='cuda:0', dtype=torch.float16) tensor(0.1193, device='cuda:0', dtype=torch.float16)
tensor(3.3594, device='cuda:0', dtype=torch.float16) tensor(0.0941, device='cuda:0', dtype=torch.float16)
pruning layer 31 name mlp.down_proj
Validation after prune:
out_inf: tensor(72.1250, device='cuda:0', dtype=torch.float16) tensor(1.6318, device='cuda:0', dtype=torch.float16)
tensor(6.9062, device='cuda:0', dtype=torch.float16) tensor(0.2651, device='cuda:0', dtype=torch.float16)
tensor(9.2344, device='cuda:0', dtype=torch.float16) tensor(0.2834, device='cuda:0', dtype=torch.float16)
tensor(8.3438, device='cuda:0', dtype=torch.float16) tensor(0.2744, device='cuda:0', dtype=torch.float16)
tensor(5.9375, device='cuda:0', dtype=torch.float16) tensor(0.2722, device='cuda:0', dtype=torch.float16)
tensor(0.8223, device='cuda:0')
old_score: tensor(0.2739, device='cuda:0', dtype=torch.float16) new_score: tensor(0.0887, device='cuda:0', dtype=torch.float16)
Converged!
Dual ascent finished!
Time: 97.88749384880066
Validation after dual ascent:
out_inf: tensor(72.1250, device='cuda:0', dtype=torch.float16) tensor(1.6318, device='cuda:0', dtype=torch.float16)
tensor(2.2188, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
tensor(1.6562, device='cuda:0', dtype=torch.float16) tensor(0.0894, device='cuda:0', dtype=torch.float16)
tensor(2.1250, device='cuda:0', dtype=torch.float16) tensor(0.1068, device='cuda:0', dtype=torch.float16)
tensor(2.1289, device='cuda:0', dtype=torch.float16) tensor(0.0793, device='cuda:0', dtype=torch.float16)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.23it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.10it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.94it/s]
{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25': 0, 'model.layers.26': 0, 'model.layers.27': 0, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
use device  1
******************************
layer 0 sparsity 0.899920
layer 1 sparsity 0.899920
layer 2 sparsity 0.899920
layer 3 sparsity 0.899920
layer 4 sparsity 0.899920
layer 5 sparsity 0.899920
layer 6 sparsity 0.899920
layer 7 sparsity 0.899920
layer 8 sparsity 0.899920
layer 9 sparsity 0.899920
layer 10 sparsity 0.899920
layer 11 sparsity 0.899920
layer 12 sparsity 0.899920
layer 13 sparsity 0.899920
layer 14 sparsity 0.899920
layer 15 sparsity 0.899920
layer 16 sparsity 0.899920
layer 17 sparsity 0.899920
layer 18 sparsity 0.899920
layer 19 sparsity 0.899920
layer 20 sparsity 0.899920
layer 21 sparsity 0.899920
layer 22 sparsity 0.899920
layer 23 sparsity 0.899920
layer 24 sparsity 0.899920
layer 25 sparsity 0.899920
layer 26 sparsity 0.899920
layer 27 sparsity 0.899920
layer 28 sparsity 0.899920
layer 29 sparsity 0.899920
layer 30 sparsity 0.899920
layer 31 sparsity 0.899920
sparsity sanity check 0.8999
******************************
evaluating on wikitext2
nsamples 83
sample 0
sample 50
wikitext perplexity 690.9219360351562
wanda_dual_3	0.8999	690.9219	256
Namespace(model='/h3cstore_ns/jcxie/hf_weights/llama-2-7b-hf', seed=0, nsamples=256, dual_theld=0.03, n_batch=8, sparsity_ratio=0.9, epsilon=0.02, n_flod=1, sparsity_type='unstructured', prune_method='wanda_dual_3', cache_dir='llm_weights', use_variant=False, save='/h3cstore_ns/jcxie/LISA/nips2024/log', save_model=None, exclude='gate_proj', ww_metric='alpha_peak', ww_metric_cache='/h3cstore_ns/jcxie/LISA/wanda-main/data/llama2-7b-hf', wanda_scale=0.01, ww_epsilon=0.02, mapping_type='block_wise', dual_sp_theld=0.0, Hyper_m=3, Lamda=0.2, eval_zero_shot=0, save_ckpt=0)
